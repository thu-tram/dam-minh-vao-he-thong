
-   -   [11. Storage and the Memory
        Hierarchy](../C11-MemHierarchy/index.html){.nav-link}
        -   [11.1. The Memory
            Hierarchy](../C11-MemHierarchy/mem_hierarchy.html){.nav-link}
        -   [11.2. Storage
            Devices](../C11-MemHierarchy/devices.html){.nav-link}
        -   [11.3.
            Locality](../C11-MemHierarchy/locality.html){.nav-link}
        -   [11.4. Caching](../C11-MemHierarchy/caching.html){.nav-link}
        -   [11.5. Cache Analysis and
            Cachegrind](../C11-MemHierarchy/cachegrind.html){.nav-link}
        -   [11.6. Looking Ahead: Caching on Multicore
            Processors](../C11-MemHierarchy/coherency.html){.nav-link}
        -   [11.7. Summary](../C11-MemHierarchy/summary.html){.nav-link}
        -   [11.8.
            Exercises](../C11-MemHierarchy/exercises.html){.nav-link}

-   -   [12. Code Optimization](../C12-CodeOpt/index.html){.nav-link}
        -   [12.1. First Steps](../C12-CodeOpt/basic.html){.nav-link}
        -   [12.2. Other Compiler
            Optimizations](../C12-CodeOpt/loops_functions.html){.nav-link}
        -   [12.3. Memory
            Considerations](../C12-CodeOpt/memory_considerations.html){.nav-link}
        -   [12.4. Summary](../C12-CodeOpt/summary.html){.nav-link}

-   -   [13. The Operating System](../C13-OS/index.html){.nav-link}
        -   [13.1. Booting and Running](../C13-OS/impl.html){.nav-link}
        -   [13.2. Processes](../C13-OS/processes.html){.nav-link}
        -   [13.3. Virtual Memory](../C13-OS/vm.html){.nav-link}
        -   [13.4. Interprocess
            Communication](../C13-OS/ipc.html){.nav-link}
            -   [13.4.1. Signals](../C13-OS/ipc_signals.html){.nav-link}
            -   [13.4.2. Message
                Passing](../C13-OS/ipc_msging.html){.nav-link}
            -   [13.4.3. Shared
                Memory](../C13-OS/ipc_shm.html){.nav-link}
        -   [13.5. Summary and Other OS
            Functionality](../C13-OS/advanced.html){.nav-link}
        -   [13.6. Exercises](../C13-OS/exercises.html){.nav-link}

-   -   [14. Leveraging Shared Memory in the Multicore
        Era](index.html){.nav-link}
        -   [14.1. Programming Multicore
            Systems](multicore.html){.nav-link}
        -   [14.2. POSIX Threads](posix.html){.nav-link}
        -   [14.3. Synchronizing
            Threads](synchronization.html){.nav-link}
            -   [14.3.1. Mutual Exclusion](mutex.html){.nav-link}
            -   [14.3.2. Semaphores](semaphores.html){.nav-link}
            -   [14.3.3. Other Synchronization
                Constructs](other_syncs.html){.nav-link}
        -   [14.4. Measuring Parallel
            Performance](performance.html){.nav-link}
            -   [14.4.1. Parallel Performance
                Basics](performance_basics.html){.nav-link}
            -   [14.4.2. Advanced
                Topics](performance_advanced.html){.nav-link}
        -   [14.5. Cache Coherence](cache_coherence.html){.nav-link}
        -   [14.6. Thread Safety](thread_safety.html){.nav-link}
        -   [14.7. Implicit Threading with
            OpenMP](openmp.html){.nav-link}
        -   [14.8. Summary](summary.html){.nav-link}
        -   [14.9. Exercises](exercises.html){.nav-link}

-   -   [15. Looking Ahead: Other Parallel
        Systems](../C15-Parallel/index.html){.nav-link}
        -   [15.1. Hardware Acceleration and
            CUDA](../C15-Parallel/gpu.html){.nav-link}
        -   [15.2. Distributed Memory
            Systems](../C15-Parallel/distrmem.html){.nav-link}
        -   [15.3. To Exascale and
            Beyond](../C15-Parallel/cloud.html){.nav-link}

-   -   [16. Appendix 1: Chapter 1 for Java
        Programmers](../Appendix1/index.html){.nav-link}
        -   [16.1. Getting Started Programming in
            C](../Appendix1/getting_started.html){.nav-link}
        -   [16.2. Input/Output (printf and
            scanf)](../Appendix1/input_output.html){.nav-link}
        -   [16.3. Conditionals and
            Loops](../Appendix1/conditionals.html){.nav-link}
        -   [16.4. Functions](../Appendix1/functions.html){.nav-link}
        -   [16.5. Arrays and
            Strings](../Appendix1/arrays_strings.html){.nav-link}
        -   [16.6. Structs](../Appendix1/structs.html){.nav-link}
        -   [16.7. Summary](../Appendix1/summary.html){.nav-link}
        -   [16.8. Exercises](../Appendix1/exercises.html){.nav-link}

-   -   [17. Appendix 2: Using Unix](../Appendix2/index.html){.nav-link}
        -   [17.1. Unix Command Line and the Unix File
            System](../Appendix2/cmdln_basics.html){.nav-link}
        -   [17.2. Man and the Unix
            Manual](../Appendix2/man.html){.nav-link}
        -   [17.3. Remote Access](../Appendix2/ssh_scp.html){.nav-link}
        -   [17.4. Unix Editors](../Appendix2/editors.html){.nav-link}
        -   [17.5. make and
            Makefiles](../Appendix2/makefiles.html){.nav-link}
        -   [17.6 Searching: grep and
            find](../Appendix2/grep.html){.nav-link}
        -   [17.7 File Permissions](../Appendix2/chmod.html){.nav-link}
        -   [17.8 Archiving and Compressing
            Files](../Appendix2/tar.html){.nav-link}
        -   [17.9 Process Control](../Appendix2/pskill.html){.nav-link}
        -   [17.10 Timing](../Appendix2/timing.html){.nav-link}
        -   [17.11 Command
            History](../Appendix2/history.html){.nav-link}
        -   [17.12 I/0
            Redirection](../Appendix2/ioredirect.html){.nav-link}
        -   [17.13 Pipes](../Appendix2/pipe.html){.nav-link}
        -   [17.14 Dot Files and
            .bashrc](../Appendix2/dotfiles.html){.nav-link}
        -   [17.15 Shell
            Programming](../Appendix2/shellprog.html){.nav-link}
        -   [17.16 Getting System
            Information](../Appendix2/sysinfo.html){.nav-link}



-   [Dive Into Systems](../index-2.html)
-   [14. Leveraging Shared Memory in the Multicore Era](index.html)
-   [14.2. POSIX Threads](posix.html)
:::

::: content
::: sect1
## [](#_hello_threading_writing_your_first_multithreaded_program){.anchor}14.2. Hello Threading! Writing Your First Multithreaded Program {#_hello_threading_writing_your_first_multithreaded_program}

::: sectionbody
::: paragraph
In this section, we examine the ubiquitous POSIX thread library
**Pthreads**. POSIX is an acronym for Portable Operating System
Interface. It is an IEEE standard that specifies how UNIX systems look,
act, and feel. The POSIX threads API is available on almost all
UNIX-like operating systems, each of which meets the standard in its
entirety or to some great degree. So, if you write parallel code using
POSIX threads on a Linux machine, it will certainly work on other Linux
machines, and it will likely work on machines running macOS or other
UNIX variants.
:::

::: paragraph
Let's begin by analyzing an example \"Hello World\" Pthreads program
([hellothreads.c](_attachments/hellothreads.c)). For brevity, we have
excluded error handling in the listing, though the [downloadable
version](_attachments/hellothreads.c) contains sample error handling.
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>

/* The "thread function" passed to pthread_create.  Each thread executes this
 * function and terminates when it returns from this function. */
void *HelloWorld(void *id) {

    /* We know the argument is a pointer to a long, so we cast it from a
     * generic (void *) to a (long *). */
    long *myid = (long *) id;

    printf("Hello world! I am thread %ld\n", *myid);

    return NULL; // We don't need our threads to return anything.
}

int main(int argc, char **argv) {
    int i;
    int nthreads; //number of threads
    pthread_t *thread_array; //pointer to future thread array
    long *thread_ids;

    // Read the number of threads to create from the command line.
    if (argc !=2) {
        fprintf(stderr, "usage: %s <n>\n", argv[0]);
        fprintf(stderr, "where <n> is the number of threads\n");
        return 1;
    }
    nthreads = strtol(argv[1], NULL, 10);

    // Allocate space for thread structs and identifiers.
    thread_array = malloc(nthreads * sizeof(pthread_t));
    thread_ids = malloc(nthreads * sizeof(long));

    // Assign each thread an ID and create all the threads.
    for (i = 0; i < nthreads; i++) {
        thread_ids[i] = i;
        pthread_create(&thread_array[i], NULL, HelloWorld, &thread_ids[i]);
    }

    /* Join all the threads. Main will pause in this loop until all threads
     * have returned from the thread function. */
    for (i = 0; i < nthreads; i++) {
        pthread_join(thread_array[i], NULL);
    }

    free(thread_array);
    free(thread_ids);

    return 0;
}
```
:::
:::

::: paragraph
Let's examine this program in smaller components.
:::

::: ulist
-   Notice the inclusion of the `pthread.h` header file, which declares
    `pthread` types and functions.

-   Next, the `HelloWorld` function defines the **thread function** that
    we later pass to `pthread_create`. A thread function is analogous to
    a `main` function for a worker (created) thread --- a thread begins
    execution at the start of its thread function and terminates when it
    reaches the end. Each thread executes the thread function using its
    private execution state (i.e., its own stack memory and register
    values). Note also that the thread function is of type `void*`.
    Specifying an [**anonymous
    pointer**](../C2-C_depth/advanced_voidstar.html#_c_voidstar_recasting_){.page}
    in this context allows programmers to write thread functions that
    deal with arguments and return values of different types.

-   Lastly, in the `main` function, the main thread initializes the
    program state before creating and joining the worker threads.
:::

::: sect2
### [](#_creating_and_joining_threads){.anchor}14.2.1. Creating and Joining Threads {#_creating_and_joining_threads}

::: paragraph
The program first starts as a single-threaded process. As it executes
the `main` function, it reads the number of threads to create, and it
allocates memory for two arrays: `thread_array` and `thread_ids`. The
`thread_array` array contains the set of addresses for each thread
created. The `thread_ids` array stores the set of arguments that each
thread is passed. In this example, each thread is passed the address of
its rank (or ID, represented by `thread_ids[i]`).
:::

::: paragraph
After all the preliminary variables are allocated and initialized, the
`main` thread executes the two major steps of multithreading:
:::

::: ulist
-   The **creation** step, in which the main thread spawns one or more
    worker threads. After being spawned, each worker thread runs within
    its own execution context concurrently with the other threads and
    processes on the system.

-   The **join** step, in which the main thread waits for all the
    workers to complete before proceeding as a single-thread process.
    Joining a thread that has terminated frees the thread's execution
    context and resources. Attempting to join a thread that *hasn't*
    terminated blocks the caller until the thread terminates, similar to
    the semantics of the [wait function for
    processes](../C13-OS/processes.html#_exit_and_wait){.page}.
:::

::: paragraph
The Pthreads library offers a `pthread_create` function for creating
threads and a `pthread_join` function for joining them. The
`pthread_create` function has the following signature:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
pthread_create(pthread_t *thread, const pthread_attr_t *attr,
               void *thread_function, void *thread_args)
```
:::
:::

::: paragraph
The function takes a pointer to a thread struct (of type `pthread_t`), a
pointer to an attribute struct (normally set to `NULL`), the name of the
function the thread should execute, and the array of arguments to pass
to the thread function when it starts.
:::

::: paragraph
The Hello World program calls `pthread_create` in the `main` function
using:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
pthread_create(&thread_array[i], NULL, HelloWorld, &thread_ids[i]);
```
:::
:::

::: paragraph
Here:
:::

::: ulist
-   `&thread_array[i]` contains the address of thread *i*. The
    `pthread_create` function allocates a `pthread_t` thread object and
    stores its address at this location, enabling the programmer to
    reference the thread later (e.g., when joining it).

-   `NULL` specifies that the thread should be created with default
    attributes. In most programs, it is safe to leave this second
    parameter as `NULL`.

-   `HelloWorld` names the thread function that the created thread
    should execute. This function behaves like the \"main\" function for
    the thread. For an arbitrary thread function (e.g., `function`), its
    prototype must match the form `void * function(void *)`.

-   `&thread_ids[i]` specifies the address of the arguments to be passed
    to thread *i*. In this case, `thread_ids[i]` contains a single
    `long` representing the thread's ID. Since the last argument to
    `pthread_create` must be a pointer, we pass the *address* of the
    thread's ID.
:::

::: paragraph
To generate several threads that execute the `HelloWorld` thread
function, the program assigns each thread a unique ID and creates each
thread within a `for` loop:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
for (i = 0; i < nthreads; i++) {
    thread_ids[i] = i;
    pthread_create(&thread_array[i], NULL, HelloWorld, &thread_ids[i]);
}
```
:::
:::

::: paragraph
The OS schedules the execution of each created thread; the user cannot
make any assumption on the order in which the threads will execute.
:::

::: paragraph
The `pthread_join` function suspends the execution of its caller until
the thread it references terminates. Its signature is:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
pthread_join(pthread_t thread, void **return_val)
```
:::
:::

::: paragraph
The `pthread_join` takes as input a `pthread_t` struct, indicating which
thread to wait on, and an optional pointer argument that specifies where
the thread's return value should be stored.
:::

::: paragraph
The Hello World program calls `pthread_join` in `main` using:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
pthread_join(thread_array[t], NULL);
```
:::
:::

::: paragraph
This line indicates that the main thread must wait on the termination of
thread `t`. Passing `NULL` as the second argument indicates that the
program does not use the thread's return value.
:::

::: paragraph
In the previous program, `main` calls `pthread_join` in a loop because
*all* of the worker threads need to terminate before the `main` function
proceeds to clean up memory and terminate the process:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
for (i = 0; i < nthreads; i++) {
    pthread_join(thread_array[i], NULL);
}
```
:::
:::
:::

::: sect2
### [](#_the_thread_function){.anchor}14.2.2. The Thread Function {#_the_thread_function}

::: paragraph
In the previous program, each spawned thread prints out
`Hello world! I am thread n`, where `n` is the thread's unique id. After
the thread prints out its message, it terminates. Let's take a closer
look at the `HelloWorld` function:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
void *HelloWorld(void *id) {
    long *myid = (long*)id;

    printf("Hello world! I am thread %ld\n", *myid);

    return NULL;
}
```
:::
:::

::: paragraph
Recall that `pthread_create` passes the arguments to the thread function
using the `thread_args` parameter. In the `pthread_create` function in
`main`, the Hello World program specified that this parameter is in fact
the thread's ID. Note that the parameter to `HelloWorld` must be
declared as a generic or [anonymous pointer
(`void *`)](../C2-C_depth/advanced_voidstar.html#_c_voidstar_recasting_){.page}.
The Pthreads library uses `void *` to make `pthread_create` more general
purpose by not prescribing a parameter type. As a programmer, the
`void *` is mildly inconvenient given that it must be recast before use.
Here, we *know* the parameter is of type `long *` because that's what we
passed to `pthread_create` in `main`. Thus, we can safely cast the value
as a `long *` and dereference the pointer to access the `long` value.
Many parallel programs follow this structure.
:::

::: paragraph
Similar to the thread function's parameter, the Pthreads library avoids
prescribing the thread function's return type by specifying another
`void *` --- the programmer is free to return any pointer from the
thread function. If the program needs to access the thread's return
value, it can retrieve it via the second argument to `pthread_join`. In
our example, the thread has no need to return a value, so it simply
returns a `NULL` pointer.
:::
:::

::: sect2
### [](#_running_the_code){.anchor}14.2.3. Running the Code {#_running_the_code}

::: paragraph
The command that follows shows how to use GCC to compile
[hellothreads.c](_attachments/hellothreads.c). Building a Pthreads
application requires that the `-pthread` linker flag be passed to GCC to
ensure that the Pthreads functions and types are accessible:
:::

::: listingblock
::: content
    $ gcc -o hellothreads hellothreads.c -pthread
:::
:::

::: paragraph
Running the program without a command line argument results in a usage
message:
:::

::: listingblock
::: content
    $ ./hellothreads
    usage: ./hellothreads <n>
    where <n> is the number of threads
:::
:::

::: paragraph
Running the program with four threads yields the following output:
:::

::: listingblock
::: content
    $ ./hellothreads 4
    Hello world! I am thread 1
    Hello world! I am thread 2
    Hello world! I am thread 3
    Hello world! I am thread 0
:::
:::

::: paragraph
Notice that each thread prints its unique ID number. In this run, thread
1's output displays first, followed by threads 2, 3, and 0. If we run
the program again, we may see the output displayed in a different order:
:::

::: listingblock
::: content
    $ ./hellothreads 4
    Hello world! I am thread 0
    Hello world! I am thread 1
    Hello world! I am thread 2
    Hello world! I am thread 3
:::
:::

::: paragraph
Recall that the operating system's scheduler determines the thread
execution order. From a user's perspective, the order is *effectively
random* due to being influenced by many factors that vary outside the
user's control (e.g., available system resources, the system receiving
input, or OS scheduling). Since all threads are running concurrently
with one another and each thread executes a call to `printf` (which
prints to `stdout`), the first thread that prints to `stdout` will have
its output show up first. Subsequent executions may (or may not) result
in different output.
:::

::: {.admonitionblock .warning}
+-----------------------------------+-----------------------------------+
|                                   | ::: title                         |
|                                   | Thread Execution Order            |
|                                   | :::                               |
|                                   |                                   |
|                                   | ::: paragraph                     |
|                                   | You should *never* make any       |
|                                   | assumptions about the order in    |
|                                   | which threads will execute. If    |
|                                   | the correctness of your program   |
|                                   | requires that threads run in a    |
|                                   | particular order, you must add    |
|                                   | [**sync                           |
|                                   | hronization**](synchronization.ht |
|                                   | ml#_synchronizing_threads){.page} |
|                                   | to your program to prevent        |
|                                   | threads from running when they    |
|                                   | shouldn't.                        |
|                                   | :::                               |
+-----------------------------------+-----------------------------------+
:::
:::

::: sect2
### [](#_revisiting_scalar_multiplication){.anchor}14.2.4. Revisiting Scalar Multiplication {#_revisiting_scalar_multiplication}

::: paragraph
Let's explore how to create a multithreaded implementation of the
[scalar
multiplication](multicore.html#_an_example_scalar_multiplication){.page}
program from the previous section. Recall that our general strategy for
parallelizing `scalar_multiply` is to:
:::

::: {.olist .arabic}
1.  Create multiple threads,

2.  Assign each thread a subset of the input array,

3.  Instruct each thread to multiply the elements in its array subset by
    `s`.
:::

::: paragraph
The following is a thread function that accomplishes this task. Notice
that we have moved `array`, `length`, and `s` to the global scope of the
program.
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
long *array; //allocated in main
long length; //set in main (1 billion)
long nthreads; //number of threads
long s; //scalar

void *scalar_multiply(void *id) {
    long *myid = (long *) id;
    int i;

    //assign each thread its own chunk of elements to process
    long chunk = length / nthreads;
    long start = *myid * chunk;
    long end  = start + chunk;
    if (*myid == nthreads - 1) {
        end = length;
    }

    //perform scalar multiplication on assigned chunk
    for (i = start; i < end; i++) {
        array[i] *= s;
    }

    return NULL;
}
```
:::
:::

::: paragraph
Let's break this down into parts. Recall that the first step is to
assign each thread a component of the array. The following lines
accomplish this task:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
long chunk = length / nthreads;
long start = *myid * chunk;
long end  = start + chunk;
```
:::
:::

::: paragraph
The variable `chunk` stores the number of elements that each thread is
assigned. To ensure that each thread gets roughly the same amount of
work, we first set the chunk size to the number of elements divided by
the number of threads, or `length / nthreads`.
:::

::: paragraph
Next, we assign each thread a distinct range of elements to process.
Each thread computes its range's `start` and `end` index using the
`chunk` size and its unique thread ID.
:::

::: paragraph
For example, with four threads (with IDs 0-3) operating over an array
with 100 million elements, each thread is responsible for processing a
25 million element `chunk`. Incorporating the thread ID assigns each
thread a unique subset of the input.
:::

::: paragraph
The next two lines account for the case in which `length` is not evenly
divisible by the number of threads:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
if (*myid == nthreads - 1) {
    end = length;
}
```
:::
:::

::: paragraph
Suppose that we specified three rather than four threads. The nominal
chunk size would be 33,333,333 elements, leaving one element unaccounted
for. The code in the previous example would assign the remaining element
to the last thread.
:::

::: {.admonitionblock .note}
+-----------------------------------+-----------------------------------+
|                                   | ::: title                         |
|                                   | Creating balanced input           |
|                                   | :::                               |
|                                   |                                   |
|                                   | ::: paragraph                     |
|                                   | The chunking code just shown is   |
|                                   | imperfect. In the case where the  |
|                                   | number of threads does not evenly |
|                                   | divide the input, the remainder   |
|                                   | is assigned to the last thread.   |
|                                   | Consider a sample run in which    |
|                                   | the array has 100 elements, and   |
|                                   | 12 threads are specified. The     |
|                                   | nominal chunk size would be 8,    |
|                                   | and the remainder would be 4.     |
|                                   | With the example code, the first  |
|                                   | 11 threads will each have 8       |
|                                   | assigned elements, whereas the    |
|                                   | last thread will be assigned 12   |
|                                   | elements. Consequently, the last  |
|                                   | thread performs 50% more work     |
|                                   | than the other threads. A         |
|                                   | potentially better way to chunk   |
|                                   | this example is to have the first |
|                                   | 4 threads process 9 elements      |
|                                   | each, while the last 8 threads    |
|                                   | process 8 elements each. This     |
|                                   | will result in better **load      |
|                                   | balancing** of the input across   |
|                                   | the threads.                      |
|                                   | :::                               |
+-----------------------------------+-----------------------------------+
:::

::: paragraph
With an appropriate local `start` and `end` index computed, each thread
is now ready to perform scalar multiplication on its component of the
array. The last portion of the `scalar_multiply` function accomplishes
this:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
for (i = start; i < end; i++) {
    array[i] *= s;
}
```
:::
:::
:::

::: sect2
### [](#_improving_scalar_multiplication_multiple_arguments){.anchor}14.2.5. Improving Scalar Multiplication: Multiple Arguments {#_improving_scalar_multiplication_multiple_arguments}

::: paragraph
A key weakness of the previous implementation is the wide use of global
variables. Our original discussion of [global
variables](../C2-C_depth/scope_memory.html#_parts_of_program_memory_and_scope){.page}
showed that although useful, global variables should generally be
avoided in C. To reduce the number of global variables in the program,
one solution is to declare a `t_arg` struct as follows in the global
scope:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
struct t_arg {
    int *array; // pointer to shared array
    long length; // num elements in array
    long s; //scaling factor
    long numthreads; // total number of threads
    long id; //  logical thread id
};
```
:::
:::

::: paragraph
Our main function would, in addition to allocating `array` and setting
local variables `length`, `nthreads`, and `s` (our scaling factor),
allocate an array of `t_arg` records:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
long nthreads = strtol(argv[1], NULL, 10); //get number of threads
long length = strtol(argv[2], NULL, 10); //get length of array
long s = strtol( argv[3], NULL, 10 ); //get scaling factor

int *array = malloc(length*sizeof(int));

//allocate space for thread structs and identifiers
pthread_t *thread_array = malloc(nthreads * sizeof(pthread_t));
struct t_arg *thread_args = malloc(nthreads * sizeof(struct t_arg));

//Populate thread arguments for all the threads
for (i = 0; i < nthreads; i++){
    thread_args[i].array = array;
    thread_args[i].length = length;
    thread_args[i].s = s;
    thread_args[i].numthreads = nthreads;
    thread_args[i].id = i;
}
```
:::
:::

::: paragraph
Later in `main`, when `pthread_create` is called, the thread's
associated `t_args` struct is passed as an argument:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
for (i = 0; i < nthreads; i++){
    pthread_create(&thread_array[i], NULL, scalar_multiply, &thread_args[i]);
}
```
:::
:::

::: paragraph
Lastly, our `scalar_multiply` function would look like the following:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
void * scalar_multiply(void* args) {
    //cast to a struct t_arg from void*
    struct t_arg * myargs = (struct t_arg *) args;

    //extract all variables from struct
    long myid =  myargs->id;
    long length = myargs->length;
    long s = myargs->s;
    long nthreads = myargs->numthreads;
    int * ap = myargs->array; //pointer to array in main

    //code as before
    long chunk = length/nthreads;
    long start = myid * chunk;
    long end  = start + chunk;
    if (myid == nthreads-1) {
        end = length;
    }

    int i;
    for (i = start; i < end; i++) {
        ap[i] *= s;
    }

    return NULL;
}
```
:::
:::

::: paragraph
Implementing this program fully is an exercise we leave to the reader.
Please note that error handling has been omitted for the sake of
brevity.
:::
:::
:::
:::

::: toc-menu
:::
:::
:::
:::

Copyright (C) 2020 Dive into Systems, LLC.

*Dive into Systems,* is licensed under the Creative Commons
[Attribution-NonCommercial-NoDerivatives 4.0
International](https://creativecommons.org/licenses/by-nc-nd/4.0/) (CC
BY-NC-ND 4.0).
