
-   -   [11. Storage and the Memory
        Hierarchy](../C11-MemHierarchy/index.html){.nav-link}
        -   [11.1. The Memory
            Hierarchy](../C11-MemHierarchy/mem_hierarchy.html){.nav-link}
        -   [11.2. Storage
            Devices](../C11-MemHierarchy/devices.html){.nav-link}
        -   [11.3.
            Locality](../C11-MemHierarchy/locality.html){.nav-link}
        -   [11.4. Caching](../C11-MemHierarchy/caching.html){.nav-link}
        -   [11.5. Cache Analysis and
            Cachegrind](../C11-MemHierarchy/cachegrind.html){.nav-link}
        -   [11.6. Looking Ahead: Caching on Multicore
            Processors](../C11-MemHierarchy/coherency.html){.nav-link}
        -   [11.7. Summary](../C11-MemHierarchy/summary.html){.nav-link}
        -   [11.8.
            Exercises](../C11-MemHierarchy/exercises.html){.nav-link}

-   -   [12. Code Optimization](../C12-CodeOpt/index.html){.nav-link}
        -   [12.1. First Steps](../C12-CodeOpt/basic.html){.nav-link}
        -   [12.2. Other Compiler
            Optimizations](../C12-CodeOpt/loops_functions.html){.nav-link}
        -   [12.3. Memory
            Considerations](../C12-CodeOpt/memory_considerations.html){.nav-link}
        -   [12.4. Summary](../C12-CodeOpt/summary.html){.nav-link}

-   -   [13. The Operating System](../C13-OS/index.html){.nav-link}
        -   [13.1. Booting and Running](../C13-OS/impl.html){.nav-link}
        -   [13.2. Processes](../C13-OS/processes.html){.nav-link}
        -   [13.3. Virtual Memory](../C13-OS/vm.html){.nav-link}
        -   [13.4. Interprocess
            Communication](../C13-OS/ipc.html){.nav-link}
            -   [13.4.1. Signals](../C13-OS/ipc_signals.html){.nav-link}
            -   [13.4.2. Message
                Passing](../C13-OS/ipc_msging.html){.nav-link}
            -   [13.4.3. Shared
                Memory](../C13-OS/ipc_shm.html){.nav-link}
        -   [13.5. Summary and Other OS
            Functionality](../C13-OS/advanced.html){.nav-link}
        -   [13.6. Exercises](../C13-OS/exercises.html){.nav-link}

-   -   [14. Leveraging Shared Memory in the Multicore
        Era](index.html){.nav-link}
        -   [14.1. Programming Multicore
            Systems](multicore.html){.nav-link}
        -   [14.2. POSIX Threads](posix.html){.nav-link}
        -   [14.3. Synchronizing
            Threads](synchronization.html){.nav-link}
            -   [14.3.1. Mutual Exclusion](mutex.html){.nav-link}
            -   [14.3.2. Semaphores](semaphores.html){.nav-link}
            -   [14.3.3. Other Synchronization
                Constructs](other_syncs.html){.nav-link}
        -   [14.4. Measuring Parallel
            Performance](performance.html){.nav-link}
            -   [14.4.1. Parallel Performance
                Basics](performance_basics.html){.nav-link}
            -   [14.4.2. Advanced
                Topics](performance_advanced.html){.nav-link}
        -   [14.5. Cache Coherence](cache_coherence.html){.nav-link}
        -   [14.6. Thread Safety](thread_safety.html){.nav-link}
        -   [14.7. Implicit Threading with
            OpenMP](openmp.html){.nav-link}
        -   [14.8. Summary](summary.html){.nav-link}
        -   [14.9. Exercises](exercises.html){.nav-link}

-   -   [15. Looking Ahead: Other Parallel
        Systems](../C15-Parallel/index.html){.nav-link}
        -   [15.1. Hardware Acceleration and
            CUDA](../C15-Parallel/gpu.html){.nav-link}
        -   [15.2. Distributed Memory
            Systems](../C15-Parallel/distrmem.html){.nav-link}
        -   [15.3. To Exascale and
            Beyond](../C15-Parallel/cloud.html){.nav-link}

-   -   [16. Appendix 1: Chapter 1 for Java
        Programmers](../Appendix1/index.html){.nav-link}
        -   [16.1. Getting Started Programming in
            C](../Appendix1/getting_started.html){.nav-link}
        -   [16.2. Input/Output (printf and
            scanf)](../Appendix1/input_output.html){.nav-link}
        -   [16.3. Conditionals and
            Loops](../Appendix1/conditionals.html){.nav-link}
        -   [16.4. Functions](../Appendix1/functions.html){.nav-link}
        -   [16.5. Arrays and
            Strings](../Appendix1/arrays_strings.html){.nav-link}
        -   [16.6. Structs](../Appendix1/structs.html){.nav-link}
        -   [16.7. Summary](../Appendix1/summary.html){.nav-link}
        -   [16.8. Exercises](../Appendix1/exercises.html){.nav-link}

-   -   [17. Appendix 2: Using Unix](../Appendix2/index.html){.nav-link}
        -   [17.1. Unix Command Line and the Unix File
            System](../Appendix2/cmdln_basics.html){.nav-link}
        -   [17.2. Man and the Unix
            Manual](../Appendix2/man.html){.nav-link}
        -   [17.3. Remote Access](../Appendix2/ssh_scp.html){.nav-link}
        -   [17.4. Unix Editors](../Appendix2/editors.html){.nav-link}
        -   [17.5. make and
            Makefiles](../Appendix2/makefiles.html){.nav-link}
        -   [17.6 Searching: grep and
            find](../Appendix2/grep.html){.nav-link}
        -   [17.7 File Permissions](../Appendix2/chmod.html){.nav-link}
        -   [17.8 Archiving and Compressing
            Files](../Appendix2/tar.html){.nav-link}
        -   [17.9 Process Control](../Appendix2/pskill.html){.nav-link}
        -   [17.10 Timing](../Appendix2/timing.html){.nav-link}
        -   [17.11 Command
            History](../Appendix2/history.html){.nav-link}
        -   [17.12 I/0
            Redirection](../Appendix2/ioredirect.html){.nav-link}
        -   [17.13 Pipes](../Appendix2/pipe.html){.nav-link}
        -   [17.14 Dot Files and
            .bashrc](../Appendix2/dotfiles.html){.nav-link}
        -   [17.15 Shell
            Programming](../Appendix2/shellprog.html){.nav-link}
        -   [17.16 Getting System
            Information](../Appendix2/sysinfo.html){.nav-link}



-   [Dive Into Systems](../index-2.html)
-   [14. Leveraging Shared Memory in the Multicore Era](index.html)
-   [14.3. Synchronizing Threads](synchronization.html)
-   [14.3.2. Semaphores](semaphores.html)
:::

::: content
::: sect2
### [](#_semaphores){.anchor}14.3.2. Semaphores {#_semaphores}

::: paragraph
Semaphores are commonly used in operating systems and concurrent
programs where the goal is to manage concurrent access to a pool of
resources. When using a semaphore, the goal isn't *who* owns what, but
*how many* resources are still available. Semaphores are different from
mutexes in several ways:
:::

::: ulist
-   Semaphores need not be in a binary (locked or unlocked) state. A
    special type of semaphore called a *counting semaphore* can range in
    value from 0 to some *r*, where *r* is the number of possible
    resources. Any time a resource is produced, the semaphore is
    incremented. Any time a resource is being used, the semaphore is
    decremented. When a counting semaphore has a value of 0, it means
    that no resources are available, and any other threads that attempt
    to acquire a resource must wait (e.g., block).

-   Semaphores can be locked by default.
:::

::: paragraph
While a mutex and condition variables can simulate the functionality of
a semaphore, using a semaphore may be simpler and more efficient in some
cases. Semaphores also have the advantage that *any* thread can unlock
the semaphore (in contrast to a mutex, where the calling thread must
unlock it).
:::

::: paragraph
Semaphores are not part of the Pthreads library, but that does not mean
that you cannot use them. On Linux and macOS systems, semaphore
primitives can be accessed from `semaphore.h`, typically located in
`/usr/include`. Since there is no standard, the function calls may
differ on different systems. That said, the semaphore library has
similar declarations to those of mutexes:
:::

::: ulist
-   Declare a semaphore (type `sem_t`, e.g., `sem_t semaphore`).

-   Initialize a semaphore using `sem_init` (usually in `main`). The
    `sem_init` function has three parameters: the first is the address
    of a semaphore, the second is its initial state (locked or
    unlocked), and the third parameter indicates whether the semaphore
    should be shared with the threads of a process (e.g., with value 0)
    or between processes (e.g., with value 1). This is useful because
    semaphores are commonly used for process synchronization. For
    example, initializing a semaphore with the call
    `sem_init(&semaphore, 1, 0)` indicates that our semaphore is
    initially locked (the second parameter is 1), and is to be shared
    among the threads of a common process (the third parameter is 0). In
    contrast, mutexes always start out unlocked. It is important to note
    that in macOS, the equivalent function is `sem_open`.

-   Destroy a semaphore using `sem_destroy` (usually in `main`). This
    function only takes a pointer to the semaphore
    (`sem_destroy(&semaphore)`). Note that in macOS, the equivalent
    function may be `sem_unlink` or `sem_close`.

-   The `sem_wait` function indicates that a resource is being used, and
    decrements the semaphore. If the semaphore's value is greater than 0
    (indicating there are still resources available), the function will
    immediately return, and the thread is allowed to proceed. If the
    semaphore's value is already 0, the thread will block until a
    resource becomes available (i.e., the semaphore has a positive
    value). A call to `sem_wait` typically looks like
    `sem_wait(&semaphore)`.

-   The `sem_post` function indicates that a resource is being freed,
    and increments the semaphore. This function returns immediately. If
    there is a thread waiting on the semaphore (i.e., the semaphore's
    value was previously 0), then the other thread will take ownership
    of the freed resource. A call to `sem_post` looks like
    `sem_post(&semaphore)`.
:::
:::

::: toc-menu
:::
:::
:::
:::

Copyright (C) 2020 Dive into Systems, LLC.

*Dive into Systems,* is licensed under the Creative Commons
[Attribution-NonCommercial-NoDerivatives 4.0
International](https://creativecommons.org/licenses/by-nc-nd/4.0/) (CC
BY-NC-ND 4.0).
