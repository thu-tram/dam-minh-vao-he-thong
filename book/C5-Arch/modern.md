
-   -   [4. Binary and Data
        Representation](../C4-Binary/index.html){.nav-link}
        -   [4.1. Number Bases and Unsigned
            Integers](../C4-Binary/bases.html){.nav-link}
        -   [4.2. Converting Between
            Bases](../C4-Binary/conversion.html){.nav-link}
        -   [4.3. Signed Binary
            Integers](../C4-Binary/signed.html){.nav-link}
        -   [4.4. Binary Integer
            Arithmetic](../C4-Binary/arithmetic.html){.nav-link}
            -   [4.4.1.
                Addition](../C4-Binary/arithmetic_addition.html){.nav-link}
            -   [4.4.2.
                Subtraction](../C4-Binary/arithmetic_subtraction.html){.nav-link}
            -   [4.4.3. Multiplication &
                Division](../C4-Binary/arithmetic_mult_div.html){.nav-link}
        -   [4.5. Overflow](../C4-Binary/overflow.html){.nav-link}
        -   [4.6. Bitwise
            Operators](../C4-Binary/bitwise.html){.nav-link}
        -   [4.7. Integer Byte
            Order](../C4-Binary/byte_order.html){.nav-link}
        -   [4.8. Real Numbers in
            Binary](../C4-Binary/floating_point.html){.nav-link}
        -   [4.9. Summary](../C4-Binary/summary.html){.nav-link}
        -   [4.10. Exercises](../C4-Binary/exercises.html){.nav-link}

-   -   [5. What von Neumann Knew: Computer
        Architecture](index.html){.nav-link}
        -   [5.1. The Origins of Modern Computing](hist.html){.nav-link}
        -   [5.2. The von Neumann Architecture](von.html){.nav-link}
        -   [5.3. Logic Gates](gates.html){.nav-link}
        -   [5.4. Circuits](circuits.html){.nav-link}
            -   [5.4.1. Arithmetic and Logic
                Circuits](arithlogiccircs.html){.nav-link}
            -   [5.4.2. Control Circuits](controlcircs.html){.nav-link}
            -   [5.4.3. Storage Circuits](storagecircs.html){.nav-link}
        -   [5.5. Building a Processor](cpu.html){.nav-link}
        -   [5.6. The Processor's Execution of Program
            Instructions](instrexec.html){.nav-link}
        -   [5.7. Pipelining Instruction
            Execution](pipelining.html){.nav-link}
        -   [5.8. Advanced Pipelining
            Considerations](pipelining_advanced.html){.nav-link}
        -   [5.9. Looking Ahead: CPUs Today](modern.html){.nav-link}
        -   [5.10. Summary](summary.html){.nav-link}
        -   [5.11. Exercises](exercises.html){.nav-link}

-   -   [6. Under the C: Dive into
        Assembly](../C6-asm_intro/index.html){.nav-link}

-   -   [7. 64-bit x86 Assembly](../C7-x86_64/index.html){.nav-link}
        -   [7.1. Assembly Basics](../C7-x86_64/basics.html){.nav-link}
        -   [7.2. Common
            Instructions](../C7-x86_64/common.html){.nav-link}
        -   [7.3. Additional Arithmetic
            Instructions](../C7-x86_64/arithmetic.html){.nav-link}
        -   [7.4. Conditional Control and
            Loops](../C7-x86_64/conditional_control_loops.html){.nav-link}
            -   [7.4.1.
                Preliminaries](../C7-x86_64/preliminaries.html){.nav-link}
            -   [7.4.2. If
                Statements](../C7-x86_64/if_statements.html){.nav-link}
            -   [7.4.3. Loops](../C7-x86_64/loops.html){.nav-link}
        -   [7.5. Functions in
            Assembly](../C7-x86_64/functions.html){.nav-link}
        -   [7.6. Recursion](../C7-x86_64/recursion.html){.nav-link}
        -   [7.7. Arrays in
            Assembly](../C7-x86_64/arrays.html){.nav-link}
        -   [7.8. Matrices in
            Assembly](../C7-x86_64/matrices.html){.nav-link}
        -   [7.9. Structs in
            Assembly](../C7-x86_64/structs.html){.nav-link}
        -   [7.10. Buffer
            Overflows](../C7-x86_64/buffer_overflow.html){.nav-link}
        -   [7.11. Exercises](../C7-x86_64/exercises.html){.nav-link}

-   -   [8. 32-bit x86 Assembly](../C8-IA32/index.html){.nav-link}
        -   [8.1. Assembly Basics](../C8-IA32/basics.html){.nav-link}
        -   [8.2. Common
            Instructions](../C8-IA32/common.html){.nav-link}
        -   [8.3. Additional Arithmetic
            Instructions](../C8-IA32/arithmetic.html){.nav-link}
        -   [8.4. Conditional Control and
            Loops](../C8-IA32/conditional_control_loops.html){.nav-link}
            -   [8.4.1.
                Preliminaries](../C8-IA32/preliminaries.html){.nav-link}
            -   [8.4.2. If
                Statements](../C8-IA32/if_statements.html){.nav-link}
            -   [8.4.3. Loops](../C8-IA32/loops.html){.nav-link}
        -   [8.5. Functions in
            Assembly](../C8-IA32/functions.html){.nav-link}
        -   [8.6. Recursion](../C8-IA32/recursion.html){.nav-link}
        -   [8.7. Arrays in Assembly](../C8-IA32/arrays.html){.nav-link}
        -   [8.8. Matrices in
            Assembly](../C8-IA32/matrices.html){.nav-link}
        -   [8.9. Structs in
            Assembly](../C8-IA32/structs.html){.nav-link}
        -   [8.10. Buffer
            Overflows](../C8-IA32/buffer_overflow.html){.nav-link}
        -   [8.11. Exercises](../C8-IA32/exercises.html){.nav-link}

-   -   [9. ARMv8 Assembly](../C9-ARM64/index.html){.nav-link}
        -   [9.1. Assembly Basics](../C9-ARM64/basics.html){.nav-link}
        -   [9.2. Common
            Instructions](../C9-ARM64/common.html){.nav-link}
        -   [9.3. Arithmetic
            Instructions](../C9-ARM64/arithmetic.html){.nav-link}
        -   [9.4. Conditional Control and
            Loops](../C9-ARM64/conditional_control_loops.html){.nav-link}
            -   [9.4.1.
                Preliminaries](../C9-ARM64/preliminaries.html){.nav-link}
            -   [9.4.2. If
                Statements](../C9-ARM64/if_statements.html){.nav-link}
            -   [9.4.3. Loops](../C9-ARM64/loops.html){.nav-link}
        -   [9.5. Functions in
            Assembly](../C9-ARM64/functions.html){.nav-link}
        -   [9.6. Recursion](../C9-ARM64/recursion.html){.nav-link}
        -   [9.7. Arrays in
            Assembly](../C9-ARM64/arrays.html){.nav-link}
        -   [9.8. Matrices in
            Assembly](../C9-ARM64/matrices.html){.nav-link}
        -   [9.9. Structs in
            Assembly](../C9-ARM64/structs.html){.nav-link}
        -   [9.10. Buffer
            Overflows](../C9-ARM64/buffer_overflow.html){.nav-link}
        -   [9.11. Exercises](../C9-ARM64/exercises.html){.nav-link}

-   -   [10. Key Assembly
        Takeaways](../C10-asm_takeaways/index.html){.nav-link}

-   -   [11. Storage and the Memory
        Hierarchy](../C11-MemHierarchy/index.html){.nav-link}
        -   [11.1. The Memory
            Hierarchy](../C11-MemHierarchy/mem_hierarchy.html){.nav-link}
        -   [11.2. Storage
            Devices](../C11-MemHierarchy/devices.html){.nav-link}
        -   [11.3.
            Locality](../C11-MemHierarchy/locality.html){.nav-link}
        -   [11.4. Caching](../C11-MemHierarchy/caching.html){.nav-link}
        -   [11.5. Cache Analysis and
            Cachegrind](../C11-MemHierarchy/cachegrind.html){.nav-link}
        -   [11.6. Looking Ahead: Caching on Multicore
            Processors](../C11-MemHierarchy/coherency.html){.nav-link}
        -   [11.7. Summary](../C11-MemHierarchy/summary.html){.nav-link}
        -   [11.8.
            Exercises](../C11-MemHierarchy/exercises.html){.nav-link}

-   -   [12. Code Optimization](../C12-CodeOpt/index.html){.nav-link}
        -   [12.1. First Steps](../C12-CodeOpt/basic.html){.nav-link}
        -   [12.2. Other Compiler
            Optimizations](../C12-CodeOpt/loops_functions.html){.nav-link}
        -   [12.3. Memory
            Considerations](../C12-CodeOpt/memory_considerations.html){.nav-link}
        -   [12.4. Summary](../C12-CodeOpt/summary.html){.nav-link}

-   -   [13. The Operating System](../C13-OS/index.html){.nav-link}
        -   [13.1. Booting and Running](../C13-OS/impl.html){.nav-link}
        -   [13.2. Processes](../C13-OS/processes.html){.nav-link}
        -   [13.3. Virtual Memory](../C13-OS/vm.html){.nav-link}
        -   [13.4. Interprocess
            Communication](../C13-OS/ipc.html){.nav-link}
            -   [13.4.1. Signals](../C13-OS/ipc_signals.html){.nav-link}
            -   [13.4.2. Message
                Passing](../C13-OS/ipc_msging.html){.nav-link}
            -   [13.4.3. Shared
                Memory](../C13-OS/ipc_shm.html){.nav-link}
        -   [13.5. Summary and Other OS
            Functionality](../C13-OS/advanced.html){.nav-link}
        -   [13.6. Exercises](../C13-OS/exercises.html){.nav-link}

-   -   [14. Leveraging Shared Memory in the Multicore
        Era](../C14-SharedMemory/index.html){.nav-link}
        -   [14.1. Programming Multicore
            Systems](../C14-SharedMemory/multicore.html){.nav-link}
        -   [14.2. POSIX
            Threads](../C14-SharedMemory/posix.html){.nav-link}
        -   [14.3. Synchronizing
            Threads](../C14-SharedMemory/synchronization.html){.nav-link}
            -   [14.3.1. Mutual
                Exclusion](../C14-SharedMemory/mutex.html){.nav-link}
            -   [14.3.2.
                Semaphores](../C14-SharedMemory/semaphores.html){.nav-link}
            -   [14.3.3. Other Synchronization
                Constructs](../C14-SharedMemory/other_syncs.html){.nav-link}
        -   [14.4. Measuring Parallel
            Performance](../C14-SharedMemory/performance.html){.nav-link}
            -   [14.4.1. Parallel Performance
                Basics](../C14-SharedMemory/performance_basics.html){.nav-link}
            -   [14.4.2. Advanced
                Topics](../C14-SharedMemory/performance_advanced.html){.nav-link}
        -   [14.5. Cache
            Coherence](../C14-SharedMemory/cache_coherence.html){.nav-link}
        -   [14.6. Thread
            Safety](../C14-SharedMemory/thread_safety.html){.nav-link}
        -   [14.7. Implicit Threading with
            OpenMP](../C14-SharedMemory/openmp.html){.nav-link}
        -   [14.8. Summary](../C14-SharedMemory/summary.html){.nav-link}
        -   [14.9.
            Exercises](../C14-SharedMemory/exercises.html){.nav-link}

-   -   [15. Looking Ahead: Other Parallel
        Systems](../C15-Parallel/index.html){.nav-link}
        -   [15.1. Hardware Acceleration and
            CUDA](../C15-Parallel/gpu.html){.nav-link}
        -   [15.2. Distributed Memory
            Systems](../C15-Parallel/distrmem.html){.nav-link}
        -   [15.3. To Exascale and
            Beyond](../C15-Parallel/cloud.html){.nav-link}

-   -   [16. Appendix 1: Chapter 1 for Java
        Programmers](../Appendix1/index.html){.nav-link}
        -   [16.1. Getting Started Programming in
            C](../Appendix1/getting_started.html){.nav-link}
        -   [16.2. Input/Output (printf and
            scanf)](../Appendix1/input_output.html){.nav-link}
        -   [16.3. Conditionals and
            Loops](../Appendix1/conditionals.html){.nav-link}
        -   [16.4. Functions](../Appendix1/functions.html){.nav-link}
        -   [16.5. Arrays and
            Strings](../Appendix1/arrays_strings.html){.nav-link}
        -   [16.6. Structs](../Appendix1/structs.html){.nav-link}
        -   [16.7. Summary](../Appendix1/summary.html){.nav-link}
        -   [16.8. Exercises](../Appendix1/exercises.html){.nav-link}

-   -   [17. Appendix 2: Using Unix](../Appendix2/index.html){.nav-link}
        -   [17.1. Unix Command Line and the Unix File
            System](../Appendix2/cmdln_basics.html){.nav-link}
        -   [17.2. Man and the Unix
            Manual](../Appendix2/man.html){.nav-link}
        -   [17.3. Remote Access](../Appendix2/ssh_scp.html){.nav-link}
        -   [17.4. Unix Editors](../Appendix2/editors.html){.nav-link}
        -   [17.5. make and
            Makefiles](../Appendix2/makefiles.html){.nav-link}
        -   [17.6 Searching: grep and
            find](../Appendix2/grep.html){.nav-link}
        -   [17.7 File Permissions](../Appendix2/chmod.html){.nav-link}
        -   [17.8 Archiving and Compressing
            Files](../Appendix2/tar.html){.nav-link}
        -   [17.9 Process Control](../Appendix2/pskill.html){.nav-link}
        -   [17.10 Timing](../Appendix2/timing.html){.nav-link}
        -   [17.11 Command
            History](../Appendix2/history.html){.nav-link}
        -   [17.12 I/0
            Redirection](../Appendix2/ioredirect.html){.nav-link}
        -   [17.13 Pipes](../Appendix2/pipe.html){.nav-link}
        -   [17.14 Dot Files and
            .bashrc](../Appendix2/dotfiles.html){.nav-link}
        -   [17.15 Shell
            Programming](../Appendix2/shellprog.html){.nav-link}
        -   [17.16 Getting System
            Information](../Appendix2/sysinfo.html){.nav-link}



-   [Dive Into Systems](../index-2.html)
-   [5. What von Neumann Knew: Computer Architecture](index.html)
-   [5.9. Looking Ahead: CPUs Today](modern.html)
:::

::: content
::: sect1
## [](#_looking_ahead_cpus_today){.anchor}5.9. Looking Ahead: CPUs Today {#_looking_ahead_cpus_today}

::: sectionbody
::: paragraph
CPU pipelining is one example of **instruction-level parallelism**
(ILP), in which the CPU simultaneously executes multiple instructions in
parallel. In a pipelined execution, the CPU simultaneously executes
multiple instructions by overlapping their execution in the pipeline. A
simple pipelined CPU can achieve a CPI of 1, completing the execution of
one instruction every clock cycle. Modern microprocessors typically
employ pipelining along with other ILP techniques and include multiple
CPU cores to achieve processor CPI values of less than 1. For these
microarchitectures, the average number of **instructions per cycle**
(IPC) is the metric commonly used to describe their performance. A large
IPC value indicates that a processor achieves a high sustained degree of
simultaneous instruction execution.
:::

::: paragraph
Transistors are the building blocks of all circuitry on an integrated
circuit (a chip). The processing and control units of modern CPUs are
constructed from circuits, which are built from subcircuits and basic
logic gates that are implemented with transistors. Transistors also
implement the storage circuits used in CPU registers and in fast on-chip
cache memory that stores copies of recently accessed data and
instructions (we discuss cache memory in detail in [Chapter
11](../C11-MemHierarchy/index.html#_storage_and_the_memory_hierarchy){.page}).
:::

::: paragraph
The number of transistors that can fit on a chip is a rough measure of
its performance. **Moore's Law** is the observation, made by Gordon
Moore in 1975, that the number of transistors per integrated circuit
doubles about every two years^1,2^. A doubling in the number of
transistors per chip every two years means that computer architects can
design a new chip with twice as much space for storage and computation
circuitry, roughly doubling its power. Historically, computer architects
used the extra transistors to design more complex single processors
using ILP techniques to improve overall performance.
:::

::: sect2
### [](#_instruction_level_parallelism){.anchor}5.9.1. Instruction-Level Parallelism {#_instruction_level_parallelism}

::: paragraph
Instruction level parallelism (ILP) is a term for a set of design
techniques used to support parallel execution of a single program's
instructions on a single processor. ILP techniques are transparent to
the programmer, meaning that a programmer writes a sequential C program
but the processor executes several of its instructions simultaneously,
in parallel, on one or more execution units. Pipelining is one example
of ILP, where a sequence of program instructions execute simultaneously,
each in a different pipeline stage. A pipelined processor can execute
one instruction per cycle (can achieve an IPC of 1). Other types of
microprocessor ILP designs can execute more than a single instruction
per clock cycle and achieve IPC values higher than 1.
:::

::: paragraph
A **vector processor** is an architecture that implements ILP through
special vector instructions that take one-dimensional arrays (vectors)
of data as their operands. Vector instructions are executed in parallel
by a vector processor on multiple execution units, each unit performing
an arithmetic operation on single elements of its vector operands. In
the past, vector processors were often used in large parallel computers.
The 1976 Cray-1 was the first vector processor-based supercomputer, and
Cray continued to design its supercomputers with vector processors
throughout the 1990s. However, eventually this design could not compete
with other parallel supercomputer designs, and today vector processors
appear primarily in accelerator devices such as graphics processing
units (GPUs) that are particularly optimized for performing computation
on image data stored in 1D arrays.
:::

::: paragraph
**Superscalar** is another example of an ILP processor design. A
superscalar processor is a single processor with multiple execution
units and multiple execution pipelines. A superscalar processor fetches
a set of instructions from a sequential program's instruction stream,
and breaks them up into multiple independent streams of instructions
that are executed in parallel by its execution units. A superscalar
processor is an **out-of-order processor**, or one that executes
instructions out of the order in which they appear in a sequential
instruction stream. Out-of-order execution requires identifying
sequences of instructions without dependencies that can safely execute
in parallel. A superscalar processor contains functionality to
dynamically create the multiple streams of independent instructions to
feed through its multiple execution units. This functionality must
perform dependency analysis to ensure the correct ordering of any
instruction whose execution depends on the result of a previous
instruction in these sequential streams. As an example, a superscalar
processor with five pipelined execution units can execute five
instructions from a sequential program in a single cycle (can achieve an
IPC of 5). However, due to instruction dependencies, it is not always
the case that a superscalar processor can keep all of its pipelines
full.
:::

::: paragraph
**Very long instruction word** (VLIW) is another ILP microarchitecture
design that is similar to superscalar. In VLIW architectures, however,
the compiler is responsible for constructing the multiple independent
instruction streams executed in parallel by the processor. A compiler
for a VLIW architecture analyzes the program instructions to statically
construct a VLIW instruction that consists of multiple instructions, one
from each independent stream. VLIW leads to simpler processor design
than superscalar because the VLIW processor does not need to perform
dependency analysis to construct the multiple independent instruction
streams as part of its execution of program instructions. Instead, a
VLIW processor just needs added circuitry to fetch the next VLIW
instruction and break it up into its multiple instructions that it feeds
into each of its execution pipelines. However, by pushing dependency
analysis to the compiler, VLIW architectures require specialized
compilers to achieve good performance.
:::

::: paragraph
One problem with both superscalar and VLIW is that the degree of
parallel performance is often significantly limited by the sequential
application programs they execute. Dependencies between instructions in
the program limit the ability to keep all of the pipelines full.
:::
:::

::: sect2
### [](#_multicore_and_hardware_multithreading){.anchor}5.9.2. Multicore and Hardware Multithreading {#_multicore_and_hardware_multithreading}

::: paragraph
By designing single processors that employed increasingly complicated
ILP techniques and increasing the CPU clock speed to drive this
increasingly complicated functionality, computer architects designed
processors whose performance kept pace with Moore's Law until the early
2000s. After this time, CPU clock speeds could no longer increase
without greatly increasing a processor's power consumption^3^. This led
to the current era of multicore and multithreaded microarchitectures,
both of which require *explicit parallel programming* by a programmer to
speed up the execution of a single program.
:::

::: paragraph
**Hardware multithreading** is a single-processor design that supports
executing multiple hardware threads. A **thread** is an independent
stream of execution. For example, two running programs each have their
own thread of independent execution. These two programs\' threads of
execution could then be scheduled by the operating system to run \"at
the same time\" on a multithreaded processor. Hardware multithreading
may be implemented by a processor alternating between executing
instructions from each of its threads\' instruction streams each cycle.
In this case, the instructions of different hardware threads are not all
executed simultaneously each cycle. Instead, the processor is designed
to quickly switch between executing instructions from different
threads\' execution streams. This usually results in a speed-up of their
execution as a whole as compared to their execution on a singly threaded
processor.
:::

::: paragraph
Multithreading can be implemented in hardware on either scalar- or
super-scalar type microprocessors. At a minimum, the hardware needs to
support fetching instructions from multiple separate instruction streams
(one for each thread of execution), and have separate register sets for
each thread's execution stream. These architectures are **explicitly
multithreaded**^4^ because, unlike superscalar architectures, each of
the execution streams is independently scheduled by the operating system
to run a separate logical sequence of program instructions. The multiple
execution streams could come from multiple sequential programs or from
multiple software threads from a single multithreaded parallel program
(we discuss multithreaded parallel programming in [Chapter
14](../C14-SharedMemory/multicore.html#_programming_multicore_systems){.page}).
:::

::: paragraph
Hardware multithreaded microarchitectures that are based on superscalar
processors have multiple pipelines and multiple execution units, and
thus they can execute instructions from several hardware threads
simultaneously, in parallel, resulting in an IPC value greater than 1.
Multithreaded architectures based on simple scalar processors implement
**interleaved multithreading**. These microarchitectures typically share
a pipeline and always share the processor's single ALU (the CPU switches
between executing different threads on the ALU). This type of
multithreading cannot achieve IPC values greater than 1. Hardware
threading supported by superscalar-based microarchitectures is often
called **simultaneous multithreading** (SMT)^4^. Unfortunately, SMT is
often used to refer to both types of hardware multithreading, and the
term alone is not always sufficient to determine whether a multithreaded
microarchitecture implements true simultaneous or interleaved
multithreading.
:::

::: paragraph
**Multicore processors** contain multiple complete CPU cores. Like
multithreaded processors, each core is independently scheduled by the
OS. However, each core of a multicore processor is a full CPU core, one
that contains its own complete and separate functionality to execute
program instructions. A multicore processor contains replicas of these
CPU cores with some additional hardware support for the cores to share
cached data. Each core of a multicore processor could be scalar,
superscalar, or hardware multithreaded. [Figure
1](#Figmulticoreprocesor) shows an example of a multicore computer.
:::

::: {#Figmulticoreprocesor .imageblock .text-center}
::: content
![a multicore computer showing the processor chip with multiple CPU
cores](_images/multicore.png){width="750"}
:::

::: title
Figure 1. A computer with a multicore processor. The processor contains
multiple complete CPU cores, each with its own private cache memory. The
cores communicate with each and share a larger shared cached memory via
on-chip buses.
:::
:::

::: paragraph
Multicore microprocessor design is the primary way in which the
performance of processor architectures can continue to keep pace with
Moore's Law without increasing the processor clock rate. A multicore
computer can simultaneously run several sequential programs, the OS
scheduling each core with a different program's instruction stream. It
can speed up execution of a single program if the program is written as
an explicitly multithreaded (software-level threads) parallel program.
For example, the OS can schedule the threads of an individual program to
run simultaneously on individual cores of the multicore processor,
speeding up the execution of the program compared to its execution of a
sequential version of the same program. In [Chapter
14](../C14-SharedMemory/index.html#_leveraging_shared_memory_in_the_multicore_era){.page},
we discuss explicit multithreaded parallel programming for multicore and
other types of parallel systems with shared main memory.
:::
:::

::: sect2
### [](#_some_example_processors){.anchor}5.9.3. Some Example Processors {#_some_example_processors}

::: paragraph
Today, processors are built using a mix of ILP, hardware multithreading,
and multicore technologies. In fact, it is difficult to find a processor
that is not multicore. Desktop-class processors typically have two to
eight cores, many of which also support a low level of per-core
multithreading. For example, AMD Zen multicore processors^5^ and Intel's
hyperthreaded multicore Xeon and Core processors^6^ both support two
hardware threads per core. Intel's hyperthreaded cores implement
interleaved multithreading. Thus, each of its cores can only achieve an
IPC of 1, but with multiple CPU cores per chip, the processor can
achieve higher IPC levels.
:::

::: paragraph
Processors designed for high-end systems, such as those used in servers
and supercomputers, contain many cores, where each core has a high
degree of multithreading. For example, Oracle's SPARC M7 processor^7^,
used in high-end servers, has 32 cores. Each of its cores has eight
hardware threads, two of which can execute simultaneously, resulting in
a maximum IPC value of 64 for the processor. The two fastest
supercomputers in the world (as of June 2019)^8^, use IBM's Power 9
processors^9^. Power 9 processors have up to 24 cores per chip, and each
core supports up to eight-way simultaneous multithreading. A 24-core
version of the Power 9 processor can achieve an IPC of 192.
:::

### Footnotes and References {#_footnotes_and_references .discrete}

::: {.olist .arabic}
1.  Moore first observed a doubling every year in 1965, that he then
    updated in 1975 to every \> 2 years, which became known as Moore's
    Law.

2.  Moore's Law held until around 2012 when improvements in transistor
    density began to slow. Moore predicted the end of Moore's Law in the
    mid 2020s.

3.  \"The End of Dennard scaling\" by Adrian McMenamin, 2013.
    [https://cartesianproduct.wordpress.com/2013/04/15/the-end-of-dennard-scaling/](https://cartesianproduct.wordpress.com/2013/04/15/the-end-of-dennard-scaling/){.bare}

4.  \"A Survey of Processors with Explicit Multithreading\", by Ungerer,
    Robic, and Silc. In ACM Computing Surveys, Vol. 35, No. 1, March
    2003, pp. 29--63.
    [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.9105&rep=rep1&type=pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.9105&rep=rep1&type=pdf){.bare}

5.  AMD's Zen Architectures:
    [https://www.amd.com/en/technologies/zen-core](https://www.amd.com/en/technologies/zen-core){.bare}

6.  Intel's Xeon and Core processors with Hyper-Threading:
    [https://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html](https://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html){.bare}

7.  Oracle's SPARC M7 Processor:
    [http://www.oracle.com/us/products/servers-storage/sparc-m7-processor-ds-2687041.pdf](http://www.oracle.com/us/products/servers-storage/sparc-m7-processor-ds-2687041.pdf){.bare}

8.  Top 500 Lists:
    [https://www.top500.org/lists/top500/](https://www.top500.org/lists/top500/){.bare}

9.  IBM's Power 9 Processor:
    [https://www.ibm.com/it-infrastructure/power/power9](https://www.ibm.com/it-infrastructure/power/power9){.bare}
:::
:::
:::
:::

::: toc-menu
:::
:::
:::
:::

Copyright (C) 2020 Dive into Systems, LLC.

*Dive into Systems,* is licensed under the Creative Commons
[Attribution-NonCommercial-NoDerivatives 4.0
International](https://creativecommons.org/licenses/by-nc-nd/4.0/) (CC
BY-NC-ND 4.0).
