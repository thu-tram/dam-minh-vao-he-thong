
-   -   [11. Storage and the Memory
        Hierarchy](../C11-MemHierarchy/index.html){.nav-link}
        -   [11.1. The Memory
            Hierarchy](../C11-MemHierarchy/mem_hierarchy.html){.nav-link}
        -   [11.2. Storage
            Devices](../C11-MemHierarchy/devices.html){.nav-link}
        -   [11.3.
            Locality](../C11-MemHierarchy/locality.html){.nav-link}
        -   [11.4. Caching](../C11-MemHierarchy/caching.html){.nav-link}
        -   [11.5. Cache Analysis and
            Cachegrind](../C11-MemHierarchy/cachegrind.html){.nav-link}
        -   [11.6. Looking Ahead: Caching on Multicore
            Processors](../C11-MemHierarchy/coherency.html){.nav-link}
        -   [11.7. Summary](../C11-MemHierarchy/summary.html){.nav-link}
        -   [11.8.
            Exercises](../C11-MemHierarchy/exercises.html){.nav-link}

-   -   [12. Code Optimization](../C12-CodeOpt/index.html){.nav-link}
        -   [12.1. First Steps](../C12-CodeOpt/basic.html){.nav-link}
        -   [12.2. Other Compiler
            Optimizations](../C12-CodeOpt/loops_functions.html){.nav-link}
        -   [12.3. Memory
            Considerations](../C12-CodeOpt/memory_considerations.html){.nav-link}
        -   [12.4. Summary](../C12-CodeOpt/summary.html){.nav-link}

-   -   [13. The Operating System](../C13-OS/index.html){.nav-link}
        -   [13.1. Booting and Running](../C13-OS/impl.html){.nav-link}
        -   [13.2. Processes](../C13-OS/processes.html){.nav-link}
        -   [13.3. Virtual Memory](../C13-OS/vm.html){.nav-link}
        -   [13.4. Interprocess
            Communication](../C13-OS/ipc.html){.nav-link}
            -   [13.4.1. Signals](../C13-OS/ipc_signals.html){.nav-link}
            -   [13.4.2. Message
                Passing](../C13-OS/ipc_msging.html){.nav-link}
            -   [13.4.3. Shared
                Memory](../C13-OS/ipc_shm.html){.nav-link}
        -   [13.5. Summary and Other OS
            Functionality](../C13-OS/advanced.html){.nav-link}
        -   [13.6. Exercises](../C13-OS/exercises.html){.nav-link}

-   -   [14. Leveraging Shared Memory in the Multicore
        Era](../C14-SharedMemory/index.html){.nav-link}
        -   [14.1. Programming Multicore
            Systems](../C14-SharedMemory/multicore.html){.nav-link}
        -   [14.2. POSIX
            Threads](../C14-SharedMemory/posix.html){.nav-link}
        -   [14.3. Synchronizing
            Threads](../C14-SharedMemory/synchronization.html){.nav-link}
            -   [14.3.1. Mutual
                Exclusion](../C14-SharedMemory/mutex.html){.nav-link}
            -   [14.3.2.
                Semaphores](../C14-SharedMemory/semaphores.html){.nav-link}
            -   [14.3.3. Other Synchronization
                Constructs](../C14-SharedMemory/other_syncs.html){.nav-link}
        -   [14.4. Measuring Parallel
            Performance](../C14-SharedMemory/performance.html){.nav-link}
            -   [14.4.1. Parallel Performance
                Basics](../C14-SharedMemory/performance_basics.html){.nav-link}
            -   [14.4.2. Advanced
                Topics](../C14-SharedMemory/performance_advanced.html){.nav-link}
        -   [14.5. Cache
            Coherence](../C14-SharedMemory/cache_coherence.html){.nav-link}
        -   [14.6. Thread
            Safety](../C14-SharedMemory/thread_safety.html){.nav-link}
        -   [14.7. Implicit Threading with
            OpenMP](../C14-SharedMemory/openmp.html){.nav-link}
        -   [14.8. Summary](../C14-SharedMemory/summary.html){.nav-link}
        -   [14.9.
            Exercises](../C14-SharedMemory/exercises.html){.nav-link}

-   -   [15. Looking Ahead: Other Parallel
        Systems](index.html){.nav-link}
        -   [15.1. Hardware Acceleration and CUDA](gpu.html){.nav-link}
        -   [15.2. Distributed Memory Systems](distrmem.html){.nav-link}
        -   [15.3. To Exascale and Beyond](cloud.html){.nav-link}

-   -   [16. Appendix 1: Chapter 1 for Java
        Programmers](../Appendix1/index.html){.nav-link}
        -   [16.1. Getting Started Programming in
            C](../Appendix1/getting_started.html){.nav-link}
        -   [16.2. Input/Output (printf and
            scanf)](../Appendix1/input_output.html){.nav-link}
        -   [16.3. Conditionals and
            Loops](../Appendix1/conditionals.html){.nav-link}
        -   [16.4. Functions](../Appendix1/functions.html){.nav-link}
        -   [16.5. Arrays and
            Strings](../Appendix1/arrays_strings.html){.nav-link}
        -   [16.6. Structs](../Appendix1/structs.html){.nav-link}
        -   [16.7. Summary](../Appendix1/summary.html){.nav-link}
        -   [16.8. Exercises](../Appendix1/exercises.html){.nav-link}

-   -   [17. Appendix 2: Using Unix](../Appendix2/index.html){.nav-link}
        -   [17.1. Unix Command Line and the Unix File
            System](../Appendix2/cmdln_basics.html){.nav-link}
        -   [17.2. Man and the Unix
            Manual](../Appendix2/man.html){.nav-link}
        -   [17.3. Remote Access](../Appendix2/ssh_scp.html){.nav-link}
        -   [17.4. Unix Editors](../Appendix2/editors.html){.nav-link}
        -   [17.5. make and
            Makefiles](../Appendix2/makefiles.html){.nav-link}
        -   [17.6 Searching: grep and
            find](../Appendix2/grep.html){.nav-link}
        -   [17.7 File Permissions](../Appendix2/chmod.html){.nav-link}
        -   [17.8 Archiving and Compressing
            Files](../Appendix2/tar.html){.nav-link}
        -   [17.9 Process Control](../Appendix2/pskill.html){.nav-link}
        -   [17.10 Timing](../Appendix2/timing.html){.nav-link}
        -   [17.11 Command
            History](../Appendix2/history.html){.nav-link}
        -   [17.12 I/0
            Redirection](../Appendix2/ioredirect.html){.nav-link}
        -   [17.13 Pipes](../Appendix2/pipe.html){.nav-link}
        -   [17.14 Dot Files and
            .bashrc](../Appendix2/dotfiles.html){.nav-link}
        -   [17.15 Shell
            Programming](../Appendix2/shellprog.html){.nav-link}
        -   [17.16 Getting System
            Information](../Appendix2/sysinfo.html){.nav-link}



-   [Dive Into Systems](../index-2.html)
-   [15. Looking Ahead: Other Parallel Systems](index.html)
:::

::: content
::: sect1
## [](#_looking_ahead_other_parallel_systems_and_parallel_programming_models){.anchor}15. Looking Ahead: Other Parallel Systems and Parallel Programming Models {#_looking_ahead_other_parallel_systems_and_parallel_programming_models}

::: sectionbody
::: paragraph
In the [previous
chapter](../C14-SharedMemory/index.html#_leveraging_shared_memory_in_the_multicore_era){.page},
we discussed shared memory parallelism and multithreaded programming. In
this chapter, we introduce other parallel programming models and
languages for different classes of architecture. Namely, we introduce
parallelism for hardware accelerators focusing on graphics processing
units (GPUs) and general-purpose computing on GPUs (GPGPU computing),
using CUDA as an example; distributed memory systems and message
passing, using MPI as an example; and cloud computing, using MapReduce
and Apache Spark as examples.
:::

### A Whole New World: Flynn's Taxonomy of Architecture {#_a_whole_new_world_flynns_taxonomy_of_architecture .discrete}

::: paragraph
**Flynn's taxonomy** is commonly used to describe the ecosystem of
modern computing architecture ([Figure 1](#Flynn)).
:::

::: {#Flynn .imageblock .text-center}
::: content
![Flynn's Taxonomy consists of two independent
axes](_images/flynn.png){width="450"}
:::

::: title
Figure 1. Flynn's taxonomy classifies the ways in which a processor
applies instructions.
:::
:::

::: paragraph
The horizontal axis refers to the data stream, whereas the vertical axis
refers to the instruction stream. A **stream** in this context is a flow
of data or instructions. A **single stream** issues one element per time
unit, similar to a queue. In contrast, **multiple streams** typically
issue many elements per time unit (think of multiple queues). Thus, a
single instruction stream (SI) issues a single instruction per time
unit, whereas a multiple instruction stream (MI) issues many
instructions per time unit. Likewise, a single data stream (SD) issues
one data element per time unit, whereas a multiple data stream (MD)
issues many data elements per time unit.
:::

::: paragraph
A processor can be classified into one of four categories based on the
types of streams it employs:
:::

::: ulist
-   **SISD**: Single instruction/single data systems have a single
    control unit processing a single stream of instructions, allowing it
    to execute only one instruction at a time. Likewise, the processor
    can process only a single stream of data or process one data unit at
    a time. Most commercially available processors prior to the
    mid-2000s were SISD machines.

-   **MISD**: Multiple instruction/single data systems have multiple
    instruction units performing on a single data stream. MISD systems
    were typically designed for incorporating fault tolerance in
    mission-critical systems, such as the flight control programs for
    NASA shuttles. That said, MISD machines are rarely used in practice
    anymore.

-   **SIMD**: Single instruction/multiple data systems execute the
    *same* instruction on multiple data simultaneously and in lockstep
    fashion. During \"lockstep\" execution, all instructions are placed
    into a queue, while data is distributed among different compute
    units. During execution, each compute unit executes the first
    instruction in the queue simultaneously, before simultaneously
    executing the next instruction in the queue, and then the next, and
    so forth. The most well-known example of the SIMD architecture is
    the graphics processing unit. Early supercomputers also followed the
    SIMD architecture. We discuss GPUs more in the [next
    section](gpu.html#_GPUs){.page}.

-   **MIMD**: Multiple instruction/multiple data systems represent the
    most widely used architecture class. They are extremely flexible and
    have the ability to work on multiple instructions or multiple data
    streams. Since nearly all modern computers use multicore CPUs, most
    are classified as MIMD machines. We discuss another class of MIMD
    systems, distributed memory systems, in [Section
    15.2](distrmem.html#_distributed_memory_systems_message_passing_and_mpi){.page}.
:::
:::
:::

::: toc-menu
:::
:::
:::
:::

Copyright (C) 2020 Dive into Systems, LLC.

*Dive into Systems,* is licensed under the Creative Commons
[Attribution-NonCommercial-NoDerivatives 4.0
International](https://creativecommons.org/licenses/by-nc-nd/4.0/) (CC
BY-NC-ND 4.0).
