
-   -   [11. Storage and the Memory Hierarchy](index.html){.nav-link}
        -   [11.1. The Memory Hierarchy](mem_hierarchy.html){.nav-link}
        -   [11.2. Storage Devices](devices.html){.nav-link}
        -   [11.3. Locality](locality.html){.nav-link}
        -   [11.4. Caching](caching.html){.nav-link}
        -   [11.5. Cache Analysis and
            Cachegrind](cachegrind.html){.nav-link}
        -   [11.6. Looking Ahead: Caching on Multicore
            Processors](coherency.html){.nav-link}
        -   [11.7. Summary](summary.html){.nav-link}
        -   [11.8. Exercises](exercises.html){.nav-link}

-   -   [12. Code Optimization](../C12-CodeOpt/index.html){.nav-link}
        -   [12.1. First Steps](../C12-CodeOpt/basic.html){.nav-link}
        -   [12.2. Other Compiler
            Optimizations](../C12-CodeOpt/loops_functions.html){.nav-link}
        -   [12.3. Memory
            Considerations](../C12-CodeOpt/memory_considerations.html){.nav-link}
        -   [12.4. Summary](../C12-CodeOpt/summary.html){.nav-link}

-   -   [13. The Operating System](../C13-OS/index.html){.nav-link}
        -   [13.1. Booting and Running](../C13-OS/impl.html){.nav-link}
        -   [13.2. Processes](../C13-OS/processes.html){.nav-link}
        -   [13.3. Virtual Memory](../C13-OS/vm.html){.nav-link}
        -   [13.4. Interprocess
            Communication](../C13-OS/ipc.html){.nav-link}
            -   [13.4.1. Signals](../C13-OS/ipc_signals.html){.nav-link}
            -   [13.4.2. Message
                Passing](../C13-OS/ipc_msging.html){.nav-link}
            -   [13.4.3. Shared
                Memory](../C13-OS/ipc_shm.html){.nav-link}
        -   [13.5. Summary and Other OS
            Functionality](../C13-OS/advanced.html){.nav-link}
        -   [13.6. Exercises](../C13-OS/exercises.html){.nav-link}

-   -   [14. Leveraging Shared Memory in the Multicore
        Era](../C14-SharedMemory/index.html){.nav-link}
        -   [14.1. Programming Multicore
            Systems](../C14-SharedMemory/multicore.html){.nav-link}
        -   [14.2. POSIX
            Threads](../C14-SharedMemory/posix.html){.nav-link}
        -   [14.3. Synchronizing
            Threads](../C14-SharedMemory/synchronization.html){.nav-link}
            -   [14.3.1. Mutual
                Exclusion](../C14-SharedMemory/mutex.html){.nav-link}
            -   [14.3.2.
                Semaphores](../C14-SharedMemory/semaphores.html){.nav-link}
            -   [14.3.3. Other Synchronization
                Constructs](../C14-SharedMemory/other_syncs.html){.nav-link}
        -   [14.4. Measuring Parallel
            Performance](../C14-SharedMemory/performance.html){.nav-link}
            -   [14.4.1. Parallel Performance
                Basics](../C14-SharedMemory/performance_basics.html){.nav-link}
            -   [14.4.2. Advanced
                Topics](../C14-SharedMemory/performance_advanced.html){.nav-link}
        -   [14.5. Cache
            Coherence](../C14-SharedMemory/cache_coherence.html){.nav-link}
        -   [14.6. Thread
            Safety](../C14-SharedMemory/thread_safety.html){.nav-link}
        -   [14.7. Implicit Threading with
            OpenMP](../C14-SharedMemory/openmp.html){.nav-link}
        -   [14.8. Summary](../C14-SharedMemory/summary.html){.nav-link}
        -   [14.9.
            Exercises](../C14-SharedMemory/exercises.html){.nav-link}

-   -   [15. Looking Ahead: Other Parallel
        Systems](../C15-Parallel/index.html){.nav-link}
        -   [15.1. Hardware Acceleration and
            CUDA](../C15-Parallel/gpu.html){.nav-link}
        -   [15.2. Distributed Memory
            Systems](../C15-Parallel/distrmem.html){.nav-link}
        -   [15.3. To Exascale and
            Beyond](../C15-Parallel/cloud.html){.nav-link}

-   -   [16. Appendix 1: Chapter 1 for Java
        Programmers](../Appendix1/index.html){.nav-link}
        -   [16.1. Getting Started Programming in
            C](../Appendix1/getting_started.html){.nav-link}
        -   [16.2. Input/Output (printf and
            scanf)](../Appendix1/input_output.html){.nav-link}
        -   [16.3. Conditionals and
            Loops](../Appendix1/conditionals.html){.nav-link}
        -   [16.4. Functions](../Appendix1/functions.html){.nav-link}
        -   [16.5. Arrays and
            Strings](../Appendix1/arrays_strings.html){.nav-link}
        -   [16.6. Structs](../Appendix1/structs.html){.nav-link}
        -   [16.7. Summary](../Appendix1/summary.html){.nav-link}
        -   [16.8. Exercises](../Appendix1/exercises.html){.nav-link}

-   -   [17. Appendix 2: Using Unix](../Appendix2/index.html){.nav-link}
        -   [17.1. Unix Command Line and the Unix File
            System](../Appendix2/cmdln_basics.html){.nav-link}
        -   [17.2. Man and the Unix
            Manual](../Appendix2/man.html){.nav-link}
        -   [17.3. Remote Access](../Appendix2/ssh_scp.html){.nav-link}
        -   [17.4. Unix Editors](../Appendix2/editors.html){.nav-link}
        -   [17.5. make and
            Makefiles](../Appendix2/makefiles.html){.nav-link}
        -   [17.6 Searching: grep and
            find](../Appendix2/grep.html){.nav-link}
        -   [17.7 File Permissions](../Appendix2/chmod.html){.nav-link}
        -   [17.8 Archiving and Compressing
            Files](../Appendix2/tar.html){.nav-link}
        -   [17.9 Process Control](../Appendix2/pskill.html){.nav-link}
        -   [17.10 Timing](../Appendix2/timing.html){.nav-link}
        -   [17.11 Command
            History](../Appendix2/history.html){.nav-link}
        -   [17.12 I/0
            Redirection](../Appendix2/ioredirect.html){.nav-link}
        -   [17.13 Pipes](../Appendix2/pipe.html){.nav-link}
        -   [17.14 Dot Files and
            .bashrc](../Appendix2/dotfiles.html){.nav-link}
        -   [17.15 Shell
            Programming](../Appendix2/shellprog.html){.nav-link}
        -   [17.16 Getting System
            Information](../Appendix2/sysinfo.html){.nav-link}



-   [Dive Into Systems](../index-2.html)
-   [11. Storage and the Memory Hierarchy](index.html)
-   [11.5. Cache Analysis and Cachegrind](cachegrind.html)
:::

::: content
::: sect1
## [](#_cache_analysis_and_valgrind){.anchor}11.5. Cache Analysis and Valgrind {#_cache_analysis_and_valgrind}

::: sectionbody
::: paragraph
Because caches significantly influence program performance, most systems
provide profiling tools to measure a program's use of the cache. One
such tool is Valgrind's `cachegrind` mode, which this section uses to
evaluate cache performance.
:::

::: paragraph
Consider the following program that generates a random *N*Ã—*N* matrix:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
#include <stdio.h>
#include <stdlib.h>
#include <sys/time.h>
#include <time.h>

int **genRandomMatrix(int n, int max) {
    int i, j;
    int **mat = malloc(n * sizeof(int *));

    for (i = 0; i < n; i++) {
        mat[i] = malloc(n * sizeof(int));

        for (j = 0; j < n; j++) {
            mat[i][j] = 1 + rand() % max;
        }
    }

    return mat;
}

void free_all(int **mat, int n) {
    int i;

    for (i = 0; i < n; i++) {
        free(mat[i]);
    }

    free(mat);
}

int main(int argc, char **argv) {
    int i, n;
    int **matrix;

    if (argc != 2) {
        fprintf(stderr, "usage: %s <n>\n", argv[0]);
        fprintf(stderr, "where <n> is the dimension of the matrix\n");
        return 1;
    }

    n = strtol(argv[1], NULL, 10);
    srand(time(NULL));

    matrix = genRandomMatrix(n, 100);

    free_all(matrix, n);
    return 0;
}
```
:::
:::

::: paragraph
Prior sections in this chapter introduced two functions for averaging
every element of a matrix. They differ only in the way they index into
the matrix:
:::

+-----------------------------------+-----------------------------------+
| ::: content                       | ::: content                       |
| ::: listingblock                  | ::: listingblock                  |
| ::: content                       | ::: content                       |
| ``` {.highlightjs .highlight}     | ``` {.highlightjs .highlight}     |
| float                             | float                             |
| averageMat_v1(int **mat, int n) { | averageMat_v2(int **mat, int n) { |
|     int i, j, total = 0;          |     int i, j, total = 0;          |
|                                   |                                   |
|     for (i = 0; i < n; i++) {     |     for (i = 0; i < n; i++) {     |
|         for (j = 0; j < n; j++) { |         for (j = 0; j < n; j++) { |
|                                   |                                   |
|          // Note indexing: [i][j] |          // Note indexing: [j][i] |
|             total += mat[i][j];   |             total += mat[j][i];   |
|         }                         |         }                         |
|     }                             |     }                             |
|                                   |                                   |
|                                   |                                   |
|   return (float) total / (n * n); |   return (float) total / (n * n); |
| }                                 | }                                 |
| ```                               | ```                               |
| :::                               | :::                               |
| :::                               | :::                               |
| :::                               | :::                               |
+-----------------------------------+-----------------------------------+

::: paragraph
This section uses cache profiling tools to quantify the differences
between them.
:::

::: sect2
### [](#_a_first_cut_theoretical_analysis_and_benchmarking){.anchor}11.5.1. A First Cut: Theoretical Analysis and Benchmarking {#_a_first_cut_theoretical_analysis_and_benchmarking}

::: paragraph
A theoretical analysis based on locality and the memory hierarchy
suggests that the first version exhibits better spatial locality (on
matrix `mat`) due to the fact that `mat` is stored in [row-major
order](../C2-C_depth/arrays.html#_two_dimensional_array_memory_layout){.page}
in memory. The second solution has poor spatial locality because each
element in the matrix is visited in column-major order. Recall that data
is loaded into a cache in *blocks*. Traversing the matrix in
column-major order will likely lead to more cache misses, resulting in
poorer performance.
:::

::: paragraph
Let's modify the main function to include calls to the `gettimeofday`
function to accurately measure the difference in performance between the
two versions:
:::

::: listingblock
::: content
``` {.highlightjs .highlight}
int main(int argc, char** argv) {
   /* Validate command line parameters. */
   if (argc != 2) {
       fprintf(stderr, "usage: %s <n>\n", argv[0]);
       fprintf(stderr, "where <n> is the dimension of the matrix\n");
       return 1;
   }

   /* Declare and initialize variables. */
   int i;
   float res;
   double timer;
   int n = strtol(argv[1], NULL, 10);
   srand(time(NULL));
   struct timeval tstart, tend;
   int ** matrix = genRandomMatrix(n, 100);

   /* Time version 1. */
   gettimeofday(&tstart, NULL);
   res = averageMat_v1(matrix, n);
   gettimeofday(&tend, NULL);
   timer = tend.tv_sec - tstart.tv_sec + (tend.tv_usec - tstart.tv_usec)/1.e6;
   printf("v1 average is: %.2f; time is %g\n", res, timer);

   /* Time version 2. */
   gettimeofday(&tstart, NULL);
   res = averageMat_v2(matrix, n);
   gettimeofday(&tend, NULL);
   timer = tend.tv_sec - tstart.tv_sec + (tend.tv_usec - tstart.tv_usec)/1.e6;
   printf("v2 average is: %.2f; time is %g\n", res, timer);

   /* Clean up. */
   free_all(matrix, n);
   return 0;
}
```
:::
:::

::: paragraph
Compiling the code and running it yields the following result (note that
times will vary based on the on which machine it's run):
:::

::: listingblock
::: content
    $ gcc -o cachex cachex.c
    $ ./cachex 5000
    v1 average is: 50.49; time is 0.053641
    v2 average is: 50.49; time is 0.247644
:::
:::

::: paragraph
That's a big difference! In essence, the solution using row-major order
is 4.61 times faster than the second one!
:::
:::

::: sect2
### [](#_cache_analysis_in_the_real_world_cachegrind){.anchor}11.5.2. Cache Analysis in the Real World: Cachegrind {#_cache_analysis_in_the_real_world_cachegrind}

::: paragraph
Theoretically analyzing the two solutions and then running them verifies
that the first version is faster than the second. However, it doesn't
confirm the details of the cache analysis. Fortunately, the Valgrind
suite of tools can help. Earlier in the book, we discussed how Valgrind
can help [find memory
leaks](../C3-C_debug/valgrind.html#_debugging_memory_with_valgrind){.page}
in a program. This section describes Cachegrind, Valgrind's cache
simulator. Cachegrind enables a programmer to study how a program or
particular function affects the cache.
:::

::: paragraph
Cachegrind simulates how a program interacts with the computer's cache
hierarchy. In many cases, Cachegrind can autodetect the cache
organization of a machine. In the cases that it cannot, Cachegrind still
simulates the first level (L1) cache and the last level (LL) cache. It
assumes the first level cache has two independent components: the
instruction cache and the data cache. The reason for this is that the
last level cache has the most important implications for runtime. L1
caches also have the lowest level of associativity, so it's important to
ensure that programs interact well with it. These assumptions match the
structure of most modern machines.
:::

::: paragraph
Cachegrind collects and outputs the following information:
:::

::: ulist
-   Instruction cache reads (`Ir`)

-   L1 instruction cache read misses (`I1mr`) and LL cache instruction
    read misses (`ILmr`)

-   Data cache reads (`Dr`)

-   D1 cache read misses (`D1mr`) and LL cache data misses (`DLmr`)

-   Data cache writes (`Dw`)

-   D1 cache write misses (`D1mw`) and LL cache data write misses
    (`DLmw`)
:::

::: paragraph
Note that D1 total access is computed by `D1 = D1mr + D1mw` and LL total
access is given by `ILmr + DLmr + DLmw`.
:::

::: paragraph
Let's see how well version 1 of the code operates under Cachegrind. To
run it, execute Valgrind on the compiled code with the following
command:
:::

::: listingblock
::: content
    $ valgrind --tool=cachegrind --cache-sim=yes ./cachex 1000
:::
:::

::: paragraph
In this invocation, Valgrind's `cachegrind` tool acts as a wrapper
around the `cachex` executable. Choosing a smaller matrix size for
Cachegrind aids in the speed of execution. Cachegrind outputs
information about the number of cache hits and misses in the overall
program:
:::

::: listingblock
::: content
    ==28657== Cachegrind, a cache and branch-prediction profiler
    ==28657== Copyright (C) 2002-2017, and GNU GPL'd by Nicholas Nethercote et al.
    ==28657== Using Valgrind-3.18.1 and LibVEX; rerun with -h for copyright info
    ==28657== Command: ./cachex 1000
    ==28657==
    --28657-- warning: L3 cache found, using its data for the LL simulation.
    average is: 50.49; time is 0.080304
    average is: 50.49; time is 0.09733
    ==28657==
    ==28657== I   refs:      122,626,329
    ==28657== I1  misses:          1,070
    ==28657== LLi misses:          1,053
    ==28657== I1  miss rate:        0.00%
    ==28657== LLi miss rate:        0.00%
    ==28657==
    ==28657== D   refs:       75,292,076  (56,205,598 rd   + 19,086,478 wr)
    ==28657== D1  misses:      1,192,118  ( 1,129,099 rd   +     63,019 wr)
    ==28657== LLd misses:         64,399  (     1,543 rd   +     62,856 wr)
    ==28657== D1  miss rate:         1.6% (       2.0%     +        0.3%  )
    ==28657== LLd miss rate:         0.1% (       0.0%     +        0.3%  )
    ==28657==
    ==28657== LL refs:         1,193,188  ( 1,130,169 rd   +     63,019 wr)
    ==28657== LL misses:          65,452  (     2,596 rd   +     62,856 wr)
    ==28657== LL miss rate:          0.0% (       0.0%     +        0.3%  )
:::
:::

::: paragraph
However, this analysis is interested *specifically* in the hits and
misses for the two versions of this averaging function. To view that
information, use the Cachegrind tool `cg_annotate`. Running Cachegrind
should have produced a file in the current working directory that looks
similar to `cachegrind.out.n`, where `n` is some process ID number. To
run `cg_annotate`, type in the following command (replacing
`cachegrind.out.28657` with the name of the output file):
:::

::: listingblock
::: content
    $ cg_annotate cachegrind.out.28657

    I1 cache:         32768 B, 64 B, 8-way associative
    D1 cache:         32768 B, 64 B, 8-way associative
    LL cache:         8388608 B, 64 B, 16-way associative
    Command:          ./cachex 1000
    Data file:        cachegrind.out.28657
    Events recorded:  Ir I1mr ILmr Dr D1mr DLmr Dw D1mw DLmw
    Events shown:     Ir I1mr ILmr Dr D1mr DLmr Dw D1mw DLmw
    Event sort order: Ir I1mr ILmr Dr D1mr DLmr Dw D1mw DLmw
    Thresholds:       0.1 100 100 100 100 100 100 100 100
    Include dirs:
    User annotated:
    Auto-annotation:  off

     ----------------------------------------------------------------------------
             Ir  I1mr  ILmr         Dr      D1mr  DLmr         Dw   D1mw   DLmw
     ----------------------------------------------------------------------------
    122,626,329 1,070 1,053 56,205,598 1,129,099 1,543 19,086,478 63,019 62,856  PROGRAM TOTALS

     ----------------------------------------------------------------------------
            Ir I1mr ILmr         Dr      D1mr DLmr        Dw   D1mw   DLmw  file:function
     ----------------------------------------------------------------------------
    14,009,017    3    3  9,005,008    62,688    0     1,004      0      0  averageMat_v1
    14,009,017    0    0  9,005,008 1,062,996    0     1,004      0      0  averageMat_v2
:::
:::

::: paragraph
We've edited the output from this command slightly to focus on the two
versions of the average function. This output shows that version 2
yields 1,062,996 data misses, compared to only `62,688` misses in
version 1. Cachegrind provides solid proof that our analysis is correct!
:::
:::
:::
:::

::: toc-menu
:::
:::
:::
:::

Copyright (C) 2020 Dive into Systems, LLC.

*Dive into Systems,* is licensed under the Creative Commons
[Attribution-NonCommercial-NoDerivatives 4.0
International](https://creativecommons.org/licenses/by-nc-nd/4.0/) (CC
BY-NC-ND 4.0).
